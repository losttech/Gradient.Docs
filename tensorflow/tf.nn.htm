<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>tf.nn - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow/AggregationMethod.htm">AggregationMethod</a>
        </li>
				<li>
            <a href="../tensorflow/ConditionalAccumulator.htm">ConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/ConditionalAccumulatorBase.htm">ConditionalAccumulatorBase</a>
        </li>
				<li>
            <a href="../tensorflow/constant_initializer.htm">constant_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/CriticalSection.htm">CriticalSection</a>
        </li>
				<li>
            <a href="../tensorflow/DeviceSpec.htm">DeviceSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Dimension.htm">Dimension</a>
        </li>
				<li>
            <a href="../tensorflow/DType.htm">DType</a>
        </li>
				<li>
            <a href="../tensorflow/FIFOQueue.htm">FIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLenFeature.htm">FixedLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLengthRecordReader.htm">FixedLengthRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLenSequenceFeature.htm">FixedLenSequenceFeature</a>
        </li>
				<li>
            <a href="../tensorflow/glorot_normal_initializer.htm">glorot_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/glorot_uniform_initializer.htm">glorot_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/GradientTape.htm">GradientTape</a>
        </li>
				<li>
            <a href="../tensorflow/Graph.htm">Graph</a>
        </li>
				<li>
            <a href="../tensorflow/Graph._ControlDependenciesController.htm">Graph._ControlDependenciesController</a>
        </li>
				<li>
            <a href="../tensorflow/Graph.I_ControlDependenciesController.htm">Graph.I_ControlDependenciesController</a>
        </li>
				<li>
            <a href="../tensorflow/GraphKeys.htm">GraphKeys</a>
        </li>
				<li>
            <a href="../tensorflow/HeadingAxes.htm">HeadingAxes</a>
        </li>
				<li>
            <a href="../tensorflow/IAggregationMethod.htm">IAggregationMethod</a>
        </li>
				<li>
            <a href="../tensorflow/IConditionalAccumulator.htm">IConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/IConditionalAccumulatorBase.htm">IConditionalAccumulatorBase</a>
        </li>
				<li>
            <a href="../tensorflow/Iconstant_initializer.htm">Iconstant_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/ICriticalSection.htm">ICriticalSection</a>
        </li>
				<li>
            <a href="../tensorflow/IdentityReader.htm">IdentityReader</a>
        </li>
				<li>
            <a href="../tensorflow/IDeviceSpec.htm">IDeviceSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IDimension.htm">IDimension</a>
        </li>
				<li>
            <a href="../tensorflow/IDType.htm">IDType</a>
        </li>
				<li>
            <a href="../tensorflow/IFIFOQueue.htm">IFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLenFeature.htm">IFixedLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLengthRecordReader.htm">IFixedLengthRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLenSequenceFeature.htm">IFixedLenSequenceFeature</a>
        </li>
				<li>
            <a href="../tensorflow/Iglorot_normal_initializer.htm">Iglorot_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Iglorot_uniform_initializer.htm">Iglorot_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IGradientTape.htm">IGradientTape</a>
        </li>
				<li>
            <a href="../tensorflow/IGraph.htm">IGraph</a>
        </li>
				<li>
            <a href="../tensorflow/IGraphKeys.htm">IGraphKeys</a>
        </li>
				<li>
            <a href="../tensorflow/IIdentityReader.htm">IIdentityReader</a>
        </li>
				<li>
            <a href="../tensorflow/IIndexedSlices.htm">IIndexedSlices</a>
        </li>
				<li>
            <a href="../tensorflow/IIndexedSlicesSpec.htm">IIndexedSlicesSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IInteractiveSession.htm">IInteractiveSession</a>
        </li>
				<li>
            <a href="../tensorflow/ILazyLoader.htm">ILazyLoader</a>
        </li>
				<li>
            <a href="../tensorflow/ILMDBReader.htm">ILMDBReader</a>
        </li>
				<li>
            <a href="../tensorflow/IModule.htm">IModule</a>
        </li>
				<li>
            <a href="../tensorflow/Iname_scope.htm">Iname_scope</a>
        </li>
				<li>
            <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a>
        </li>
				<li>
            <a href="../tensorflow/IndexedSlicesSpec.htm">IndexedSlicesSpec</a>
        </li>
				<li>
            <a href="../tensorflow/InteractiveSession.htm">InteractiveSession</a>
        </li>
				<li>
            <a href="../tensorflow/Iones_initializer.htm">Iones_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IOperation.htm">IOperation</a>
        </li>
				<li>
            <a href="../tensorflow/IOpError.htm">IOpError</a>
        </li>
				<li>
            <a href="../tensorflow/IOptionalSpec.htm">IOptionalSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Iorthogonal_initializer.htm">Iorthogonal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IPaddingFIFOQueue.htm">IPaddingFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IPriorityQueue.htm">IPriorityQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IQueueBase.htm">IQueueBase</a>
        </li>
				<li>
            <a href="../tensorflow/IRaggedTensor.htm">IRaggedTensor</a>
        </li>
				<li>
            <a href="../tensorflow/IRaggedTensorSpec.htm">IRaggedTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Irandom_normal_initializer.htm">Irandom_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Irandom_uniform_initializer.htm">Irandom_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IRandomShuffleQueue.htm">IRandomShuffleQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IReaderBase.htm">IReaderBase</a>
        </li>
				<li>
            <a href="../tensorflow/IRegisterGradient.htm">IRegisterGradient</a>
        </li>
				<li>
            <a href="../tensorflow/ISession.htm">ISession</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseConditionalAccumulator.htm">ISparseConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseFeature.htm">ISparseFeature</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensor.htm">ISparseTensor</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensorSpec.htm">ISparseTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensorValue.htm">ISparseTensorValue</a>
        </li>
				<li>
            <a href="../tensorflow/ITensor.htm">ITensor</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorArray.htm">ITensorArray</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorArraySpec.htm">ITensorArraySpec</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorShape.htm">ITensorShape</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorSpec.htm">ITensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/ITextLineReader.htm">ITextLineReader</a>
        </li>
				<li>
            <a href="../tensorflow/ITFRecordReader.htm">ITFRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/Itruncated_normal_initializer.htm">Itruncated_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/ITypeSpec.htm">ITypeSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IUnconnectedGradients.htm">IUnconnectedGradients</a>
        </li>
				<li>
            <a href="../tensorflow/Iuniform_unit_scaling_initializer.htm">Iuniform_unit_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IVariable.htm">IVariable</a>
        </li>
				<li>
            <a href="../tensorflow/Ivariable_scope.htm">Ivariable_scope</a>
        </li>
				<li>
            <a href="../tensorflow/IVariableScope.htm">IVariableScope</a>
        </li>
				<li>
            <a href="../tensorflow/Ivariance_scaling_initializer.htm">Ivariance_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IVarLenFeature.htm">IVarLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/IWholeFileReader.htm">IWholeFileReader</a>
        </li>
				<li>
            <a href="../tensorflow/Izeros_initializer.htm">Izeros_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/LazyLoader.htm">LazyLoader</a>
        </li>
				<li>
            <a href="../tensorflow/LMDBReader.htm">LMDBReader</a>
        </li>
				<li>
            <a href="../tensorflow/Module.htm">Module</a>
        </li>
				<li>
            <a href="../tensorflow/name_scope.htm">name_scope</a>
        </li>
				<li>
            <a href="../tensorflow/ones_initializer.htm">ones_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Operation.htm">Operation</a>
        </li>
				<li>
            <a href="../tensorflow/Operation._InputList.htm">Operation._InputList</a>
        </li>
				<li>
            <a href="../tensorflow/Operation.I_InputList.htm">Operation.I_InputList</a>
        </li>
				<li>
            <a href="../tensorflow/OpError.htm">OpError</a>
        </li>
				<li>
            <a href="../tensorflow/OptionalSpec.htm">OptionalSpec</a>
        </li>
				<li>
            <a href="../tensorflow/orthogonal_initializer.htm">orthogonal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/PaddingFIFOQueue.htm">PaddingFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/PriorityQueue.htm">PriorityQueue</a>
        </li>
				<li>
            <a href="../tensorflow/QueueBase.htm">QueueBase</a>
        </li>
				<li>
            <a href="../tensorflow/RaggedTensor.htm">RaggedTensor</a>
        </li>
				<li>
            <a href="../tensorflow/RaggedTensorSpec.htm">RaggedTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/random_normal_initializer.htm">random_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/random_uniform_initializer.htm">random_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/RandomShuffleQueue.htm">RandomShuffleQueue</a>
        </li>
				<li>
            <a href="../tensorflow/ReaderBase.htm">ReaderBase</a>
        </li>
				<li>
            <a href="../tensorflow/RegisterGradient.htm">RegisterGradient</a>
        </li>
				<li>
            <a href="../tensorflow/Session.htm">Session</a>
        </li>
				<li>
            <a href="../tensorflow/SparseConditionalAccumulator.htm">SparseConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/SparseFeature.htm">SparseFeature</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensor.htm">SparseTensor</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensorSpec.htm">SparseTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensorValue.htm">SparseTensorValue</a>
        </li>
				<li>
            <a href="../tensorflow/Tensor.htm">Tensor</a>
        </li>
				<li>
            <a href="../tensorflow/Tensor`1.htm">Tensor&lt;T&gt;</a>
        </li>
				<li>
            <a href="../tensorflow/TensorArray.htm">TensorArray</a>
        </li>
				<li>
            <a href="../tensorflow/TensorArraySpec.htm">TensorArraySpec</a>
        </li>
				<li>
            <a href="../tensorflow/TensorDimension.htm">TensorDimension</a>
        </li>
				<li>
            <a href="../tensorflow/TensorDimensionSlice.htm">TensorDimensionSlice</a>
        </li>
				<li>
            <a href="../tensorflow/TensorShape.htm">TensorShape</a>
        </li>
				<li>
            <a href="../tensorflow/TensorSpec.htm">TensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/TextLineReader.htm">TextLineReader</a>
        </li>
				<li>
            <a href="../tensorflow/tf.htm">tf</a>
        </li>
				<li>
            <a href="../tensorflow/tf.audio.htm">tf.audio</a>
        </li>
				<li>
            <a href="../tensorflow/tf.autograph.htm">tf.autograph</a>
        </li>
				<li>
            <a href="../tensorflow/tf.autograph.experimental.htm">tf.autograph.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.bitwise.htm">tf.bitwise</a>
        </li>
				<li>
            <a href="../tensorflow/tf.compat.htm">tf.compat</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.htm">tf.config</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.experimental.htm">tf.config.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.optimizer.htm">tf.config.optimizer</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.threading.htm">tf.config.threading</a>
        </li>
				<li>
            <a href="../tensorflow/tf.data.htm">tf.data</a>
        </li>
				<li>
            <a href="../tensorflow/tf.data.experimental.htm">tf.data.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.debugging.htm">tf.debugging</a>
        </li>
				<li>
            <a href="../tensorflow/tf.distribute.htm">tf.distribute</a>
        </li>
				<li>
            <a href="../tensorflow/tf.distributions.htm">tf.distributions</a>
        </li>
				<li>
            <a href="../tensorflow/tf.errors.htm">tf.errors</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.htm">tf.estimator</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.experimental.htm">tf.estimator.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.export.htm">tf.estimator.export</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.inputs.htm">tf.estimator.inputs</a>
        </li>
				<li>
            <a href="../tensorflow/tf.experimental.htm">tf.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.feature_column.htm">tf.feature_column</a>
        </li>
				<li>
            <a href="../tensorflow/tf.gfile.htm">tf.gfile</a>
        </li>
				<li>
            <a href="../tensorflow/tf.graph_util.htm">tf.graph_util</a>
        </li>
				<li>
            <a href="../tensorflow/tf.image.htm">tf.image</a>
        </li>
				<li>
            <a href="../tensorflow/tf.initializers.htm">tf.initializers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.io.htm">tf.io</a>
        </li>
				<li>
            <a href="../tensorflow/tf.io.gfile.htm">tf.io.gfile</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.htm">tf.keras</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.activations.htm">tf.keras.activations</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.htm">tf.keras.applications</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.densenet.htm">tf.keras.applications.densenet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.imagenet_utils.htm">tf.keras.applications.imagenet_utils</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.inception_resnet_v2.htm">tf.keras.applications.inception_resnet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.inception_v3.htm">tf.keras.applications.inception_v3</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.mobilenet.htm">tf.keras.applications.mobilenet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.mobilenet_v2.htm">tf.keras.applications.mobilenet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.nasnet.htm">tf.keras.applications.nasnet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.resnet.htm">tf.keras.applications.resnet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.resnet_v2.htm">tf.keras.applications.resnet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.vgg16.htm">tf.keras.applications.vgg16</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.vgg19.htm">tf.keras.applications.vgg19</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.xception.htm">tf.keras.applications.xception</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.backend.htm">tf.keras.backend</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.constraints.htm">tf.keras.constraints</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.htm">tf.keras.datasets</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.boston_housing.htm">tf.keras.datasets.boston_housing</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.cifar10.htm">tf.keras.datasets.cifar10</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.cifar100.htm">tf.keras.datasets.cifar100</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.fashion_mnist.htm">tf.keras.datasets.fashion_mnist</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.imdb.htm">tf.keras.datasets.imdb</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.mnist.htm">tf.keras.datasets.mnist</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.reuters.htm">tf.keras.datasets.reuters</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.estimator.htm">tf.keras.estimator</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.experimental.htm">tf.keras.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.initializers.htm">tf.keras.initializers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.layers.htm">tf.keras.layers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.losses.htm">tf.keras.losses</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.metrics.htm">tf.keras.metrics</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.mixed_precision.htm">tf.keras.mixed_precision</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.mixed_precision.experimental.htm">tf.keras.mixed_precision.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.models.htm">tf.keras.models</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.optimizers.htm">tf.keras.optimizers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.optimizers.schedules.htm">tf.keras.optimizers.schedules</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.preprocessing.htm">tf.keras.preprocessing</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.preprocessing.image.htm">tf.keras.preprocessing.image</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.regularizers.htm">tf.keras.regularizers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.utils.htm">tf.keras.utils</a>
        </li>
				<li>
            <a href="../tensorflow/tf.layers.htm">tf.layers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.layers.experimental.htm">tf.layers.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.linalg.htm">tf.linalg</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.htm">tf.lite</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.htm">tf.lite.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.htm">tf.lite.experimental.microfrontend</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.python.htm">tf.lite.experimental.microfrontend.python</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.python.ops.htm">tf.lite.experimental.microfrontend.python.ops</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.nn.htm">tf.lite.experimental.nn</a>
        </li>
				<li>
            <a href="../tensorflow/tf.logging.htm">tf.logging</a>
        </li>
				<li>
            <a href="../tensorflow/tf.losses.htm">tf.losses</a>
        </li>
				<li>
            <a href="../tensorflow/tf.math.htm">tf.math</a>
        </li>
				<li>
            <a href="../tensorflow/tf.metrics.htm">tf.metrics</a>
        </li>
				<li>
            <a href="../tensorflow/tf.nest.htm">tf.nest</a>
        </li>
				<li>
            <a href="../tensorflow/tf.nn.htm" class="current">tf.nn</a>
        </li>
				<li>
            <a href="../tensorflow/tf.profiler.htm">tf.profiler</a>
        </li>
				<li>
            <a href="../tensorflow/tf.quantization.htm">tf.quantization</a>
        </li>
				<li>
            <a href="../tensorflow/tf.ragged.htm">tf.ragged</a>
        </li>
				<li>
            <a href="../tensorflow/tf.random.htm">tf.random</a>
        </li>
				<li>
            <a href="../tensorflow/tf.random.experimental.htm">tf.random.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.resource_loader.htm">tf.resource_loader</a>
        </li>
				<li>
            <a href="../tensorflow/tf.saved_model.htm">tf.saved_model</a>
        </li>
				<li>
            <a href="../tensorflow/tf.saved_model.main_op.htm">tf.saved_model.main_op</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sets.htm">tf.sets</a>
        </li>
				<li>
            <a href="../tensorflow/tf.signal.htm">tf.signal</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sparse.htm">tf.sparse</a>
        </li>
				<li>
            <a href="../tensorflow/tf.strings.htm">tf.strings</a>
        </li>
				<li>
            <a href="../tensorflow/tf.summary.htm">tf.summary</a>
        </li>
				<li>
            <a href="../tensorflow/tf.summary.experimental.htm">tf.summary.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sysconfig.htm">tf.sysconfig</a>
        </li>
				<li>
            <a href="../tensorflow/tf.test.htm">tf.test</a>
        </li>
				<li>
            <a href="../tensorflow/tf.tpu.htm">tf.tpu</a>
        </li>
				<li>
            <a href="../tensorflow/tf.tpu.experimental.htm">tf.tpu.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.train.htm">tf.train</a>
        </li>
				<li>
            <a href="../tensorflow/tf.train.experimental.htm">tf.train.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.user_ops.htm">tf.user_ops</a>
        </li>
				<li>
            <a href="../tensorflow/tf.xla.htm">tf.xla</a>
        </li>
				<li>
            <a href="../tensorflow/tf.xla.experimental.htm">tf.xla.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/TFRecordReader.htm">TFRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/truncated_normal_initializer.htm">truncated_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/TypeSpec.htm">TypeSpec</a>
        </li>
				<li>
            <a href="../tensorflow/UnconnectedGradients.htm">UnconnectedGradients</a>
        </li>
				<li>
            <a href="../tensorflow/uniform_unit_scaling_initializer.htm">uniform_unit_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Variable.htm">Variable</a>
        </li>
				<li>
            <a href="../tensorflow/variable_scope.htm">variable_scope</a>
        </li>
				<li>
            <a href="../tensorflow/VariableAggregation.htm">VariableAggregation</a>
        </li>
				<li>
            <a href="../tensorflow/VariableScope.htm">VariableScope</a>
        </li>
				<li>
            <a href="../tensorflow/VariableSynchronization.htm">VariableSynchronization</a>
        </li>
				<li>
            <a href="../tensorflow/variance_scaling_initializer.htm">variance_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/VarLenFeature.htm">VarLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/WholeFileReader.htm">WholeFileReader</a>
        </li>
				<li>
            <a href="../tensorflow/zeros_initializer.htm">zeros_initializer</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> tf.nn</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow</p>
		</header>
    <div class="sub-header">
		
		
			<h3 class="section">Methods</h3>
			<ul>
				<li><a href="../tensorflow/tf.nn.htm#all_candidate_sampler">all_candidate_sampler</a></li>
				<li><a href="../tensorflow/tf.nn.htm#all_candidate_sampler_dyn">all_candidate_sampler_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d">atrous_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_dyn">atrous_conv2d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_transpose">atrous_conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_transpose">atrous_conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_transpose">atrous_conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_transpose">atrous_conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_transpose">atrous_conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_transpose">atrous_conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_transpose">atrous_conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_transpose">atrous_conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_transpose_dyn">atrous_conv2d_transpose_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool">avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool_dyn">avg_pool_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool_v2">avg_pool_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool_v2">avg_pool_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool_v2_dyn">avg_pool_v2_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool1d">avg_pool1d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool1d">avg_pool1d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool1d_dyn">avg_pool1d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d">avg_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_norm_with_global_normalization">batch_norm_with_global_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_norm_with_global_normalization_dyn">batch_norm_with_global_normalization_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization_dyn">batch_normalization_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add_dyn">bias_add_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bidirectional_dynamic_rnn">bidirectional_dynamic_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#collapse_repeated">collapse_repeated</a></li>
				<li><a href="../tensorflow/tf.nn.htm#collapse_repeated">collapse_repeated</a></li>
				<li><a href="../tensorflow/tf.nn.htm#collapse_repeated">collapse_repeated</a></li>
				<li><a href="../tensorflow/tf.nn.htm#collapse_repeated">collapse_repeated</a></li>
				<li><a href="../tensorflow/tf.nn.htm#collapse_repeated_dyn">collapse_repeated_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#compute_accidental_hits">compute_accidental_hits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#compute_accidental_hits">compute_accidental_hits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#compute_accidental_hits">compute_accidental_hits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#compute_accidental_hits_dyn">compute_accidental_hits_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#compute_average_loss">compute_average_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#compute_average_loss">compute_average_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#compute_average_loss_dyn">compute_average_loss_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv_transpose">conv_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv_transpose">conv_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv_transpose">conv_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv_transpose">conv_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv_transpose">conv_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv_transpose">conv_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv_transpose">conv_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv_transpose">conv_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv_transpose_dyn">conv_transpose_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d">conv1d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d">conv1d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d">conv1d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d">conv1d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_dyn">conv1d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose">conv1d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose_dyn">conv1d_transpose_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_filter">conv2d_backprop_filter</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_filter">conv2d_backprop_filter</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_filter">conv2d_backprop_filter</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_filter">conv2d_backprop_filter</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_filter_dyn">conv2d_backprop_filter_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input">conv2d_backprop_input</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input">conv2d_backprop_input</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input">conv2d_backprop_input</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input">conv2d_backprop_input</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input">conv2d_backprop_input</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input">conv2d_backprop_input</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input">conv2d_backprop_input</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input">conv2d_backprop_input</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input">conv2d_backprop_input</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input_dyn">conv2d_backprop_input_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_dyn">conv2d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose_dyn">conv2d_transpose_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d">conv3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_backprop_filter">conv3d_backprop_filter</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_backprop_filter_dyn">conv3d_backprop_filter_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_dyn">conv3d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose">conv3d_transpose</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose_dyn">conv3d_transpose_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution">convolution</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution_dyn">convolution_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#crelu">crelu</a></li>
				<li><a href="../tensorflow/tf.nn.htm#crelu">crelu</a></li>
				<li><a href="../tensorflow/tf.nn.htm#crelu_dyn">crelu_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder">ctc_beam_search_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder">ctc_beam_search_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder">ctc_beam_search_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder">ctc_beam_search_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder">ctc_beam_search_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder">ctc_beam_search_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder">ctc_beam_search_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder">ctc_beam_search_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder_dyn">ctc_beam_search_decoder_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder_v2">ctc_beam_search_decoder_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder_v2_dyn">ctc_beam_search_decoder_v2_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_greedy_decoder">ctc_greedy_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_greedy_decoder">ctc_greedy_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_greedy_decoder">ctc_greedy_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_greedy_decoder">ctc_greedy_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_greedy_decoder">ctc_greedy_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_greedy_decoder">ctc_greedy_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_greedy_decoder">ctc_greedy_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_greedy_decoder">ctc_greedy_decoder</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_greedy_decoder_dyn">ctc_greedy_decoder_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss">ctc_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss_dyn">ctc_loss_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss_v2">ctc_loss_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss_v2">ctc_loss_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss_v2_dyn">ctc_loss_v2_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_unique_labels">ctc_unique_labels</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_unique_labels">ctc_unique_labels</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_unique_labels_dyn">ctc_unique_labels_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d">depthwise_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_backprop_filter">depthwise_conv2d_backprop_filter</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_backprop_filter_dyn">depthwise_conv2d_backprop_filter_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_backprop_input">depthwise_conv2d_backprop_input</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_backprop_input_dyn">depthwise_conv2d_backprop_input_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_dyn">depthwise_conv2d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native">depthwise_conv2d_native</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native_dyn">depthwise_conv2d_native_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dilation2d">dilation2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dilation2d_dyn">dilation2d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout_dyn">dropout_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dynamic_rnn">dynamic_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dynamic_rnn">dynamic_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dynamic_rnn">dynamic_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dynamic_rnn">dynamic_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dynamic_rnn">dynamic_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dynamic_rnn">dynamic_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dynamic_rnn">dynamic_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dynamic_rnn">dynamic_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#elu">elu</a></li>
				<li><a href="../tensorflow/tf.nn.htm#elu_dyn">elu_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup">embedding_lookup</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup">embedding_lookup</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup">embedding_lookup</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup">embedding_lookup</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup">embedding_lookup</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup">embedding_lookup</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup">embedding_lookup</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup">embedding_lookup</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup">embedding_lookup</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup">embedding_lookup</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_dyn">embedding_lookup_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_sparse">embedding_lookup_sparse</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_sparse">embedding_lookup_sparse</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_sparse">embedding_lookup_sparse</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_sparse">embedding_lookup_sparse</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_sparse">embedding_lookup_sparse</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_sparse">embedding_lookup_sparse</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_sparse">embedding_lookup_sparse</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_sparse">embedding_lookup_sparse</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_sparse_dyn">embedding_lookup_sparse_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#erosion2d">erosion2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#erosion2d_dyn">erosion2d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fixed_unigram_candidate_sampler">fixed_unigram_candidate_sampler</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fixed_unigram_candidate_sampler_dyn">fixed_unigram_candidate_sampler_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fractional_avg_pool">fractional_avg_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fractional_max_pool">fractional_max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fused_batch_norm">fused_batch_norm</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fused_batch_norm">fused_batch_norm</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fused_batch_norm_dyn">fused_batch_norm_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#l2_loss">l2_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#l2_loss_dyn">l2_loss_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#l2_normalize">l2_normalize</a></li>
				<li><a href="../tensorflow/tf.nn.htm#l2_normalize_dyn">l2_normalize_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#learned_unigram_candidate_sampler">learned_unigram_candidate_sampler</a></li>
				<li><a href="../tensorflow/tf.nn.htm#learned_unigram_candidate_sampler_dyn">learned_unigram_candidate_sampler_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_poisson_loss">log_poisson_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_poisson_loss">log_poisson_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_poisson_loss">log_poisson_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_poisson_loss">log_poisson_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_poisson_loss_dyn">log_poisson_loss_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_softmax">log_softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_softmax">log_softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_softmax">log_softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_softmax">log_softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_softmax">log_softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_softmax">log_softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_softmax">log_softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_softmax_dyn">log_softmax_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_uniform_candidate_sampler">log_uniform_candidate_sampler</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_uniform_candidate_sampler_dyn">log_uniform_candidate_sampler_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#lrn">lrn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#lrn">lrn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#lrn">lrn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#lrn">lrn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#lrn_dyn">lrn_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool">max_pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool_dyn">max_pool_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool_v2">max_pool_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool_v2">max_pool_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool_v2_dyn">max_pool_v2_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool_with_argmax">max_pool_with_argmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool_with_argmax_dyn">max_pool_with_argmax_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool1d">max_pool1d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool1d">max_pool1d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool1d_dyn">max_pool1d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool2d">max_pool2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool2d_dyn">max_pool2d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d">max_pool3d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#moments">moments</a></li>
				<li><a href="../tensorflow/tf.nn.htm#moments_dyn">moments_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#nce_loss">nce_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#nce_loss">nce_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#nce_loss_dyn">nce_loss_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#normalize_moments">normalize_moments</a></li>
				<li><a href="../tensorflow/tf.nn.htm#normalize_moments_dyn">normalize_moments_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool">pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool">pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool">pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool">pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool">pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool">pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool">pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool">pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool">pool</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool_dyn">pool_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#raw_rnn">raw_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#raw_rnn">raw_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#raw_rnn_dyn">raw_rnn_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.nn.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.nn.htm#relu_dyn">relu_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#relu_layer">relu_layer</a></li>
				<li><a href="../tensorflow/tf.nn.htm#relu_layer_dyn">relu_layer_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#relu6">relu6</a></li>
				<li><a href="../tensorflow/tf.nn.htm#safe_embedding_lookup_sparse_dyn">safe_embedding_lookup_sparse_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sampled_softmax_loss">sampled_softmax_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sampled_softmax_loss">sampled_softmax_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sampled_softmax_loss">sampled_softmax_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sampled_softmax_loss">sampled_softmax_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sampled_softmax_loss_dyn">sampled_softmax_loss_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#scale_regularization_loss">scale_regularization_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#scale_regularization_loss">scale_regularization_loss</a></li>
				<li><a href="../tensorflow/tf.nn.htm#scale_regularization_loss_dyn">scale_regularization_loss_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#selu">selu</a></li>
				<li><a href="../tensorflow/tf.nn.htm#selu_dyn">selu_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d_dyn">separable_conv2d_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sigmoid_cross_entropy_with_logits">sigmoid_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sigmoid_cross_entropy_with_logits">sigmoid_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sigmoid_cross_entropy_with_logits_dyn">sigmoid_cross_entropy_with_logits_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax">softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax">softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax">softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax">softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax">softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax">softmax</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_dyn">softmax_cross_entropy_with_logits_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2">softmax_cross_entropy_with_logits_v2</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2_dyn">softmax_cross_entropy_with_logits_v2_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_dyn">softmax_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softplus">softplus</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softplus_dyn">softplus_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softsign">softsign</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softsign_dyn">softsign_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits_dyn">sparse_softmax_cross_entropy_with_logits_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn">static_bidirectional_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn_dyn">static_bidirectional_rnn_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn">static_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn_dyn">static_rnn_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_state_saving_rnn">static_state_saving_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_state_saving_rnn">static_state_saving_rnn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_state_saving_rnn_dyn">static_state_saving_rnn_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sufficient_statistics">sufficient_statistics</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sufficient_statistics_dyn">sufficient_statistics_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#swish">swish</a></li>
				<li><a href="../tensorflow/tf.nn.htm#swish_dyn">swish_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#top_k">top_k</a></li>
				<li><a href="../tensorflow/tf.nn.htm#top_k">top_k</a></li>
				<li><a href="../tensorflow/tf.nn.htm#top_k_dyn">top_k_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#uniform_candidate_sampler">uniform_candidate_sampler</a></li>
				<li><a href="../tensorflow/tf.nn.htm#uniform_candidate_sampler_dyn">uniform_candidate_sampler_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#weighted_cross_entropy_with_logits">weighted_cross_entropy_with_logits</a></li>
				<li><a href="../tensorflow/tf.nn.htm#weighted_cross_entropy_with_logits_dyn">weighted_cross_entropy_with_logits_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#weighted_moments">weighted_moments</a></li>
				<li><a href="../tensorflow/tf.nn.htm#weighted_moments">weighted_moments</a></li>
				<li><a href="../tensorflow/tf.nn.htm#weighted_moments">weighted_moments</a></li>
				<li><a href="../tensorflow/tf.nn.htm#weighted_moments">weighted_moments</a></li>
				<li><a href="../tensorflow/tf.nn.htm#weighted_moments_dyn">weighted_moments_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch">with_space_to_batch</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch_dyn">with_space_to_batch_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#xw_plus_b">xw_plus_b</a></li>
				<li><a href="../tensorflow/tf.nn.htm#xw_plus_b">xw_plus_b</a></li>
				<li><a href="../tensorflow/tf.nn.htm#xw_plus_b">xw_plus_b</a></li>
				<li><a href="../tensorflow/tf.nn.htm#xw_plus_b_dyn">xw_plus_b_dyn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#zero_fraction">zero_fraction</a></li>
				<li><a href="../tensorflow/tf.nn.htm#zero_fraction">zero_fraction</a></li>
				<li><a href="../tensorflow/tf.nn.htm#zero_fraction">zero_fraction</a></li>
				<li><a href="../tensorflow/tf.nn.htm#zero_fraction_dyn">zero_fraction_dyn</a></li>
			</ul>
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow/tf.nn.htm#all_candidate_sampler_fn">all_candidate_sampler_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_fn">atrous_conv2d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#atrous_conv2d_transpose_fn">atrous_conv2d_transpose_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool_fn">avg_pool_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool_v2_fn">avg_pool_v2_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool1d_fn">avg_pool1d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#avg_pool3d_fn">avg_pool3d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_norm_with_global_normalization_fn">batch_norm_with_global_normalization_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#batch_normalization_fn">batch_normalization_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bias_add_fn">bias_add_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#bidirectional_dynamic_rnn_fn">bidirectional_dynamic_rnn_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#collapse_repeated_fn">collapse_repeated_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#compute_accidental_hits_fn">compute_accidental_hits_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#compute_average_loss_fn">compute_average_loss_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv_transpose_fn">conv_transpose_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_fn">conv1d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv1d_transpose_fn">conv1d_transpose_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_filter_fn">conv2d_backprop_filter_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_backprop_input_fn">conv2d_backprop_input_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_fn">conv2d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv2d_transpose_fn">conv2d_transpose_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_backprop_filter_fn_">conv3d_backprop_filter_fn_</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_fn">conv3d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#conv3d_transpose_fn">conv3d_transpose_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#convolution_fn">convolution_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#crelu_fn">crelu_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder_fn">ctc_beam_search_decoder_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_beam_search_decoder_v2_fn">ctc_beam_search_decoder_v2_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_greedy_decoder_fn">ctc_greedy_decoder_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss_fn">ctc_loss_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_loss_v2_fn">ctc_loss_v2_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#ctc_unique_labels_fn">ctc_unique_labels_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_backprop_filter_fn">depthwise_conv2d_backprop_filter_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_backprop_input_fn">depthwise_conv2d_backprop_input_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_fn">depthwise_conv2d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#depthwise_conv2d_native_fn">depthwise_conv2d_native_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dilation2d_fn">dilation2d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dropout_fn">dropout_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#dynamic_rnn_fn">dynamic_rnn_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#elu_fn">elu_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_fn">embedding_lookup_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#embedding_lookup_sparse_fn">embedding_lookup_sparse_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#erosion2d_fn">erosion2d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fixed_unigram_candidate_sampler_fn">fixed_unigram_candidate_sampler_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fractional_avg_pool_fn">fractional_avg_pool_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fractional_max_pool_fn">fractional_max_pool_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#fused_batch_norm_fn">fused_batch_norm_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#in_top_k_fn">in_top_k_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#l2_loss_fn">l2_loss_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#l2_normalize_fn">l2_normalize_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#leaky_relu_fn">leaky_relu_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#learned_unigram_candidate_sampler_fn">learned_unigram_candidate_sampler_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_poisson_loss_fn">log_poisson_loss_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_softmax_fn">log_softmax_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#log_uniform_candidate_sampler_fn">log_uniform_candidate_sampler_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#lrn_fn">lrn_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool_fn">max_pool_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool_v2_fn">max_pool_v2_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool_with_argmax_fn">max_pool_with_argmax_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool1d_fn">max_pool1d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool2d_fn">max_pool2d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#max_pool3d_fn">max_pool3d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#moments_fn">moments_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#nce_loss_fn">nce_loss_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#normalize_moments_fn">normalize_moments_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#pool_fn">pool_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#raw_rnn_fn">raw_rnn_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#relu_fn">relu_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#relu_layer_fn">relu_layer_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#relu6_fn">relu6_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#safe_embedding_lookup_sparse_fn">safe_embedding_lookup_sparse_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sampled_softmax_loss_fn">sampled_softmax_loss_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#scale_regularization_loss_fn">scale_regularization_loss_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#selu_fn">selu_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#separable_conv2d_fn">separable_conv2d_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sigmoid_cross_entropy_with_logits_fn">sigmoid_cross_entropy_with_logits_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_fn">softmax_cross_entropy_with_logits_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_cross_entropy_with_logits_v2_fn">softmax_cross_entropy_with_logits_v2_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softmax_fn">softmax_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softplus_fn">softplus_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#softsign_fn">softsign_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sparse_softmax_cross_entropy_with_logits_fn">sparse_softmax_cross_entropy_with_logits_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_bidirectional_rnn_fn">static_bidirectional_rnn_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_rnn_fn">static_rnn_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#static_state_saving_rnn_fn">static_state_saving_rnn_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#sufficient_statistics_fn">sufficient_statistics_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#swish_fn">swish_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#top_k_fn">top_k_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#uniform_candidate_sampler_fn">uniform_candidate_sampler_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#weighted_cross_entropy_with_logits_fn">weighted_cross_entropy_with_logits_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#weighted_moments_fn">weighted_moments_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#with_space_to_batch_fn">with_space_to_batch_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#xw_plus_b_fn">xw_plus_b_fn</a></li>
				<li><a href="../tensorflow/tf.nn.htm#zero_fraction_fn">zero_fraction_fn</a></li>
			</ul>
		
	</div>
	
	
	<h3 class="section">Public static methods</h3>

	<div id="all_candidate_sampler" class="method">
		<h4>
			<span title="System.object">object</span> <strong>all_candidate_sampler</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> true_classes, <span title="System.int">int</span> num_true, <span title="System.int">int</span> num_sampled, <span title="System.bool">bool</span> unique, <span title="System.object">object</span> seed, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Generate the set of all classes. <p></p> Deterministically generates and returns the set of all possible classes.
For testing purposes.  There is no need to use this, since you might as
well use full softmax or full logistic regression. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unique
						</dt>
						<dd>A `bool`. Ignored.
unique. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="all_candidate_sampler_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>all_candidate_sampler_dyn</strong>(<span title="System.object">object</span> true_classes, <span title="System.object">object</span> num_true, <span title="System.object">object</span> num_sampled, <span title="System.object">object</span> unique, <span title="System.object">object</span> seed, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Generate the set of all classes. <p></p> Deterministically generates and returns the set of all possible classes.
For testing purposes.  There is no need to use this, since you might as
well use full softmax or full logistic regression. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> unique
						</dt>
						<dd>A `bool`. Ignored.
unique. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="atrous_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>atrous_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.int">int</span> rate, <span title="System.string">string</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Atrous convolution (a.k.a. convolution with holes or dilated convolution). <p></p> This function is a simpler wrapper around the more general
<a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a>, and exists only for backwards compatibility. You can
use <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> to perform 1-D, 2-D, or 3-D atrous convolution. <p></p> <p></p> Computes a 2-D atrous convolution, also known as convolution with holes or
dilated convolution, given 4-D `value` and `filters` tensors. If the `rate`
parameter is equal to one, it performs regular 2-D convolution. If the `rate`
parameter is greater than one, it performs convolution with holes, sampling
the input values every `rate` pixels in the `height` and `width` dimensions.
This is equivalent to convolving the input with a set of upsampled filters,
produced by inserting `rate - 1` zeros between two consecutive values of the
filters along the `height` and `width` dimensions, hence the name atrous
convolution or convolution with holes (the French word trous means holes in
English). <p></p> More specifically: <p></p> ```
output[batch, height, width, out_channel] =
sum_{dheight, dwidth, in_channel} (
filters[dheight, dwidth, in_channel, out_channel] *
value[batch, height + rate*dheight, width + rate*dwidth, in_channel]
)
``` <p></p> Atrous convolution allows us to explicitly control how densely to compute
feature responses in fully convolutional networks. Used in conjunction with
bilinear interpolation, it offers an alternative to `conv2d_transpose` in
dense prediction tasks such as semantic image segmentation, optical flow
computation, or depth estimation. It also allows us to effectively enlarge
the field of view of filters without increasing the number of parameters or
the amount of computation. <p></p> For a description of atrous convolution and how it can be used for dense
feature extraction, please see: [Semantic Image Segmentation with Deep
Convolutional Nets and Fully Connected CRFs](http://arxiv.org/abs/1412.7062).
The same operation is investigated further in [Multi-Scale Context Aggregation
by Dilated Convolutions](http://arxiv.org/abs/1511.07122). Previous works
that effectively use atrous convolution in different ways are, among others,
[OverFeat: Integrated Recognition, Localization and Detection using
Convolutional Networks](http://arxiv.org/abs/1312.6229) and [Fast Image
Scanning with Deep Max-Pooling Convolutional Neural
Networks](http://arxiv.org/abs/1302.1700).
Atrous convolution is also closely related to the so-called noble identities
in multi-rate signal processing. <p></p> There are many different ways to implement atrous convolution (see the refs
above). The implementation here reduces
to the following three operations:
Advanced usage. Note the following optimization: A sequence of `atrous_conv2d`
operations with identical `rate` parameters, 'SAME' `padding`, and filters
with odd heights/ widths:
can be equivalently performed cheaper in terms of computation and memory as:
because a pair of consecutive `space_to_batch` and `batch_to_space` ops with
the same `block_size` cancel out when their respective `paddings` and `crops`
inputs are identical. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default "NHWC"
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, in_channels, out_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.
Output shape with `'VALID'` padding is: <p></p> [batch, height - 2 * (filter_width - 1),
width - 2 * (filter_height - 1), out_channels]. <p></p> Output shape with `'SAME'` padding is: <p></p> [batch, height, width, out_channels]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>atrous_conv2d(value, filters, rate, padding=padding) </pre>
</div>
		</div>
	</div>
	<div id="atrous_conv2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>atrous_conv2d_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> filters, <span title="System.object">object</span> rate, <span title="System.object">object</span> padding, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Atrous convolution (a.k.a. convolution with holes or dilated convolution). <p></p> This function is a simpler wrapper around the more general
<a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a>, and exists only for backwards compatibility. You can
use <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> to perform 1-D, 2-D, or 3-D atrous convolution. <p></p> <p></p> Computes a 2-D atrous convolution, also known as convolution with holes or
dilated convolution, given 4-D `value` and `filters` tensors. If the `rate`
parameter is equal to one, it performs regular 2-D convolution. If the `rate`
parameter is greater than one, it performs convolution with holes, sampling
the input values every `rate` pixels in the `height` and `width` dimensions.
This is equivalent to convolving the input with a set of upsampled filters,
produced by inserting `rate - 1` zeros between two consecutive values of the
filters along the `height` and `width` dimensions, hence the name atrous
convolution or convolution with holes (the French word trous means holes in
English). <p></p> More specifically: <p></p> ```
output[batch, height, width, out_channel] =
sum_{dheight, dwidth, in_channel} (
filters[dheight, dwidth, in_channel, out_channel] *
value[batch, height + rate*dheight, width + rate*dwidth, in_channel]
)
``` <p></p> Atrous convolution allows us to explicitly control how densely to compute
feature responses in fully convolutional networks. Used in conjunction with
bilinear interpolation, it offers an alternative to `conv2d_transpose` in
dense prediction tasks such as semantic image segmentation, optical flow
computation, or depth estimation. It also allows us to effectively enlarge
the field of view of filters without increasing the number of parameters or
the amount of computation. <p></p> For a description of atrous convolution and how it can be used for dense
feature extraction, please see: [Semantic Image Segmentation with Deep
Convolutional Nets and Fully Connected CRFs](http://arxiv.org/abs/1412.7062).
The same operation is investigated further in [Multi-Scale Context Aggregation
by Dilated Convolutions](http://arxiv.org/abs/1511.07122). Previous works
that effectively use atrous convolution in different ways are, among others,
[OverFeat: Integrated Recognition, Localization and Detection using
Convolutional Networks](http://arxiv.org/abs/1312.6229) and [Fast Image
Scanning with Deep Max-Pooling Convolutional Neural
Networks](http://arxiv.org/abs/1302.1700).
Atrous convolution is also closely related to the so-called noble identities
in multi-rate signal processing. <p></p> There are many different ways to implement atrous convolution (see the refs
above). The implementation here reduces
to the following three operations:
Advanced usage. Note the following optimization: A sequence of `atrous_conv2d`
operations with identical `rate` parameters, 'SAME' `padding`, and filters
with odd heights/ widths:
can be equivalently performed cheaper in terms of computation and memory as:
because a pair of consecutive `space_to_batch` and `batch_to_space` ops with
the same `block_size` cancel out when their respective `paddings` and `crops`
inputs are identical. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default "NHWC"
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, in_channels, out_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.
Output shape with `'VALID'` padding is: <p></p> [batch, height - 2 * (filter_width - 1),
width - 2 * (filter_height - 1), out_channels]. <p></p> Output shape with `'SAME'` padding is: <p></p> [batch, height, width, out_channels]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>atrous_conv2d(value, filters, rate, padding=padding) </pre>
</div>
		</div>
	</div>
	<div id="atrous_conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>atrous_conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.int">int</span> rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `atrous_conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `atrous_conv2d` rather than an
actual deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default `NHWC`
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, out_channels, in_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` of shape representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="atrous_conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>atrous_conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.int">int</span> rate, <span title="System.string">string</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `atrous_conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `atrous_conv2d` rather than an
actual deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default `NHWC`
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, out_channels, in_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` of shape representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="atrous_conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>atrous_conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span> output_shape, <span title="System.int">int</span> rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `atrous_conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `atrous_conv2d` rather than an
actual deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default `NHWC`
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, out_channels, in_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` of shape representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="atrous_conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>atrous_conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.int">int</span> rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `atrous_conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `atrous_conv2d` rather than an
actual deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default `NHWC`
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, out_channels, in_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` of shape representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="atrous_conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>atrous_conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span> output_shape, <span title="System.int">int</span> rate, <span title="System.string">string</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `atrous_conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `atrous_conv2d` rather than an
actual deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default `NHWC`
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, out_channels, in_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` of shape representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="atrous_conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>atrous_conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.object">object</span> output_shape, <span title="System.int">int</span> rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `atrous_conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `atrous_conv2d` rather than an
actual deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default `NHWC`
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, out_channels, in_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` of shape representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="atrous_conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>atrous_conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.object">object</span> output_shape, <span title="System.int">int</span> rate, <span title="System.string">string</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `atrous_conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `atrous_conv2d` rather than an
actual deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default `NHWC`
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, out_channels, in_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` of shape representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="atrous_conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>atrous_conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.int">int</span> rate, <span title="System.string">string</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `atrous_conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `atrous_conv2d` rather than an
actual deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default `NHWC`
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, out_channels, in_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` of shape representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="atrous_conv2d_transpose_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>atrous_conv2d_transpose_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> filters, <span title="System.object">object</span> output_shape, <span title="System.object">object</span> rate, <span title="System.object">object</span> padding, <span title="System.object">object</span> name)
		</h4>
		<div class="content">The transpose of `atrous_conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `atrous_conv2d` rather than an
actual deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float`. It needs to be in the default `NHWC`
format. Its shape is `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[filter_height, filter_width, out_channels, in_channels]`. `filters`'
`in_channels` dimension must match that of `value`. Atrous convolution is
equivalent to standard convolution with upsampled filters with effective
height `filter_height + (filter_height - 1) * (rate - 1)` and effective
width `filter_width + (filter_width - 1) * (rate - 1)`, produced by
inserting `rate - 1` zeros along consecutive elements across the
`filters`' spatial dimensions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` of shape representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A positive int32. The stride with which we sample input values across
the `height` and `width` dimensions. Equivalently, the rate by which we
upsample the filter values by inserting zeros across the `height` and
`width` dimensions. In the literature, the same parameter is sometimes
called `input stride` or `dilation`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.object">object</span> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.object">object</span> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.object">object</span> value, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.object">object</span> value, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> value, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> value, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.object">object</span> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.object">object</span> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>avg_pool_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <span title="System.object">object</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool_v2</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the avg pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape `[batch_size] + input_spatial_shape +
[num_channels]` if `data_format` does not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC". Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The size
of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string. Specifies the channel dimension. For N=1 it can be
either "NWC" (default) or "NCW", for N=2 it can be either "NHWC" (default)
or "NCHW" and for N=3 either "NDHWC" (default) or "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool_v2</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the avg pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape `[batch_size] + input_spatial_shape +
[num_channels]` if `data_format` does not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC". Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The size
of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string. Specifies the channel dimension. For N=1 it can be
either "NWC" (default) or "NCW", for N=2 it can be either "NHWC" (default)
or "NCHW" and for N=3 either "NDHWC" (default) or "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool_v2_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>avg_pool_v2_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Performs the avg pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape `[batch_size] + input_spatial_shape +
[num_channels]` if `data_format` does not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC". Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The size
of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string. Specifies the channel dimension. For N=1 it can be
either "NWC" (default) or "NCW", for N=2 it can be either "NHWC" (default)
or "NCHW" and for N=3 either "NDHWC" (default) or "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool1d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool1d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. <p></p> Note internally this op reshapes and uses the underlying 2d operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The size of the
window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The stride of
the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NWC", "NCW". Defaults to "NWC". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool1d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool1d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. <p></p> Note internally this op reshapes and uses the underlying 2d operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The size of the
window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The stride of
the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NWC", "NCW". Defaults to "NWC". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool1d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>avg_pool1d_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. <p></p> Note internally this op reshapes and uses the underlying 2d operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A 3-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The size of the
window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The stride of
the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>An optional string from: "NWC", "NCW". Defaults to "NWC". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.int">int</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.int">int</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="avg_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>avg_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the average pooling on the input. <p></p> Each entry in `output` is the mean of the corresponding size `ksize`
window in `value`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of shape `[batch, height, width, channels]` and type
`float32`, `float64`, `qint8`, `quint8`, or `qint32`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NDHWC' and 'NCDHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`.  The average pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_norm_with_global_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_norm_with_global_normalization</strong>(<span title="System.object">object</span> t, <span title="System.object">object</span> m, <span title="System.object">object</span> v, <span title="System.object">object</span> beta, <span title="System.object">object</span> gamma, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> scale_after_normalization, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> mean, <span title="System.object">object</span> variance)
		</h4>
		<div class="content">Batch normalization. <p></p> This op is deprecated. See <a href="..\..\tf\nn\batch_normalization.md"><code>tf.nn.batch_normalization</code></a>. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> t
						</dt>
						<dd>A 4D input Tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> m
						</dt>
						<dd>A 1D mean Tensor with size matching the last dimension of t.
This is the first output from tf.nn.moments,
or a saved moving average thereof. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> v
						</dt>
						<dd>A 1D variance Tensor with size matching the last dimension of t.
This is the second output from tf.nn.moments,
or a saved moving average thereof. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> beta
						</dt>
						<dd>A 1D beta Tensor with size matching the last dimension of t.
An offset to be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> gamma
						</dt>
						<dd>A 1D gamma Tensor with size matching the last dimension of t.
If "scale_after_normalization" is true, this tensor will be multiplied
with the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> scale_after_normalization
						</dt>
						<dd>A bool indicating whether the resulted tensor
needs to be multiplied with gamma. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for t. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>Alias for m. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>Alias for v. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A batch-normalized `t`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_norm_with_global_normalization_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_norm_with_global_normalization_dyn</strong>(<span title="System.object">object</span> t, <span title="System.object">object</span> m, <span title="System.object">object</span> v, <span title="System.object">object</span> beta, <span title="System.object">object</span> gamma, <span title="System.object">object</span> variance_epsilon, <span title="System.object">object</span> scale_after_normalization, <span title="System.object">object</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> mean, <span title="System.object">object</span> variance)
		</h4>
		<div class="content">Batch normalization. <p></p> This op is deprecated. See <a href="..\..\tf\nn\batch_normalization.md"><code>tf.nn.batch_normalization</code></a>. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> t
						</dt>
						<dd>A 4D input Tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> m
						</dt>
						<dd>A 1D mean Tensor with size matching the last dimension of t.
This is the first output from tf.nn.moments,
or a saved moving average thereof. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> v
						</dt>
						<dd>A 1D variance Tensor with size matching the last dimension of t.
This is the second output from tf.nn.moments,
or a saved moving average thereof. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> beta
						</dt>
						<dd>A 1D beta Tensor with size matching the last dimension of t.
An offset to be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> gamma
						</dt>
						<dd>A 1D gamma Tensor with size matching the last dimension of t.
If "scale_after_normalization" is true, this tensor will be multiplied
with the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale_after_normalization
						</dt>
						<dd>A bool indicating whether the resulted tensor
needs to be multiplied with gamma. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for t. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>Alias for m. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>Alias for v. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A batch-normalized `t`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.object">object</span> mean, <span title="System.object">object</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.object">object</span> mean, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> mean, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> mean, <span title="System.object">object</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.object">object</span> mean, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.object">object</span> mean, <span title="System.object">object</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> mean, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> mean, <span title="System.object">object</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.object">object</span> mean, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.object">object</span> mean, <span title="System.object">object</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> mean, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> mean, <span title="System.object">object</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.object">object</span> mean, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.object">object</span> mean, <span title="System.object">object</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> mean, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> mean, <span title="System.object">object</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> variance_epsilon, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> mean, <span title="System.object">object</span> variance, <span title="System.object">object</span> offset, <span title="System.object">object</span> scale, <span title="System.object">object</span> variance_epsilon, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> Normalizes a tensor by `mean` and `variance`, and applies (optionally) a
`scale` \\(\gamma\\) to it, as well as an `offset` \\(\beta\\): <p></p> \\(\frac{\gamma(x-\mu)}{\sigma}+\beta\\) <p></p> `mean`, `variance`, `offset` and `scale` are all expected to be of one of two
shapes: <p></p> * In all generality, they can have the same number of dimensions as the
input `x`, with identical sizes as `x` for the dimensions that are not
normalized over (the 'depth' dimension(s)), and dimension 1 for the
others which are being normalized over.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=True)` during training, or running averages
thereof during inference.
* In the common case where the 'depth' dimension is the last dimension in
the input tensor `x`, they may be one dimensional tensors of the same
size as the 'depth' dimension.
This is the case for example for the common `[batch, depth]` layout of
fully-connected layers, and `[batch, height, width, depth]` for
convolutions.
`mean` and `variance` in this case would typically be the outputs of
`tf.nn.moments(..., keep_dims=False)` during training, or running averages
thereof during inference. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Input `Tensor` of arbitrary dimensionality. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>A mean `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>A variance `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>An offset `Tensor`, often denoted \\(\beta\\) in equations, or
None. If present, will be added to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A scale `Tensor`, often denoted \\(\gamma\\) in equations, or
`None`. If present, the scale is applied to the normalized tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance_epsilon
						</dt>
						<dd>A small float number to avoid dividing by 0. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>the normalized, scaled, offset tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> bias, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> bias, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> bias, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> bias, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> bias, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> bias, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> bias, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> bias, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> bias, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> value, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> bias, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> value, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> bias, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> value, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> bias, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> value, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> bias, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bias_add</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> bias, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>bias_add_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> bias, <span title="System.object">object</span> data_format, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Adds `bias` to `value`. <p></p> This is (mostly) a special case of <a href="..\..\tf\math\add.md"><code>tf.add</code></a> where `bias` is restricted to 1-D.
Broadcasting is supported, so `value` may have any number of dimensions.
Unlike <a href="..\..\tf\math\add.md"><code>tf.add</code></a>, the type of `bias` is allowed to differ from `value` in the
case where both types are quantized. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int64`, `int32`, `uint8`,
`int16`, `int8`, `complex64`, or `complex128`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> bias
						</dt>
						<dd>A 1-D `Tensor` with size matching the channel dimension of `value`.
Must be the same type as `value` unless `value` is a quantized type,
in which case a different quantized type may be used. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string. 'N...C' and 'NC...' are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bidirectional_dynamic_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>bidirectional_dynamic_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LSTMCell.htm">LSTMCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/LSTMCell.htm">LSTMCell</a> cell_bw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> time_major, <span title="System.object">object</span> scope)
		</h4>
		<div class="content">Creates a dynamic version of bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API <p></p> Takes input and builds independent forward and backward RNNs. The input_size
of forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not
given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LSTMCell.htm">LSTMCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LSTMCell.htm">LSTMCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>The RNN inputs.
If time_major == False (default), this must be a tensor of shape:
`[batch_size, max_time,...]`, or a nested tuple of such elements.
If time_major == True, this must be a tensor of shape: `[max_time,
batch_size,...]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences in the batch. If
not provided, all batch entries are assumed to be full sequences; and time
reversal is applied from time `0` to `max_time` for each sequence. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial states and expected output.
Required if initial_states are not provided or RNN states have a
heterogeneous dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` and `outputs` Tensors. If true,
these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,
these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using
`time_major = True` is a bit more efficient because it avoids transposes
at the beginning and end of the RNN calculation.  However, most TensorFlow
data is batch-major, so by default this function accepts input and emits
output in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>A tuple (outputs, output_states) where: 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="collapse_repeated" class="method">
		<h4>
			<span title="System.ValueTuple<Tensor, object>">ValueTuple&lt;Tensor, object&gt;</span> <strong>collapse_repeated</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> seq_length, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Merge repeated labels into single labels. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>Tensor of shape [batch, max value in seq_length] 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> seq_length
						</dt>
						<dd>Tensor of shape [batch], sequence length of each batch element. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "collapse_repeated_labels". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<Tensor, object>">ValueTuple&lt;Tensor, object&gt;</span></code>
					</dt>
					<dd>A tuple `(collapsed_labels, new_seq_length)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="collapse_repeated" class="method">
		<h4>
			<span title="System.ValueTuple<Tensor, object>">ValueTuple&lt;Tensor, object&gt;</span> <strong>collapse_repeated</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> seq_length, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Merge repeated labels into single labels. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> labels
						</dt>
						<dd>Tensor of shape [batch, max value in seq_length] 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> seq_length
						</dt>
						<dd>Tensor of shape [batch], sequence length of each batch element. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "collapse_repeated_labels". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<Tensor, object>">ValueTuple&lt;Tensor, object&gt;</span></code>
					</dt>
					<dd>A tuple `(collapsed_labels, new_seq_length)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="collapse_repeated" class="method">
		<h4>
			<span title="System.ValueTuple<Tensor, object>">ValueTuple&lt;Tensor, object&gt;</span> <strong>collapse_repeated</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> seq_length, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Merge repeated labels into single labels. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>Tensor of shape [batch, max value in seq_length] 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> seq_length
						</dt>
						<dd>Tensor of shape [batch], sequence length of each batch element. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "collapse_repeated_labels". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<Tensor, object>">ValueTuple&lt;Tensor, object&gt;</span></code>
					</dt>
					<dd>A tuple `(collapsed_labels, new_seq_length)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="collapse_repeated" class="method">
		<h4>
			<span title="System.ValueTuple<Tensor, object>">ValueTuple&lt;Tensor, object&gt;</span> <strong>collapse_repeated</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> seq_length, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Merge repeated labels into single labels. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> labels
						</dt>
						<dd>Tensor of shape [batch, max value in seq_length] 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> seq_length
						</dt>
						<dd>Tensor of shape [batch], sequence length of each batch element. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "collapse_repeated_labels". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<Tensor, object>">ValueTuple&lt;Tensor, object&gt;</span></code>
					</dt>
					<dd>A tuple `(collapsed_labels, new_seq_length)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="collapse_repeated_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>collapse_repeated_dyn</strong>(<span title="System.object">object</span> labels, <span title="System.object">object</span> seq_length, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Merge repeated labels into single labels. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>Tensor of shape [batch, max value in seq_length] 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seq_length
						</dt>
						<dd>Tensor of shape [batch], sequence length of each batch element. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "collapse_repeated_labels". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple `(collapsed_labels, new_seq_length)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="compute_accidental_hits" class="method">
		<h4>
			<span title="System.object">object</span> <strong>compute_accidental_hits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> true_classes, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sampled_candidates, <span title="System.int">int</span> num_true, <span title="System.object">object</span> seed, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Compute the position ids in `sampled_candidates` matching `true_classes`. <p></p> In Candidate Sampling, this operation facilitates virtually removing
sampled classes which happen to match target classes.  This is done
in Sampled Softmax and Sampled Logistic. <p></p> See our [Candidate Sampling Algorithms
Reference](http://www.tensorflow.org/extras/candidate_sampling.pdf). <p></p> We presuppose that the `sampled_candidates` are unique. <p></p> We call it an 'accidental hit' when one of the target classes
matches one of the sampled classes.  This operation reports
accidental hits as triples `(index, id, weight)`, where `index`
represents the row number in `true_classes`, `id` represents the
position in `sampled_candidates`, and weight is `-FLOAT_MAX`. <p></p> The result of this op should be passed through a `sparse_to_dense`
operation, then added to the logits of the sampled classes. This
removes the contradictory effect of accidentally sampling the true
target classes as noise classes for the same example. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sampled_candidates
						</dt>
						<dd>A tensor of type `int64` and shape `[num_sampled]`.
The sampled_candidates output of CandidateSampler. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="compute_accidental_hits" class="method">
		<h4>
			<span title="System.object">object</span> <strong>compute_accidental_hits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> true_classes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sampled_candidates, <span title="System.int">int</span> num_true, <span title="System.object">object</span> seed, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Compute the position ids in `sampled_candidates` matching `true_classes`. <p></p> In Candidate Sampling, this operation facilitates virtually removing
sampled classes which happen to match target classes.  This is done
in Sampled Softmax and Sampled Logistic. <p></p> See our [Candidate Sampling Algorithms
Reference](http://www.tensorflow.org/extras/candidate_sampling.pdf). <p></p> We presuppose that the `sampled_candidates` are unique. <p></p> We call it an 'accidental hit' when one of the target classes
matches one of the sampled classes.  This operation reports
accidental hits as triples `(index, id, weight)`, where `index`
represents the row number in `true_classes`, `id` represents the
position in `sampled_candidates`, and weight is `-FLOAT_MAX`. <p></p> The result of this op should be passed through a `sparse_to_dense`
operation, then added to the logits of the sampled classes. This
removes the contradictory effect of accidentally sampling the true
target classes as noise classes for the same example. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sampled_candidates
						</dt>
						<dd>A tensor of type `int64` and shape `[num_sampled]`.
The sampled_candidates output of CandidateSampler. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="compute_accidental_hits" class="method">
		<h4>
			<span title="System.object">object</span> <strong>compute_accidental_hits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> true_classes, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sampled_candidates, <span title="System.int">int</span> num_true, <span title="System.object">object</span> seed, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Compute the position ids in `sampled_candidates` matching `true_classes`. <p></p> In Candidate Sampling, this operation facilitates virtually removing
sampled classes which happen to match target classes.  This is done
in Sampled Softmax and Sampled Logistic. <p></p> See our [Candidate Sampling Algorithms
Reference](http://www.tensorflow.org/extras/candidate_sampling.pdf). <p></p> We presuppose that the `sampled_candidates` are unique. <p></p> We call it an 'accidental hit' when one of the target classes
matches one of the sampled classes.  This operation reports
accidental hits as triples `(index, id, weight)`, where `index`
represents the row number in `true_classes`, `id` represents the
position in `sampled_candidates`, and weight is `-FLOAT_MAX`. <p></p> The result of this op should be passed through a `sparse_to_dense`
operation, then added to the logits of the sampled classes. This
removes the contradictory effect of accidentally sampling the true
target classes as noise classes for the same example. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sampled_candidates
						</dt>
						<dd>A tensor of type `int64` and shape `[num_sampled]`.
The sampled_candidates output of CandidateSampler. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="compute_accidental_hits_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>compute_accidental_hits_dyn</strong>(<span title="System.object">object</span> true_classes, <span title="System.object">object</span> sampled_candidates, <span title="System.object">object</span> num_true, <span title="System.object">object</span> seed, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Compute the position ids in `sampled_candidates` matching `true_classes`. <p></p> In Candidate Sampling, this operation facilitates virtually removing
sampled classes which happen to match target classes.  This is done
in Sampled Softmax and Sampled Logistic. <p></p> See our [Candidate Sampling Algorithms
Reference](http://www.tensorflow.org/extras/candidate_sampling.pdf). <p></p> We presuppose that the `sampled_candidates` are unique. <p></p> We call it an 'accidental hit' when one of the target classes
matches one of the sampled classes.  This operation reports
accidental hits as triples `(index, id, weight)`, where `index`
represents the row number in `true_classes`, `id` represents the
position in `sampled_candidates`, and weight is `-FLOAT_MAX`. <p></p> The result of this op should be passed through a `sparse_to_dense`
operation, then added to the logits of the sampled classes. This
removes the contradictory effect of accidentally sampling the true
target classes as noise classes for the same example. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sampled_candidates
						</dt>
						<dd>A tensor of type `int64` and shape `[num_sampled]`.
The sampled_candidates output of CandidateSampler. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="compute_average_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>compute_average_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> per_example_loss, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> sample_weight, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> global_batch_size)
		</h4>
		<div class="content">Scales per-example losses with sample_weights and computes their average. <p></p> Usage with distribution strategy and custom training loop: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> per_example_loss
						</dt>
						<dd>Per-example loss. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> sample_weight
						</dt>
						<dd>Optional weighting for each example. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> global_batch_size
						</dt>
						<dd>Optional global batch size value. Defaults to (size of
first dimension of `losses`) * (number of replicas). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Scalar loss value. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>with strategy.scope():
              def compute_loss(labels, predictions, sample_weight=None): <p></p> # If you are using a `Loss` class instead, set reduction to `NONE` so that
# we can do the reduction afterwards and divide by global batch size.
per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(
    labels, predictions) <p></p> # Compute loss that is scaled by sample_weight and by global batch size.
return tf.compute_average_loss(
    per_example_loss,
    sample_weight=sample_weight,
    global_batch_size=GLOBAL_BATCH_SIZE) </pre>
</div>
		</div>
	</div>
	<div id="compute_average_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>compute_average_loss</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> per_example_loss, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> sample_weight, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> global_batch_size)
		</h4>
		<div class="content">Scales per-example losses with sample_weights and computes their average. <p></p> Usage with distribution strategy and custom training loop: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> per_example_loss
						</dt>
						<dd>Per-example loss. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> sample_weight
						</dt>
						<dd>Optional weighting for each example. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> global_batch_size
						</dt>
						<dd>Optional global batch size value. Defaults to (size of
first dimension of `losses`) * (number of replicas). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Scalar loss value. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>with strategy.scope():
              def compute_loss(labels, predictions, sample_weight=None): <p></p> # If you are using a `Loss` class instead, set reduction to `NONE` so that
# we can do the reduction afterwards and divide by global batch size.
per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(
    labels, predictions) <p></p> # Compute loss that is scaled by sample_weight and by global batch size.
return tf.compute_average_loss(
    per_example_loss,
    sample_weight=sample_weight,
    global_batch_size=GLOBAL_BATCH_SIZE) </pre>
</div>
		</div>
	</div>
	<div id="compute_average_loss_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>compute_average_loss_dyn</strong>(<span title="System.object">object</span> per_example_loss, <span title="System.object">object</span> sample_weight, <span title="System.object">object</span> global_batch_size)
		</h4>
		<div class="content">Scales per-example losses with sample_weights and computes their average. <p></p> Usage with distribution strategy and custom training loop: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> per_example_loss
						</dt>
						<dd>Per-example loss. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sample_weight
						</dt>
						<dd>Optional weighting for each example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> global_batch_size
						</dt>
						<dd>Optional global batch size value. Defaults to (size of
first dimension of `losses`) * (number of replicas). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Scalar loss value. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>with strategy.scope():
              def compute_loss(labels, predictions, sample_weight=None): <p></p> # If you are using a `Loss` class instead, set reduction to `NONE` so that
# we can do the reduction afterwards and divide by global batch size.
per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(
    labels, predictions) <p></p> # Compute loss that is scaled by sample_weight and by global batch size.
return tf.compute_average_loss(
    per_example_loss,
    sample_weight=sample_weight,
    global_batch_size=GLOBAL_BATCH_SIZE) </pre>
</div>
		</div>
	</div>
	<div id="conv_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `convolution`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf), but is
actually the transpose (gradient) of `convolution` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An N+2 dimensional `Tensor` of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". It must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>An N+2 dimensional `Tensor` with the same type as `input` and
shape `spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the spatial dimensions. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the spatial dimensions. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "conv_transpose"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `convolution`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf), but is
actually the transpose (gradient) of `convolution` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An N+2 dimensional `Tensor` of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". It must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>An N+2 dimensional `Tensor` with the same type as `input` and
shape `spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the spatial dimensions. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the spatial dimensions. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "conv_transpose"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `convolution`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf), but is
actually the transpose (gradient) of `convolution` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An N+2 dimensional `Tensor` of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". It must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>An N+2 dimensional `Tensor` with the same type as `input` and
shape `spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the spatial dimensions. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the spatial dimensions. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "conv_transpose"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `convolution`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf), but is
actually the transpose (gradient) of `convolution` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An N+2 dimensional `Tensor` of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". It must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>An N+2 dimensional `Tensor` with the same type as `input` and
shape `spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the spatial dimensions. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the spatial dimensions. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "conv_transpose"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `convolution`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf), but is
actually the transpose (gradient) of `convolution` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An N+2 dimensional `Tensor` of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". It must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>An N+2 dimensional `Tensor` with the same type as `input` and
shape `spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the spatial dimensions. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the spatial dimensions. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "conv_transpose"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `convolution`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf), but is
actually the transpose (gradient) of `convolution` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An N+2 dimensional `Tensor` of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". It must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>An N+2 dimensional `Tensor` with the same type as `input` and
shape `spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the spatial dimensions. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the spatial dimensions. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "conv_transpose"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `convolution`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf), but is
actually the transpose (gradient) of `convolution` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An N+2 dimensional `Tensor` of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". It must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>An N+2 dimensional `Tensor` with the same type as `input` and
shape `spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the spatial dimensions. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the spatial dimensions. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "conv_transpose"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `convolution`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf), but is
actually the transpose (gradient) of `convolution` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An N+2 dimensional `Tensor` of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". It must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>An N+2 dimensional `Tensor` with the same type as `input` and
shape `spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the spatial dimensions. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the spatial dimensions. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "conv_transpose"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv_transpose_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv_transpose_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> output_shape, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations, <span title="System.object">object</span> name)
		</h4>
		<div class="content">The transpose of `convolution`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf), but is
actually the transpose (gradient) of `convolution` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>An N+2 dimensional `Tensor` of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". It must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>An N+2 dimensional `Tensor` with the same type as `input` and
shape `spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the spatial dimensions. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the spatial dimensions. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "conv_transpose"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> stride, <span title="System.string">string</span> padding, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes a 1-D convolution given 3-D input and filter tensors. (deprecated argument values) (deprecated argument values) <p></p> Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(data_format='NCHW')`. They will be removed in a future version.
Instructions for updating:
`NCHW` for data_format is deprecated, use `NCW` instead <p></p> Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(data_format='NHWC')`. They will be removed in a future version.
Instructions for updating:
`NHWC` for data_format is deprecated, use `NWC` instead <p></p> Given an input tensor of shape
[batch, in_width, in_channels]
if data_format is "NWC", or
[batch, in_channels, in_width]
if data_format is "NCW",
and a filter / kernel tensor of shape
[filter_width, in_channels, out_channels], this op reshapes
the arguments to pass them to conv2d to perform the equivalent
convolution operation. <p></p> Internally, this op reshapes the input tensors and invokes <a href="..\..\tf\nn\conv2d.md"><code>tf.nn.conv2d</code></a>.
For example, if `data_format` does not start with "NC", a tensor of shape
[batch, in_width, in_channels]
is reshaped to
[batch, 1, in_width, in_channels],
and the filter is reshaped to
[1, filter_width, in_channels, out_channels].
The result is then reshaped back to
[batch, out_width, out_channels]
\(where out_width is a function of the stride and padding as in conv2d\) and
returned to the caller. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A 3D `Tensor`.  Must be of type `float16`, `float32`, or `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3D `Tensor`.  Must have the same type as `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> stride
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>'SAME' or 'VALID' 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`.  Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from `"NWC", "NCW"`.  Defaults to `"NWC"`,
the data is stored in the order of [batch, in_width, in_channels].  The
`"NCW"` format stores data as [batch, in_channels, in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`.  Has the same type as input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> stride, <span title="System.string">string</span> padding, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes a 1-D convolution given 3-D input and filter tensors. (deprecated argument values) (deprecated argument values) <p></p> Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(data_format='NCHW')`. They will be removed in a future version.
Instructions for updating:
`NCHW` for data_format is deprecated, use `NCW` instead <p></p> Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(data_format='NHWC')`. They will be removed in a future version.
Instructions for updating:
`NHWC` for data_format is deprecated, use `NWC` instead <p></p> Given an input tensor of shape
[batch, in_width, in_channels]
if data_format is "NWC", or
[batch, in_channels, in_width]
if data_format is "NCW",
and a filter / kernel tensor of shape
[filter_width, in_channels, out_channels], this op reshapes
the arguments to pass them to conv2d to perform the equivalent
convolution operation. <p></p> Internally, this op reshapes the input tensors and invokes <a href="..\..\tf\nn\conv2d.md"><code>tf.nn.conv2d</code></a>.
For example, if `data_format` does not start with "NC", a tensor of shape
[batch, in_width, in_channels]
is reshaped to
[batch, 1, in_width, in_channels],
and the filter is reshaped to
[1, filter_width, in_channels, out_channels].
The result is then reshaped back to
[batch, out_width, out_channels]
\(where out_width is a function of the stride and padding as in conv2d\) and
returned to the caller. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 3D `Tensor`.  Must be of type `float16`, `float32`, or `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3D `Tensor`.  Must have the same type as `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> stride
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>'SAME' or 'VALID' 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`.  Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from `"NWC", "NCW"`.  Defaults to `"NWC"`,
the data is stored in the order of [batch, in_width, in_channels].  The
`"NCW"` format stores data as [batch, in_channels, in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`.  Has the same type as input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.int">int</span> stride, <span title="System.string">string</span> padding, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes a 1-D convolution given 3-D input and filter tensors. (deprecated argument values) (deprecated argument values) <p></p> Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(data_format='NCHW')`. They will be removed in a future version.
Instructions for updating:
`NCHW` for data_format is deprecated, use `NCW` instead <p></p> Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(data_format='NHWC')`. They will be removed in a future version.
Instructions for updating:
`NHWC` for data_format is deprecated, use `NWC` instead <p></p> Given an input tensor of shape
[batch, in_width, in_channels]
if data_format is "NWC", or
[batch, in_channels, in_width]
if data_format is "NCW",
and a filter / kernel tensor of shape
[filter_width, in_channels, out_channels], this op reshapes
the arguments to pass them to conv2d to perform the equivalent
convolution operation. <p></p> Internally, this op reshapes the input tensors and invokes <a href="..\..\tf\nn\conv2d.md"><code>tf.nn.conv2d</code></a>.
For example, if `data_format` does not start with "NC", a tensor of shape
[batch, in_width, in_channels]
is reshaped to
[batch, 1, in_width, in_channels],
and the filter is reshaped to
[1, filter_width, in_channels, out_channels].
The result is then reshaped back to
[batch, out_width, out_channels]
\(where out_width is a function of the stride and padding as in conv2d\) and
returned to the caller. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 3D `Tensor`.  Must be of type `float16`, `float32`, or `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3D `Tensor`.  Must have the same type as `value`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> stride
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>'SAME' or 'VALID' 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`.  Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from `"NWC", "NCW"`.  Defaults to `"NWC"`,
the data is stored in the order of [batch, in_width, in_channels].  The
`"NCW"` format stores data as [batch, in_channels, in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`.  Has the same type as input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.int">int</span> stride, <span title="System.string">string</span> padding, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes a 1-D convolution given 3-D input and filter tensors. (deprecated argument values) (deprecated argument values) <p></p> Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(data_format='NCHW')`. They will be removed in a future version.
Instructions for updating:
`NCHW` for data_format is deprecated, use `NCW` instead <p></p> Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(data_format='NHWC')`. They will be removed in a future version.
Instructions for updating:
`NHWC` for data_format is deprecated, use `NWC` instead <p></p> Given an input tensor of shape
[batch, in_width, in_channels]
if data_format is "NWC", or
[batch, in_channels, in_width]
if data_format is "NCW",
and a filter / kernel tensor of shape
[filter_width, in_channels, out_channels], this op reshapes
the arguments to pass them to conv2d to perform the equivalent
convolution operation. <p></p> Internally, this op reshapes the input tensors and invokes <a href="..\..\tf\nn\conv2d.md"><code>tf.nn.conv2d</code></a>.
For example, if `data_format` does not start with "NC", a tensor of shape
[batch, in_width, in_channels]
is reshaped to
[batch, 1, in_width, in_channels],
and the filter is reshaped to
[1, filter_width, in_channels, out_channels].
The result is then reshaped back to
[batch, out_width, out_channels]
\(where out_width is a function of the stride and padding as in conv2d\) and
returned to the caller. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A 3D `Tensor`.  Must be of type `float16`, `float32`, or `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3D `Tensor`.  Must have the same type as `value`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> stride
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>'SAME' or 'VALID' 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`.  Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from `"NWC", "NCW"`.  Defaults to `"NWC"`,
the data is stored in the order of [batch, in_width, in_channels].  The
`"NCW"` format stores data as [batch, in_channels, in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`.  Has the same type as input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv1d_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> filters, <span title="System.object">object</span> stride, <span title="System.object">object</span> padding, <span title="System.object">object</span> use_cudnn_on_gpu, <span title="System.object">object</span> data_format, <span title="System.object">object</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes a 1-D convolution given 3-D input and filter tensors. (deprecated argument values) (deprecated argument values) <p></p> Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(data_format='NCHW')`. They will be removed in a future version.
Instructions for updating:
`NCHW` for data_format is deprecated, use `NCW` instead <p></p> Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(data_format='NHWC')`. They will be removed in a future version.
Instructions for updating:
`NHWC` for data_format is deprecated, use `NWC` instead <p></p> Given an input tensor of shape
[batch, in_width, in_channels]
if data_format is "NWC", or
[batch, in_channels, in_width]
if data_format is "NCW",
and a filter / kernel tensor of shape
[filter_width, in_channels, out_channels], this op reshapes
the arguments to pass them to conv2d to perform the equivalent
convolution operation. <p></p> Internally, this op reshapes the input tensors and invokes <a href="..\..\tf\nn\conv2d.md"><code>tf.nn.conv2d</code></a>.
For example, if `data_format` does not start with "NC", a tensor of shape
[batch, in_width, in_channels]
is reshaped to
[batch, 1, in_width, in_channels],
and the filter is reshaped to
[1, filter_width, in_channels, out_channels].
The result is then reshaped back to
[batch, out_width, out_channels]
\(where out_width is a function of the stride and padding as in conv2d\) and
returned to the caller. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 3D `Tensor`.  Must be of type `float16`, `float32`, or `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>A 3D `Tensor`.  Must have the same type as `value`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> stride
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>'SAME' or 'VALID' 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`.  Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>An optional `string` from `"NWC", "NCW"`.  Defaults to `"NWC"`,
the data is stored in the order of [batch, in_width, in_channels].  The
`"NCW"` format stores data as [batch, in_channels, in_width]. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`.  Has the same type as input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv1d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> filters, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.string">string</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_transpose_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv1d_transpose_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> output_shape, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <span title="System.object">object</span> dilations, <span title="System.object">object</span> name)
		</h4>
		<div class="content">The transpose of `conv1d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv1d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A 3-D `Tensor` of type `float` and shape
`[batch, in_width, in_channels]` for `NWC` data format or
`[batch, in_channels, in_width]` for `NCW` data format. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>A 3-D `Tensor` with the same type as `value` and shape
`[filter_width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor`, containing three elements, representing the
output shape of the deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`.  The number of
entries by which the filter is moved right at each step. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>A string. `'NWC'` and `'NCW'` are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3` which
defaults to 1. The dilation factor for each dimension of input. If set to
k > 1, there will be k-1 skipped cells between each filter element on that
dimension. Dilations in the batch and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span> strides, <span title="System.int">int</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span> strides, <span title="System.double">double</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.double">double</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.double">double</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span> strides, <span title="System.int">int</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span> strides, <span title="System.double">double</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object, object>">ValueTuple&lt;int, object, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.int">int</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.int">int</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.int">int</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.double">double</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.double">double</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.int">int</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_filter" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_filter</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the filter. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the tensor shape of `filter`,
where `filter` is a 4-D
`[filter_height, filter_width, in_channels, out_channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_filter" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_filter</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the filter. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the tensor shape of `filter`,
where `filter` is a 4-D
`[filter_height, filter_width, in_channels, out_channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_filter" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_filter</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the filter. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the tensor shape of `filter`,
where `filter` is a 4-D
`[filter_height, filter_width, in_channels, out_channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_filter" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_filter</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the filter. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the tensor shape of `filter`,
where `filter` is a 4-D
`[filter_height, filter_width, in_channels, out_channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_filter_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_backprop_filter_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter_sizes, <span title="System.object">object</span> out_backprop, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> use_cudnn_on_gpu, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the filter. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape `[batch, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the tensor shape of `filter`,
where `filter` is a 4-D
`[filter_height, filter_width, in_channels, out_channels]` tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_input" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_input</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`,
where `input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_input" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_input</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`,
where `input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_input" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_input</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`,
where `input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_input" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_input</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`,
where `input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_input" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_input</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`,
where `input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_input" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_input</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`,
where `input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_input" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_input</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`,
where `input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_input" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_input</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`,
where `input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_input" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_backprop_input</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.bool">bool</span> use_cudnn_on_gpu, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`,
where `input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_backprop_input_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_backprop_input_dyn</strong>(<span title="System.object">object</span> input_sizes, <span title="System.object">object</span> filter, <span title="System.object">object</span> out_backprop, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> use_cudnn_on_gpu, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.object">object</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes the gradients of convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`,
where `input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. Must be in the same order as the dimension specified
with format. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>Either the `string `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, in_height, in_width, in_channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, in_channels, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by
the value of `data_format`, see above for details. Dilations in the batch
and depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> use_cudnn_on_gpu, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.object">object</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 2-D convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following: <p></p> 1. Flattens the filter to a 2-D matrix with shape
`[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
tensor of shape `[batch, out_height, out_width,
filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
vector. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] =
sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]
* filter[di, dj, q, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types:
`half`, `bfloat16`, `float32`, `float64`.
A 4-D tensor. The dimension order is interpreted according to the value
of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
A 4-D tensor of shape
`[filter_height, filter_width, in_channels, out_channels]` 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 1. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>Either the `string` `"SAME"` or `"VALID"` indicating the type of
padding algorithm to use, or a list indicating the explicit paddings at
the start and end of each dimension. When explicit padding is used and
data_format is `"NHWC"`, this should be in the form `[[0, 0], [pad_top,
pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used
and data_format is `"NCHW"`, this should be in the form `[[0, 0], [0, 0],
[pad_top, pad_bottom], [pad_left, pad_right]]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> use_cudnn_on_gpu
						</dt>
						<dd>An optional `bool`. Defaults to `True`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`.
Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> output_shape, <span title="System.object">object</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> output_shape, <span title="System.object">object</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.object">object</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.object">object</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.object">object</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.object">object</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span> output_shape, <span title="System.object">object</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span> output_shape, <span title="System.object">object</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, PythonClassContainer>">ValueTuple&lt;IEnumerable&lt;object&gt;, PythonClassContainer&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> filter, <span title="System.object">object</span> output_shape, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <span title="System.object">object</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv2d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv2d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of type `float` and shape
`[batch, height, width, in_channels]` for `NHWC` data format or
`[batch, in_channels, height, width]` for `NCHW` data format. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>A 4-D `Tensor` with the same type as `value` and shape
`[height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.  The
stride of the sliding window for each dimension of `input`. If a single
value is given it is replicated in the `H` and `W` dimension. By default
the `N` and `C` dimensions are set to 0. The dimension order is determined
by the value of `data_format`, see below for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>A string. 'NHWC' and 'NCHW' are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias for filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `H` and `W` dimension. By
default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 4-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 3-D convolution given 5-D `input` and `filter` tensors. <p></p> In signal processing, cross-correlation is a measure of similarity of
two waveforms as a function of a time-lag applied to one of them. This
is also known as a sliding dot product or sliding inner-product. <p></p> Our Conv3D implements a form of cross-correlation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
Shape `[batch, in_depth, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
Shape `[filter_depth, filter_height, filter_width, in_channels,
out_channels]`. `in_channels` must match between `input` and `filter`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints` that has length `>= 5`.
1-D tensor of length 5. The stride of the sliding window for each
dimension of `input`. Must have `strides[0] = strides[4] = 1`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
The data format of the input and output data. With the
default format "NDHWC", the data is stored in the order of:
[batch, in_depth, in_height, in_width, in_channels].
Alternatively, the format could be "NCDHW", the data storage order is:
[batch, in_channels, in_depth, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1, 1]`.
1-D tensor of length 5.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by the
value of `data_format`, see above for details. Dilations in the batch and
depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_backprop_filter" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_backprop_filter</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the gradients of 3-D convolution with respect to the filter. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
Shape `[batch, depth, rows, cols, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the tensor shape of `filter`,
where `filter` is a 5-D
`[filter_depth, filter_height, filter_width, in_channels, out_channels]`
tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints` that has length `>= 5`.
1-D tensor of length 5. The stride of the sliding window for each
dimension of `input`. Must have `strides[0] = strides[4] = 1`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
The data format of the input and output data. With the
default format "NDHWC", the data is stored in the order of:
[batch, in_depth, in_height, in_width, in_channels].
Alternatively, the format could be "NCDHW", the data storage order is:
[batch, in_channels, in_depth, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1, 1]`.
1-D tensor of length 5.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by the
value of `data_format`, see above for details. Dilations in the batch and
depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_backprop_filter_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv3d_backprop_filter_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter_sizes, <span title="System.object">object</span> out_backprop, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the gradients of 3-D convolution with respect to the filter. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
Shape `[batch, depth, rows, cols, in_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the tensor shape of `filter`,
where `filter` is a 5-D
`[filter_depth, filter_height, filter_width, in_channels, out_channels]`
tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints` that has length `>= 5`.
1-D tensor of length 5. The stride of the sliding window for each
dimension of `input`. Must have `strides[0] = strides[4] = 1`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
The data format of the input and output data. With the
default format "NDHWC", the data is stored in the order of:
[batch, in_depth, in_height, in_width, in_channels].
Alternatively, the format could be "NCDHW", the data storage order is:
[batch, in_channels, in_depth, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1, 1]`.
1-D tensor of length 5.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by the
value of `data_format`, see above for details. Dilations in the batch and
depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv3d_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.object">object</span> name, <span title="System.object">object</span> filters)
		</h4>
		<div class="content">Computes a 3-D convolution given 5-D `input` and `filter` tensors. <p></p> In signal processing, cross-correlation is a measure of similarity of
two waveforms as a function of a time-lag applied to one of them. This
is also known as a sliding dot product or sliding inner-product. <p></p> Our Conv3D implements a form of cross-correlation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
Shape `[batch, in_depth, in_height, in_width, in_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
Shape `[filter_depth, filter_height, filter_width, in_channels,
out_channels]`. `in_channels` must match between `input` and `filter`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints` that has length `>= 5`.
1-D tensor of length 5. The stride of the sliding window for each
dimension of `input`. Must have `strides[0] = strides[4] = 1`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
The data format of the input and output data. With the
default format "NDHWC", the data is stored in the order of:
[batch, in_depth, in_height, in_width, in_channels].
Alternatively, the format could be "NCDHW", the data storage order is:
[batch, in_channels, in_depth, in_height, in_width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1, 1]`.
1-D tensor of length 5.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each
filter element on that dimension. The dimension order is determined by the
value of `data_format`, see above for details. Dilations in the batch and
depth dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> output_shape, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> output_shape, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>conv3d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> output_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_transpose_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv3d_transpose_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> filter, <span title="System.object">object</span> output_shape, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <span title="System.object">object</span> name, <span title="System.object">object</span> input, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">The transpose of `conv3d`. <p></p> This operation is sometimes called "deconvolution" after [Deconvolutional
Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf),
but is really the transpose (gradient) of `conv3d` rather than an actual
deconvolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 5-D `Tensor` of type `float` and shape
`[batch, depth, height, width, in_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>A 5-D `Tensor` with the same type as `value` and shape
`[depth, height, width, output_channels, in_channels]`.  `filter`'s
`in_channels` dimension must match that of `value`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>A 1-D `Tensor` representing the output shape of the
deconvolution op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of ints. The stride of the sliding window for each
dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>A string, either `'NDHWC'` or `'NCDHW`' specifying the layout
of the input and output tensors. Defaults to `'NDHWC'`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias of value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`,
defaults to 1. The dilation factor for each dimension of`input`. If a
single value is given it is replicated in the `D`, `H` and `W` dimension.
By default the `N` and `C` dimensions are set to 1. If set to k > 1, there
will be k-1 skipped cells between each filter element on that dimension.
The dimension order is determined by the value of `data_format`, see above
for details. Dilations in the batch and depth dimensions if a 5-d tensor
must be 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `value`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.string">string</span> padding, <span title="System.int">int</span> strides, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convolution_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convolution_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter, <span title="System.object">object</span> padding, <span title="System.object">object</span> strides, <span title="System.object">object</span> dilation_rate, <span title="System.object">object</span> name, <span title="System.object">object</span> data_format, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes sums of N-D convolutions (actually cross-correlation). <p></p> This also supports either output striding via the optional `strides` parameter
or atrous convolution (also known as convolution with holes or dilated
convolution, based on the French word "trous" meaning holes in English) via
the optional `dilation_rate` parameter.  Currently, however, output striding
is not supported for atrous convolutions. <p></p> Specifically, in the case that `data_format` does not start with "NC", given
a rank (N+2) `input` Tensor of shape <p></p> [num_batches,
input_spatial_shape[0],
...,
input_spatial_shape[N-1],
num_input_channels], <p></p> a rank (N+2) `filter` Tensor of shape <p></p> [spatial_filter_shape[0],
...,
spatial_filter_shape[N-1],
num_input_channels,
num_output_channels], <p></p> an optional `dilation_rate` tensor of shape [N] (defaulting to [1]*N)
specifying the filter upsampling/input downsampling rate, and an optional list
of N `strides` (defaulting [1]*N), this computes for each N-D spatial output
position (x[0],..., x[N-1]): <p></p> ```
output[b, x[0],..., x[N-1], k] =
sum_{z[0],..., z[N-1], q}
filter[z[0],..., z[N-1], q, k] *
padded_input[b,
x[0]*strides[0] + dilation_rate[0]*z[0],
...,
x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],
q]
```
where b is the index into the batch, k is the output channel number, q is the
input channel number, and z is the N-D spatial offset within the filter. Here,
`padded_input` is obtained by zero padding the input using an effective
spatial filter shape of `(spatial_filter_shape-1) * dilation_rate + 1` and
output striding `strides` as described in the
[comment here](https://tensorflow.org/api_guides/python/nn#Convolution). <p></p> In the case that `data_format` does start with `"NC"`, the `input` and output
(but not the `filter`) are simply transposed as follows: <p></p> convolution(input, data_format, **kwargs) =
tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1)) <p></p> It is required that 1 <= N <= 3. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>An (N+2)-D `Tensor` of type `T`, of shape
`[batch_size] + input_spatial_shape + [in_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, in_channels] + input_spatial_shape` if data_format starts
with "NC". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>An (N+2)-D `Tensor` with the same type as `input` and shape
`spatial_filter_shape + [in_channels, out_channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `"VALID"` or `"SAME"`. The padding algorithm. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the output stride.
Defaults to [1]*N.  If any value of strides is > 1, then all values of
dilation_rate must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilation_rate
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Specifies the filter
upsampling/input downsampling rate.  In the literature, the same parameter
is sometimes called `input stride` or `dilation`.  The effective filter
size used for the convolution will be `spatial_filter_shape +
(spatial_filter_shape - 1) * (rate - 1)`, obtained by inserting
(dilation_rate[i]-1) zeros between consecutive elements of the original
filter in each spatial dimension i.  If any value of dilation_rate is > 1,
then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dd>Alias of filter. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of dilation_rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `input` of shape <p></p> `[batch_size] + output_spatial_shape + [out_channels]` <p></p> if data_format is None or does not start with "NC", or <p></p> `[batch_size, out_channels] + output_spatial_shape` <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of `padding`. <p></p> If padding == "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding == "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] -
(spatial_filter_shape[i]-1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crelu" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crelu</strong>(<a href="../numpy/ndarray.htm">ndarray</a> features, <span title="System.string">string</span> name, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Computes Concatenated ReLU. <p></p> Concatenates a ReLU which selects only the positive part of the activation
with a ReLU which selects only the *negative* part of the activation.
Note that as a result this non-linearity doubles the depth of the activations.
Source: [Understanding and Improving Convolutional Neural Networks via
Concatenated Rectified Linear Units. W. Shang, et
al.](https://arxiv.org/abs/1603.05201) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> features
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,
`int16`, or `int8`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The axis that the output values are concatenated along. Default is -1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crelu" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crelu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> features, <span title="System.string">string</span> name, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Computes Concatenated ReLU. <p></p> Concatenates a ReLU which selects only the positive part of the activation
with a ReLU which selects only the *negative* part of the activation.
Note that as a result this non-linearity doubles the depth of the activations.
Source: [Understanding and Improving Convolutional Neural Networks via
Concatenated Rectified Linear Units. W. Shang, et
al.](https://arxiv.org/abs/1603.05201) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> features
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,
`int16`, or `int8`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The axis that the output values are concatenated along. Default is -1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crelu_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>crelu_dyn</strong>(<span title="System.object">object</span> features, <span title="System.object">object</span> name, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis)
		</h4>
		<div class="content">Computes Concatenated ReLU. <p></p> Concatenates a ReLU which selects only the positive part of the activation
with a ReLU which selects only the *negative* part of the activation.
Note that as a result this non-linearity doubles the depth of the activations.
Source: [Understanding and Improving Convolutional Neural Networks via
Concatenated Rectified Linear Units. W. Shang, et
al.](https://arxiv.org/abs/1603.05201) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> features
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,
`int16`, or `int8`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>The axis that the output values are concatenated along. Default is -1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_beam_search_decoder</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). <p></p> If `merge_repeated` is `True`, merge repeated classes in the output beams.
This means that if consecutive entries in a beam are the same,
only the first of these is emitted.  That is, when the sequence is
`A B B * B * B` (where '*' is the blank label), the return value is: <p></p> * `A B` if `merge_repeated = True`.
* `A B B B` if `merge_repeated = False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time x batch_size x num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_beam_search_decoder</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). <p></p> If `merge_repeated` is `True`, merge repeated classes in the output beams.
This means that if consecutive entries in a beam are the same,
only the first of these is emitted.  That is, when the sequence is
`A B B * B * B` (where '*' is the blank label), the return value is: <p></p> * `A B` if `merge_repeated = True`.
* `A B B B` if `merge_repeated = False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time x batch_size x num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_beam_search_decoder</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). <p></p> If `merge_repeated` is `True`, merge repeated classes in the output beams.
This means that if consecutive entries in a beam are the same,
only the first of these is emitted.  That is, when the sequence is
`A B B * B * B` (where '*' is the blank label), the return value is: <p></p> * `A B` if `merge_repeated = True`.
* `A B B B` if `merge_repeated = False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time x batch_size x num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_beam_search_decoder</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../numpy/ndarray.htm">ndarray</a> sequence_length, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). <p></p> If `merge_repeated` is `True`, merge repeated classes in the output beams.
This means that if consecutive entries in a beam are the same,
only the first of these is emitted.  That is, when the sequence is
`A B B * B * B` (where '*' is the blank label), the return value is: <p></p> * `A B` if `merge_repeated = True`.
* `A B B B` if `merge_repeated = False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time x batch_size x num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_beam_search_decoder</strong>(<span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). <p></p> If `merge_repeated` is `True`, merge repeated classes in the output beams.
This means that if consecutive entries in a beam are the same,
only the first of these is emitted.  That is, when the sequence is
`A B B * B * B` (where '*' is the blank label), the return value is: <p></p> * `A B` if `merge_repeated = True`.
* `A B B B` if `merge_repeated = False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time x batch_size x num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_beam_search_decoder</strong>(<span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). <p></p> If `merge_repeated` is `True`, merge repeated classes in the output beams.
This means that if consecutive entries in a beam are the same,
only the first of these is emitted.  That is, when the sequence is
`A B B * B * B` (where '*' is the blank label), the return value is: <p></p> * `A B` if `merge_repeated = True`.
* `A B B B` if `merge_repeated = False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time x batch_size x num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_beam_search_decoder</strong>(<span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). <p></p> If `merge_repeated` is `True`, merge repeated classes in the output beams.
This means that if consecutive entries in a beam are the same,
only the first of these is emitted.  That is, when the sequence is
`A B B * B * B` (where '*' is the blank label), the return value is: <p></p> * `A B` if `merge_repeated = True`.
* `A B B B` if `merge_repeated = False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time x batch_size x num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_beam_search_decoder</strong>(<span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span> inputs, <a href="../numpy/ndarray.htm">ndarray</a> sequence_length, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). <p></p> If `merge_repeated` is `True`, merge repeated classes in the output beams.
This means that if consecutive entries in a beam are the same,
only the first of these is emitted.  That is, when the sequence is
`A B B * B * B` (where '*' is the blank label), the return value is: <p></p> * `A B` if `merge_repeated = True`.
* `A B B B` if `merge_repeated = False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time x batch_size x num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_beam_search_decoder_dyn</strong>(<span title="System.object">object</span> inputs, <span title="System.object">object</span> sequence_length, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> beam_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> top_paths, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> merge_repeated)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). <p></p> If `merge_repeated` is `True`, merge repeated classes in the output beams.
This means that if consecutive entries in a beam are the same,
only the first of these is emitted.  That is, when the sequence is
`A B B * B * B` (where '*' is the blank label), the return value is: <p></p> * `A B` if `merge_repeated = True`.
* `A B B B` if `merge_repeated = False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time x batch_size x num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder_v2" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_beam_search_decoder_v2</strong>(<span title="System.object">object</span> inputs, <span title="System.object">object</span> sequence_length, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_beam_search_decoder_v2_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_beam_search_decoder_v2_dyn</strong>(<span title="System.object">object</span> inputs, <span title="System.object">object</span> sequence_length, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> beam_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> top_paths)
		</h4>
		<div class="content">Performs beam search decoding on the logits given in input. <p></p> **Note** The `ctc_greedy_decoder` is a special case of the
`ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but
that decoder is faster for this special case). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`, size `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> beam_width
						</dt>
						<dd>An int scalar >= 0 (beam search beam width). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> top_paths
						</dt>
						<dd>An int scalar >= 0, <= beam_width (controls output size). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple `(decoded, log_probabilities)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_greedy_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_greedy_decoder</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs greedy decoding on the logits given in input (best path). <p></p> Note: Regardless of the value of merge_repeated, if the maximum index of a
given time and batch corresponds to the blank index `(num_classes - 1)`, no
new element is emitted. <p></p> If `merge_repeated` is `True`, merge repeated classes in output.
This means that if consecutive logits' maximum indices are the same,
only the first of these is emitted.  The sequence `A B B * B * B` (where '*'
is the blank label) becomes <p></p> * `A B B B` if `merge_repeated=True`.
* `A B B B B` if `merge_repeated=False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor` sized `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, neg_sum_logits)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_greedy_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_greedy_decoder</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs greedy decoding on the logits given in input (best path). <p></p> Note: Regardless of the value of merge_repeated, if the maximum index of a
given time and batch corresponds to the blank index `(num_classes - 1)`, no
new element is emitted. <p></p> If `merge_repeated` is `True`, merge repeated classes in output.
This means that if consecutive logits' maximum indices are the same,
only the first of these is emitted.  The sequence `A B B * B * B` (where '*'
is the blank label) becomes <p></p> * `A B B B` if `merge_repeated=True`.
* `A B B B B` if `merge_repeated=False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor` sized `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, neg_sum_logits)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_greedy_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_greedy_decoder</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs greedy decoding on the logits given in input (best path). <p></p> Note: Regardless of the value of merge_repeated, if the maximum index of a
given time and batch corresponds to the blank index `(num_classes - 1)`, no
new element is emitted. <p></p> If `merge_repeated` is `True`, merge repeated classes in output.
This means that if consecutive logits' maximum indices are the same,
only the first of these is emitted.  The sequence `A B B * B * B` (where '*'
is the blank label) becomes <p></p> * `A B B B` if `merge_repeated=True`.
* `A B B B B` if `merge_repeated=False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor` sized `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, neg_sum_logits)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_greedy_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_greedy_decoder</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../numpy/ndarray.htm">ndarray</a> sequence_length, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs greedy decoding on the logits given in input (best path). <p></p> Note: Regardless of the value of merge_repeated, if the maximum index of a
given time and batch corresponds to the blank index `(num_classes - 1)`, no
new element is emitted. <p></p> If `merge_repeated` is `True`, merge repeated classes in output.
This means that if consecutive logits' maximum indices are the same,
only the first of these is emitted.  The sequence `A B B * B * B` (where '*'
is the blank label) becomes <p></p> * `A B B B` if `merge_repeated=True`.
* `A B B B B` if `merge_repeated=False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor` sized `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, neg_sum_logits)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_greedy_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_greedy_decoder</strong>(<span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs greedy decoding on the logits given in input (best path). <p></p> Note: Regardless of the value of merge_repeated, if the maximum index of a
given time and batch corresponds to the blank index `(num_classes - 1)`, no
new element is emitted. <p></p> If `merge_repeated` is `True`, merge repeated classes in output.
This means that if consecutive logits' maximum indices are the same,
only the first of these is emitted.  The sequence `A B B * B * B` (where '*'
is the blank label) becomes <p></p> * `A B B B` if `merge_repeated=True`.
* `A B B B B` if `merge_repeated=False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor` sized `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, neg_sum_logits)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_greedy_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_greedy_decoder</strong>(<span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs greedy decoding on the logits given in input (best path). <p></p> Note: Regardless of the value of merge_repeated, if the maximum index of a
given time and batch corresponds to the blank index `(num_classes - 1)`, no
new element is emitted. <p></p> If `merge_repeated` is `True`, merge repeated classes in output.
This means that if consecutive logits' maximum indices are the same,
only the first of these is emitted.  The sequence `A B B * B * B` (where '*'
is the blank label) becomes <p></p> * `A B B B` if `merge_repeated=True`.
* `A B B B B` if `merge_repeated=False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor` sized `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, neg_sum_logits)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_greedy_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_greedy_decoder</strong>(<span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs greedy decoding on the logits given in input (best path). <p></p> Note: Regardless of the value of merge_repeated, if the maximum index of a
given time and batch corresponds to the blank index `(num_classes - 1)`, no
new element is emitted. <p></p> If `merge_repeated` is `True`, merge repeated classes in output.
This means that if consecutive logits' maximum indices are the same,
only the first of these is emitted.  The sequence `A B B * B * B` (where '*'
is the blank label) becomes <p></p> * `A B B B` if `merge_repeated=True`.
* `A B B B B` if `merge_repeated=False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor` sized `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, neg_sum_logits)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_greedy_decoder" class="method">
		<h4>
			<span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span> <strong>ctc_greedy_decoder</strong>(<span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span> inputs, <a href="../numpy/ndarray.htm">ndarray</a> sequence_length, <span title="System.bool">bool</span> merge_repeated)
		</h4>
		<div class="content">Performs greedy decoding on the logits given in input (best path). <p></p> Note: Regardless of the value of merge_repeated, if the maximum index of a
given time and batch corresponds to the blank index `(num_classes - 1)`, no
new element is emitted. <p></p> If `merge_repeated` is `True`, merge repeated classes in output.
This means that if consecutive logits' maximum indices are the same,
only the first of these is emitted.  The sequence `A B B * B * B` (where '*'
is the blank label) becomes <p></p> * `A B B B` if `merge_repeated=True`.
* `A B B B B` if `merge_repeated=False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor` sized `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<SparseTensor>, object>">ValueTuple&lt;IList&lt;SparseTensor&gt;, object&gt;</span></code>
					</dt>
					<dd>A tuple `(decoded, neg_sum_logits)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_greedy_decoder_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_greedy_decoder_dyn</strong>(<span title="System.object">object</span> inputs, <span title="System.object">object</span> sequence_length, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> merge_repeated)
		</h4>
		<div class="content">Performs greedy decoding on the logits given in input (best path). <p></p> Note: Regardless of the value of merge_repeated, if the maximum index of a
given time and batch corresponds to the blank index `(num_classes - 1)`, no
new element is emitted. <p></p> If `merge_repeated` is `True`, merge repeated classes in output.
This means that if consecutive logits' maximum indices are the same,
only the first of these is emitted.  The sequence `A B B * B * B` (where '*'
is the blank label) becomes <p></p> * `A B B B` if `merge_repeated=True`.
* `A B B B B` if `merge_repeated=False`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor` sized `[max_time, batch_size, num_classes]`.
The logits. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector containing sequence lengths, having size
`[batch_size]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple `(decoded, neg_sum_logits)` where 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../numpy/ndarray.htm">ndarray</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <a href="../numpy/ndarray.htm">ndarray</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../numpy/ndarray.htm">ndarray</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <a href="../numpy/ndarray.htm">ndarray</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <a href="../numpy/ndarray.htm">ndarray</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../numpy/ndarray.htm">ndarray</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.bool">bool</span> preprocess_collapse_repeated, <span title="System.bool">bool</span> ctc_merge_repeated, <span title="System.bool">bool</span> ignore_longer_outputs_than_inputs, <span title="System.bool">bool</span> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss_dyn</strong>(<span title="System.object">object</span> labels, <span title="System.object">object</span> inputs, <span title="System.object">object</span> sequence_length, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> preprocess_collapse_repeated, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> ctc_merge_repeated, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> ignore_longer_outputs_than_inputs, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> time_major, <span title="System.object">object</span> logits)
		</h4>
		<div class="content">Computes the CTC (Connectionist Temporal Classification) Loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Input requirements: <p></p> ```
sequence_length(b) <= time for all b <p></p> max(labels.indices(labels.indices[:, 1] == b, 2))
<= sequence_length(b) for all b.
``` <p></p> Notes: <p></p> This class performs the softmax operation for you, so inputs should
be e.g. linear projections of outputs by an LSTM. <p></p> The `inputs` Tensor's innermost dimension size, `num_classes`, represents
`num_labels + 1` classes, where num_labels is the number of true labels, and
the largest value `(num_classes - 1)` is reserved for the blank label. <p></p> For example, for a vocabulary containing 3 labels `[a, b, c]`,
`num_classes = 4` and the labels indexing is `{a: 0, b: 1, c: 2, blank: 3}`. <p></p> Regarding the arguments `preprocess_collapse_repeated` and
`ctc_merge_repeated`: <p></p> If `preprocess_collapse_repeated` is True, then a preprocessing step runs
before loss calculation, wherein repeated labels passed to the loss
are merged into single labels.  This is useful if the training labels come
from, e.g., forced alignments and therefore have unnecessary repetitions. <p></p> If `ctc_merge_repeated` is set False, then deep within the CTC calculation,
repeated non-blank labels will not be merged and are interpreted
as individual labels.  This is a simplified (non-standard) version of CTC. <p></p> Here is a table of the (roughly) expected first order behavior: <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=True` <p></p> Classical CTC behavior: Outputs true repeated classes with blanks in
between, and can also output repeated classes with no blanks in
between that need to be collapsed by the decoder. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=False` <p></p> Never learns to output repeated classes, as they are collapsed
in the input labels before training. <p></p> * `preprocess_collapse_repeated=False`, `ctc_merge_repeated=False` <p></p> Outputs repeated classes with blanks in between, but generally does not
require the decoder to collapse/merge repeated classes. <p></p> * `preprocess_collapse_repeated=True`, `ctc_merge_repeated=True` <p></p> Untested.  Very likely will not learn to output repeated classes. <p></p> The `ignore_longer_outputs_than_inputs` option allows to specify the behavior
of the CTCLoss when dealing with sequences that have longer outputs than
inputs. If true, the CTCLoss will simply return zero gradient for those
items, otherwise an InvalidArgument error is returned, stopping training. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>An `int32` `SparseTensor`.
`labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id
for (batch b, time t). `labels.values[i]` must take on values in `[0,
num_labels)`. See `core/ops/ctc_ops.cc` for more details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>3-D `float` `Tensor`.
If time_major == False, this will be a `Tensor` shaped: `[batch_size,
max_time, num_classes]`.
If time_major == True (default), this will be a `Tensor` shaped:
`[max_time, batch_size, num_classes]`. The logits. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>1-D `int32` vector, size `[batch_size]`. The sequence
lengths. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> preprocess_collapse_repeated
						</dt>
						<dd>Boolean.  Default: False. If True, repeated
labels are collapsed prior to the CTC calculation. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> ctc_merge_repeated
						</dt>
						<dd>Boolean.  Default: True. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> ignore_longer_outputs_than_inputs
						</dt>
						<dd>Boolean. Default: False. If True,
sequences with longer outputs than inputs will be ignored. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> time_major
						</dt>
						<dd>The shape format of the `inputs` Tensors. If True, these
`Tensors` must be shaped `[max_time, batch_size, num_classes]`. If False,
these `Tensors` must be shaped `[batch_size, max_time, num_classes]`.
Using `time_major = True` (default) is a bit more efficient because it
avoids transposes at the beginning of the ctc_loss calculation.  However,
most TensorFlow data is batch-major, so by this function also accepts
inputs in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Alias for inputs. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1-D `float` `Tensor`, size `[batch]`, containing the negative log
probabilities. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss_v2" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss_v2</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> logits, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_length, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> logit_length, <span title="System.bool">bool</span> logits_time_major, <span title="System.object">object</span> unique, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> blank_index, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes CTC (Connectionist Temporal Classification) loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Notes: <p></p> - Same as the "Classic CTC" in TensorFlow 1.x's tf.compat.v1.nn.ctc_loss
setting of preprocess_collapse_repeated=False, ctc_merge_repeated=True
- Labels may be supplied as either a dense, zero-padded tensor with a
vector of label sequence lengths OR as a SparseTensor.
- On TPU and GPU: Only dense padded labels are supported.
- On CPU: Caller may use SparseTensor or dense padded labels but calling with
a SparseTensor will be significantly faster.
- Default blank label is 0 rather num_classes - 1, unless overridden by
blank_index. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>tensor of shape [batch_size, max_label_seq_length] or SparseTensor 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> logits
						</dt>
						<dd>tensor of shape [frames, batch_size, num_labels], if
logits_time_major == False, shape is [batch_size, frames, num_labels]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_length
						</dt>
						<dd>tensor of shape [batch_size], None if labels is SparseTensor
Length of reference label sequence in labels. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> logit_length
						</dt>
						<dd>tensor of shape [batch_size] Length of input sequence in
logits. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> logits_time_major
						</dt>
						<dd>(optional) If True (default), logits is shaped [time,
batch, logits]. If False, shape is [batch, time, logits] 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> unique
						</dt>
						<dd>(optional) Unique label indices as computed by
ctc_unique_labels(labels).  If supplied, enable a faster, memory efficient
implementation on TPU. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> blank_index
						</dt>
						<dd>(optional) Set the class index to use for the blank label.
Negative values will start from num_classes, ie, -1 will reproduce the
ctc_loss behavior of using num_classes - 1 for the blank symbol. There is
some memory/performance overhead to switching from the default of 0 as an
additional shifted copy of the logits may be created. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "ctc_loss_dense". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss_v2" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss_v2</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> logits, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_length, <a href="../numpy/ndarray.htm">ndarray</a> logit_length, <span title="System.bool">bool</span> logits_time_major, <span title="System.object">object</span> unique, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> blank_index, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes CTC (Connectionist Temporal Classification) loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Notes: <p></p> - Same as the "Classic CTC" in TensorFlow 1.x's tf.compat.v1.nn.ctc_loss
setting of preprocess_collapse_repeated=False, ctc_merge_repeated=True
- Labels may be supplied as either a dense, zero-padded tensor with a
vector of label sequence lengths OR as a SparseTensor.
- On TPU and GPU: Only dense padded labels are supported.
- On CPU: Caller may use SparseTensor or dense padded labels but calling with
a SparseTensor will be significantly faster.
- Default blank label is 0 rather num_classes - 1, unless overridden by
blank_index. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>tensor of shape [batch_size, max_label_seq_length] or SparseTensor 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> logits
						</dt>
						<dd>tensor of shape [frames, batch_size, num_labels], if
logits_time_major == False, shape is [batch_size, frames, num_labels]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_length
						</dt>
						<dd>tensor of shape [batch_size], None if labels is SparseTensor
Length of reference label sequence in labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> logit_length
						</dt>
						<dd>tensor of shape [batch_size] Length of input sequence in
logits. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> logits_time_major
						</dt>
						<dd>(optional) If True (default), logits is shaped [time,
batch, logits]. If False, shape is [batch, time, logits] 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> unique
						</dt>
						<dd>(optional) Unique label indices as computed by
ctc_unique_labels(labels).  If supplied, enable a faster, memory efficient
implementation on TPU. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> blank_index
						</dt>
						<dd>(optional) Set the class index to use for the blank label.
Negative values will start from num_classes, ie, -1 will reproduce the
ctc_loss behavior of using num_classes - 1 for the blank symbol. There is
some memory/performance overhead to switching from the default of 0 as an
additional shifted copy of the logits may be created. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "ctc_loss_dense". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_loss_v2_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_loss_v2_dyn</strong>(<span title="System.object">object</span> labels, <span title="System.object">object</span> logits, <span title="System.object">object</span> label_length, <span title="System.object">object</span> logit_length, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> logits_time_major, <span title="System.object">object</span> unique, <span title="System.object">object</span> blank_index, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes CTC (Connectionist Temporal Classification) loss. <p></p> This op implements the CTC loss as presented in the article: <p></p> [A. Graves, S. Fernandez, F. Gomez, J. Schmidhuber.
Connectionist Temporal Classification: Labeling Unsegmented Sequence Data
with Recurrent Neural Networks. ICML 2006, Pittsburgh, USA,
pp. 369-376.](http://www.cs.toronto.edu/~graves/icml_2006.pdf) <p></p> Notes: <p></p> - Same as the "Classic CTC" in TensorFlow 1.x's tf.compat.v1.nn.ctc_loss
setting of preprocess_collapse_repeated=False, ctc_merge_repeated=True
- Labels may be supplied as either a dense, zero-padded tensor with a
vector of label sequence lengths OR as a SparseTensor.
- On TPU and GPU: Only dense padded labels are supported.
- On CPU: Caller may use SparseTensor or dense padded labels but calling with
a SparseTensor will be significantly faster.
- Default blank label is 0 rather num_classes - 1, unless overridden by
blank_index. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>tensor of shape [batch_size, max_label_seq_length] or SparseTensor 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>tensor of shape [frames, batch_size, num_labels], if
logits_time_major == False, shape is [batch_size, frames, num_labels]. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> label_length
						</dt>
						<dd>tensor of shape [batch_size], None if labels is SparseTensor
Length of reference label sequence in labels. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logit_length
						</dt>
						<dd>tensor of shape [batch_size] Length of input sequence in
logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> logits_time_major
						</dt>
						<dd>(optional) If True (default), logits is shaped [time,
batch, logits]. If False, shape is [batch, time, logits] 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> unique
						</dt>
						<dd>(optional) Unique label indices as computed by
ctc_unique_labels(labels).  If supplied, enable a faster, memory efficient
implementation on TPU. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> blank_index
						</dt>
						<dd>(optional) Set the class index to use for the blank label.
Negative values will start from num_classes, ie, -1 will reproduce the
ctc_loss behavior of using num_classes - 1 for the blank symbol. There is
some memory/performance overhead to switching from the default of 0 as an
additional shifted copy of the logits may be created. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "ctc_loss_dense". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_unique_labels" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_unique_labels</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Get unique labels and indices for batched labels for <a href="..\..\tf\nn\ctc_loss.md"><code>tf.nn.ctc_loss</code></a>. <p></p> For use with <a href="..\..\tf\nn\ctc_loss.md"><code>tf.nn.ctc_loss</code></a> optional argument `unique`: This op can be
used to preprocess labels in input pipeline to for better speed/memory use
computing the ctc loss on TPU. <p></p> Example:
ctc_unique_labels([[3, 4, 4, 3]]) ->
unique labels padded with 0: [[3, 4, 0, 0]]
indices of original labels in unique: [0, 1, 1, 0] 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>tensor of shape [batch_size, max_label_length] padded with 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "ctc_unique_labels". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>tuple of
- unique labels, tensor of shape `[batch_size, max_label_length]`
- indices into unique labels, shape `[batch_size, max_label_length]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_unique_labels" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_unique_labels</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> labels, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Get unique labels and indices for batched labels for <a href="..\..\tf\nn\ctc_loss.md"><code>tf.nn.ctc_loss</code></a>. <p></p> For use with <a href="..\..\tf\nn\ctc_loss.md"><code>tf.nn.ctc_loss</code></a> optional argument `unique`: This op can be
used to preprocess labels in input pipeline to for better speed/memory use
computing the ctc loss on TPU. <p></p> Example:
ctc_unique_labels([[3, 4, 4, 3]]) ->
unique labels padded with 0: [[3, 4, 0, 0]]
indices of original labels in unique: [0, 1, 1, 0] 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> labels
						</dt>
						<dd>tensor of shape [batch_size, max_label_length] padded with 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "ctc_unique_labels". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>tuple of
- unique labels, tensor of shape `[batch_size, max_label_length]`
- indices into unique labels, shape `[batch_size, max_label_length]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_unique_labels_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_unique_labels_dyn</strong>(<span title="System.object">object</span> labels, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Get unique labels and indices for batched labels for <a href="..\..\tf\nn\ctc_loss.md"><code>tf.nn.ctc_loss</code></a>. <p></p> For use with <a href="..\..\tf\nn\ctc_loss.md"><code>tf.nn.ctc_loss</code></a> optional argument `unique`: This op can be
used to preprocess labels in input pipeline to for better speed/memory use
computing the ctc loss on TPU. <p></p> Example:
ctc_unique_labels([[3, 4, 4, 3]]) ->
unique labels padded with 0: [[3, 4, 0, 0]]
indices of original labels in unique: [0, 1, 1, 0] 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>tensor of shape [batch_size, max_label_length] padded with 0. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this `Op`. Defaults to "ctc_unique_labels". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>tuple of
- unique labels, tensor of shape `[batch_size, max_label_length]`
- indices into unique labels, shape `[batch_size, max_label_length]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.object">object</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.object">object</span> filter, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.object">object</span> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.string">string</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.string">string</span> filter, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.object">object</span> filter, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.string">string</span> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.string">string</span> filter, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.object">object</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.object">object</span> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.string">string</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.string">string</span> filter, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.string">string</span> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.string">string</span> filter, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.object">object</span> filter, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.object">object</span> filter, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_backprop_filter" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_backprop_filter</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the gradients of depthwise convolution with respect to the filter. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
4-D with shape based on `data_format`.  For example, if
`data_format` is 'NHWC' then `input` is a 4-D `[batch, in_height,
in_width, in_channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the tensor shape of `filter`,
where `filter` is a 4-D
`[filter_height, filter_width, in_channels, depthwise_multiplier]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
4-D with shape  based on `data_format`.
For example, if `data_format` is 'NHWC' then
out_backprop shape is `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_backprop_filter_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>depthwise_conv2d_backprop_filter_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter_sizes, <span title="System.object">object</span> out_backprop, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the gradients of depthwise convolution with respect to the filter. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
4-D with shape based on `data_format`.  For example, if
`data_format` is 'NHWC' then `input` is a 4-D `[batch, in_height,
in_width, in_channels]` tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the tensor shape of `filter`,
where `filter` is a 4-D
`[filter_height, filter_width, in_channels, depthwise_multiplier]` tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
4-D with shape  based on `data_format`.
For example, if `data_format` is 'NHWC' then
out_backprop shape is `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_backprop_input" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_backprop_input</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_sizes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> out_backprop, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the gradients of depthwise convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`, based
on `data_format`.  For example, if `data_format` is 'NHWC' then
`input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, depthwise_multiplier]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape  based on `data_format`.
For example, if `data_format` is 'NHWC' then
out_backprop shape is `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_backprop_input_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>depthwise_conv2d_backprop_input_dyn</strong>(<span title="System.object">object</span> input_sizes, <span title="System.object">object</span> filter, <span title="System.object">object</span> out_backprop, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the gradients of depthwise convolution with respect to the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input_sizes
						</dt>
						<dd>A `Tensor` of type `int32`.
An integer vector representing the shape of `input`, based
on `data_format`.  For example, if `data_format` is 'NHWC' then
`input` is a 4-D `[batch, height, width, channels]` tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
4-D with shape
`[filter_height, filter_width, in_channels, depthwise_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> out_backprop
						</dt>
						<dd>A `Tensor`. Must have the same type as `filter`.
4-D with shape  based on `data_format`.
For example, if `data_format` is 'NHWC' then
out_backprop shape is `[batch, out_height, out_width, out_channels]`.
Gradients w.r.t. the output of the convolution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
The stride of the sliding window for each dimension of the input
of the convolution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `filter`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>depthwise_conv2d_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.object">object</span> name, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Depthwise 2-D convolution. <p></p> Given a 4D input tensor ('NHWC' or 'NCHW' data formats)
and a filter tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`
containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d`
applies a different filter to each input channel (expanding from 1 channel
to `channel_multiplier` channels for each), then concatenates the results
together.  The output has `in_channels * channel_multiplier` channels. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,
strides[2] * j + rate[1] * dj, k] <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the
same horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>4-D with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>4-D with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>1-D of size 4.  The stride of the sliding window for each
dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to `data_format`.  E.g., for
"NHWC" format, shape is
`[batch, out_height, out_width, in_channels * channel_multiplier].` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.object">object</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>depthwise_conv2d_native</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> filter, <span title="System.int">int</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="depthwise_conv2d_native_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>depthwise_conv2d_native_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilations, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors. <p></p> Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
a different filter to each input channel (expanding from 1 channel to
`channel_multiplier` channels for each), then concatenates the results
together. Thus, the output has `in_channels * channel_multiplier` channels. <p></p> ```
for k in 0..in_channels-1
for q in 0..channel_multiplier-1
output[b, i, j, k * channel_multiplier + q] =
sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
filter[di, dj, k, q]
``` <p></p> Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints`.
1-D of length 4.  The stride of the sliding window for each dimension
of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
Specify the data format of the input and output data. With the
default format "NHWC", the data is stored in the order of:
[batch, height, width, channels].
Alternatively, the format could be "NCHW", the data storage order of:
[batch, channels, height, width]. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilations
						</dt>
						<dd>An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
1-D tensor of length 4.  The dilation factor for each dimension of
`input`. If set to k > 1, there will be k-1 skipped cells between each filter
element on that dimension. The dimension order is determined by the value of
`data_format`, see above for details. Dilations in the batch and depth
dimensions must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dilation2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dilation2d</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> rates, <span title="System.object">object</span> padding, <span title="System.string">string</span> name, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes the grayscale dilation of 4-D `input` and 3-D `filter` tensors. <p></p> The `input` tensor has shape `[batch, in_height, in_width, depth]` and the
`filter` tensor has shape `[filter_height, filter_width, depth]`, i.e., each
input channel is processed independently of the others with its own structuring
function. The `output` tensor has shape
`[batch, out_height, out_width, depth]`. The spatial dimensions of the output
tensor depend on the `padding` algorithm. We currently only support the default
"NHWC" `data_format`. <p></p> In detail, the grayscale morphological 2-D dilation is the max-sum correlation
(for consistency with `conv2d`, we use unmirrored filters): <p></p> output[b, y, x, c] =
max_{dy, dx} input[b,
strides[1] * y + rates[1] * dy,
strides[2] * x + rates[2] * dx,
c] +
filter[dy, dx, c] <p></p> Max-pooling is a special case when the filter has size equal to the pooling
kernel size and contains all zeros. <p></p> Note on duality: The dilation of `input` by the `filter` is equal to the
negation of the erosion of `-input` by the reflected `filter`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
4-D with shape `[batch, in_height, in_width, depth]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
3-D with shape `[filter_height, filter_width, depth]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
The stride of the sliding window for each dimension of the input
tensor. Must be: `[1, stride_height, stride_width, 1]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rates
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
The input stride for atrous morphological dilation. Must be:
`[1, rate_height, rate_width, 1]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dilation2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dilation2d_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> rates, <span title="System.object">object</span> padding, <span title="System.object">object</span> name, <span title="System.object">object</span> filters, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Computes the grayscale dilation of 4-D `input` and 3-D `filter` tensors. <p></p> The `input` tensor has shape `[batch, in_height, in_width, depth]` and the
`filter` tensor has shape `[filter_height, filter_width, depth]`, i.e., each
input channel is processed independently of the others with its own structuring
function. The `output` tensor has shape
`[batch, out_height, out_width, depth]`. The spatial dimensions of the output
tensor depend on the `padding` algorithm. We currently only support the default
"NHWC" `data_format`. <p></p> In detail, the grayscale morphological 2-D dilation is the max-sum correlation
(for consistency with `conv2d`, we use unmirrored filters): <p></p> output[b, y, x, c] =
max_{dy, dx} input[b,
strides[1] * y + rates[1] * dy,
strides[2] * x + rates[2] * dx,
c] +
filter[dy, dx, c] <p></p> Max-pooling is a special case when the filter has size equal to the pooling
kernel size and contains all zeros. <p></p> Note on duality: The dilation of `input` by the `filter` is equal to the
negation of the erosion of `-input` by the reflected `filter`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
4-D with shape `[batch, in_height, in_width, depth]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter
						</dt>
						<dd>A `Tensor`. Must have the same type as `input`.
3-D with shape `[filter_height, filter_width, depth]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
The stride of the sliding window for each dimension of the input
tensor. Must be: `[1, stride_height, stride_width, 1]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rates
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
The input stride for atrous morphological dilation. Must be:
`[1, rate_height, rate_width, 1]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filters
						</dt>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> x, <span title="System.double">double</span> keep_prob, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> keep_prob, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> x, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> keep_prob, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> x, <span title="System.double">double</span> keep_prob, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> x, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> keep_prob, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> keep_prob, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> keep_prob, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> keep_prob, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> keep_prob, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> keep_prob, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> keep_prob, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> keep_prob, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> keep_prob, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> keep_prob, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> keep_prob, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> keep_prob, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> keep_prob, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> keep_prob, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> noise_shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> keep_prob, <span title="System.object">object</span> noise_shape, <span title="System.object">object</span> seed, <span title="System.object">object</span> name, <span title="System.object">object</span> rate)
		</h4>
		<div class="content">Computes dropout. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_prob)`. They will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. <p></p> For each element of `x`, with probability `rate`, outputs `0`, and otherwise
scales up the input by `1 / (1-rate)`. The scaling is such that the expected
sum is unchanged. <p></p> By default, each element is kept or dropped independently.  If `noise_shape`
is specified, it must be
[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`
will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`
and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be
kept independently and each row and column will be kept or not kept together. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A floating point tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> keep_prob
						</dt>
						<dd>(deprecated) A deprecated alias for `(1-rate)`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> noise_shape
						</dt>
						<dd>A 1-D `Tensor` of type `int32`, representing the
shape for randomly generated keep/drop flags. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>A Python integer. Used to create random seeds. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>A scalar `Tensor` with the same type as `x`. The probability that each
element of `x` is discarded. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor of the same shape of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dynamic_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>dynamic_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> time_major, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API <p></p> Performs fully dynamic unrolling of `inputs`. <p></p> Example: <p></p> 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>The RNN inputs.
If `time_major == False` (default), this must be a `Tensor` of shape:
`[batch_size, max_time,...]`, or a nested tuple of such elements.
If `time_major == True`, this must be a `Tensor` of shape: `[max_time,
batch_size,...]`, or a nested tuple of such elements. This may also be
a (possibly nested) tuple of Tensors satisfying this property.  The
first two dimensions must match across all the inputs, but otherwise the
ranks and other shape components may differ. In this case, input to
`cell` at each time-step will replicate the structure of these tuples,
except for the time dimension (from which the time is taken). The input
to `cell` at each time step will be a `Tensor` or (possibly nested)
tuple of Tensors each with dimensions `[batch_size,...]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector sized `[batch_size]`. Used
to copy-through state and zero-out outputs when past a batch element's
sequence length.  This parameter enables users to extract the last valid
state and properly padded outputs, so it is provided for correctness. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` and `outputs` Tensors. If true,
these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,
these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using
`time_major = True` is a bit more efficient because it avoids transposes
at the beginning and end of the RNN calculation.  However, most TensorFlow
data is batch-major, so by default this function accepts input and emits
output in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># create a BasicRNNCell
            rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size) <p></p> # 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size] <p></p> # defining initial state
initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32) <p></p> # 'state' is a tensor of shape [batch_size, cell_state_size]
outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,
                                   initial_state=initial_state,
                                   dtype=tf.float32) </pre>
</div>
		</div>
	</div>
	<div id="dynamic_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>dynamic_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> time_major, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API <p></p> Performs fully dynamic unrolling of `inputs`. <p></p> Example: <p></p> 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>The RNN inputs.
If `time_major == False` (default), this must be a `Tensor` of shape:
`[batch_size, max_time,...]`, or a nested tuple of such elements.
If `time_major == True`, this must be a `Tensor` of shape: `[max_time,
batch_size,...]`, or a nested tuple of such elements. This may also be
a (possibly nested) tuple of Tensors satisfying this property.  The
first two dimensions must match across all the inputs, but otherwise the
ranks and other shape components may differ. In this case, input to
`cell` at each time-step will replicate the structure of these tuples,
except for the time dimension (from which the time is taken). The input
to `cell` at each time step will be a `Tensor` or (possibly nested)
tuple of Tensors each with dimensions `[batch_size,...]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector sized `[batch_size]`. Used
to copy-through state and zero-out outputs when past a batch element's
sequence length.  This parameter enables users to extract the last valid
state and properly padded outputs, so it is provided for correctness. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` and `outputs` Tensors. If true,
these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,
these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using
`time_major = True` is a bit more efficient because it avoids transposes
at the beginning and end of the RNN calculation.  However, most TensorFlow
data is batch-major, so by default this function accepts input and emits
output in batch-major form. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># create a BasicRNNCell
            rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size) <p></p> # 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size] <p></p> # defining initial state
initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32) <p></p> # 'state' is a tensor of shape [batch_size, cell_state_size]
outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,
                                   initial_state=initial_state,
                                   dtype=tf.float32) </pre>
</div>
		</div>
	</div>
	<div id="dynamic_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>dynamic_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> inputs, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> sequence_length, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> time_major, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API <p></p> Performs fully dynamic unrolling of `inputs`. <p></p> Example: <p></p> 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>The RNN inputs.
If `time_major == False` (default), this must be a `Tensor` of shape:
`[batch_size, max_time,...]`, or a nested tuple of such elements.
If `time_major == True`, this must be a `Tensor` of shape: `[max_time,
batch_size,...]`, or a nested tuple of such elements. This may also be
a (possibly nested) tuple of Tensors satisfying this property.  The
first two dimensions must match across all the inputs, but otherwise the
ranks and other shape components may differ. In this case, input to
`cell` at each time-step will replicate the structure of these tuples,
except for the time dimension (from which the time is taken). The input
to `cell` at each time step will be a `Tensor` or (possibly nested)
tuple of Tensors each with dimensions `[batch_size,...]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector sized `[batch_size]`. Used
to copy-through state and zero-out outputs when past a batch element's
sequence length.  This parameter enables users to extract the last valid
state and properly padded outputs, so it is provided for correctness. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` and `outputs` Tensors. If true,
these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,
these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using
`time_major = True` is a bit more efficient because it avoids transposes
at the beginning and end of the RNN calculation.  However, most TensorFlow
data is batch-major, so by default this function accepts input and emits
output in batch-major form. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># create a BasicRNNCell
            rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size) <p></p> # 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size] <p></p> # defining initial state
initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32) <p></p> # 'state' is a tensor of shape [batch_size, cell_state_size]
outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,
                                   initial_state=initial_state,
                                   dtype=tf.float32) </pre>
</div>
		</div>
	</div>
	<div id="dynamic_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>dynamic_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> time_major, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API <p></p> Performs fully dynamic unrolling of `inputs`. <p></p> Example: <p></p> 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>The RNN inputs.
If `time_major == False` (default), this must be a `Tensor` of shape:
`[batch_size, max_time,...]`, or a nested tuple of such elements.
If `time_major == True`, this must be a `Tensor` of shape: `[max_time,
batch_size,...]`, or a nested tuple of such elements. This may also be
a (possibly nested) tuple of Tensors satisfying this property.  The
first two dimensions must match across all the inputs, but otherwise the
ranks and other shape components may differ. In this case, input to
`cell` at each time-step will replicate the structure of these tuples,
except for the time dimension (from which the time is taken). The input
to `cell` at each time step will be a `Tensor` or (possibly nested)
tuple of Tensors each with dimensions `[batch_size,...]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector sized `[batch_size]`. Used
to copy-through state and zero-out outputs when past a batch element's
sequence length.  This parameter enables users to extract the last valid
state and properly padded outputs, so it is provided for correctness. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` and `outputs` Tensors. If true,
these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,
these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using
`time_major = True` is a bit more efficient because it avoids transposes
at the beginning and end of the RNN calculation.  However, most TensorFlow
data is batch-major, so by default this function accepts input and emits
output in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># create a BasicRNNCell
            rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size) <p></p> # 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size] <p></p> # defining initial state
initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32) <p></p> # 'state' is a tensor of shape [batch_size, cell_state_size]
outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,
                                   initial_state=initial_state,
                                   dtype=tf.float32) </pre>
</div>
		</div>
	</div>
	<div id="dynamic_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>dynamic_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> inputs, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> sequence_length, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> time_major, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API <p></p> Performs fully dynamic unrolling of `inputs`. <p></p> Example: <p></p> 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>The RNN inputs.
If `time_major == False` (default), this must be a `Tensor` of shape:
`[batch_size, max_time,...]`, or a nested tuple of such elements.
If `time_major == True`, this must be a `Tensor` of shape: `[max_time,
batch_size,...]`, or a nested tuple of such elements. This may also be
a (possibly nested) tuple of Tensors satisfying this property.  The
first two dimensions must match across all the inputs, but otherwise the
ranks and other shape components may differ. In this case, input to
`cell` at each time-step will replicate the structure of these tuples,
except for the time dimension (from which the time is taken). The input
to `cell` at each time step will be a `Tensor` or (possibly nested)
tuple of Tensors each with dimensions `[batch_size,...]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector sized `[batch_size]`. Used
to copy-through state and zero-out outputs when past a batch element's
sequence length.  This parameter enables users to extract the last valid
state and properly padded outputs, so it is provided for correctness. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` and `outputs` Tensors. If true,
these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,
these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using
`time_major = True` is a bit more efficient because it avoids transposes
at the beginning and end of the RNN calculation.  However, most TensorFlow
data is batch-major, so by default this function accepts input and emits
output in batch-major form. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># create a BasicRNNCell
            rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size) <p></p> # 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size] <p></p> # defining initial state
initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32) <p></p> # 'state' is a tensor of shape [batch_size, cell_state_size]
outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,
                                   initial_state=initial_state,
                                   dtype=tf.float32) </pre>
</div>
		</div>
	</div>
	<div id="dynamic_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>dynamic_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> inputs, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> time_major, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API <p></p> Performs fully dynamic unrolling of `inputs`. <p></p> Example: <p></p> 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>The RNN inputs.
If `time_major == False` (default), this must be a `Tensor` of shape:
`[batch_size, max_time,...]`, or a nested tuple of such elements.
If `time_major == True`, this must be a `Tensor` of shape: `[max_time,
batch_size,...]`, or a nested tuple of such elements. This may also be
a (possibly nested) tuple of Tensors satisfying this property.  The
first two dimensions must match across all the inputs, but otherwise the
ranks and other shape components may differ. In this case, input to
`cell` at each time-step will replicate the structure of these tuples,
except for the time dimension (from which the time is taken). The input
to `cell` at each time step will be a `Tensor` or (possibly nested)
tuple of Tensors each with dimensions `[batch_size,...]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector sized `[batch_size]`. Used
to copy-through state and zero-out outputs when past a batch element's
sequence length.  This parameter enables users to extract the last valid
state and properly padded outputs, so it is provided for correctness. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` and `outputs` Tensors. If true,
these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,
these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using
`time_major = True` is a bit more efficient because it avoids transposes
at the beginning and end of the RNN calculation.  However, most TensorFlow
data is batch-major, so by default this function accepts input and emits
output in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># create a BasicRNNCell
            rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size) <p></p> # 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size] <p></p> # defining initial state
initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32) <p></p> # 'state' is a tensor of shape [batch_size, cell_state_size]
outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,
                                   initial_state=initial_state,
                                   dtype=tf.float32) </pre>
</div>
		</div>
	</div>
	<div id="dynamic_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>dynamic_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> time_major, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API <p></p> Performs fully dynamic unrolling of `inputs`. <p></p> Example: <p></p> 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>The RNN inputs.
If `time_major == False` (default), this must be a `Tensor` of shape:
`[batch_size, max_time,...]`, or a nested tuple of such elements.
If `time_major == True`, this must be a `Tensor` of shape: `[max_time,
batch_size,...]`, or a nested tuple of such elements. This may also be
a (possibly nested) tuple of Tensors satisfying this property.  The
first two dimensions must match across all the inputs, but otherwise the
ranks and other shape components may differ. In this case, input to
`cell` at each time-step will replicate the structure of these tuples,
except for the time dimension (from which the time is taken). The input
to `cell` at each time step will be a `Tensor` or (possibly nested)
tuple of Tensors each with dimensions `[batch_size,...]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector sized `[batch_size]`. Used
to copy-through state and zero-out outputs when past a batch element's
sequence length.  This parameter enables users to extract the last valid
state and properly padded outputs, so it is provided for correctness. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` and `outputs` Tensors. If true,
these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,
these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using
`time_major = True` is a bit more efficient because it avoids transposes
at the beginning and end of the RNN calculation.  However, most TensorFlow
data is batch-major, so by default this function accepts input and emits
output in batch-major form. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># create a BasicRNNCell
            rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size) <p></p> # 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size] <p></p> # defining initial state
initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32) <p></p> # 'state' is a tensor of shape [batch_size, cell_state_size]
outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,
                                   initial_state=initial_state,
                                   dtype=tf.float32) </pre>
</div>
		</div>
	</div>
	<div id="dynamic_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>dynamic_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> inputs, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> time_major, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API <p></p> Performs fully dynamic unrolling of `inputs`. <p></p> Example: <p></p> 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>The RNN inputs.
If `time_major == False` (default), this must be a `Tensor` of shape:
`[batch_size, max_time,...]`, or a nested tuple of such elements.
If `time_major == True`, this must be a `Tensor` of shape: `[max_time,
batch_size,...]`, or a nested tuple of such elements. This may also be
a (possibly nested) tuple of Tensors satisfying this property.  The
first two dimensions must match across all the inputs, but otherwise the
ranks and other shape components may differ. In this case, input to
`cell` at each time-step will replicate the structure of these tuples,
except for the time dimension (from which the time is taken). The input
to `cell` at each time step will be a `Tensor` or (possibly nested)
tuple of Tensors each with dimensions `[batch_size,...]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector sized `[batch_size]`. Used
to copy-through state and zero-out outputs when past a batch element's
sequence length.  This parameter enables users to extract the last valid
state and properly padded outputs, so it is provided for correctness. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> time_major
						</dt>
						<dd>The shape format of the `inputs` and `outputs` Tensors. If true,
these `Tensors` must be shaped `[max_time, batch_size, depth]`. If false,
these `Tensors` must be shaped `[batch_size, max_time, depth]`. Using
`time_major = True` is a bit more efficient because it avoids transposes
at the beginning and end of the RNN calculation.  However, most TensorFlow
data is batch-major, so by default this function accepts input and emits
output in batch-major form. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># create a BasicRNNCell
            rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size) <p></p> # 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size] <p></p> # defining initial state
initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32) <p></p> # 'state' is a tensor of shape [batch_size, cell_state_size]
outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,
                                   initial_state=initial_state,
                                   dtype=tf.float32) </pre>
</div>
		</div>
	</div>
	<div id="elu" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>elu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> features, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes exponential linear: `exp(features) - 1` if < 0, `features` otherwise. <p></p> See [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
](http://arxiv.org/abs/1511.07289) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="elu_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>elu_dyn</strong>(<span title="System.object">object</span> features, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes exponential linear: `exp(features) - 1` if < 0, `features` otherwise. <p></p> See [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
](http://arxiv.org/abs/1511.07289) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>embedding_lookup</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> params, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> ids, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.bool">bool</span> validate_indices, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>embedding_lookup</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> params, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> ids, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.bool">bool</span> validate_indices, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>embedding_lookup</strong>(<span title="System.object">object</span> params, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> ids, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.bool">bool</span> validate_indices, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>embedding_lookup</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> params, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> ids, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.bool">bool</span> validate_indices, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>embedding_lookup</strong>(<span title="System.object">object</span> params, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> ids, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.bool">bool</span> validate_indices, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>embedding_lookup</strong>(<span title="System.object">object</span> params, <span title="System.object">object</span> ids, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.bool">bool</span> validate_indices, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>embedding_lookup</strong>(<span title="System.object">object</span> params, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ids, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.bool">bool</span> validate_indices, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>embedding_lookup</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> params, <span title="System.object">object</span> ids, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.bool">bool</span> validate_indices, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>embedding_lookup</strong>(<span title="System.object">object</span> params, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> ids, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.bool">bool</span> validate_indices, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>embedding_lookup</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> params, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ids, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.bool">bool</span> validate_indices, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>embedding_lookup_dyn</strong>(<span title="System.object">object</span> params, <span title="System.object">object</span> ids, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> partition_strategy, <span title="System.object">object</span> name, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> validate_indices, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Looks up `ids` in a list of embedding tensors. <p></p> This function is used to perform parallel lookups on the list of
tensors in `params`.  It is a generalization of
<a href="..\..\tf\gather.md"><code>tf.gather</code></a>, where `params` is
interpreted as a partitioning of a large embedding tensor.  `params` may be
a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`
with a
partitioner. <p></p> If `len(params) > 1`, each element `id` of `ids` is partitioned between
the elements of `params` according to the `partition_strategy`.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first `(max_id + 1) % len(params)` partitions will
be assigned one more id. <p></p> If `partition_strategy` is `"mod"`, we assign each id to partition
`p = id % len(params)`. For instance,
13 ids are split across 5 partitions as:
`[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]` <p></p> If `partition_strategy` is `"div"`, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
`[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]` <p></p> The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ids
						</dt>
						<dd>A `Tensor` with type `int32` or `int64` containing the ids to be looked
up in `params`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> validate_indices
						</dt>
						<dd>DEPRECATED. If this operation is assigned to CPU, values
in `indices` are always validated to be within range.  If assigned to GPU,
out-of-bound indices result in safe but unspecified behavior, which may
include raising an error. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same type as the tensors in `params`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup_sparse" class="method">
		<h4>
			<span title="System.object">object</span> <strong>embedding_lookup_sparse</strong>(<span title="System.object">object</span> params, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_ids, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_weights, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.string">string</span> combiner, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Computes embeddings for the given ids and weights. <p></p> This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order. <p></p> It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_ids
						</dt>
						<dd>N x M `SparseTensor` of int64 ids where N is typically batch size
and M is arbitrary. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_weights
						</dt>
						<dd>either a `SparseTensor` of float / double weights, or `None` to
indicate all weights should be taken to be 1. If specified, `sp_weights`
must have exactly the same shape and indices as `sp_ids`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> combiner
						</dt>
						<dd>A string specifying the reduction op. Currently "mean", "sqrtn"
and "sum" are supported. "sum" computes the weighted sum of the embedding
results for each row. "mean" is the weighted sum divided by the total
weight. "sqrtn" is the weighted sum divided by the square root of the sum
of the squares of the weights. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value, before combining. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor representing the combined embeddings for the
sparse ids. For each row in the dense tensor represented by `sp_ids`, the op
looks up the embeddings for all ids in that row, multiplies them by the
corresponding weight, and combines these embeddings as specified. <p></p> In other words, if <p></p> `shape(combined params) = [p0, p1,..., pm]` <p></p> and <p></p> `shape(sp_ids) = shape(sp_weights) = [d0, d1,..., dn]` <p></p> then <p></p> `shape(output) = [d0, d1,..., dn-1, p1,..., pm]`. <p></p> For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are <p></p> ```python
[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
``` <p></p> with `combiner`="mean", then the output will be a 3x20 matrix where <p></p> ```python
output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
output[1, :] = (params[0, :] * 1.0) / 1.0
output[2, :] = (params[1, :] * 3.0) / 3.0
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup_sparse" class="method">
		<h4>
			<span title="System.object">object</span> <strong>embedding_lookup_sparse</strong>(<span title="System.object">object</span> params, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_ids, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_weights, <span title="System.string">string</span> partition_strategy, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> combiner, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Computes embeddings for the given ids and weights. <p></p> This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order. <p></p> It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_ids
						</dt>
						<dd>N x M `SparseTensor` of int64 ids where N is typically batch size
and M is arbitrary. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_weights
						</dt>
						<dd>either a `SparseTensor` of float / double weights, or `None` to
indicate all weights should be taken to be 1. If specified, `sp_weights`
must have exactly the same shape and indices as `sp_ids`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> combiner
						</dt>
						<dd>A string specifying the reduction op. Currently "mean", "sqrtn"
and "sum" are supported. "sum" computes the weighted sum of the embedding
results for each row. "mean" is the weighted sum divided by the total
weight. "sqrtn" is the weighted sum divided by the square root of the sum
of the squares of the weights. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value, before combining. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor representing the combined embeddings for the
sparse ids. For each row in the dense tensor represented by `sp_ids`, the op
looks up the embeddings for all ids in that row, multiplies them by the
corresponding weight, and combines these embeddings as specified. <p></p> In other words, if <p></p> `shape(combined params) = [p0, p1,..., pm]` <p></p> and <p></p> `shape(sp_ids) = shape(sp_weights) = [d0, d1,..., dn]` <p></p> then <p></p> `shape(output) = [d0, d1,..., dn-1, p1,..., pm]`. <p></p> For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are <p></p> ```python
[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
``` <p></p> with `combiner`="mean", then the output will be a 3x20 matrix where <p></p> ```python
output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
output[1, :] = (params[0, :] * 1.0) / 1.0
output[2, :] = (params[1, :] * 3.0) / 3.0
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup_sparse" class="method">
		<h4>
			<span title="System.object">object</span> <strong>embedding_lookup_sparse</strong>(<a href="../tensorflow.python.ops.variables/PartitionedVariable.htm">PartitionedVariable</a> params, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_ids, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_weights, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.string">string</span> combiner, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Computes embeddings for the given ids and weights. <p></p> This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order. <p></p> It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.ops.variables/PartitionedVariable.htm">PartitionedVariable</a></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_ids
						</dt>
						<dd>N x M `SparseTensor` of int64 ids where N is typically batch size
and M is arbitrary. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_weights
						</dt>
						<dd>either a `SparseTensor` of float / double weights, or `None` to
indicate all weights should be taken to be 1. If specified, `sp_weights`
must have exactly the same shape and indices as `sp_ids`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> combiner
						</dt>
						<dd>A string specifying the reduction op. Currently "mean", "sqrtn"
and "sum" are supported. "sum" computes the weighted sum of the embedding
results for each row. "mean" is the weighted sum divided by the total
weight. "sqrtn" is the weighted sum divided by the square root of the sum
of the squares of the weights. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value, before combining. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor representing the combined embeddings for the
sparse ids. For each row in the dense tensor represented by `sp_ids`, the op
looks up the embeddings for all ids in that row, multiplies them by the
corresponding weight, and combines these embeddings as specified. <p></p> In other words, if <p></p> `shape(combined params) = [p0, p1,..., pm]` <p></p> and <p></p> `shape(sp_ids) = shape(sp_weights) = [d0, d1,..., dn]` <p></p> then <p></p> `shape(output) = [d0, d1,..., dn-1, p1,..., pm]`. <p></p> For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are <p></p> ```python
[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
``` <p></p> with `combiner`="mean", then the output will be a 3x20 matrix where <p></p> ```python
output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
output[1, :] = (params[0, :] * 1.0) / 1.0
output[2, :] = (params[1, :] * 3.0) / 3.0
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup_sparse" class="method">
		<h4>
			<span title="System.object">object</span> <strong>embedding_lookup_sparse</strong>(<a href="../tensorflow.python.ops.variables/PartitionedVariable.htm">PartitionedVariable</a> params, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_ids, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_weights, <span title="System.string">string</span> partition_strategy, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> combiner, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Computes embeddings for the given ids and weights. <p></p> This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order. <p></p> It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.ops.variables/PartitionedVariable.htm">PartitionedVariable</a></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_ids
						</dt>
						<dd>N x M `SparseTensor` of int64 ids where N is typically batch size
and M is arbitrary. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_weights
						</dt>
						<dd>either a `SparseTensor` of float / double weights, or `None` to
indicate all weights should be taken to be 1. If specified, `sp_weights`
must have exactly the same shape and indices as `sp_ids`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> combiner
						</dt>
						<dd>A string specifying the reduction op. Currently "mean", "sqrtn"
and "sum" are supported. "sum" computes the weighted sum of the embedding
results for each row. "mean" is the weighted sum divided by the total
weight. "sqrtn" is the weighted sum divided by the square root of the sum
of the squares of the weights. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value, before combining. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor representing the combined embeddings for the
sparse ids. For each row in the dense tensor represented by `sp_ids`, the op
looks up the embeddings for all ids in that row, multiplies them by the
corresponding weight, and combines these embeddings as specified. <p></p> In other words, if <p></p> `shape(combined params) = [p0, p1,..., pm]` <p></p> and <p></p> `shape(sp_ids) = shape(sp_weights) = [d0, d1,..., dn]` <p></p> then <p></p> `shape(output) = [d0, d1,..., dn-1, p1,..., pm]`. <p></p> For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are <p></p> ```python
[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
``` <p></p> with `combiner`="mean", then the output will be a 3x20 matrix where <p></p> ```python
output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
output[1, :] = (params[0, :] * 1.0) / 1.0
output[2, :] = (params[1, :] * 3.0) / 3.0
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup_sparse" class="method">
		<h4>
			<span title="System.object">object</span> <strong>embedding_lookup_sparse</strong>(<a href="../tensorflow.compat.v2/Variable.htm">Variable</a> params, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_ids, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_weights, <span title="System.string">string</span> partition_strategy, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> combiner, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Computes embeddings for the given ids and weights. <p></p> This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order. <p></p> It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.compat.v2/Variable.htm">Variable</a></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_ids
						</dt>
						<dd>N x M `SparseTensor` of int64 ids where N is typically batch size
and M is arbitrary. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_weights
						</dt>
						<dd>either a `SparseTensor` of float / double weights, or `None` to
indicate all weights should be taken to be 1. If specified, `sp_weights`
must have exactly the same shape and indices as `sp_ids`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> combiner
						</dt>
						<dd>A string specifying the reduction op. Currently "mean", "sqrtn"
and "sum" are supported. "sum" computes the weighted sum of the embedding
results for each row. "mean" is the weighted sum divided by the total
weight. "sqrtn" is the weighted sum divided by the square root of the sum
of the squares of the weights. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value, before combining. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor representing the combined embeddings for the
sparse ids. For each row in the dense tensor represented by `sp_ids`, the op
looks up the embeddings for all ids in that row, multiplies them by the
corresponding weight, and combines these embeddings as specified. <p></p> In other words, if <p></p> `shape(combined params) = [p0, p1,..., pm]` <p></p> and <p></p> `shape(sp_ids) = shape(sp_weights) = [d0, d1,..., dn]` <p></p> then <p></p> `shape(output) = [d0, d1,..., dn-1, p1,..., pm]`. <p></p> For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are <p></p> ```python
[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
``` <p></p> with `combiner`="mean", then the output will be a 3x20 matrix where <p></p> ```python
output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
output[1, :] = (params[0, :] * 1.0) / 1.0
output[2, :] = (params[1, :] * 3.0) / 3.0
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup_sparse" class="method">
		<h4>
			<span title="System.object">object</span> <strong>embedding_lookup_sparse</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> params, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_ids, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_weights, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.string">string</span> combiner, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Computes embeddings for the given ids and weights. <p></p> This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order. <p></p> It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_ids
						</dt>
						<dd>N x M `SparseTensor` of int64 ids where N is typically batch size
and M is arbitrary. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_weights
						</dt>
						<dd>either a `SparseTensor` of float / double weights, or `None` to
indicate all weights should be taken to be 1. If specified, `sp_weights`
must have exactly the same shape and indices as `sp_ids`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> combiner
						</dt>
						<dd>A string specifying the reduction op. Currently "mean", "sqrtn"
and "sum" are supported. "sum" computes the weighted sum of the embedding
results for each row. "mean" is the weighted sum divided by the total
weight. "sqrtn" is the weighted sum divided by the square root of the sum
of the squares of the weights. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value, before combining. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor representing the combined embeddings for the
sparse ids. For each row in the dense tensor represented by `sp_ids`, the op
looks up the embeddings for all ids in that row, multiplies them by the
corresponding weight, and combines these embeddings as specified. <p></p> In other words, if <p></p> `shape(combined params) = [p0, p1,..., pm]` <p></p> and <p></p> `shape(sp_ids) = shape(sp_weights) = [d0, d1,..., dn]` <p></p> then <p></p> `shape(output) = [d0, d1,..., dn-1, p1,..., pm]`. <p></p> For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are <p></p> ```python
[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
``` <p></p> with `combiner`="mean", then the output will be a 3x20 matrix where <p></p> ```python
output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
output[1, :] = (params[0, :] * 1.0) / 1.0
output[2, :] = (params[1, :] * 3.0) / 3.0
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup_sparse" class="method">
		<h4>
			<span title="System.object">object</span> <strong>embedding_lookup_sparse</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> params, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_ids, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_weights, <span title="System.string">string</span> partition_strategy, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> combiner, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Computes embeddings for the given ids and weights. <p></p> This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order. <p></p> It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_ids
						</dt>
						<dd>N x M `SparseTensor` of int64 ids where N is typically batch size
and M is arbitrary. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_weights
						</dt>
						<dd>either a `SparseTensor` of float / double weights, or `None` to
indicate all weights should be taken to be 1. If specified, `sp_weights`
must have exactly the same shape and indices as `sp_ids`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>Optional name for the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> combiner
						</dt>
						<dd>A string specifying the reduction op. Currently "mean", "sqrtn"
and "sum" are supported. "sum" computes the weighted sum of the embedding
results for each row. "mean" is the weighted sum divided by the total
weight. "sqrtn" is the weighted sum divided by the square root of the sum
of the squares of the weights. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value, before combining. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor representing the combined embeddings for the
sparse ids. For each row in the dense tensor represented by `sp_ids`, the op
looks up the embeddings for all ids in that row, multiplies them by the
corresponding weight, and combines these embeddings as specified. <p></p> In other words, if <p></p> `shape(combined params) = [p0, p1,..., pm]` <p></p> and <p></p> `shape(sp_ids) = shape(sp_weights) = [d0, d1,..., dn]` <p></p> then <p></p> `shape(output) = [d0, d1,..., dn-1, p1,..., pm]`. <p></p> For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are <p></p> ```python
[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
``` <p></p> with `combiner`="mean", then the output will be a 3x20 matrix where <p></p> ```python
output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
output[1, :] = (params[0, :] * 1.0) / 1.0
output[2, :] = (params[1, :] * 3.0) / 3.0
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup_sparse" class="method">
		<h4>
			<span title="System.object">object</span> <strong>embedding_lookup_sparse</strong>(<a href="../tensorflow.compat.v2/Variable.htm">Variable</a> params, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_ids, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sp_weights, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.string">string</span> combiner, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Computes embeddings for the given ids and weights. <p></p> This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order. <p></p> It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.compat.v2/Variable.htm">Variable</a></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_ids
						</dt>
						<dd>N x M `SparseTensor` of int64 ids where N is typically batch size
and M is arbitrary. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sp_weights
						</dt>
						<dd>either a `SparseTensor` of float / double weights, or `None` to
indicate all weights should be taken to be 1. If specified, `sp_weights`
must have exactly the same shape and indices as `sp_ids`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> combiner
						</dt>
						<dd>A string specifying the reduction op. Currently "mean", "sqrtn"
and "sum" are supported. "sum" computes the weighted sum of the embedding
results for each row. "mean" is the weighted sum divided by the total
weight. "sqrtn" is the weighted sum divided by the square root of the sum
of the squares of the weights. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value, before combining. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor representing the combined embeddings for the
sparse ids. For each row in the dense tensor represented by `sp_ids`, the op
looks up the embeddings for all ids in that row, multiplies them by the
corresponding weight, and combines these embeddings as specified. <p></p> In other words, if <p></p> `shape(combined params) = [p0, p1,..., pm]` <p></p> and <p></p> `shape(sp_ids) = shape(sp_weights) = [d0, d1,..., dn]` <p></p> then <p></p> `shape(output) = [d0, d1,..., dn-1, p1,..., pm]`. <p></p> For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are <p></p> ```python
[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
``` <p></p> with `combiner`="mean", then the output will be a 3x20 matrix where <p></p> ```python
output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
output[1, :] = (params[0, :] * 1.0) / 1.0
output[2, :] = (params[1, :] * 3.0) / 3.0
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="embedding_lookup_sparse_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>embedding_lookup_sparse_dyn</strong>(<span title="System.object">object</span> params, <span title="System.object">object</span> sp_ids, <span title="System.object">object</span> sp_weights, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> partition_strategy, <span title="System.object">object</span> name, <span title="System.object">object</span> combiner, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Computes embeddings for the given ids and weights. <p></p> This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order. <p></p> It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> params
						</dt>
						<dd>A single tensor representing the complete embedding tensor, or a
list of P tensors all of same shape except for the first dimension,
representing sharded embedding tensors.  Alternatively, a
`PartitionedVariable`, created by partitioning along dimension 0. Each
element must be appropriately sized for the given `partition_strategy`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sp_ids
						</dt>
						<dd>N x M `SparseTensor` of int64 ids where N is typically batch size
and M is arbitrary. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sp_weights
						</dt>
						<dd>either a `SparseTensor` of float / double weights, or `None` to
indicate all weights should be taken to be 1. If specified, `sp_weights`
must have exactly the same shape and indices as `sp_ids`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(params) > 1`. Currently `"div"` and `"mod"` are supported. Default
is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> combiner
						</dt>
						<dd>A string specifying the reduction op. Currently "mean", "sqrtn"
and "sum" are supported. "sum" computes the weighted sum of the embedding
results for each row. "mean" is the weighted sum divided by the total
weight. "sqrtn" is the weighted sum divided by the square root of the sum
of the squares of the weights. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, each embedding is clipped if its l2-norm is larger
than this value, before combining. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor representing the combined embeddings for the
sparse ids. For each row in the dense tensor represented by `sp_ids`, the op
looks up the embeddings for all ids in that row, multiplies them by the
corresponding weight, and combines these embeddings as specified. <p></p> In other words, if <p></p> `shape(combined params) = [p0, p1,..., pm]` <p></p> and <p></p> `shape(sp_ids) = shape(sp_weights) = [d0, d1,..., dn]` <p></p> then <p></p> `shape(output) = [d0, d1,..., dn-1, p1,..., pm]`. <p></p> For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are <p></p> ```python
[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
``` <p></p> with `combiner`="mean", then the output will be a 3x20 matrix where <p></p> ```python
output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
output[1, :] = (params[0, :] * 1.0) / 1.0
output[2, :] = (params[1, :] * 3.0) / 3.0
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="erosion2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>erosion2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> rates, <span title="System.string">string</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the grayscale erosion of 4-D `value` and 3-D `kernel` tensors. <p></p> The `value` tensor has shape `[batch, in_height, in_width, depth]` and the
`kernel` tensor has shape `[kernel_height, kernel_width, depth]`, i.e.,
each input channel is processed independently of the others with its own
structuring function. The `output` tensor has shape
`[batch, out_height, out_width, depth]`. The spatial dimensions of the
output tensor depend on the `padding` algorithm. We currently only support the
default "NHWC" `data_format`. <p></p> In detail, the grayscale morphological 2-D erosion is given by: <p></p> output[b, y, x, c] =
min_{dy, dx} value[b,
strides[1] * y - rates[1] * dy,
strides[2] * x - rates[2] * dx,
c] -
kernel[dy, dx, c] <p></p> Duality: The erosion of `value` by the `kernel` is equal to the negation of
the dilation of `-value` by the reflected `kernel`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A `Tensor`. 4-D with shape `[batch, in_height, in_width, depth]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>A `Tensor`. Must have the same type as `value`.
3-D with shape `[kernel_height, kernel_width, depth]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
1-D of length 4. The stride of the sliding window for each dimension of
the input tensor. Must be: `[1, stride_height, stride_width, 1]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> rates
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
1-D of length 4. The input stride for atrous morphological dilation.
Must be: `[1, rate_height, rate_width, 1]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "erosion2d"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `value`.
4-D with shape `[batch, out_height, out_width, depth]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="erosion2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>erosion2d_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> kernel, <span title="System.object">object</span> strides, <span title="System.object">object</span> rates, <span title="System.object">object</span> padding, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the grayscale erosion of 4-D `value` and 3-D `kernel` tensors. <p></p> The `value` tensor has shape `[batch, in_height, in_width, depth]` and the
`kernel` tensor has shape `[kernel_height, kernel_width, depth]`, i.e.,
each input channel is processed independently of the others with its own
structuring function. The `output` tensor has shape
`[batch, out_height, out_width, depth]`. The spatial dimensions of the
output tensor depend on the `padding` algorithm. We currently only support the
default "NHWC" `data_format`. <p></p> In detail, the grayscale morphological 2-D erosion is given by: <p></p> output[b, y, x, c] =
min_{dy, dx} value[b,
strides[1] * y - rates[1] * dy,
strides[2] * x - rates[2] * dx,
c] -
kernel[dy, dx, c] <p></p> Duality: The erosion of `value` by the `kernel` is equal to the negation of
the dilation of `-value` by the reflected `kernel`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A `Tensor`. 4-D with shape `[batch, in_height, in_width, depth]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel
						</dt>
						<dd>A `Tensor`. Must have the same type as `value`.
3-D with shape `[kernel_height, kernel_width, depth]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
1-D of length 4. The stride of the sliding window for each dimension of
the input tensor. Must be: `[1, stride_height, stride_width, 1]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rates
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
1-D of length 4. The input stride for atrous morphological dilation.
Must be: `[1, rate_height, rate_width, 1]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). If not specified "erosion2d"
is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `value`.
4-D with shape `[batch, out_height, out_width, depth]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="fixed_unigram_candidate_sampler" class="method">
		<h4>
			<span title="System.object">object</span> <strong>fixed_unigram_candidate_sampler</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> true_classes, <span title="System.object">object</span> num_true, <span title="System.object">object</span> num_sampled, <span title="System.object">object</span> unique, <span title="System.object">object</span> range_max, <span title="System.string">string</span> vocab_file, <span title="System.double">double</span> distortion, <span title="System.int">int</span> num_reserved_ids, <span title="System.int">int</span> num_shards, <span title="System.int">int</span> shard, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> unigrams, <span title="System.object">object</span> seed, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Samples a set of classes using the provided (fixed) base distribution. <p></p> This operation randomly samples a tensor of sampled classes
(`sampled_candidates`) from the range of integers `[0, range_max)`. <p></p> The elements of `sampled_candidates` are drawn without replacement
(if `unique=True`) or with replacement (if `unique=False`) from
the base distribution. <p></p> The base distribution is read from a file or passed in as an
in-memory array. There is also an option to skew the distribution by
applying a distortion power to the weights. <p></p> In addition, this operation returns tensors `true_expected_count`
and `sampled_expected_count` representing the number of times each
of the target classes (`true_classes`) and the sampled
classes (`sampled_candidates`) is expected to occur in an average
tensor of sampled classes.  These values correspond to `Q(y|x)`
defined in [this
document](http://www.tensorflow.org/extras/candidate_sampling.pdf).
If `unique=True`, then these are post-rejection probabilities and we
compute them approximately. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> unique
						</dt>
						<dd>A `bool`. Determines whether all sampled classes in a batch are
unique. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> range_max
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> vocab_file
						</dt>
						<dd>Each valid line in this file (which should have a CSV-like
format) corresponds to a valid word ID. IDs are in sequential order,
starting from num_reserved_ids. The last entry in each line is expected
to be a value corresponding to the count or relative probability. Exactly
one of `vocab_file` and `unigrams` needs to be passed to this operation. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> distortion
						</dt>
						<dd>The distortion is used to skew the unigram probability
distribution.  Each weight is first raised to the distortion's power
before adding to the internal unigram distribution. As a result,
`distortion = 1.0` gives regular unigram sampling (as defined by the vocab
file), and `distortion = 0.0` gives a uniform distribution. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_reserved_ids
						</dt>
						<dd>Optionally some reserved IDs can be added in the range
`[0, num_reserved_ids)` by the users. One use case is that a special
unknown word token is used as ID 0. These IDs will have a sampling
probability of 0. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_shards
						</dt>
						<dd>A sampler can be used to sample from a subset of the original
range in order to speed up the whole computation through parallelism. This
parameter (together with `shard`) indicates the number of partitions that
are being used in the overall computation. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> shard
						</dt>
						<dd>A sampler can be used to sample from a subset of the original range
in order to speed up the whole computation through parallelism. This
parameter (together with `num_shards`) indicates the particular partition
number of the operation, when partitioning is being used. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> unigrams
						</dt>
						<dd>A list of unigram counts or probabilities, one per ID in
sequential order. Exactly one of `vocab_file` and `unigrams` should be
passed to this operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="fixed_unigram_candidate_sampler_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>fixed_unigram_candidate_sampler_dyn</strong>(<span title="System.object">object</span> true_classes, <span title="System.object">object</span> num_true, <span title="System.object">object</span> num_sampled, <span title="System.object">object</span> unique, <span title="System.object">object</span> range_max, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> vocab_file, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> distortion, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> num_reserved_ids, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> num_shards, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> shard, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> unigrams, <span title="System.object">object</span> seed, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Samples a set of classes using the provided (fixed) base distribution. <p></p> This operation randomly samples a tensor of sampled classes
(`sampled_candidates`) from the range of integers `[0, range_max)`. <p></p> The elements of `sampled_candidates` are drawn without replacement
(if `unique=True`) or with replacement (if `unique=False`) from
the base distribution. <p></p> The base distribution is read from a file or passed in as an
in-memory array. There is also an option to skew the distribution by
applying a distortion power to the weights. <p></p> In addition, this operation returns tensors `true_expected_count`
and `sampled_expected_count` representing the number of times each
of the target classes (`true_classes`) and the sampled
classes (`sampled_candidates`) is expected to occur in an average
tensor of sampled classes.  These values correspond to `Q(y|x)`
defined in [this
document](http://www.tensorflow.org/extras/candidate_sampling.pdf).
If `unique=True`, then these are post-rejection probabilities and we
compute them approximately. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> unique
						</dt>
						<dd>A `bool`. Determines whether all sampled classes in a batch are
unique. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> range_max
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> vocab_file
						</dt>
						<dd>Each valid line in this file (which should have a CSV-like
format) corresponds to a valid word ID. IDs are in sequential order,
starting from num_reserved_ids. The last entry in each line is expected
to be a value corresponding to the count or relative probability. Exactly
one of `vocab_file` and `unigrams` needs to be passed to this operation. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> distortion
						</dt>
						<dd>The distortion is used to skew the unigram probability
distribution.  Each weight is first raised to the distortion's power
before adding to the internal unigram distribution. As a result,
`distortion = 1.0` gives regular unigram sampling (as defined by the vocab
file), and `distortion = 0.0` gives a uniform distribution. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> num_reserved_ids
						</dt>
						<dd>Optionally some reserved IDs can be added in the range
`[0, num_reserved_ids)` by the users. One use case is that a special
unknown word token is used as ID 0. These IDs will have a sampling
probability of 0. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> num_shards
						</dt>
						<dd>A sampler can be used to sample from a subset of the original
range in order to speed up the whole computation through parallelism. This
parameter (together with `shard`) indicates the number of partitions that
are being used in the overall computation. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> shard
						</dt>
						<dd>A sampler can be used to sample from a subset of the original range
in order to speed up the whole computation through parallelism. This
parameter (together with `num_shards`) indicates the particular partition
number of the operation, when partitioning is being used. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> unigrams
						</dt>
						<dd>A list of unigram counts or probabilities, one per ID in
sequential order. Exactly one of `vocab_file` and `unigrams` should be
passed to this operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="fractional_avg_pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>fractional_avg_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.object">object</span> pooling_ratio, <span title="System.bool">bool</span> pseudo_random, <span title="System.bool">bool</span> overlapping, <span title="System.bool">bool</span> deterministic, <span title="System.int">int</span> seed, <span title="System.int">int</span> seed2, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs fractional average pooling on the input. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
`seed2` and `deterministic` args are deprecated.  Use fractional_avg_pool_v2. <p></p> This is a deprecated version of `fractional_avg_pool`. <p></p> Fractional average pooling is similar to Fractional max pooling in the pooling
region generation step. The only difference is that after pooling regions are
generated, a mean operation is performed instead of a max operation in each
pooling region. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A `Tensor`. 4-D with shape `[batch, height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> pooling_ratio
						</dt>
						<dd>A list of `floats` that has length >= 4.  Pooling ratio for
each dimension of `value`, currently only supports row and col dimension
and should be >= 1.0. For example, a valid pooling ratio looks like [1.0,
1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't
allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling
ratio on height and width dimensions respectively. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pseudo_random
						</dt>
						<dd>An optional `bool`.  Defaults to `False`. When set to `True`,
generates the pooling sequence in a pseudorandom fashion, otherwise, in a
random fashion. Check paper [Benjamin Graham, Fractional
Max-Pooling](http://arxiv.org/abs/1412.6071) for difference between
pseudorandom and random. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> overlapping
						</dt>
						<dd>An optional `bool`.  Defaults to `False`.  When set to `True`,
it means when pooling, the values at the boundary of adjacent pooling
cells are used by both cells. For example:
`index  0  1  2  3  4`
`value  20 5  16 3  7`
If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used
twice.  The result would be [20, 16] for fractional avg pooling. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> deterministic
						</dt>
						<dd>An optional `bool`.  Deprecated; use `fractional_avg_pool_v2`
instead. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> seed
						</dt>
						<dd>An optional `int`.  Defaults to `0`.  If set to be non-zero, the
random number generator is seeded by the given seed.  Otherwise it is
seeded by a random seed. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> seed2
						</dt>
						<dd>An optional `int`.  Deprecated; use `fractional_avg_pool_v2` instead. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of `Tensor` objects (`output`, `row_pooling_sequence`,
`col_pooling_sequence`). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="fractional_max_pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>fractional_max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.object">object</span> pooling_ratio, <span title="System.bool">bool</span> pseudo_random, <span title="System.bool">bool</span> overlapping, <span title="System.bool">bool</span> deterministic, <span title="System.int">int</span> seed, <span title="System.int">int</span> seed2, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs fractional max pooling on the input. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
`seed2` and `deterministic` args are deprecated.  Use fractional_max_pool_v2. <p></p> This is a deprecated version of `fractional_max_pool`. <p></p> Fractional max pooling is slightly different than regular max pooling.  In
regular max pooling, you downsize an input set by taking the maximum value of
smaller N x N subsections of the set (often 2x2), and try to reduce the set by
a factor of N, where N is an integer.  Fractional max pooling, as you might
expect from the word "fractional", means that the overall reduction ratio N
does not have to be an integer. <p></p> The sizes of the pooling regions are generated randomly but are fairly
uniform.  For example, let's look at the height dimension, and the constraints
on the list of rows that will be pool boundaries. <p></p> First we define the following: <p></p> 1.  input_row_length : the number of rows from the input set
2.  output_row_length : which will be smaller than the input
3.  alpha = input_row_length / output_row_length : our reduction ratio
4.  K = floor(alpha)
5.  row_pooling_sequence : this is the result list of pool boundary rows <p></p> Then, row_pooling_sequence should satisfy: <p></p> 1.  a[0] = 0 : the first value of the sequence is 0
2.  a[end] = input_row_length : the last value of the sequence is the size
3.  K <= (a[i+1] - a[i]) <= K+1 : all intervals are K or K+1 size
4.  length(row_pooling_sequence) = output_row_length+1 <p></p> For more details on fractional max pooling, see this paper: [Benjamin Graham,
Fractional Max-Pooling](http://arxiv.org/abs/1412.6071) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A `Tensor`. 4-D with shape `[batch, height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> pooling_ratio
						</dt>
						<dd>A list of `floats` that has length >= 4.  Pooling ratio for
each dimension of `value`, currently only supports row and col dimension
and should be >= 1.0. For example, a valid pooling ratio looks like [1.0,
1.44, 1.73, 1.0]. The first and last elements must be 1.0 because we don't
allow pooling on batch and channels dimensions.  1.44 and 1.73 are pooling
ratio on height and width dimensions respectively. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pseudo_random
						</dt>
						<dd>An optional `bool`.  Defaults to `False`. When set to `True`,
generates the pooling sequence in a pseudorandom fashion, otherwise, in a
random fashion. Check paper [Benjamin Graham, Fractional
Max-Pooling](http://arxiv.org/abs/1412.6071) for difference between
pseudorandom and random. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> overlapping
						</dt>
						<dd>An optional `bool`.  Defaults to `False`.  When set to `True`,
it means when pooling, the values at the boundary of adjacent pooling
cells are used by both cells. For example:
`index  0  1  2  3  4`
`value  20 5  16 3  7`
If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used
twice.  The result would be [20, 16] for fractional max pooling. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> deterministic
						</dt>
						<dd>An optional `bool`.  Deprecated; use `fractional_max_pool_v2`
instead. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> seed
						</dt>
						<dd>An optional `int`.  Defaults to `0`.  If set to be non-zero, the
random number generator is seeded by the given seed.  Otherwise it is
seeded by a random seed. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> seed2
						</dt>
						<dd>An optional `int`.  Deprecated; use `fractional_max_pool_v2` instead. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of `Tensor` objects (`output`, `row_pooling_sequence`,
`col_pooling_sequence`). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="fused_batch_norm" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>fused_batch_norm</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scale, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> mean, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> variance, <span title="System.double">double</span> epsilon, <span title="System.string">string</span> data_format, <span title="System.bool">bool</span> is_training, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Input `Tensor` of 4 dimensions. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scale
						</dt>
						<dd>A `Tensor` of 1 dimension for scaling. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset
						</dt>
						<dd>A `Tensor` of 1 dimension for bias. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> mean
						</dt>
						<dd>A `Tensor` of 1 dimension for population mean used for inference. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> variance
						</dt>
						<dd>A `Tensor` of 1 dimension for population variance
used for inference. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>A small float number added to the variance of x. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for x. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> is_training
						</dt>
						<dd>A bool value to specify if the operation is used for
training or inference. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="fused_batch_norm" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>fused_batch_norm</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scale, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> mean, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> variance, <span title="System.double">double</span> epsilon, <span title="System.string">string</span> data_format, <span title="System.bool">bool</span> is_training, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input `Tensor` of 4 dimensions. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scale
						</dt>
						<dd>A `Tensor` of 1 dimension for scaling. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset
						</dt>
						<dd>A `Tensor` of 1 dimension for bias. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> mean
						</dt>
						<dd>A `Tensor` of 1 dimension for population mean used for inference. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> variance
						</dt>
						<dd>A `Tensor` of 1 dimension for population variance
used for inference. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>A small float number added to the variance of x. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for x. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> is_training
						</dt>
						<dd>A bool value to specify if the operation is used for
training or inference. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="fused_batch_norm_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>fused_batch_norm_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> scale, <span title="System.object">object</span> offset, <span title="System.object">object</span> mean, <span title="System.object">object</span> variance, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> epsilon, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> is_training, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Batch normalization. <p></p> See Source: [Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy]
(http://arxiv.org/abs/1502.03167). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Input `Tensor` of 4 dimensions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>A `Tensor` of 1 dimension for scaling. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset
						</dt>
						<dd>A `Tensor` of 1 dimension for bias. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>A `Tensor` of 1 dimension for population mean used for inference. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance
						</dt>
						<dd>A `Tensor` of 1 dimension for population variance
used for inference. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> epsilon
						</dt>
						<dd>A small float number added to the variance of x. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>The data format for x. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> is_training
						</dt>
						<dd>A bool value to specify if the operation is used for
training or inference. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="l2_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>l2_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> t, <span title="System.string">string</span> name)
		</h4>
		<div class="content">L2 Loss. <p></p> Computes half the L2 norm of a tensor without the `sqrt`: <p></p> output = sum(t ** 2) / 2 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> t
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
Typically 2-D, but may have any dimensions. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `t`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="l2_loss_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>l2_loss_dyn</strong>(<span title="System.object">object</span> t, <span title="System.object">object</span> name)
		</h4>
		<div class="content">L2 Loss. <p></p> Computes half the L2 norm of a tensor without the `sqrt`: <p></p> output = sum(t ** 2) / 2 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> t
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
Typically 2-D, but may have any dimensions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `t`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="l2_normalize" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>l2_normalize</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.double">double</span> epsilon, <span title="System.string">string</span> name, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> dim)
		</h4>
		<div class="content">Normalizes along dimension `axis` using an L2 norm. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> For a 1-D tensor with `axis = 0`, computes <p></p> output = x / sqrt(max(sum(x**2), epsilon)) <p></p> For `x` with more dimensions, independently normalizes each 1-D slice along
dimension `axis`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>Dimension along which to normalize.  A scalar or a vector of
integers. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>A lower bound value for the norm. Will use `sqrt(epsilon)` as the
divisor if `norm < sqrt(epsilon)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same shape as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="l2_normalize_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>l2_normalize_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> epsilon, <span title="System.object">object</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Normalizes along dimension `axis` using an L2 norm. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> For a 1-D tensor with `axis = 0`, computes <p></p> output = x / sqrt(max(sum(x**2), epsilon)) <p></p> For `x` with more dimensions, independently normalizes each 1-D slice along
dimension `axis`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Dimension along which to normalize.  A scalar or a vector of
integers. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> epsilon
						</dt>
						<dd>A lower bound value for the norm. Will use `sqrt(epsilon)` as the
divisor if `norm < sqrt(epsilon)`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with the same shape as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="learned_unigram_candidate_sampler" class="method">
		<h4>
			<span title="System.object">object</span> <strong>learned_unigram_candidate_sampler</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> true_classes, <span title="System.int">int</span> num_true, <span title="System.int">int</span> num_sampled, <span title="System.bool">bool</span> unique, <span title="System.int">int</span> range_max, <span title="System.object">object</span> seed, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Samples a set of classes from a distribution learned during training. <p></p> This operation randomly samples a tensor of sampled classes
(`sampled_candidates`) from the range of integers `[0, range_max)`. <p></p> The elements of `sampled_candidates` are drawn without replacement
(if `unique=True`) or with replacement (if `unique=False`) from
the base distribution. <p></p> The base distribution for this operation is constructed on the fly
during training.  It is a unigram distribution over the target
classes seen so far during training.  Every integer in `[0, range_max)`
begins with a weight of 1, and is incremented by 1 each time it is
seen as a target class.  The base distribution is not saved to checkpoints,
so it is reset when the model is reloaded. <p></p> In addition, this operation returns tensors `true_expected_count`
and `sampled_expected_count` representing the number of times each
of the target classes (`true_classes`) and the sampled
classes (`sampled_candidates`) is expected to occur in an average
tensor of sampled classes.  These values correspond to `Q(y|x)`
defined in [this
document](http://www.tensorflow.org/extras/candidate_sampling.pdf).
If `unique=True`, then these are post-rejection probabilities and we
compute them approximately. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unique
						</dt>
						<dd>A `bool`. Determines whether all sampled classes in a batch are
unique. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> range_max
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="learned_unigram_candidate_sampler_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>learned_unigram_candidate_sampler_dyn</strong>(<span title="System.object">object</span> true_classes, <span title="System.object">object</span> num_true, <span title="System.object">object</span> num_sampled, <span title="System.object">object</span> unique, <span title="System.object">object</span> range_max, <span title="System.object">object</span> seed, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Samples a set of classes from a distribution learned during training. <p></p> This operation randomly samples a tensor of sampled classes
(`sampled_candidates`) from the range of integers `[0, range_max)`. <p></p> The elements of `sampled_candidates` are drawn without replacement
(if `unique=True`) or with replacement (if `unique=False`) from
the base distribution. <p></p> The base distribution for this operation is constructed on the fly
during training.  It is a unigram distribution over the target
classes seen so far during training.  Every integer in `[0, range_max)`
begins with a weight of 1, and is incremented by 1 each time it is
seen as a target class.  The base distribution is not saved to checkpoints,
so it is reset when the model is reloaded. <p></p> In addition, this operation returns tensors `true_expected_count`
and `sampled_expected_count` representing the number of times each
of the target classes (`true_classes`) and the sampled
classes (`sampled_candidates`) is expected to occur in an average
tensor of sampled classes.  These values correspond to `Q(y|x)`
defined in [this
document](http://www.tensorflow.org/extras/candidate_sampling.pdf).
If `unique=True`, then these are post-rejection probabilities and we
compute them approximately. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> unique
						</dt>
						<dd>A `bool`. Determines whether all sampled classes in a batch are
unique. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> range_max
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_poisson_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_poisson_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> targets, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> log_input, <span title="System.bool">bool</span> compute_full_loss, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes log Poisson loss given `log_input`. <p></p> Gives the log-likelihood loss between the prediction and the target under the
assumption that the target has a Poisson distribution.
Caveat: By default, this is not the exact loss, but the loss minus a
constant term [log(z!)]. That has no effect for optimization, but
does not play well with relative loss comparisons. To compute an
approximation of the log factorial term, specify
compute_full_loss=True to enable Stirling's Approximation. <p></p> For brevity, let `c = log(x) = log_input`, `z = targets`.  The log Poisson
loss is <p></p> -log(exp(-x) * (x^z) / z!)
= -log(exp(-x) * (x^z)) + log(z!)
~ -log(exp(-x)) - log(x^z) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
[ Note the second term is the Stirling's Approximation for log(z!).
It is invariant to x and does not affect optimization, though
important for correct relative loss comparisons. It is only
computed when compute_full_loss == True. ]
= x - z * log(x) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
= exp(c) - z * c [+ z * log(z) - z + 0.5 * log(2 * pi * z)] 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> targets
						</dt>
						<dd>A `Tensor` of the same type and shape as `log_input`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> log_input
						</dt>
						<dd>A `Tensor` of type `float32` or `float64`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> compute_full_loss
						</dt>
						<dd>whether to compute the full loss. If false, a constant
term is dropped in favor of more efficient optimization. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `log_input` with the componentwise
logistic losses. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_poisson_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_poisson_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> targets, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> log_input, <span title="System.bool">bool</span> compute_full_loss, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes log Poisson loss given `log_input`. <p></p> Gives the log-likelihood loss between the prediction and the target under the
assumption that the target has a Poisson distribution.
Caveat: By default, this is not the exact loss, but the loss minus a
constant term [log(z!)]. That has no effect for optimization, but
does not play well with relative loss comparisons. To compute an
approximation of the log factorial term, specify
compute_full_loss=True to enable Stirling's Approximation. <p></p> For brevity, let `c = log(x) = log_input`, `z = targets`.  The log Poisson
loss is <p></p> -log(exp(-x) * (x^z) / z!)
= -log(exp(-x) * (x^z)) + log(z!)
~ -log(exp(-x)) - log(x^z) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
[ Note the second term is the Stirling's Approximation for log(z!).
It is invariant to x and does not affect optimization, though
important for correct relative loss comparisons. It is only
computed when compute_full_loss == True. ]
= x - z * log(x) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
= exp(c) - z * c [+ z * log(z) - z + 0.5 * log(2 * pi * z)] 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> targets
						</dt>
						<dd>A `Tensor` of the same type and shape as `log_input`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> log_input
						</dt>
						<dd>A `Tensor` of type `float32` or `float64`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> compute_full_loss
						</dt>
						<dd>whether to compute the full loss. If false, a constant
term is dropped in favor of more efficient optimization. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `log_input` with the componentwise
logistic losses. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_poisson_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_poisson_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> targets, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> log_input, <span title="System.bool">bool</span> compute_full_loss, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes log Poisson loss given `log_input`. <p></p> Gives the log-likelihood loss between the prediction and the target under the
assumption that the target has a Poisson distribution.
Caveat: By default, this is not the exact loss, but the loss minus a
constant term [log(z!)]. That has no effect for optimization, but
does not play well with relative loss comparisons. To compute an
approximation of the log factorial term, specify
compute_full_loss=True to enable Stirling's Approximation. <p></p> For brevity, let `c = log(x) = log_input`, `z = targets`.  The log Poisson
loss is <p></p> -log(exp(-x) * (x^z) / z!)
= -log(exp(-x) * (x^z)) + log(z!)
~ -log(exp(-x)) - log(x^z) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
[ Note the second term is the Stirling's Approximation for log(z!).
It is invariant to x and does not affect optimization, though
important for correct relative loss comparisons. It is only
computed when compute_full_loss == True. ]
= x - z * log(x) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
= exp(c) - z * c [+ z * log(z) - z + 0.5 * log(2 * pi * z)] 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> targets
						</dt>
						<dd>A `Tensor` of the same type and shape as `log_input`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> log_input
						</dt>
						<dd>A `Tensor` of type `float32` or `float64`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> compute_full_loss
						</dt>
						<dd>whether to compute the full loss. If false, a constant
term is dropped in favor of more efficient optimization. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `log_input` with the componentwise
logistic losses. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_poisson_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_poisson_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> targets, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> log_input, <span title="System.bool">bool</span> compute_full_loss, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes log Poisson loss given `log_input`. <p></p> Gives the log-likelihood loss between the prediction and the target under the
assumption that the target has a Poisson distribution.
Caveat: By default, this is not the exact loss, but the loss minus a
constant term [log(z!)]. That has no effect for optimization, but
does not play well with relative loss comparisons. To compute an
approximation of the log factorial term, specify
compute_full_loss=True to enable Stirling's Approximation. <p></p> For brevity, let `c = log(x) = log_input`, `z = targets`.  The log Poisson
loss is <p></p> -log(exp(-x) * (x^z) / z!)
= -log(exp(-x) * (x^z)) + log(z!)
~ -log(exp(-x)) - log(x^z) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
[ Note the second term is the Stirling's Approximation for log(z!).
It is invariant to x and does not affect optimization, though
important for correct relative loss comparisons. It is only
computed when compute_full_loss == True. ]
= x - z * log(x) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
= exp(c) - z * c [+ z * log(z) - z + 0.5 * log(2 * pi * z)] 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> targets
						</dt>
						<dd>A `Tensor` of the same type and shape as `log_input`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> log_input
						</dt>
						<dd>A `Tensor` of type `float32` or `float64`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> compute_full_loss
						</dt>
						<dd>whether to compute the full loss. If false, a constant
term is dropped in favor of more efficient optimization. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `log_input` with the componentwise
logistic losses. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_poisson_loss_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>log_poisson_loss_dyn</strong>(<span title="System.object">object</span> targets, <span title="System.object">object</span> log_input, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> compute_full_loss, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes log Poisson loss given `log_input`. <p></p> Gives the log-likelihood loss between the prediction and the target under the
assumption that the target has a Poisson distribution.
Caveat: By default, this is not the exact loss, but the loss minus a
constant term [log(z!)]. That has no effect for optimization, but
does not play well with relative loss comparisons. To compute an
approximation of the log factorial term, specify
compute_full_loss=True to enable Stirling's Approximation. <p></p> For brevity, let `c = log(x) = log_input`, `z = targets`.  The log Poisson
loss is <p></p> -log(exp(-x) * (x^z) / z!)
= -log(exp(-x) * (x^z)) + log(z!)
~ -log(exp(-x)) - log(x^z) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
[ Note the second term is the Stirling's Approximation for log(z!).
It is invariant to x and does not affect optimization, though
important for correct relative loss comparisons. It is only
computed when compute_full_loss == True. ]
= x - z * log(x) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
= exp(c) - z * c [+ z * log(z) - z + 0.5 * log(2 * pi * z)] 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> targets
						</dt>
						<dd>A `Tensor` of the same type and shape as `log_input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> log_input
						</dt>
						<dd>A `Tensor` of type `float32` or `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> compute_full_loss
						</dt>
						<dd>whether to compute the full loss. If false, a constant
term is dropped in favor of more efficient optimization. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of the same shape as `log_input` with the componentwise
logistic losses. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_softmax</strong>(<a href="../numpy/float32.htm">float32</a> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes log softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> For each batch `i` and class `j` we have <p></p> logsoftmax = logits - log(reduce_sum(exp(logits), axis)) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/float32.htm">float32</a></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `logits`. Same shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_softmax</strong>(<a href="../numpy/ndarray.htm">ndarray</a> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes log softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> For each batch `i` and class `j` we have <p></p> logsoftmax = logits - log(reduce_sum(exp(logits), axis)) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `logits`. Same shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_softmax</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes log softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> For each batch `i` and class `j` we have <p></p> logsoftmax = logits - log(reduce_sum(exp(logits), axis)) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `logits`. Same shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_softmax</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes log softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> For each batch `i` and class `j` we have <p></p> logsoftmax = logits - log(reduce_sum(exp(logits), axis)) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `logits`. Same shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_softmax</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes log softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> For each batch `i` and class `j` we have <p></p> logsoftmax = logits - log(reduce_sum(exp(logits), axis)) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `logits`. Same shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_softmax</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes log softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> For each batch `i` and class `j` we have <p></p> logsoftmax = logits - log(reduce_sum(exp(logits), axis)) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `logits`. Same shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>log_softmax</strong>(<span title="System.double">double</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes log softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> For each batch `i` and class `j` we have <p></p> logsoftmax = logits - log(reduce_sum(exp(logits), axis)) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.double">double</span></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `logits`. Same shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_softmax_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>log_softmax_dyn</strong>(<span title="System.object">object</span> logits, <span title="System.object">object</span> axis, <span title="System.object">object</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes log softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> For each batch `i` and class `j` we have <p></p> logsoftmax = logits - log(reduce_sum(exp(logits), axis)) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `logits`. Same shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_uniform_candidate_sampler" class="method">
		<h4>
			<span title="System.object">object</span> <strong>log_uniform_candidate_sampler</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> true_classes, <span title="System.int">int</span> num_true, <span title="System.int">int</span> num_sampled, <span title="System.bool">bool</span> unique, <span title="System.int">int</span> range_max, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Samples a set of classes using a log-uniform (Zipfian) base distribution. <p></p> This operation randomly samples a tensor of sampled classes
(`sampled_candidates`) from the range of integers `[0, range_max)`. <p></p> The elements of `sampled_candidates` are drawn without replacement
(if `unique=True`) or with replacement (if `unique=False`) from
the base distribution. <p></p> The base distribution for this operation is an approximately log-uniform
or Zipfian distribution: <p></p> `P(class) = (log(class + 2) - log(class + 1)) / log(range_max + 1)` <p></p> This sampler is useful when the target classes approximately follow such
a distribution - for example, if the classes represent words in a lexicon
sorted in decreasing order of frequency. If your classes are not ordered by
decreasing frequency, do not use this op. <p></p> In addition, this operation returns tensors `true_expected_count`
and `sampled_expected_count` representing the number of times each
of the target classes (`true_classes`) and the sampled
classes (`sampled_candidates`) is expected to occur in an average
tensor of sampled classes.  These values correspond to `Q(y|x)`
defined in [this
document](http://www.tensorflow.org/extras/candidate_sampling.pdf).
If `unique=True`, then these are post-rejection probabilities and we
compute them approximately. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unique
						</dt>
						<dd>A `bool`. Determines whether all sampled classes in a batch are
unique. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> range_max
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_uniform_candidate_sampler_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>log_uniform_candidate_sampler_dyn</strong>(<span title="System.object">object</span> true_classes, <span title="System.object">object</span> num_true, <span title="System.object">object</span> num_sampled, <span title="System.object">object</span> unique, <span title="System.object">object</span> range_max, <span title="System.object">object</span> seed, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Samples a set of classes using a log-uniform (Zipfian) base distribution. <p></p> This operation randomly samples a tensor of sampled classes
(`sampled_candidates`) from the range of integers `[0, range_max)`. <p></p> The elements of `sampled_candidates` are drawn without replacement
(if `unique=True`) or with replacement (if `unique=False`) from
the base distribution. <p></p> The base distribution for this operation is an approximately log-uniform
or Zipfian distribution: <p></p> `P(class) = (log(class + 2) - log(class + 1)) / log(range_max + 1)` <p></p> This sampler is useful when the target classes approximately follow such
a distribution - for example, if the classes represent words in a lexicon
sorted in decreasing order of frequency. If your classes are not ordered by
decreasing frequency, do not use this op. <p></p> In addition, this operation returns tensors `true_expected_count`
and `sampled_expected_count` representing the number of times each
of the target classes (`true_classes`) and the sampled
classes (`sampled_candidates`) is expected to occur in an average
tensor of sampled classes.  These values correspond to `Q(y|x)`
defined in [this
document](http://www.tensorflow.org/extras/candidate_sampling.pdf).
If `unique=True`, then these are post-rejection probabilities and we
compute them approximately. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> unique
						</dt>
						<dd>A `bool`. Determines whether all sampled classes in a batch are
unique. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> range_max
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="lrn" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>lrn</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> depth_radius, <span title="System.double">double</span> bias, <span title="System.double">double</span> alpha, <span title="System.double">double</span> beta, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Local Response Normalization. <p></p> The 4-D `input` tensor is treated as a 3-D array of 1-D vectors (along the last
dimension), and each vector is normalized independently.  Within a given vector,
each component is divided by the weighted, squared sum of inputs within
`depth_radius`.  In detail, <p></p> sqr_sum[a, b, c, d] =
sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
output = input / (bias + alpha * sqr_sum) ** beta <p></p> For details, see [Krizhevsky et al., ImageNet classification with deep
convolutional neural networks (NIPS 2012)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
4-D. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> depth_radius
						</dt>
						<dd>An optional `int`. Defaults to `5`.
0-D.  Half-width of the 1-D normalization window. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> bias
						</dt>
						<dd>An optional `float`. Defaults to `1`.
An offset (usually positive to avoid dividing by 0). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>An optional `float`. Defaults to `1`.
A scale factor, usually positive. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> beta
						</dt>
						<dd>An optional `float`. Defaults to `0.5`. An exponent. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="lrn" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>lrn</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> depth_radius, <span title="System.double">double</span> bias, <span title="System.int">int</span> alpha, <span title="System.double">double</span> beta, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Local Response Normalization. <p></p> The 4-D `input` tensor is treated as a 3-D array of 1-D vectors (along the last
dimension), and each vector is normalized independently.  Within a given vector,
each component is divided by the weighted, squared sum of inputs within
`depth_radius`.  In detail, <p></p> sqr_sum[a, b, c, d] =
sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
output = input / (bias + alpha * sqr_sum) ** beta <p></p> For details, see [Krizhevsky et al., ImageNet classification with deep
convolutional neural networks (NIPS 2012)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
4-D. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> depth_radius
						</dt>
						<dd>An optional `int`. Defaults to `5`.
0-D.  Half-width of the 1-D normalization window. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> bias
						</dt>
						<dd>An optional `float`. Defaults to `1`.
An offset (usually positive to avoid dividing by 0). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> alpha
						</dt>
						<dd>An optional `float`. Defaults to `1`.
A scale factor, usually positive. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> beta
						</dt>
						<dd>An optional `float`. Defaults to `0.5`. An exponent. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="lrn" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>lrn</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> depth_radius, <span title="System.int">int</span> bias, <span title="System.double">double</span> alpha, <span title="System.double">double</span> beta, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Local Response Normalization. <p></p> The 4-D `input` tensor is treated as a 3-D array of 1-D vectors (along the last
dimension), and each vector is normalized independently.  Within a given vector,
each component is divided by the weighted, squared sum of inputs within
`depth_radius`.  In detail, <p></p> sqr_sum[a, b, c, d] =
sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
output = input / (bias + alpha * sqr_sum) ** beta <p></p> For details, see [Krizhevsky et al., ImageNet classification with deep
convolutional neural networks (NIPS 2012)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
4-D. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> depth_radius
						</dt>
						<dd>An optional `int`. Defaults to `5`.
0-D.  Half-width of the 1-D normalization window. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> bias
						</dt>
						<dd>An optional `float`. Defaults to `1`.
An offset (usually positive to avoid dividing by 0). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>An optional `float`. Defaults to `1`.
A scale factor, usually positive. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> beta
						</dt>
						<dd>An optional `float`. Defaults to `0.5`. An exponent. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="lrn" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>lrn</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> depth_radius, <span title="System.int">int</span> bias, <span title="System.int">int</span> alpha, <span title="System.double">double</span> beta, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Local Response Normalization. <p></p> The 4-D `input` tensor is treated as a 3-D array of 1-D vectors (along the last
dimension), and each vector is normalized independently.  Within a given vector,
each component is divided by the weighted, squared sum of inputs within
`depth_radius`.  In detail, <p></p> sqr_sum[a, b, c, d] =
sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
output = input / (bias + alpha * sqr_sum) ** beta <p></p> For details, see [Krizhevsky et al., ImageNet classification with deep
convolutional neural networks (NIPS 2012)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
4-D. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> depth_radius
						</dt>
						<dd>An optional `int`. Defaults to `5`.
0-D.  Half-width of the 1-D normalization window. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> bias
						</dt>
						<dd>An optional `float`. Defaults to `1`.
An offset (usually positive to avoid dividing by 0). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> alpha
						</dt>
						<dd>An optional `float`. Defaults to `1`.
A scale factor, usually positive. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> beta
						</dt>
						<dd>An optional `float`. Defaults to `0.5`. An exponent. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="lrn_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>lrn_dyn</strong>(<span title="System.object">object</span> input, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> depth_radius, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> bias, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> alpha, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> beta, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Local Response Normalization. <p></p> The 4-D `input` tensor is treated as a 3-D array of 1-D vectors (along the last
dimension), and each vector is normalized independently.  Within a given vector,
each component is divided by the weighted, squared sum of inputs within
`depth_radius`.  In detail, <p></p> sqr_sum[a, b, c, d] =
sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
output = input / (bias + alpha * sqr_sum) ** beta <p></p> For details, see [Krizhevsky et al., ImageNet classification with deep
convolutional neural networks (NIPS 2012)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
4-D. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> depth_radius
						</dt>
						<dd>An optional `int`. Defaults to `5`.
0-D.  Half-width of the 1-D normalization window. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> bias
						</dt>
						<dd>An optional `float`. Defaults to `1`.
An offset (usually positive to avoid dividing by 0). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> alpha
						</dt>
						<dd>An optional `float`. Defaults to `1`.
A scale factor, usually positive. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> beta
						</dt>
						<dd>An optional `float`. Defaults to `0.5`. An exponent. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `input`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.int">int</span> ksize, <span title="System.object">object</span> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.int">int</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span> ksize, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> strides, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object>">ValueTuple&lt;int, int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>max_pool_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <span title="System.object">object</span> name, <span title="System.object">object</span> input)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`.
The stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Alias for value. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool_v2</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape `[batch_size] + input_spatial_shape +
[num_channels]` if `data_format` does not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC". Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The size
of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string. Specifies the channel dimension. For N=1 it can be
either "NWC" (default) or "NCW", for N=2 it can be either "NHWC" (default)
or "NCHW" and for N=3 either "NDHWC" (default) or "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool_v2</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.object">object</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape `[batch_size] + input_spatial_shape +
[num_channels]` if `data_format` does not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC". Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The size
of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string. Specifies the channel dimension. For N=1 it can be
either "NWC" (default) or "NCW", for N=2 it can be either "NHWC" (default)
or "NCHW" and for N=3 either "NDHWC" (default) or "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool_v2_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>max_pool_v2_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> data_format, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape `[batch_size] + input_spatial_shape +
[num_channels]` if `data_format` does not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC". Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The size
of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `N` or `N+2`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string. Specifies the channel dimension. For N=1 it can be
either "NWC" (default) or "NCW", for N=2 it can be either "NHWC" (default)
or "NCHW" and for N=3 either "NDHWC" (default) or "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool_with_argmax" class="method">
		<h4>
			<span title="System.object">object</span> <strong>max_pool_with_argmax</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.object">object</span> Targmax, <span title="System.string">string</span> name, <span title="System.object">object</span> output_dtype, <span title="System.bool">bool</span> include_batch_in_index)
		</h4>
		<div class="content">Performs max pooling on the input and outputs both max values and indices. <p></p> The indices in `argmax` are flattened, so that a maximum value at position
`[b, y, x, c]` becomes flattened index:
`(y * width + x) * channels + c` if `include_batch_in_index` is False;
`((b * height + y) * width + x) * channels + c` if `include_batch_in_index` is True. <p></p> The indices returned are always in `[0, height) x [0, width)` before flattening,
even if padding is involved and the mathematically correct answer is outside
(either negative or too large).  This is a bug, but fixing it is difficult to do
in a safe backwards compatible way, especially due to flattening. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
4-D with shape `[batch, height, width, channels]`.  Input to pool over. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ksize
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
The stride of the sliding window for each dimension of the
input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dt>
							<code><span title="System.object">object</span></code> Targmax
						</dt>
						<dd>An optional <a href="..\..\tf\dtypes\DType.md"><code>tf.DType</code></a> from: `tf.int32, tf.int64`. Defaults to <a href="..\..\tf\dtypes\int64.md"><code>tf.int64</code></a>. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_dtype
						</dt>
						<dt>
							<code><span title="System.bool">bool</span></code> include_batch_in_index
						</dt>
						<dd>An optional `bool`. Defaults to `False`.
Whether to include batch dimension in flattened index of `argmax`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of `Tensor` objects (output, argmax). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool_with_argmax_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>max_pool_with_argmax_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <span title="System.object">object</span> Targmax, <span title="System.object">object</span> name, <span title="System.object">object</span> output_dtype, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> include_batch_in_index)
		</h4>
		<div class="content">Performs max pooling on the input and outputs both max values and indices. <p></p> The indices in `argmax` are flattened, so that a maximum value at position
`[b, y, x, c]` becomes flattened index:
`(y * width + x) * channels + c` if `include_batch_in_index` is False;
`((b * height + y) * width + x) * channels + c` if `include_batch_in_index` is True. <p></p> The indices returned are always in `[0, height) x [0, width)` before flattening,
even if padding is involved and the mathematically correct answer is outside
(either negative or too large).  This is a bug, but fixing it is difficult to do
in a safe backwards compatible way, especially due to flattening. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
4-D with shape `[batch, height, width, channels]`.  Input to pool over. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ksize
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
The size of the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A list of `ints` that has length `>= 4`.
The stride of the sliding window for each dimension of the
input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A `string` from: `"SAME", "VALID"`.
The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dt>
							<code><span title="System.object">object</span></code> Targmax
						</dt>
						<dd>An optional <a href="..\..\tf\dtypes\DType.md"><code>tf.DType</code></a> from: `tf.int32, tf.int64`. Defaults to <a href="..\..\tf\dtypes\int64.md"><code>tf.int64</code></a>. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_dtype
						</dt>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> include_batch_in_index
						</dt>
						<dd>An optional `bool`. Defaults to `False`.
Whether to include batch dimension in flattened index of `argmax`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of `Tensor` objects (output, argmax). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool1d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool1d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. <p></p> Note internally this op reshapes and uses the underlying 2d operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The size of the
window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The stride of
the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NWC", "NCW". Defaults to "NWC". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool1d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool1d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. <p></p> Note internally this op reshapes and uses the underlying 2d operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 3-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The size of the
window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The stride of
the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NWC", "NCW". Defaults to "NWC". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool1d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>max_pool1d_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. <p></p> Note internally this op reshapes and uses the underlying 2d operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A 3-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The size of the
window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1` or `3`. The stride of
the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>An optional string from: "NWC", "NCW". Defaults to "NWC". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>max_pool2d_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> ksize, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> data_format, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>A 4-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `2` or `4`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> data_format
						</dt>
						<dd>A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.int">int</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.int">int</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> ksize, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> ksize, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_pool3d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max_pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> ksize, <span title="System.int">int</span> strides, <span title="System.object">object</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs the max pooling on the input. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A 5-D `Tensor` of the format specified by `data_format`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> ksize
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The size of
the window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>An int or list of `ints` that has length `1`, `3` or `5`. The
stride of the sliding window for each dimension of the input tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`. The padding algorithm. See
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>An optional string from: "NDHWC", "NCDHW". Defaults to "NDHWC".
The data format of the input and output data. With the default format
"NDHWC", the data is stored in the order of: [batch, in_depth, in_height,
in_width, in_channels]. Alternatively, the format could be "NCDHW", the
data storage order is: [batch, in_channels, in_depth, in_height,
in_width]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of format specified by `data_format`.
The max pooled output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="moments" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>moments</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes, <span title="System.object">object</span> shift, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keep_dims, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keepdims)
		</h4>
		<div class="content">Calculate the mean and variance of `x`. <p></p> The mean and variance are calculated by aggregating the contents of `x`
across `axes`.  If `x` is 1-D and `axes = [0]` this is just the mean
and variance of a vector. <p></p> Note: shift is currently not used; the true mean is computed and used. <p></p> When using these moments for batch normalization (see
<a href="..\..\tf\nn\batch_normalization.md"><code>tf.nn.batch_normalization</code></a>): <p></p> * for so-called "global normalization", used with convolutional filters with
shape `[batch, height, width, depth]`, pass `axes=[0, 1, 2]`.
* for simple batch normalization pass `axes=[0]` (batch only). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>Array of ints.  Axes along which to compute mean and
variance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> shift
						</dt>
						<dd>Not used in the current implementation 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Name used to scope the operations that compute the moments. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keep_dims
						</dt>
						<dd>produce moments with the same dimensionality as the input. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keepdims
						</dt>
						<dd>Alias to keep_dims. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>Two `Tensor` objects: `mean` and `variance`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="moments_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>moments_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axes, <span title="System.object">object</span> shift, <span title="System.object">object</span> name, <span title="System.object">object</span> keep_dims, <span title="System.object">object</span> keepdims)
		</h4>
		<div class="content">Calculate the mean and variance of `x`. <p></p> The mean and variance are calculated by aggregating the contents of `x`
across `axes`.  If `x` is 1-D and `axes = [0]` this is just the mean
and variance of a vector. <p></p> Note: shift is currently not used; the true mean is computed and used. <p></p> When using these moments for batch normalization (see
<a href="..\..\tf\nn\batch_normalization.md"><code>tf.nn.batch_normalization</code></a>): <p></p> * for so-called "global normalization", used with convolutional filters with
shape `[batch, height, width, depth]`, pass `axes=[0, 1, 2]`.
* for simple batch normalization pass `axes=[0]` (batch only). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axes
						</dt>
						<dd>Array of ints.  Axes along which to compute mean and
variance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> shift
						</dt>
						<dd>Not used in the current implementation 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Name used to scope the operations that compute the moments. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> keep_dims
						</dt>
						<dd>produce moments with the same dimensionality as the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> keepdims
						</dt>
						<dd>Alias to keep_dims. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Two `Tensor` objects: `mean` and `variance`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="nce_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>nce_loss</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> weights, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> biases, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.int">int</span> num_sampled, <span title="System.int">int</span> num_classes, <span title="System.int">int</span> num_true, <span title="System.object">object</span> sampled_values, <span title="System.bool">bool</span> remove_accidental_hits, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes and returns the noise-contrastive estimation training loss. <p></p> See [Noise-contrastive estimation: A new estimation principle for
unnormalized statistical
models](http://www.jmlr.org/proceedings/papers/v9/gutmann10a/gutmann10a.pdf).
Also see our [Candidate Sampling Algorithms
Reference](https://www.tensorflow.org/extras/candidate_sampling.pdf) <p></p> A common use case is to use this method for training, and calculate the full
sigmoid loss for evaluation or inference. In this case, you must set
`partition_strategy="div"` for the two losses to be consistent, as in the
following example:
Note: By default this uses a log-uniform (Zipfian) distribution for sampling,
so your labels must be sorted in order of decreasing frequency to achieve
good results.  For more details, see
<a href="..\..\tf\random\log_uniform_candidate_sampler.md"><code>tf.random.log_uniform_candidate_sampler</code></a>. <p></p> Note: In the case where `num_true` > 1, we assign to each target class
the target probability 1 / `num_true` so that the target probabilities
sum to 1 per-example. <p></p> Note: It would be useful to allow a variable number of target classes per
example.  We hope to provide this functionality in a future release.
For now, if you have a variable number of target classes, you can pad them
out to a constant number by either repeating them or by padding
with an otherwise unused class. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> weights
						</dt>
						<dd>A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`
objects whose concatenation along dimension 0 has shape
[num_classes, dim].  The (possibly-partitioned) class embeddings. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> biases
						</dt>
						<dd>A `Tensor` of shape `[num_classes]`.  The class biases. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A `Tensor` of shape `[batch_size, dim]`.  The forward
activations of the input network. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of negative classes to randomly sample
per batch. This single sample of negative classes is evaluated for each
element in the batch. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_classes
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sampled_values
						</dt>
						<dd>a tuple of (`sampled_candidates`, `true_expected_count`,
`sampled_expected_count`) returned by a `*_candidate_sampler` function.
(if None, we default to `log_uniform_candidate_sampler`) 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> remove_accidental_hits
						</dt>
						<dd>A `bool`.  Whether to remove "accidental hits"
where a sampled class equals one of the target classes.  If set to
`True`, this is a "Sampled Logistic" loss instead of NCE, and we are
learning to generate log-odds instead of log probabilities.  See
our [Candidate Sampling Algorithms Reference]
(https://www.tensorflow.org/extras/candidate_sampling.pdf).
Default is False. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(weights) > 1`. Currently `"div"` and `"mod"` are supported.
Default is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `batch_size` 1-D tensor of per-example NCE losses. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>if mode == "train":
              loss = tf.nn.nce_loss(
                  weights=weights,
                  biases=biases,
                  labels=labels,
                  inputs=inputs,
                 ...,
                  partition_strategy="div")
            elif mode == "eval":
              logits = tf.matmul(inputs, tf.transpose(weights))
              logits = tf.nn.bias_add(logits, biases)
              labels_one_hot = tf.one_hot(labels, n_classes)
              loss = tf.nn.sigmoid_cross_entropy_with_logits(
                  labels=labels_one_hot,
                  logits=logits)
              loss = tf.reduce_sum(loss, axis=1) </pre>
</div>
		</div>
	</div>
	<div id="nce_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>nce_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> weights, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> biases, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.int">int</span> num_sampled, <span title="System.int">int</span> num_classes, <span title="System.int">int</span> num_true, <span title="System.object">object</span> sampled_values, <span title="System.bool">bool</span> remove_accidental_hits, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes and returns the noise-contrastive estimation training loss. <p></p> See [Noise-contrastive estimation: A new estimation principle for
unnormalized statistical
models](http://www.jmlr.org/proceedings/papers/v9/gutmann10a/gutmann10a.pdf).
Also see our [Candidate Sampling Algorithms
Reference](https://www.tensorflow.org/extras/candidate_sampling.pdf) <p></p> A common use case is to use this method for training, and calculate the full
sigmoid loss for evaluation or inference. In this case, you must set
`partition_strategy="div"` for the two losses to be consistent, as in the
following example:
Note: By default this uses a log-uniform (Zipfian) distribution for sampling,
so your labels must be sorted in order of decreasing frequency to achieve
good results.  For more details, see
<a href="..\..\tf\random\log_uniform_candidate_sampler.md"><code>tf.random.log_uniform_candidate_sampler</code></a>. <p></p> Note: In the case where `num_true` > 1, we assign to each target class
the target probability 1 / `num_true` so that the target probabilities
sum to 1 per-example. <p></p> Note: It would be useful to allow a variable number of target classes per
example.  We hope to provide this functionality in a future release.
For now, if you have a variable number of target classes, you can pad them
out to a constant number by either repeating them or by padding
with an otherwise unused class. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> weights
						</dt>
						<dd>A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`
objects whose concatenation along dimension 0 has shape
[num_classes, dim].  The (possibly-partitioned) class embeddings. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> biases
						</dt>
						<dd>A `Tensor` of shape `[num_classes]`.  The class biases. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A `Tensor` of shape `[batch_size, dim]`.  The forward
activations of the input network. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of negative classes to randomly sample
per batch. This single sample of negative classes is evaluated for each
element in the batch. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_classes
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sampled_values
						</dt>
						<dd>a tuple of (`sampled_candidates`, `true_expected_count`,
`sampled_expected_count`) returned by a `*_candidate_sampler` function.
(if None, we default to `log_uniform_candidate_sampler`) 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> remove_accidental_hits
						</dt>
						<dd>A `bool`.  Whether to remove "accidental hits"
where a sampled class equals one of the target classes.  If set to
`True`, this is a "Sampled Logistic" loss instead of NCE, and we are
learning to generate log-odds instead of log probabilities.  See
our [Candidate Sampling Algorithms Reference]
(https://www.tensorflow.org/extras/candidate_sampling.pdf).
Default is False. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(weights) > 1`. Currently `"div"` and `"mod"` are supported.
Default is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `batch_size` 1-D tensor of per-example NCE losses. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>if mode == "train":
              loss = tf.nn.nce_loss(
                  weights=weights,
                  biases=biases,
                  labels=labels,
                  inputs=inputs,
                 ...,
                  partition_strategy="div")
            elif mode == "eval":
              logits = tf.matmul(inputs, tf.transpose(weights))
              logits = tf.nn.bias_add(logits, biases)
              labels_one_hot = tf.one_hot(labels, n_classes)
              loss = tf.nn.sigmoid_cross_entropy_with_logits(
                  labels=labels_one_hot,
                  logits=logits)
              loss = tf.reduce_sum(loss, axis=1) </pre>
</div>
		</div>
	</div>
	<div id="nce_loss_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>nce_loss_dyn</strong>(<span title="System.object">object</span> weights, <span title="System.object">object</span> biases, <span title="System.object">object</span> labels, <span title="System.object">object</span> inputs, <span title="System.object">object</span> num_sampled, <span title="System.object">object</span> num_classes, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> num_true, <span title="System.object">object</span> sampled_values, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> remove_accidental_hits, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> partition_strategy, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> name)
		</h4>
		<div class="content">Computes and returns the noise-contrastive estimation training loss. <p></p> See [Noise-contrastive estimation: A new estimation principle for
unnormalized statistical
models](http://www.jmlr.org/proceedings/papers/v9/gutmann10a/gutmann10a.pdf).
Also see our [Candidate Sampling Algorithms
Reference](https://www.tensorflow.org/extras/candidate_sampling.pdf) <p></p> A common use case is to use this method for training, and calculate the full
sigmoid loss for evaluation or inference. In this case, you must set
`partition_strategy="div"` for the two losses to be consistent, as in the
following example:
Note: By default this uses a log-uniform (Zipfian) distribution for sampling,
so your labels must be sorted in order of decreasing frequency to achieve
good results.  For more details, see
<a href="..\..\tf\random\log_uniform_candidate_sampler.md"><code>tf.random.log_uniform_candidate_sampler</code></a>. <p></p> Note: In the case where `num_true` > 1, we assign to each target class
the target probability 1 / `num_true` so that the target probabilities
sum to 1 per-example. <p></p> Note: It would be useful to allow a variable number of target classes per
example.  We hope to provide this functionality in a future release.
For now, if you have a variable number of target classes, you can pad them
out to a constant number by either repeating them or by padding
with an otherwise unused class. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> weights
						</dt>
						<dd>A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`
objects whose concatenation along dimension 0 has shape
[num_classes, dim].  The (possibly-partitioned) class embeddings. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> biases
						</dt>
						<dd>A `Tensor` of shape `[num_classes]`.  The class biases. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>A `Tensor` of shape `[batch_size, dim]`.  The forward
activations of the input network. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of negative classes to randomly sample
per batch. This single sample of negative classes is evaluated for each
element in the batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_classes
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sampled_values
						</dt>
						<dd>a tuple of (`sampled_candidates`, `true_expected_count`,
`sampled_expected_count`) returned by a `*_candidate_sampler` function.
(if None, we default to `log_uniform_candidate_sampler`) 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> remove_accidental_hits
						</dt>
						<dd>A `bool`.  Whether to remove "accidental hits"
where a sampled class equals one of the target classes.  If set to
`True`, this is a "Sampled Logistic" loss instead of NCE, and we are
learning to generate log-odds instead of log probabilities.  See
our [Candidate Sampling Algorithms Reference]
(https://www.tensorflow.org/extras/candidate_sampling.pdf).
Default is False. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(weights) > 1`. Currently `"div"` and `"mod"` are supported.
Default is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `batch_size` 1-D tensor of per-example NCE losses. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>if mode == "train":
              loss = tf.nn.nce_loss(
                  weights=weights,
                  biases=biases,
                  labels=labels,
                  inputs=inputs,
                 ...,
                  partition_strategy="div")
            elif mode == "eval":
              logits = tf.matmul(inputs, tf.transpose(weights))
              logits = tf.nn.bias_add(logits, biases)
              labels_one_hot = tf.one_hot(labels, n_classes)
              loss = tf.nn.sigmoid_cross_entropy_with_logits(
                  labels=labels_one_hot,
                  logits=logits)
              loss = tf.reduce_sum(loss, axis=1) </pre>
</div>
		</div>
	</div>
	<div id="normalize_moments" class="method">
		<h4>
			<span title="System.object">object</span> <strong>normalize_moments</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> counts, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> mean_ss, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> variance_ss, <span title="System.object">object</span> shift, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Calculate the mean and variance of based on the sufficient statistics. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> counts
						</dt>
						<dd>A `Tensor` containing the total count of the data (one value). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> mean_ss
						</dt>
						<dd>A `Tensor` containing the mean sufficient statistics: the (possibly
shifted) sum of the elements to average over. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> variance_ss
						</dt>
						<dd>A `Tensor` containing the variance sufficient statistics: the
(possibly shifted) squared sum of the data to compute the variance over. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> shift
						</dt>
						<dd>A `Tensor` containing the value by which the data is shifted for
numerical stability, or `None` if no shift was performed. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Name used to scope the operations that compute the moments. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Two `Tensor` objects: `mean` and `variance`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="normalize_moments_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>normalize_moments_dyn</strong>(<span title="System.object">object</span> counts, <span title="System.object">object</span> mean_ss, <span title="System.object">object</span> variance_ss, <span title="System.object">object</span> shift, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Calculate the mean and variance of based on the sufficient statistics. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> counts
						</dt>
						<dd>A `Tensor` containing the total count of the data (one value). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean_ss
						</dt>
						<dd>A `Tensor` containing the mean sufficient statistics: the (possibly
shifted) sum of the elements to average over. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variance_ss
						</dt>
						<dd>A `Tensor` containing the variance sufficient statistics: the
(possibly shifted) squared sum of the data to compute the variance over. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> shift
						</dt>
						<dd>A `Tensor` containing the value by which the data is shifted for
numerical stability, or `None` if no shift was performed. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Name used to scope the operations that compute the moments. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Two `Tensor` objects: `mean` and `variance`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> window_shape, <span title="System.string">string</span> pooling_type, <span title="System.string">string</span> padding, <a href="../numpy/ndarray.htm">ndarray</a> dilation_rate, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> strides, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Performs an N-D pooling operation. <p></p> In the case that `data_format` does not start with "NC", computes for
0 <= b < batch_size,
0 <= x[i] < output_spatial_shape[i],
0 <= c < num_channels: <p></p> ```
output[b, x[0],..., x[N-1], c] =
REDUCE_{z[0],..., z[N-1]}
input[b,
x[0] * strides[0] - pad_before[0] + dilation_rate[0]*z[0],
...
x[N-1]*strides[N-1] - pad_before[N-1] + dilation_rate[N-1]*z[N-1],
c],
``` <p></p> where the reduction function REDUCE depends on the value of `pooling_type`,
and pad_before is defined based on the value of `padding` as described in
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details.
The reduction never includes out-of-bounds positions. <p></p> In the case that `data_format` starts with `"NC"`, the `input` and output are
simply transposed as follows: <p></p> ```
pool(input, data_format, **kwargs) =
tf.transpose(pool(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1))
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape
`[batch_size] + input_spatial_shape + [num_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC".  Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> window_shape
						</dt>
						<dd>Sequence of N ints >= 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pooling_type
						</dt>
						<dd>Specifies pooling operation, must be "AVG" or "MAX". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>The padding algorithm, must be "SAME" or "VALID".
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> dilation_rate
						</dt>
						<dd>Optional.  Dilation rate.  List of N ints >= 1.
Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values
of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Defaults to [1]*N.
If any value of strides is > 1, then all values of dilation_rate must be
1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional. Name of the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias for dilation_rate 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor of rank N+2, of shape
[batch_size] + output_spatial_shape + [num_channels] <p></p> if data_format is None or does not start with "NC", or <p></p> [batch_size, num_channels] + output_spatial_shape <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of padding: <p></p> If padding = "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding = "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> window_shape, <span title="System.string">string</span> pooling_type, <span title="System.string">string</span> padding, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> strides, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Performs an N-D pooling operation. <p></p> In the case that `data_format` does not start with "NC", computes for
0 <= b < batch_size,
0 <= x[i] < output_spatial_shape[i],
0 <= c < num_channels: <p></p> ```
output[b, x[0],..., x[N-1], c] =
REDUCE_{z[0],..., z[N-1]}
input[b,
x[0] * strides[0] - pad_before[0] + dilation_rate[0]*z[0],
...
x[N-1]*strides[N-1] - pad_before[N-1] + dilation_rate[N-1]*z[N-1],
c],
``` <p></p> where the reduction function REDUCE depends on the value of `pooling_type`,
and pad_before is defined based on the value of `padding` as described in
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details.
The reduction never includes out-of-bounds positions. <p></p> In the case that `data_format` starts with `"NC"`, the `input` and output are
simply transposed as follows: <p></p> ```
pool(input, data_format, **kwargs) =
tf.transpose(pool(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1))
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape
`[batch_size] + input_spatial_shape + [num_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC".  Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> window_shape
						</dt>
						<dd>Sequence of N ints >= 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pooling_type
						</dt>
						<dd>Specifies pooling operation, must be "AVG" or "MAX". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>The padding algorithm, must be "SAME" or "VALID".
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Dilation rate.  List of N ints >= 1.
Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values
of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Defaults to [1]*N.
If any value of strides is > 1, then all values of dilation_rate must be
1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional. Name of the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias for dilation_rate 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor of rank N+2, of shape
[batch_size] + output_spatial_shape + [num_channels] <p></p> if data_format is None or does not start with "NC", or <p></p> [batch_size, num_channels] + output_spatial_shape <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of padding: <p></p> If padding = "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding = "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> window_shape, <span title="System.string">string</span> pooling_type, <span title="System.string">string</span> padding, <a href="../numpy/ndarray.htm">ndarray</a> dilation_rate, <a href="../numpy/ndarray.htm">ndarray</a> strides, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Performs an N-D pooling operation. <p></p> In the case that `data_format` does not start with "NC", computes for
0 <= b < batch_size,
0 <= x[i] < output_spatial_shape[i],
0 <= c < num_channels: <p></p> ```
output[b, x[0],..., x[N-1], c] =
REDUCE_{z[0],..., z[N-1]}
input[b,
x[0] * strides[0] - pad_before[0] + dilation_rate[0]*z[0],
...
x[N-1]*strides[N-1] - pad_before[N-1] + dilation_rate[N-1]*z[N-1],
c],
``` <p></p> where the reduction function REDUCE depends on the value of `pooling_type`,
and pad_before is defined based on the value of `padding` as described in
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details.
The reduction never includes out-of-bounds positions. <p></p> In the case that `data_format` starts with `"NC"`, the `input` and output are
simply transposed as follows: <p></p> ```
pool(input, data_format, **kwargs) =
tf.transpose(pool(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1))
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape
`[batch_size] + input_spatial_shape + [num_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC".  Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> window_shape
						</dt>
						<dd>Sequence of N ints >= 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pooling_type
						</dt>
						<dd>Specifies pooling operation, must be "AVG" or "MAX". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>The padding algorithm, must be "SAME" or "VALID".
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> dilation_rate
						</dt>
						<dd>Optional.  Dilation rate.  List of N ints >= 1.
Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values
of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Defaults to [1]*N.
If any value of strides is > 1, then all values of dilation_rate must be
1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional. Name of the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias for dilation_rate 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor of rank N+2, of shape
[batch_size] + output_spatial_shape + [num_channels] <p></p> if data_format is None or does not start with "NC", or <p></p> [batch_size, num_channels] + output_spatial_shape <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of padding: <p></p> If padding = "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding = "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> window_shape, <span title="System.string">string</span> pooling_type, <span title="System.string">string</span> padding, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Performs an N-D pooling operation. <p></p> In the case that `data_format` does not start with "NC", computes for
0 <= b < batch_size,
0 <= x[i] < output_spatial_shape[i],
0 <= c < num_channels: <p></p> ```
output[b, x[0],..., x[N-1], c] =
REDUCE_{z[0],..., z[N-1]}
input[b,
x[0] * strides[0] - pad_before[0] + dilation_rate[0]*z[0],
...
x[N-1]*strides[N-1] - pad_before[N-1] + dilation_rate[N-1]*z[N-1],
c],
``` <p></p> where the reduction function REDUCE depends on the value of `pooling_type`,
and pad_before is defined based on the value of `padding` as described in
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details.
The reduction never includes out-of-bounds positions. <p></p> In the case that `data_format` starts with `"NC"`, the `input` and output are
simply transposed as follows: <p></p> ```
pool(input, data_format, **kwargs) =
tf.transpose(pool(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1))
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape
`[batch_size] + input_spatial_shape + [num_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC".  Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> window_shape
						</dt>
						<dd>Sequence of N ints >= 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pooling_type
						</dt>
						<dd>Specifies pooling operation, must be "AVG" or "MAX". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>The padding algorithm, must be "SAME" or "VALID".
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Dilation rate.  List of N ints >= 1.
Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values
of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Defaults to [1]*N.
If any value of strides is > 1, then all values of dilation_rate must be
1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional. Name of the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias for dilation_rate 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor of rank N+2, of shape
[batch_size] + output_spatial_shape + [num_channels] <p></p> if data_format is None or does not start with "NC", or <p></p> [batch_size, num_channels] + output_spatial_shape <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of padding: <p></p> If padding = "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding = "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> window_shape, <span title="System.string">string</span> pooling_type, <span title="System.string">string</span> padding, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate, <a href="../numpy/ndarray.htm">ndarray</a> strides, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Performs an N-D pooling operation. <p></p> In the case that `data_format` does not start with "NC", computes for
0 <= b < batch_size,
0 <= x[i] < output_spatial_shape[i],
0 <= c < num_channels: <p></p> ```
output[b, x[0],..., x[N-1], c] =
REDUCE_{z[0],..., z[N-1]}
input[b,
x[0] * strides[0] - pad_before[0] + dilation_rate[0]*z[0],
...
x[N-1]*strides[N-1] - pad_before[N-1] + dilation_rate[N-1]*z[N-1],
c],
``` <p></p> where the reduction function REDUCE depends on the value of `pooling_type`,
and pad_before is defined based on the value of `padding` as described in
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details.
The reduction never includes out-of-bounds positions. <p></p> In the case that `data_format` starts with `"NC"`, the `input` and output are
simply transposed as follows: <p></p> ```
pool(input, data_format, **kwargs) =
tf.transpose(pool(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1))
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape
`[batch_size] + input_spatial_shape + [num_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC".  Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> window_shape
						</dt>
						<dd>Sequence of N ints >= 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pooling_type
						</dt>
						<dd>Specifies pooling operation, must be "AVG" or "MAX". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>The padding algorithm, must be "SAME" or "VALID".
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Dilation rate.  List of N ints >= 1.
Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values
of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Defaults to [1]*N.
If any value of strides is > 1, then all values of dilation_rate must be
1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional. Name of the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias for dilation_rate 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor of rank N+2, of shape
[batch_size] + output_spatial_shape + [num_channels] <p></p> if data_format is None or does not start with "NC", or <p></p> [batch_size, num_channels] + output_spatial_shape <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of padding: <p></p> If padding = "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding = "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> window_shape, <span title="System.string">string</span> pooling_type, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> strides, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Performs an N-D pooling operation. <p></p> In the case that `data_format` does not start with "NC", computes for
0 <= b < batch_size,
0 <= x[i] < output_spatial_shape[i],
0 <= c < num_channels: <p></p> ```
output[b, x[0],..., x[N-1], c] =
REDUCE_{z[0],..., z[N-1]}
input[b,
x[0] * strides[0] - pad_before[0] + dilation_rate[0]*z[0],
...
x[N-1]*strides[N-1] - pad_before[N-1] + dilation_rate[N-1]*z[N-1],
c],
``` <p></p> where the reduction function REDUCE depends on the value of `pooling_type`,
and pad_before is defined based on the value of `padding` as described in
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details.
The reduction never includes out-of-bounds positions. <p></p> In the case that `data_format` starts with `"NC"`, the `input` and output are
simply transposed as follows: <p></p> ```
pool(input, data_format, **kwargs) =
tf.transpose(pool(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1))
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape
`[batch_size] + input_spatial_shape + [num_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC".  Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> window_shape
						</dt>
						<dd>Sequence of N ints >= 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pooling_type
						</dt>
						<dd>Specifies pooling operation, must be "AVG" or "MAX". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>The padding algorithm, must be "SAME" or "VALID".
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Dilation rate.  List of N ints >= 1.
Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values
of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Defaults to [1]*N.
If any value of strides is > 1, then all values of dilation_rate must be
1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional. Name of the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias for dilation_rate 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor of rank N+2, of shape
[batch_size] + output_spatial_shape + [num_channels] <p></p> if data_format is None or does not start with "NC", or <p></p> [batch_size, num_channels] + output_spatial_shape <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of padding: <p></p> If padding = "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding = "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> window_shape, <span title="System.string">string</span> pooling_type, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Performs an N-D pooling operation. <p></p> In the case that `data_format` does not start with "NC", computes for
0 <= b < batch_size,
0 <= x[i] < output_spatial_shape[i],
0 <= c < num_channels: <p></p> ```
output[b, x[0],..., x[N-1], c] =
REDUCE_{z[0],..., z[N-1]}
input[b,
x[0] * strides[0] - pad_before[0] + dilation_rate[0]*z[0],
...
x[N-1]*strides[N-1] - pad_before[N-1] + dilation_rate[N-1]*z[N-1],
c],
``` <p></p> where the reduction function REDUCE depends on the value of `pooling_type`,
and pad_before is defined based on the value of `padding` as described in
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details.
The reduction never includes out-of-bounds positions. <p></p> In the case that `data_format` starts with `"NC"`, the `input` and output are
simply transposed as follows: <p></p> ```
pool(input, data_format, **kwargs) =
tf.transpose(pool(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1))
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape
`[batch_size] + input_spatial_shape + [num_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC".  Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> window_shape
						</dt>
						<dd>Sequence of N ints >= 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pooling_type
						</dt>
						<dd>Specifies pooling operation, must be "AVG" or "MAX". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>The padding algorithm, must be "SAME" or "VALID".
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Dilation rate.  List of N ints >= 1.
Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values
of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Defaults to [1]*N.
If any value of strides is > 1, then all values of dilation_rate must be
1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional. Name of the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias for dilation_rate 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor of rank N+2, of shape
[batch_size] + output_spatial_shape + [num_channels] <p></p> if data_format is None or does not start with "NC", or <p></p> [batch_size, num_channels] + output_spatial_shape <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of padding: <p></p> If padding = "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding = "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> window_shape, <span title="System.string">string</span> pooling_type, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <a href="../numpy/ndarray.htm">ndarray</a> strides, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Performs an N-D pooling operation. <p></p> In the case that `data_format` does not start with "NC", computes for
0 <= b < batch_size,
0 <= x[i] < output_spatial_shape[i],
0 <= c < num_channels: <p></p> ```
output[b, x[0],..., x[N-1], c] =
REDUCE_{z[0],..., z[N-1]}
input[b,
x[0] * strides[0] - pad_before[0] + dilation_rate[0]*z[0],
...
x[N-1]*strides[N-1] - pad_before[N-1] + dilation_rate[N-1]*z[N-1],
c],
``` <p></p> where the reduction function REDUCE depends on the value of `pooling_type`,
and pad_before is defined based on the value of `padding` as described in
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details.
The reduction never includes out-of-bounds positions. <p></p> In the case that `data_format` starts with `"NC"`, the `input` and output are
simply transposed as follows: <p></p> ```
pool(input, data_format, **kwargs) =
tf.transpose(pool(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1))
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape
`[batch_size] + input_spatial_shape + [num_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC".  Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> window_shape
						</dt>
						<dd>Sequence of N ints >= 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pooling_type
						</dt>
						<dd>Specifies pooling operation, must be "AVG" or "MAX". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>The padding algorithm, must be "SAME" or "VALID".
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>Optional.  Dilation rate.  List of N ints >= 1.
Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values
of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Defaults to [1]*N.
If any value of strides is > 1, then all values of dilation_rate must be
1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional. Name of the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias for dilation_rate 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor of rank N+2, of shape
[batch_size] + output_spatial_shape + [num_channels] <p></p> if data_format is None or does not start with "NC", or <p></p> [batch_size, num_channels] + output_spatial_shape <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of padding: <p></p> If padding = "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding = "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> window_shape, <span title="System.string">string</span> pooling_type, <span title="System.string">string</span> padding, <a href="../numpy/ndarray.htm">ndarray</a> dilation_rate, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Performs an N-D pooling operation. <p></p> In the case that `data_format` does not start with "NC", computes for
0 <= b < batch_size,
0 <= x[i] < output_spatial_shape[i],
0 <= c < num_channels: <p></p> ```
output[b, x[0],..., x[N-1], c] =
REDUCE_{z[0],..., z[N-1]}
input[b,
x[0] * strides[0] - pad_before[0] + dilation_rate[0]*z[0],
...
x[N-1]*strides[N-1] - pad_before[N-1] + dilation_rate[N-1]*z[N-1],
c],
``` <p></p> where the reduction function REDUCE depends on the value of `pooling_type`,
and pad_before is defined based on the value of `padding` as described in
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details.
The reduction never includes out-of-bounds positions. <p></p> In the case that `data_format` starts with `"NC"`, the `input` and output are
simply transposed as follows: <p></p> ```
pool(input, data_format, **kwargs) =
tf.transpose(pool(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1))
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape
`[batch_size] + input_spatial_shape + [num_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC".  Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> window_shape
						</dt>
						<dd>Sequence of N ints >= 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pooling_type
						</dt>
						<dd>Specifies pooling operation, must be "AVG" or "MAX". 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>The padding algorithm, must be "SAME" or "VALID".
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> dilation_rate
						</dt>
						<dd>Optional.  Dilation rate.  List of N ints >= 1.
Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values
of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Defaults to [1]*N.
If any value of strides is > 1, then all values of dilation_rate must be
1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional. Name of the op. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias for dilation_rate 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor of rank N+2, of shape
[batch_size] + output_spatial_shape + [num_channels] <p></p> if data_format is None or does not start with "NC", or <p></p> [batch_size, num_channels] + output_spatial_shape <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of padding: <p></p> If padding = "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding = "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> window_shape, <span title="System.object">object</span> pooling_type, <span title="System.object">object</span> padding, <span title="System.object">object</span> dilation_rate, <span title="System.object">object</span> strides, <span title="System.object">object</span> name, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">Performs an N-D pooling operation. <p></p> In the case that `data_format` does not start with "NC", computes for
0 <= b < batch_size,
0 <= x[i] < output_spatial_shape[i],
0 <= c < num_channels: <p></p> ```
output[b, x[0],..., x[N-1], c] =
REDUCE_{z[0],..., z[N-1]}
input[b,
x[0] * strides[0] - pad_before[0] + dilation_rate[0]*z[0],
...
x[N-1]*strides[N-1] - pad_before[N-1] + dilation_rate[N-1]*z[N-1],
c],
``` <p></p> where the reduction function REDUCE depends on the value of `pooling_type`,
and pad_before is defined based on the value of `padding` as described in
the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details.
The reduction never includes out-of-bounds positions. <p></p> In the case that `data_format` starts with `"NC"`, the `input` and output are
simply transposed as follows: <p></p> ```
pool(input, data_format, **kwargs) =
tf.transpose(pool(tf.transpose(input, [0] + range(2,N+2) + [1]),
**kwargs),
[0, N+1] + range(1, N+1))
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Tensor of rank N+2, of shape
`[batch_size] + input_spatial_shape + [num_channels]` if data_format does
not start with "NC" (default), or
`[batch_size, num_channels] + input_spatial_shape` if data_format starts
with "NC".  Pooling happens over the spatial dimensions only. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> window_shape
						</dt>
						<dd>Sequence of N ints >= 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> pooling_type
						</dt>
						<dd>Specifies pooling operation, must be "AVG" or "MAX". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>The padding algorithm, must be "SAME" or "VALID".
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilation_rate
						</dt>
						<dd>Optional.  Dilation rate.  List of N ints >= 1.
Defaults to [1]*N.  If any value of dilation_rate is > 1, then all values
of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>Optional.  Sequence of N ints >= 1.  Defaults to [1]*N.
If any value of strides is > 1, then all values of dilation_rate must be
1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional. Name of the op. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias for dilation_rate 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor of rank N+2, of shape
[batch_size] + output_spatial_shape + [num_channels] <p></p> if data_format is None or does not start with "NC", or <p></p> [batch_size, num_channels] + output_spatial_shape <p></p> if data_format starts with "NC",
where `output_spatial_shape` depends on the value of padding: <p></p> If padding = "SAME":
output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i]) <p></p> If padding = "VALID":
output_spatial_shape[i] =
ceil((input_spatial_shape[i] - (window_shape[i] - 1) * dilation_rate[i])
/ strides[i]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="raw_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>raw_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LSTMCell.htm">LSTMCell</a> cell, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> loop_fn, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates an `RNN` specified by RNNCell `cell` and loop function `loop_fn`. <p></p> **NOTE: This method is still in testing, and the API may change.** <p></p> This function is a more primitive version of `dynamic_rnn` that provides
more direct access to the inputs each iteration.  It also provides more
control over when to start and finish reading the sequence, and
what to emit for the output. <p></p> For example, it can be used to implement the dynamic decoder of a seq2seq
model. <p></p> Instead of working with `Tensor` objects, most operations work with
`TensorArray` objects directly. <p></p> The operation of `raw_rnn`, in pseudo-code, is basically the following:
with the additional properties that output and state may be (possibly nested)
tuples, as determined by `cell.output_size` and `cell.state_size`, and
as a result the final `state` and `emit_ta` may themselves be tuples. <p></p> A simple implementation of `dynamic_rnn` via `raw_rnn` looks like this: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LSTMCell.htm">LSTMCell</a></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> loop_fn
						</dt>
						<dd>A callable that takes inputs `(time, cell_output, cell_state,
loop_state)` and returns the tuple `(finished, next_input,
next_cell_state, emit_output, next_loop_state)`. Here `time` is an int32
scalar `Tensor`, `cell_output` is a `Tensor` or (possibly nested) tuple of
tensors as determined by `cell.output_size`, and `cell_state` is a
`Tensor` or (possibly nested) tuple of tensors, as determined by the
`loop_fn` on its first call (and should match `cell.state_size`).
The outputs are: `finished`, a boolean `Tensor` of
shape `[batch_size]`, `next_input`: the next input to feed to `cell`,
`next_cell_state`: the next state to feed to `cell`,
and `emit_output`: the output to store for this iteration.  Note that
`emit_output` should be a `Tensor` or (possibly nested) tuple of tensors
which is aggregated in the `emit_ta` inside the `while_loop`. For the
first call to `loop_fn`, the `emit_output` corresponds to the
`emit_structure` which is then used to determine the size of the
`zero_tensor` for the `emit_ta` (defaults to `cell.output_size`). For
the subsequent calls to the `loop_fn`, the `emit_output` corresponds to
the actual output tensor that is to be aggregated in the `emit_ta`. The
parameter `cell_state` and output `next_cell_state` may be either a
single or (possibly nested) tuple of tensors.  The parameter
`loop_state` and output `next_loop_state` may be either a single or
(possibly nested) tuple of `Tensor` and `TensorArray` objects.  This
last parameter may be ignored by `loop_fn` and the return value may be
`None`.  If it is not `None`, then the `loop_state` will be propagated
through the RNN loop, for use purely by `loop_fn` to keep track of its
own state. The `next_loop_state` parameter returned may be `None`.  The
first call to `loop_fn` will be `time = 0`, `cell_output = None`,
`cell_state = None`, and `loop_state = None`.  For this call: The
`next_cell_state` value should be the value with which to initialize the
cell's state.  It may be a final state from a previous RNN or it may be
the output of `cell.zero_state()`.  It should be a (possibly nested)
tuple structure of tensors. If `cell.state_size` is an integer, this
must be a `Tensor` of appropriate type and shape `[batch_size,
cell.state_size]`. If `cell.state_size` is a `TensorShape`, this must be
a `Tensor` of appropriate type and shape `[batch_size] +
cell.state_size`. If `cell.state_size` is a (possibly nested) tuple of
ints or `TensorShape`, this will be a tuple having the corresponding
shapes. The `emit_output` value may be either `None` or a (possibly
nested) tuple structure of tensors, e.g., `(tf.zeros(shape_0,
dtype=dtype_0), tf.zeros(shape_1, dtype=dtype_1))`. If this first
`emit_output` return value is `None`, then the `emit_ta` result of
`raw_rnn` will have the same structure and dtypes as `cell.output_size`.
Otherwise `emit_ta` will have the same structure, shapes (prepended with
a `batch_size` dimension), and dtypes as `emit_output`.  The actual
values returned for `emit_output` at this initializing call are ignored.
Note, this emit structure must be consistent across all time steps. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple `(emit_ta, final_state, final_loop_state)` where: <p></p> `emit_ta`: The RNN output `TensorArray`.
If `loop_fn` returns a (possibly nested) set of Tensors for
`emit_output` during initialization, (inputs `time = 0`,
`cell_output = None`, and `loop_state = None`), then `emit_ta` will
have the same structure, dtypes, and shapes as `emit_output` instead.
If `loop_fn` returns `emit_output = None` during this call,
the structure of `cell.output_size` is used:
If `cell.output_size` is a (possibly nested) tuple of integers
or `TensorShape` objects, then `emit_ta` will be a tuple having the
same structure as `cell.output_size`, containing TensorArrays whose
elements' shapes correspond to the shape data in `cell.output_size`. <p></p> `final_state`: The final cell state.  If `cell.state_size` is an int, this
will be shaped `[batch_size, cell.state_size]`.  If it is a
`TensorShape`, this will be shaped `[batch_size] + cell.state_size`.
If it is a (possibly nested) tuple of ints or `TensorShape`, this will
be a tuple having the corresponding shapes. <p></p> `final_loop_state`: The final loop state as returned by `loop_fn`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>time = tf.constant(0, dtype=tf.int32)
            (finished, next_input, initial_state, emit_structure, loop_state) = loop_fn(
                time=time, cell_output=None, cell_state=None, loop_state=None)
            emit_ta = TensorArray(dynamic_size=True, dtype=initial_state.dtype)
            state = initial_state
            while not all(finished):
              (output, cell_state) = cell(next_input, state)
              (next_finished, next_input, next_state, emit, loop_state) = loop_fn(
                  time=time + 1, cell_output=output, cell_state=cell_state,
                  loop_state=loop_state)
              # Emit zeros and copy forward state for minibatch entries that are finished.
              state = tf.where(finished, state, next_state)
              emit = tf.where(finished, tf.zeros_like(emit_structure), emit)
              emit_ta = emit_ta.write(time, emit)
              # If any new minibatch entries are marked as finished, mark these.
              finished = tf.logical_or(finished, next_finished)
              time += 1
            return (emit_ta, state, loop_state) </pre>
</div>
		</div>
	</div>
	<div id="raw_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>raw_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LSTMCell.htm">LSTMCell</a> cell, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> loop_fn, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> parallel_iterations, <span title="System.bool">bool</span> swap_memory, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates an `RNN` specified by RNNCell `cell` and loop function `loop_fn`. <p></p> **NOTE: This method is still in testing, and the API may change.** <p></p> This function is a more primitive version of `dynamic_rnn` that provides
more direct access to the inputs each iteration.  It also provides more
control over when to start and finish reading the sequence, and
what to emit for the output. <p></p> For example, it can be used to implement the dynamic decoder of a seq2seq
model. <p></p> Instead of working with `Tensor` objects, most operations work with
`TensorArray` objects directly. <p></p> The operation of `raw_rnn`, in pseudo-code, is basically the following:
with the additional properties that output and state may be (possibly nested)
tuples, as determined by `cell.output_size` and `cell.state_size`, and
as a result the final `state` and `emit_ta` may themselves be tuples. <p></p> A simple implementation of `dynamic_rnn` via `raw_rnn` looks like this: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LSTMCell.htm">LSTMCell</a></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> loop_fn
						</dt>
						<dd>A callable that takes inputs `(time, cell_output, cell_state,
loop_state)` and returns the tuple `(finished, next_input,
next_cell_state, emit_output, next_loop_state)`. Here `time` is an int32
scalar `Tensor`, `cell_output` is a `Tensor` or (possibly nested) tuple of
tensors as determined by `cell.output_size`, and `cell_state` is a
`Tensor` or (possibly nested) tuple of tensors, as determined by the
`loop_fn` on its first call (and should match `cell.state_size`).
The outputs are: `finished`, a boolean `Tensor` of
shape `[batch_size]`, `next_input`: the next input to feed to `cell`,
`next_cell_state`: the next state to feed to `cell`,
and `emit_output`: the output to store for this iteration.  Note that
`emit_output` should be a `Tensor` or (possibly nested) tuple of tensors
which is aggregated in the `emit_ta` inside the `while_loop`. For the
first call to `loop_fn`, the `emit_output` corresponds to the
`emit_structure` which is then used to determine the size of the
`zero_tensor` for the `emit_ta` (defaults to `cell.output_size`). For
the subsequent calls to the `loop_fn`, the `emit_output` corresponds to
the actual output tensor that is to be aggregated in the `emit_ta`. The
parameter `cell_state` and output `next_cell_state` may be either a
single or (possibly nested) tuple of tensors.  The parameter
`loop_state` and output `next_loop_state` may be either a single or
(possibly nested) tuple of `Tensor` and `TensorArray` objects.  This
last parameter may be ignored by `loop_fn` and the return value may be
`None`.  If it is not `None`, then the `loop_state` will be propagated
through the RNN loop, for use purely by `loop_fn` to keep track of its
own state. The `next_loop_state` parameter returned may be `None`.  The
first call to `loop_fn` will be `time = 0`, `cell_output = None`,
`cell_state = None`, and `loop_state = None`.  For this call: The
`next_cell_state` value should be the value with which to initialize the
cell's state.  It may be a final state from a previous RNN or it may be
the output of `cell.zero_state()`.  It should be a (possibly nested)
tuple structure of tensors. If `cell.state_size` is an integer, this
must be a `Tensor` of appropriate type and shape `[batch_size,
cell.state_size]`. If `cell.state_size` is a `TensorShape`, this must be
a `Tensor` of appropriate type and shape `[batch_size] +
cell.state_size`. If `cell.state_size` is a (possibly nested) tuple of
ints or `TensorShape`, this will be a tuple having the corresponding
shapes. The `emit_output` value may be either `None` or a (possibly
nested) tuple structure of tensors, e.g., `(tf.zeros(shape_0,
dtype=dtype_0), tf.zeros(shape_1, dtype=dtype_1))`. If this first
`emit_output` return value is `None`, then the `emit_ta` result of
`raw_rnn` will have the same structure and dtypes as `cell.output_size`.
Otherwise `emit_ta` will have the same structure, shapes (prepended with
a `batch_size` dimension), and dtypes as `emit_output`.  The actual
values returned for `emit_output` at this initializing call are ignored.
Note, this emit structure must be consistent across all time steps. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple `(emit_ta, final_state, final_loop_state)` where: <p></p> `emit_ta`: The RNN output `TensorArray`.
If `loop_fn` returns a (possibly nested) set of Tensors for
`emit_output` during initialization, (inputs `time = 0`,
`cell_output = None`, and `loop_state = None`), then `emit_ta` will
have the same structure, dtypes, and shapes as `emit_output` instead.
If `loop_fn` returns `emit_output = None` during this call,
the structure of `cell.output_size` is used:
If `cell.output_size` is a (possibly nested) tuple of integers
or `TensorShape` objects, then `emit_ta` will be a tuple having the
same structure as `cell.output_size`, containing TensorArrays whose
elements' shapes correspond to the shape data in `cell.output_size`. <p></p> `final_state`: The final cell state.  If `cell.state_size` is an int, this
will be shaped `[batch_size, cell.state_size]`.  If it is a
`TensorShape`, this will be shaped `[batch_size] + cell.state_size`.
If it is a (possibly nested) tuple of ints or `TensorShape`, this will
be a tuple having the corresponding shapes. <p></p> `final_loop_state`: The final loop state as returned by `loop_fn`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>time = tf.constant(0, dtype=tf.int32)
            (finished, next_input, initial_state, emit_structure, loop_state) = loop_fn(
                time=time, cell_output=None, cell_state=None, loop_state=None)
            emit_ta = TensorArray(dynamic_size=True, dtype=initial_state.dtype)
            state = initial_state
            while not all(finished):
              (output, cell_state) = cell(next_input, state)
              (next_finished, next_input, next_state, emit, loop_state) = loop_fn(
                  time=time + 1, cell_output=output, cell_state=cell_state,
                  loop_state=loop_state)
              # Emit zeros and copy forward state for minibatch entries that are finished.
              state = tf.where(finished, state, next_state)
              emit = tf.where(finished, tf.zeros_like(emit_structure), emit)
              emit_ta = emit_ta.write(time, emit)
              # If any new minibatch entries are marked as finished, mark these.
              finished = tf.logical_or(finished, next_finished)
              time += 1
            return (emit_ta, state, loop_state) </pre>
</div>
		</div>
	</div>
	<div id="raw_rnn_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>raw_rnn_dyn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> loop_fn, <span title="System.object">object</span> parallel_iterations, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> swap_memory, <span title="System.object">object</span> scope)
		</h4>
		<div class="content">Creates an `RNN` specified by RNNCell `cell` and loop function `loop_fn`. <p></p> **NOTE: This method is still in testing, and the API may change.** <p></p> This function is a more primitive version of `dynamic_rnn` that provides
more direct access to the inputs each iteration.  It also provides more
control over when to start and finish reading the sequence, and
what to emit for the output. <p></p> For example, it can be used to implement the dynamic decoder of a seq2seq
model. <p></p> Instead of working with `Tensor` objects, most operations work with
`TensorArray` objects directly. <p></p> The operation of `raw_rnn`, in pseudo-code, is basically the following:
with the additional properties that output and state may be (possibly nested)
tuples, as determined by `cell.output_size` and `cell.state_size`, and
as a result the final `state` and `emit_ta` may themselves be tuples. <p></p> A simple implementation of `dynamic_rnn` via `raw_rnn` looks like this: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> loop_fn
						</dt>
						<dd>A callable that takes inputs `(time, cell_output, cell_state,
loop_state)` and returns the tuple `(finished, next_input,
next_cell_state, emit_output, next_loop_state)`. Here `time` is an int32
scalar `Tensor`, `cell_output` is a `Tensor` or (possibly nested) tuple of
tensors as determined by `cell.output_size`, and `cell_state` is a
`Tensor` or (possibly nested) tuple of tensors, as determined by the
`loop_fn` on its first call (and should match `cell.state_size`).
The outputs are: `finished`, a boolean `Tensor` of
shape `[batch_size]`, `next_input`: the next input to feed to `cell`,
`next_cell_state`: the next state to feed to `cell`,
and `emit_output`: the output to store for this iteration.  Note that
`emit_output` should be a `Tensor` or (possibly nested) tuple of tensors
which is aggregated in the `emit_ta` inside the `while_loop`. For the
first call to `loop_fn`, the `emit_output` corresponds to the
`emit_structure` which is then used to determine the size of the
`zero_tensor` for the `emit_ta` (defaults to `cell.output_size`). For
the subsequent calls to the `loop_fn`, the `emit_output` corresponds to
the actual output tensor that is to be aggregated in the `emit_ta`. The
parameter `cell_state` and output `next_cell_state` may be either a
single or (possibly nested) tuple of tensors.  The parameter
`loop_state` and output `next_loop_state` may be either a single or
(possibly nested) tuple of `Tensor` and `TensorArray` objects.  This
last parameter may be ignored by `loop_fn` and the return value may be
`None`.  If it is not `None`, then the `loop_state` will be propagated
through the RNN loop, for use purely by `loop_fn` to keep track of its
own state. The `next_loop_state` parameter returned may be `None`.  The
first call to `loop_fn` will be `time = 0`, `cell_output = None`,
`cell_state = None`, and `loop_state = None`.  For this call: The
`next_cell_state` value should be the value with which to initialize the
cell's state.  It may be a final state from a previous RNN or it may be
the output of `cell.zero_state()`.  It should be a (possibly nested)
tuple structure of tensors. If `cell.state_size` is an integer, this
must be a `Tensor` of appropriate type and shape `[batch_size,
cell.state_size]`. If `cell.state_size` is a `TensorShape`, this must be
a `Tensor` of appropriate type and shape `[batch_size] +
cell.state_size`. If `cell.state_size` is a (possibly nested) tuple of
ints or `TensorShape`, this will be a tuple having the corresponding
shapes. The `emit_output` value may be either `None` or a (possibly
nested) tuple structure of tensors, e.g., `(tf.zeros(shape_0,
dtype=dtype_0), tf.zeros(shape_1, dtype=dtype_1))`. If this first
`emit_output` return value is `None`, then the `emit_ta` result of
`raw_rnn` will have the same structure and dtypes as `cell.output_size`.
Otherwise `emit_ta` will have the same structure, shapes (prepended with
a `batch_size` dimension), and dtypes as `emit_output`.  The actual
values returned for `emit_output` at this initializing call are ignored.
Note, this emit structure must be consistent across all time steps. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> parallel_iterations
						</dt>
						<dd>(Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values >> 1 use more memory but take less time, while smaller
values use less memory but computations take longer. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> swap_memory
						</dt>
						<dd>Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple `(emit_ta, final_state, final_loop_state)` where: <p></p> `emit_ta`: The RNN output `TensorArray`.
If `loop_fn` returns a (possibly nested) set of Tensors for
`emit_output` during initialization, (inputs `time = 0`,
`cell_output = None`, and `loop_state = None`), then `emit_ta` will
have the same structure, dtypes, and shapes as `emit_output` instead.
If `loop_fn` returns `emit_output = None` during this call,
the structure of `cell.output_size` is used:
If `cell.output_size` is a (possibly nested) tuple of integers
or `TensorShape` objects, then `emit_ta` will be a tuple having the
same structure as `cell.output_size`, containing TensorArrays whose
elements' shapes correspond to the shape data in `cell.output_size`. <p></p> `final_state`: The final cell state.  If `cell.state_size` is an int, this
will be shaped `[batch_size, cell.state_size]`.  If it is a
`TensorShape`, this will be shaped `[batch_size] + cell.state_size`.
If it is a (possibly nested) tuple of ints or `TensorShape`, this will
be a tuple having the corresponding shapes. <p></p> `final_loop_state`: The final loop state as returned by `loop_fn`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>time = tf.constant(0, dtype=tf.int32)
            (finished, next_input, initial_state, emit_structure, loop_state) = loop_fn(
                time=time, cell_output=None, cell_state=None, loop_state=None)
            emit_ta = TensorArray(dynamic_size=True, dtype=initial_state.dtype)
            state = initial_state
            while not all(finished):
              (output, cell_state) = cell(next_input, state)
              (next_finished, next_input, next_state, emit, loop_state) = loop_fn(
                  time=time + 1, cell_output=output, cell_state=cell_state,
                  loop_state=loop_state)
              # Emit zeros and copy forward state for minibatch entries that are finished.
              state = tf.where(finished, state, next_state)
              emit = tf.where(finished, tf.zeros_like(emit_structure), emit)
              emit_ta = emit_ta.write(time, emit)
              # If any new minibatch entries are marked as finished, mark these.
              finished = tf.logical_or(finished, next_finished)
              time += 1
            return (emit_ta, state, loop_state) </pre>
</div>
		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> features, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">Computes rectified linear: `max(features, 0)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> features, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes rectified linear: `max(features, 0)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu_dyn</strong>(<span title="System.object">object</span> features, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes rectified linear: `max(features, 0)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu_layer" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>relu_layer</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> weights, <span title="System.object">object</span> biases, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes Relu(x * weight + biases). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>a 2D tensor.  Dimensions typically: batch, in_units 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> weights
						</dt>
						<dd>a 2D tensor.  Dimensions typically: in_units, out_units 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> biases
						</dt>
						<dd>a 1D tensor.  Dimensions: out_units 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional).  If not specified
"nn_relu_layer" is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 2-D Tensor computing relu(matmul(x, weights) + biases).
Dimensions typically: batch, out_units. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu_layer_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu_layer_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> weights, <span title="System.object">object</span> biases, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes Relu(x * weight + biases). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>a 2D tensor.  Dimensions typically: batch, in_units 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> weights
						</dt>
						<dd>a 2D tensor.  Dimensions typically: in_units, out_units 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> biases
						</dt>
						<dd>a 1D tensor.  Dimensions: out_units 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional).  If not specified
"nn_relu_layer" is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 2-D Tensor computing relu(matmul(x, weights) + biases).
Dimensions typically: batch, out_units. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu6" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>relu6</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> features, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes Rectified Linear 6: `min(max(features, 0), 6)`. <p></p> Source: [Convolutional Deep Belief Networks on CIFAR-10. A.
Krizhevsky](http://www.cs.utoronto.ca/~kriz/conv-cifar10-aug2010.pdf) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> features
						</dt>
						<dd>A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,
`int16`, or `int8`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="safe_embedding_lookup_sparse_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>safe_embedding_lookup_sparse_dyn</strong>(<span title="System.object">object</span> embedding_weights, <span title="System.object">object</span> sparse_ids, <span title="System.object">object</span> sparse_weights, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> combiner, <span title="System.object">object</span> default_id, <span title="System.object">object</span> name, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> partition_strategy, <span title="System.object">object</span> max_norm)
		</h4>
		<div class="content">Lookup embedding results, accounting for invalid IDs and empty features. <p></p> The partitioned embedding in `embedding_weights` must all be the same shape
except for the first dimension. The first dimension is allowed to vary as the
vocabulary size is not necessarily a multiple of `P`.  `embedding_weights`
may be a `PartitionedVariable` as returned by using
`tf.compat.v1.get_variable()` with a
partitioner. <p></p> Invalid IDs (< 0) are pruned from input IDs and weights, as well as any IDs
with non-positive weight. For an entry with no features, the embedding vector
for `default_id` is returned, or the 0-vector if `default_id` is not supplied. <p></p> The ids and weights may be multi-dimensional. Embeddings are always aggregated
along the last dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> embedding_weights
						</dt>
						<dd>A list of `P` float `Tensor`s or values representing
partitioned embedding `Tensor`s.  Alternatively, a `PartitionedVariable`
created by partitioning along dimension 0.  The total unpartitioned shape
should be `[e_0, e_1,..., e_m]`, where `e_0` represents the vocab size
and `e_1,..., e_m` are the embedding dimensions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sparse_ids
						</dt>
						<dd>`SparseTensor` of shape `[d_0, d_1,..., d_n]` containing the
ids. `d_0` is typically batch size. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sparse_weights
						</dt>
						<dd>`SparseTensor` of same shape as `sparse_ids`, containing
float weights corresponding to `sparse_ids`, or `None` if all weights are
be assumed to be 1.0. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> combiner
						</dt>
						<dd>A string specifying how to combine embedding results for each
entry. Currently "mean", "sqrtn" and "sum" are supported, with "mean" the
default. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> default_id
						</dt>
						<dd>The id to use for an entry with no features. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy. Currently
`"div"` and `"mod"` are supported. Default is `"div"`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_norm
						</dt>
						<dd>If not `None`, all embeddings are l2-normalized to max_norm before
combining. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Dense `Tensor` of shape `[d_0, d_1,..., d_{n-1}, e_1,..., e_m]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sampled_softmax_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sampled_softmax_loss</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> weights, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> biases, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.int">int</span> num_sampled, <span title="System.int">int</span> num_classes, <span title="System.int">int</span> num_true, <span title="System.object">object</span> sampled_values, <span title="System.bool">bool</span> remove_accidental_hits, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Computes and returns the sampled softmax training loss. <p></p> This is a faster way to train a softmax classifier over a huge number of
classes. <p></p> This operation is for training only.  It is generally an underestimate of
the full softmax loss. <p></p> A common use case is to use this method for training, and calculate the full
softmax loss for evaluation or inference. In this case, you must set
`partition_strategy="div"` for the two losses to be consistent, as in the
following example:
See our [Candidate Sampling Algorithms Reference]
(https://www.tensorflow.org/extras/candidate_sampling.pdf) <p></p> Also see Section 3 of [Jean et al., 2014](http://arxiv.org/abs/1412.2007)
([pdf](http://arxiv.org/pdf/1412.2007.pdf)) for the math. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> weights
						</dt>
						<dd>A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`
objects whose concatenation along dimension 0 has shape
[num_classes, dim].  The (possibly-sharded) class embeddings. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> biases
						</dt>
						<dd>A `Tensor` of shape `[num_classes]`.  The class biases. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes.  Note that this format differs from
the `labels` argument of `nn.softmax_cross_entropy_with_logits`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A `Tensor` of shape `[batch_size, dim]`.  The forward
activations of the input network. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample per batch. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_classes
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sampled_values
						</dt>
						<dd>a tuple of (`sampled_candidates`, `true_expected_count`,
`sampled_expected_count`) returned by a `*_candidate_sampler` function.
(if None, we default to `log_uniform_candidate_sampler`) 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> remove_accidental_hits
						</dt>
						<dd>A `bool`.  whether to remove "accidental hits"
where a sampled class equals one of the target classes.  Default is
True. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(weights) > 1`. Currently `"div"` and `"mod"` are supported.
Default is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>random seed for candidate sampling. Default to None, which doesn't set
the op-level random seed for candidate sampling. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `batch_size` 1-D tensor of per-example sampled softmax losses. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>if mode == "train":
              loss = tf.nn.sampled_softmax_loss(
                  weights=weights,
                  biases=biases,
                  labels=labels,
                  inputs=inputs,
                 ...,
                  partition_strategy="div")
            elif mode == "eval":
              logits = tf.matmul(inputs, tf.transpose(weights))
              logits = tf.nn.bias_add(logits, biases)
              labels_one_hot = tf.one_hot(labels, n_classes)
              loss = tf.nn.softmax_cross_entropy_with_logits(
                  labels=labels_one_hot,
                  logits=logits) </pre>
</div>
		</div>
	</div>
	<div id="sampled_softmax_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sampled_softmax_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> weights, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> biases, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.int">int</span> num_sampled, <span title="System.int">int</span> num_classes, <span title="System.int">int</span> num_true, <span title="System.object">object</span> sampled_values, <span title="System.bool">bool</span> remove_accidental_hits, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Computes and returns the sampled softmax training loss. <p></p> This is a faster way to train a softmax classifier over a huge number of
classes. <p></p> This operation is for training only.  It is generally an underestimate of
the full softmax loss. <p></p> A common use case is to use this method for training, and calculate the full
softmax loss for evaluation or inference. In this case, you must set
`partition_strategy="div"` for the two losses to be consistent, as in the
following example:
See our [Candidate Sampling Algorithms Reference]
(https://www.tensorflow.org/extras/candidate_sampling.pdf) <p></p> Also see Section 3 of [Jean et al., 2014](http://arxiv.org/abs/1412.2007)
([pdf](http://arxiv.org/pdf/1412.2007.pdf)) for the math. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> weights
						</dt>
						<dd>A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`
objects whose concatenation along dimension 0 has shape
[num_classes, dim].  The (possibly-sharded) class embeddings. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> biases
						</dt>
						<dd>A `Tensor` of shape `[num_classes]`.  The class biases. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes.  Note that this format differs from
the `labels` argument of `nn.softmax_cross_entropy_with_logits`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A `Tensor` of shape `[batch_size, dim]`.  The forward
activations of the input network. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample per batch. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_classes
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sampled_values
						</dt>
						<dd>a tuple of (`sampled_candidates`, `true_expected_count`,
`sampled_expected_count`) returned by a `*_candidate_sampler` function.
(if None, we default to `log_uniform_candidate_sampler`) 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> remove_accidental_hits
						</dt>
						<dd>A `bool`.  whether to remove "accidental hits"
where a sampled class equals one of the target classes.  Default is
True. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(weights) > 1`. Currently `"div"` and `"mod"` are supported.
Default is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>random seed for candidate sampling. Default to None, which doesn't set
the op-level random seed for candidate sampling. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `batch_size` 1-D tensor of per-example sampled softmax losses. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>if mode == "train":
              loss = tf.nn.sampled_softmax_loss(
                  weights=weights,
                  biases=biases,
                  labels=labels,
                  inputs=inputs,
                 ...,
                  partition_strategy="div")
            elif mode == "eval":
              logits = tf.matmul(inputs, tf.transpose(weights))
              logits = tf.nn.bias_add(logits, biases)
              labels_one_hot = tf.one_hot(labels, n_classes)
              loss = tf.nn.softmax_cross_entropy_with_logits(
                  labels=labels_one_hot,
                  logits=logits) </pre>
</div>
		</div>
	</div>
	<div id="sampled_softmax_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sampled_softmax_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> weights, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> biases, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.int">int</span> num_sampled, <span title="System.int">int</span> num_classes, <span title="System.int">int</span> num_true, <span title="System.ValueTuple<IEnumerable<int>, ndarray, object>">ValueTuple&lt;IEnumerable&lt;int&gt;, ndarray, object&gt;</span> sampled_values, <span title="System.bool">bool</span> remove_accidental_hits, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Computes and returns the sampled softmax training loss. <p></p> This is a faster way to train a softmax classifier over a huge number of
classes. <p></p> This operation is for training only.  It is generally an underestimate of
the full softmax loss. <p></p> A common use case is to use this method for training, and calculate the full
softmax loss for evaluation or inference. In this case, you must set
`partition_strategy="div"` for the two losses to be consistent, as in the
following example:
See our [Candidate Sampling Algorithms Reference]
(https://www.tensorflow.org/extras/candidate_sampling.pdf) <p></p> Also see Section 3 of [Jean et al., 2014](http://arxiv.org/abs/1412.2007)
([pdf](http://arxiv.org/pdf/1412.2007.pdf)) for the math. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> weights
						</dt>
						<dd>A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`
objects whose concatenation along dimension 0 has shape
[num_classes, dim].  The (possibly-sharded) class embeddings. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> biases
						</dt>
						<dd>A `Tensor` of shape `[num_classes]`.  The class biases. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes.  Note that this format differs from
the `labels` argument of `nn.softmax_cross_entropy_with_logits`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A `Tensor` of shape `[batch_size, dim]`.  The forward
activations of the input network. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample per batch. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_classes
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<int>, ndarray, object>">ValueTuple&lt;IEnumerable&lt;int&gt;, ndarray, object&gt;</span></code> sampled_values
						</dt>
						<dd>a tuple of (`sampled_candidates`, `true_expected_count`,
`sampled_expected_count`) returned by a `*_candidate_sampler` function.
(if None, we default to `log_uniform_candidate_sampler`) 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> remove_accidental_hits
						</dt>
						<dd>A `bool`.  whether to remove "accidental hits"
where a sampled class equals one of the target classes.  Default is
True. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(weights) > 1`. Currently `"div"` and `"mod"` are supported.
Default is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>random seed for candidate sampling. Default to None, which doesn't set
the op-level random seed for candidate sampling. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `batch_size` 1-D tensor of per-example sampled softmax losses. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>if mode == "train":
              loss = tf.nn.sampled_softmax_loss(
                  weights=weights,
                  biases=biases,
                  labels=labels,
                  inputs=inputs,
                 ...,
                  partition_strategy="div")
            elif mode == "eval":
              logits = tf.matmul(inputs, tf.transpose(weights))
              logits = tf.nn.bias_add(logits, biases)
              labels_one_hot = tf.one_hot(labels, n_classes)
              loss = tf.nn.softmax_cross_entropy_with_logits(
                  labels=labels_one_hot,
                  logits=logits) </pre>
</div>
		</div>
	</div>
	<div id="sampled_softmax_loss" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sampled_softmax_loss</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> weights, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> biases, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.int">int</span> num_sampled, <span title="System.int">int</span> num_classes, <span title="System.int">int</span> num_true, <span title="System.ValueTuple<IEnumerable<int>, ndarray, object>">ValueTuple&lt;IEnumerable&lt;int&gt;, ndarray, object&gt;</span> sampled_values, <span title="System.bool">bool</span> remove_accidental_hits, <span title="System.string">string</span> partition_strategy, <span title="System.string">string</span> name, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Computes and returns the sampled softmax training loss. <p></p> This is a faster way to train a softmax classifier over a huge number of
classes. <p></p> This operation is for training only.  It is generally an underestimate of
the full softmax loss. <p></p> A common use case is to use this method for training, and calculate the full
softmax loss for evaluation or inference. In this case, you must set
`partition_strategy="div"` for the two losses to be consistent, as in the
following example:
See our [Candidate Sampling Algorithms Reference]
(https://www.tensorflow.org/extras/candidate_sampling.pdf) <p></p> Also see Section 3 of [Jean et al., 2014](http://arxiv.org/abs/1412.2007)
([pdf](http://arxiv.org/pdf/1412.2007.pdf)) for the math. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> weights
						</dt>
						<dd>A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`
objects whose concatenation along dimension 0 has shape
[num_classes, dim].  The (possibly-sharded) class embeddings. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> biases
						</dt>
						<dd>A `Tensor` of shape `[num_classes]`.  The class biases. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes.  Note that this format differs from
the `labels` argument of `nn.softmax_cross_entropy_with_logits`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A `Tensor` of shape `[batch_size, dim]`.  The forward
activations of the input network. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample per batch. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_classes
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<int>, ndarray, object>">ValueTuple&lt;IEnumerable&lt;int&gt;, ndarray, object&gt;</span></code> sampled_values
						</dt>
						<dd>a tuple of (`sampled_candidates`, `true_expected_count`,
`sampled_expected_count`) returned by a `*_candidate_sampler` function.
(if None, we default to `log_uniform_candidate_sampler`) 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> remove_accidental_hits
						</dt>
						<dd>A `bool`.  whether to remove "accidental hits"
where a sampled class equals one of the target classes.  Default is
True. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(weights) > 1`. Currently `"div"` and `"mod"` are supported.
Default is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>random seed for candidate sampling. Default to None, which doesn't set
the op-level random seed for candidate sampling. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `batch_size` 1-D tensor of per-example sampled softmax losses. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>if mode == "train":
              loss = tf.nn.sampled_softmax_loss(
                  weights=weights,
                  biases=biases,
                  labels=labels,
                  inputs=inputs,
                 ...,
                  partition_strategy="div")
            elif mode == "eval":
              logits = tf.matmul(inputs, tf.transpose(weights))
              logits = tf.nn.bias_add(logits, biases)
              labels_one_hot = tf.one_hot(labels, n_classes)
              loss = tf.nn.softmax_cross_entropy_with_logits(
                  labels=labels_one_hot,
                  logits=logits) </pre>
</div>
		</div>
	</div>
	<div id="sampled_softmax_loss_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sampled_softmax_loss_dyn</strong>(<span title="System.object">object</span> weights, <span title="System.object">object</span> biases, <span title="System.object">object</span> labels, <span title="System.object">object</span> inputs, <span title="System.object">object</span> num_sampled, <span title="System.object">object</span> num_classes, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> num_true, <span title="System.object">object</span> sampled_values, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> remove_accidental_hits, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> partition_strategy, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> name, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Computes and returns the sampled softmax training loss. <p></p> This is a faster way to train a softmax classifier over a huge number of
classes. <p></p> This operation is for training only.  It is generally an underestimate of
the full softmax loss. <p></p> A common use case is to use this method for training, and calculate the full
softmax loss for evaluation or inference. In this case, you must set
`partition_strategy="div"` for the two losses to be consistent, as in the
following example:
See our [Candidate Sampling Algorithms Reference]
(https://www.tensorflow.org/extras/candidate_sampling.pdf) <p></p> Also see Section 3 of [Jean et al., 2014](http://arxiv.org/abs/1412.2007)
([pdf](http://arxiv.org/pdf/1412.2007.pdf)) for the math. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> weights
						</dt>
						<dd>A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`
objects whose concatenation along dimension 0 has shape
[num_classes, dim].  The (possibly-sharded) class embeddings. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> biases
						</dt>
						<dd>A `Tensor` of shape `[num_classes]`.  The class biases. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes.  Note that this format differs from
the `labels` argument of `nn.softmax_cross_entropy_with_logits`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>A `Tensor` of shape `[batch_size, dim]`.  The forward
activations of the input network. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample per batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_classes
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sampled_values
						</dt>
						<dd>a tuple of (`sampled_candidates`, `true_expected_count`,
`sampled_expected_count`) returned by a `*_candidate_sampler` function.
(if None, we default to `log_uniform_candidate_sampler`) 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> remove_accidental_hits
						</dt>
						<dd>A `bool`.  whether to remove "accidental hits"
where a sampled class equals one of the target classes.  Default is
True. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> partition_strategy
						</dt>
						<dd>A string specifying the partitioning strategy, relevant
if `len(weights) > 1`. Currently `"div"` and `"mod"` are supported.
Default is `"mod"`. See <a href="..\..\tf\nn\embedding_lookup.md"><code>tf.nn.embedding_lookup</code></a> for more details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>random seed for candidate sampling. Default to None, which doesn't set
the op-level random seed for candidate sampling. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `batch_size` 1-D tensor of per-example sampled softmax losses. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>if mode == "train":
              loss = tf.nn.sampled_softmax_loss(
                  weights=weights,
                  biases=biases,
                  labels=labels,
                  inputs=inputs,
                 ...,
                  partition_strategy="div")
            elif mode == "eval":
              logits = tf.matmul(inputs, tf.transpose(weights))
              logits = tf.nn.bias_add(logits, biases)
              labels_one_hot = tf.one_hot(labels, n_classes)
              loss = tf.nn.softmax_cross_entropy_with_logits(
                  labels=labels_one_hot,
                  logits=logits) </pre>
</div>
		</div>
	</div>
	<div id="scale_regularization_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>scale_regularization_loss</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> regularization_loss)
		</h4>
		<div class="content">Scales the sum of the given regularization losses by number of replicas. <p></p> Usage with distribution strategy and custom training loop: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> regularization_loss
						</dt>
						<dd>Regularization loss. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Scalar loss value. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>with strategy.scope():
              def compute_loss(self, label, predictions):
                per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(
                    labels, predictions) <p></p> # Compute loss that is scaled by sample_weight and by global batch size.
loss = tf.compute_average_loss(
    per_example_loss,
    sample_weight=sample_weight,
    global_batch_size=GLOBAL_BATCH_SIZE) <p></p> # Add scaled regularization losses.
loss += tf.scale_regularization_loss(tf.nn.l2_loss(weights))
return loss </pre>
</div>
		</div>
	</div>
	<div id="scale_regularization_loss" class="method">
		<h4>
			<span title="System.object">object</span> <strong>scale_regularization_loss</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> regularization_loss)
		</h4>
		<div class="content">Scales the sum of the given regularization losses by number of replicas. <p></p> Usage with distribution strategy and custom training loop: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> regularization_loss
						</dt>
						<dd>Regularization loss. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Scalar loss value. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>with strategy.scope():
              def compute_loss(self, label, predictions):
                per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(
                    labels, predictions) <p></p> # Compute loss that is scaled by sample_weight and by global batch size.
loss = tf.compute_average_loss(
    per_example_loss,
    sample_weight=sample_weight,
    global_batch_size=GLOBAL_BATCH_SIZE) <p></p> # Add scaled regularization losses.
loss += tf.scale_regularization_loss(tf.nn.l2_loss(weights))
return loss </pre>
</div>
		</div>
	</div>
	<div id="scale_regularization_loss_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>scale_regularization_loss_dyn</strong>(<span title="System.object">object</span> regularization_loss)
		</h4>
		<div class="content">Scales the sum of the given regularization losses by number of replicas. <p></p> Usage with distribution strategy and custom training loop: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> regularization_loss
						</dt>
						<dd>Regularization loss. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Scalar loss value. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>with strategy.scope():
              def compute_loss(self, label, predictions):
                per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(
                    labels, predictions) <p></p> # Compute loss that is scaled by sample_weight and by global batch size.
loss = tf.compute_average_loss(
    per_example_loss,
    sample_weight=sample_weight,
    global_batch_size=GLOBAL_BATCH_SIZE) <p></p> # Add scaled regularization losses.
loss += tf.scale_regularization_loss(tf.nn.l2_loss(weights))
return loss </pre>
</div>
		</div>
	</div>
	<div id="selu" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>selu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> features, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes scaled exponential linear: `scale * alpha * (exp(features) - 1)` <p></p> if < 0, `scale * features` otherwise. <p></p> To be used together with
`initializer = tf.variance_scaling_initializer(factor=1.0, mode='FAN_IN')`.
For correct dropout, use <a href="..\..\tf\contrib\nn\alpha_dropout.md"><code>tf.contrib.nn.alpha_dropout</code></a>. <p></p> See [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="selu_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>selu_dyn</strong>(<span title="System.object">object</span> features, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes scaled exponential linear: `scale * alpha * (exp(features) - 1)` <p></p> if < 0, `scale * features` otherwise. <p></p> To be used together with
`initializer = tf.variance_scaling_initializer(factor=1.0, mode='FAN_IN')`.
For correct dropout, use <a href="..\..\tf\contrib\nn\alpha_dropout.md"><code>tf.contrib.nn.alpha_dropout</code></a>. <p></p> See [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.int">int</span> rate, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.int">int</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.int">int</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> rate, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> rate, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.int">int</span> rate, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.int">int</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.int">int</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> rate, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> rate, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.int">int</span> rate, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> rate, <span title="System.string">string</span> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>separable_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_filter, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_filter, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.int">int</span> rate, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.string">string</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>separable_conv2d_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> depthwise_filter, <span title="System.object">object</span> pointwise_filter, <span title="System.object">object</span> strides, <span title="System.object">object</span> padding, <span title="System.object">object</span> rate, <span title="System.object">object</span> name, <span title="System.object">object</span> data_format, <span title="System.object">object</span> dilations)
		</h4>
		<div class="content">2-D convolution with separable filters. <p></p> Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions `[1, 2]` and `3`, not spatial separability between
dimensions `1` and `2`. <p></p> In detail, with the default NHWC format, <p></p> output[b, i, j, k] = sum_{di, dj, q, r}
input[b, strides[1] * i + di, strides[2] * j + dj, q] *
depthwise_filter[di, dj, q, r] *
pointwise_filter[0, 0, q * channel_multiplier + r, k] <p></p> `strides` controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of `[1, 1, 1, 1]`.  Must have
`strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertical strides, `strides = [1, stride, stride, 1]`.
If any value in `rate` is greater than 1, we perform atrous depthwise
convolution, in which case all values in the `strides` tensor must be equal
to 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>4-D `Tensor` with shape according to `data_format`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> depthwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[filter_height, filter_width, in_channels, channel_multiplier]`.
Contains `in_channels` convolutional filters of depth 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> pointwise_filter
						</dt>
						<dd>4-D `Tensor` with shape
`[1, 1, channel_multiplier * in_channels, out_channels]`.  Pointwise
filter to mix channels after `depthwise_filter` has convolved spatially. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>1-D of size 4.  The strides for the depthwise convolution for
each dimension of `input`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>A string, either `'VALID'` or `'SAME'`.  The padding algorithm.
See the "returns" section of <a href="..\..\tf\nn\convolution.md"><code>tf.nn.convolution</code></a> for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rate
						</dt>
						<dd>1-D of size 2. The dilation rate in which we sample input values
across the `height` and `width` dimensions in atrous convolution. If it is
greater than 1, then all values of strides must be 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>The data format for input. Either "NHWC" (default) or "NCHW". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilations
						</dt>
						<dd>Alias of rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4-D `Tensor` with shape according to 'data_format'. For
example, with data_format="NHWC", shape is [batch, out_height,
out_width, out_channels]. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sigmoid_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sigmoid_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.object">object</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sigmoid cross entropy given `logits`. <p></p> Measures the probability error in discrete classification tasks in which each
class is independent and not mutually exclusive.  For instance, one could
perform multilabel classification where a picture can contain both an elephant
and a dog at the same time. <p></p> For brevity, let `x = logits`, `z = labels`.  The logistic loss is <p></p> z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
= z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
= z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
= z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
= (1 - z) * x + log(1 + exp(-x))
= x - x * z + log(1 + exp(-x)) <p></p> For x < 0, to avoid overflow in exp(-x), we reformulate the above <p></p> x - x * z + log(1 + exp(-x))
= log(exp(x)) - x * z + log(1 + exp(-x))
= - x * z + log(1 + exp(x)) <p></p> Hence, to ensure stability and avoid overflow, the implementation uses this
equivalent formulation <p></p> max(x, 0) - x * z + log(1 + exp(-abs(x))) <p></p> `logits` and `labels` must have the same type and shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>A `Tensor` of the same type and shape as `logits`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>A `Tensor` of type `float32` or `float64`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `logits` with the componentwise
logistic losses. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sigmoid_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sigmoid_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sigmoid cross entropy given `logits`. <p></p> Measures the probability error in discrete classification tasks in which each
class is independent and not mutually exclusive.  For instance, one could
perform multilabel classification where a picture can contain both an elephant
and a dog at the same time. <p></p> For brevity, let `x = logits`, `z = labels`.  The logistic loss is <p></p> z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
= z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
= z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
= z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
= (1 - z) * x + log(1 + exp(-x))
= x - x * z + log(1 + exp(-x)) <p></p> For x < 0, to avoid overflow in exp(-x), we reformulate the above <p></p> x - x * z + log(1 + exp(-x))
= log(exp(x)) - x * z + log(1 + exp(-x))
= - x * z + log(1 + exp(x)) <p></p> Hence, to ensure stability and avoid overflow, the implementation uses this
equivalent formulation <p></p> max(x, 0) - x * z + log(1 + exp(-abs(x))) <p></p> `logits` and `labels` must have the same type and shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>A `Tensor` of the same type and shape as `logits`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>A `Tensor` of type `float32` or `float64`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `logits` with the componentwise
logistic losses. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sigmoid_cross_entropy_with_logits_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sigmoid_cross_entropy_with_logits_dyn</strong>(<span title="System.object">object</span> _sentinel, <span title="System.object">object</span> labels, <span title="System.object">object</span> logits, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes sigmoid cross entropy given `logits`. <p></p> Measures the probability error in discrete classification tasks in which each
class is independent and not mutually exclusive.  For instance, one could
perform multilabel classification where a picture can contain both an elephant
and a dog at the same time. <p></p> For brevity, let `x = logits`, `z = labels`.  The logistic loss is <p></p> z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
= z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
= z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
= z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
= (1 - z) * x + log(1 + exp(-x))
= x - x * z + log(1 + exp(-x)) <p></p> For x < 0, to avoid overflow in exp(-x), we reformulate the above <p></p> x - x * z + log(1 + exp(-x))
= log(exp(x)) - x * z + log(1 + exp(-x))
= - x * z + log(1 + exp(x)) <p></p> Hence, to ensure stability and avoid overflow, the implementation uses this
equivalent formulation <p></p> max(x, 0) - x * z + log(1 + exp(-abs(x))) <p></p> `logits` and `labels` must have the same type and shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>A `Tensor` of the same type and shape as `logits`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>A `Tensor` of type `float32` or `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of the same shape as `logits` with the componentwise
logistic losses. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> This function performs the equivalent of <p></p> softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type and shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.int">int</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> This function performs the equivalent of <p></p> softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type and shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> logits, <span title="System.int">int</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> This function performs the equivalent of <p></p> softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type and shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> logits, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> This function performs the equivalent of <p></p> softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type and shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax</strong>(<span title="System.object">object</span> logits, <span title="System.int">int</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> This function performs the equivalent of <p></p> softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type and shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax</strong>(<span title="System.object">object</span> logits, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> This function performs the equivalent of <p></p> softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type and shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> logits, <span title="System.int">int</span> dim, <span title="System.string">string</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> logits, <span title="System.int">int</span> dim, <span title="System.string">string</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> logits, <span title="System.int">int</span> dim, <span title="System.string">string</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> logits, <span title="System.int">int</span> dim, <span title="System.string">string</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <span title="System.int">int</span> labels, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> logits, <span title="System.int">int</span> dim, <span title="System.string">string</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <span title="System.int">int</span> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> logits, <span title="System.int">int</span> dim, <span title="System.string">string</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> logits, <span title="System.int">int</span> dim, <span title="System.string">string</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> logits, <span title="System.int">int</span> dim, <span title="System.string">string</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> logits, <span title="System.int">int</span> dim, <span title="System.string">string</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits</strong>(<span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> _sentinel, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> logits, <span title="System.int">int</span> dim, <span title="System.string">string</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>softmax_cross_entropy_with_logits_dyn</strong>(<span title="System.object">object</span> _sentinel, <span title="System.object">object</span> labels, <span title="System.object">object</span> logits, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dim, <span title="System.object">object</span> name, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating: <p></p> Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default. <p></p> See <a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `dim` argument specifying the class dimension. <p></p> Backpropagation will happen only into `logits`.  To calculate a cross entropy
loss that allows backpropagation into both `logits` and `labels`, see
<a href="..\..\tf\nn\softmax_cross_entropy_with_logits_v2.md"><code>tf.nn.softmax_cross_entropy_with_logits_v2</code></a>. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Per-label activations, typically a linear output. These activation
energies are interpreted as unnormalized log probabilities. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dim
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Alias for dim. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.object">object</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.object">object</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <span title="System.object">object</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <span title="System.object">object</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> labels, <span title="System.object">object</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> labels, <span title="System.object">object</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> labels, <span title="System.object">object</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <span title="System.object">object</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> labels, <span title="System.object">object</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <span title="System.object">object</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.string">string</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax_cross_entropy_with_logits_v2</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>softmax_cross_entropy_with_logits_v2_dyn</strong>(<span title="System.object">object</span> labels, <span title="System.object">object</span> logits, <span title="System.object">object</span> axis, <span title="System.object">object</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax cross entropy between `logits` and `labels`. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of `labels` is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect. <p></p> If using exclusive `labels` (wherein one and only
one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits and labels of shape
`[batch_size, num_classes]`, but higher dimensions are supported, with
the `axis` argument specifying the class dimension. <p></p> `logits` and `labels` must have the same dtype (either `float16`, `float32`,
or `float64`). <p></p> Backpropagation will happen into both `logits` and `labels`.  To disallow
backpropagation into `labels`, pass label tensors through <a href="..\..\tf\stop_gradient.md"><code>tf.stop_gradient</code></a>
before feeding it to this function. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>Each vector along the class dimension should hold a valid
probability distribution e.g. for the case in which labels are of shape
`[batch_size, num_classes]`, each row of `labels[i]` must be a valid
probability distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Unscaled log probabilities. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>The class dimension. Defaulted to -1 which is the last dimension. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` that contains the softmax cross entropy loss. Its type is the
same as `logits` and its shape is the same as `labels` except that it does
not have the last dimension of `labels`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>softmax_dyn</strong>(<span title="System.object">object</span> logits, <span title="System.object">object</span> axis, <span title="System.object">object</span> name, <span title="System.object">object</span> dim)
		</h4>
		<div class="content">Computes softmax activations. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead <p></p> This function performs the equivalent of <p></p> softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>A non-empty `Tensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on. The default is -1 which
indicates the last dimension. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dim
						</dt>
						<dd>Deprecated alias for `axis`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type and shape as `logits`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softplus" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softplus</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> features, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes softplus: `log(exp(features) + 1)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softplus_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>softplus_dyn</strong>(<span title="System.object">object</span> features, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes softplus: `log(exp(features) + 1)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softsign" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softsign</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> features, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes softsign: `features / (abs(features) + 1)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softsign_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>softsign_dyn</strong>(<span title="System.object">object</span> features, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes softsign: `features / (abs(features) + 1)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> features
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `features`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.object">object</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <span title="System.object">object</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <span title="System.object">object</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> labels, <span title="System.object">object</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <span title="System.double">double</span> labels, <span title="System.object">object</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <a href="../numpy/ndarray.htm">ndarray</a> labels, <span title="System.object">object</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <a href="../numpy/ndarray.htm">ndarray</a> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_softmax_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> _sentinel, <span title="System.double">double</span> labels, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> logits, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sparse_softmax_cross_entropy_with_logits_dyn</strong>(<span title="System.object">object</span> _sentinel, <span title="System.object">object</span> labels, <span title="System.object">object</span> logits, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes sparse softmax cross entropy between `logits` and `labels`. <p></p> Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both. <p></p> **NOTE:**  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the `labels` vector
must provide a single specific index for the true class for each row of
`logits` (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
`softmax_cross_entropy_with_logits_v2`. <p></p> **WARNING:** This op expects unscaled logits, since it performs a `softmax`
on `logits` internally for efficiency.  Do not call this op with the
output of `softmax`, as it will produce incorrect results. <p></p> A common use case is to have logits of shape
`[batch_size, num_classes]` and have labels of shape
`[batch_size]`, but higher dimensions are supported, in which
case the `dim`-th dimension is assumed to be of size `num_classes`.
`logits` must have the dtype of `float16`, `float32`, or `float64`, and
`labels` must have the dtype of `int32` or `int64`. <p></p> **Note that to avoid confusion, it is required to pass only named arguments to
this function.** 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> _sentinel
						</dt>
						<dd>Used to prevent positional parameters. Internal, do not use. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>`Tensor` of shape `[d_0, d_1,..., d_{r-1}]` (where `r` is rank of
`labels` and result) and dtype `int32` or `int64`. Each entry in `labels`
must be an index in `[0, num_classes)`. Other values will raise an
exception when this op is run on CPU, and return `NaN` for corresponding
loss and gradient rows on GPU. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>Per-label activations (typically a linear output) of shape
`[d_0, d_1,..., d_{r-1}, num_classes]` and dtype `float16`, `float32`, or
`float64`. These activation energies are interpreted as unnormalized log
probabilities. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of the same shape as `labels` and of the same type as `logits`
with the softmax cross entropy loss. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_bw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_bw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_bw, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_bw, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_bw, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_bw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_bw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_bw, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_bw, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_bw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_bw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_bw, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_bw, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_bw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_bw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a> cell_fw, <a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell_bw, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_fw, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state_bw, <a href="../tensorflow/DType.htm">DType</a> dtype, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/LayerRNNCell.htm">LayerRNNCell</a></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_bidirectional_rnn_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_bidirectional_rnn_dyn</strong>(<span title="System.object">object</span> cell_fw, <span title="System.object">object</span> cell_bw, <span title="System.object">object</span> inputs, <span title="System.object">object</span> initial_state_fw, <span title="System.object">object</span> initial_state_bw, <span title="System.object">object</span> dtype, <span title="System.object">object</span> sequence_length, <span title="System.object">object</span> scope)
		</h4>
		<div class="content">Creates a bidirectional recurrent neural network. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API <p></p> Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell_fw
						</dt>
						<dd>An instance of RNNCell, to be used for forward direction. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> cell_bw
						</dt>
						<dd>An instance of RNNCell, to be used for backward direction. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a tensor of shape [batch_size,
input_size], or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state_fw
						</dt>
						<dd>(optional) An initial state for the forward RNN. This must
be a tensor of appropriate type and shape `[batch_size,
cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a
tuple of tensors having shapes `[batch_size, s] for s in
cell_fw.state_size`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state_bw
						</dt>
						<dd>(optional) Same as for `initial_state_fw`, but using the
corresponding properties of `cell_bw`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state.  Required if either
of the initial states are not provided. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector, size `[batch_size]`,
containing the actual lengths for each of the sequences. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to
"bidirectional_rnn" 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple (outputs, output_state_fw, output_state_bw) where:
outputs is a length `T` list of outputs (one for each input), which
are depth-concatenated forward and backward outputs.
output_state_fw is the final state of the forward rnn.
output_state_bw is the final state of the backward rnn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../tensorflow.contrib.seq2seq/AttentionWrapperState.htm">AttentionWrapperState</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.seq2seq/AttentionWrapperState.htm">AttentionWrapperState</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../tensorflow.contrib.seq2seq/AttentionWrapperState.htm">AttentionWrapperState</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.seq2seq/AttentionWrapperState.htm">AttentionWrapperState</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.string">string</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.string">string</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow.contrib.seq2seq/AttentionWrapperState.htm">AttentionWrapperState</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.seq2seq/AttentionWrapperState.htm">AttentionWrapperState</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.object">object</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow.contrib.seq2seq/AttentionWrapperState.htm">AttentionWrapperState</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.seq2seq/AttentionWrapperState.htm">AttentionWrapperState</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.string">string</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <a href="../tensorflow/VariableScope.htm">VariableScope</a> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/VariableScope.htm">VariableScope</a></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.string">string</span> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_rnn</strong>(<span title="System.object">object</span> cell, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> initial_state, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_rnn_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_rnn_dyn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> inputs, <span title="System.object">object</span> initial_state, <span title="System.object">object</span> dtype, <span title="System.object">object</span> sequence_length, <span title="System.object">object</span> scope)
		</h4>
		<div class="content">Creates a recurrent neural network specified by RNNCell `cell`. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API <p></p> The simplest form of RNN network generated is:
However, a few other options are available: <p></p> An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output. <p></p> The dynamic calculation performed is, at time `t` for batch row `b`, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of RNNCell. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`, or a nested tuple of such elements. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>(optional) An initial state for the RNN. If `cell.state_size`
is an integer, this must be a `Tensor` of appropriate type and shape
`[batch_size, cell.state_size]`. If `cell.state_size` is a tuple, this
should be a tuple of tensors having shapes `[batch_size, s] for s in
cell.state_size`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>(optional) The data type for the initial state and expected output.
Required if initial_state is not provided or RNN state has a heterogeneous
dtype. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>Specifies the length of each sequence in inputs. An int32
or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A pair (outputs, state) where: <p></p> - outputs is a length T list of outputs (one for each input), or a nested
tuple of such elements.
- state is the final state 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>state = cell.zero_state(...)
            outputs = []
            for input_ in inputs:
              output, state = cell(input_, state)
              outputs.append(output)
            return (outputs, state) </pre>
</div>
		</div>
	</div>
	<div id="static_state_saving_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_state_saving_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.Object">Object</span> state_saver, <span title="System.Collections.Generic.IEnumerable<string>">IEnumerable&lt;string&gt;</span> state_name, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">RNN that accepts a state saver for time-truncated RNN calculation. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, stateful=True)`, which is equivalent to this API 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell
						</dt>
						<dd>An instance of `RNNCell`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`. 
						</dd>
						<dt>
							<code><span title="System.Object">Object</span></code> state_saver
						</dt>
						<dd>A state saver object with methods `state` and `save_state`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<string>">IEnumerable&lt;string&gt;</span></code> state_name
						</dt>
						<dd>Python string or tuple of strings.  The name to use with the
state_saver. If the cell returns tuples of states (i.e., `cell.state_size`
is a tuple) then `state_name` should be a tuple of strings having the same
length as `cell.state_size`.  Otherwise it should be a single string. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector size [batch_size]. See the
documentation for rnn() for more details about sequence_length. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where:
outputs is a length T list of outputs (one for each input)
states is the final state 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_state_saving_rnn" class="method">
		<h4>
			<span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span> <strong>static_state_saving_rnn</strong>(<a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a> cell, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.Object">Object</span> state_saver, <span title="System.string">string</span> state_name, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> sequence_length, <span title="System.string">string</span> scope)
		</h4>
		<div class="content">RNN that accepts a state saver for time-truncated RNN calculation. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, stateful=True)`, which is equivalent to this API 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.nn.rnn_cell/RNNCell.htm">RNNCell</a></code> cell
						</dt>
						<dd>An instance of `RNNCell`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`. 
						</dd>
						<dt>
							<code><span title="System.Object">Object</span></code> state_saver
						</dt>
						<dd>A state saver object with methods `state` and `save_state`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> state_name
						</dt>
						<dd>Python string or tuple of strings.  The name to use with the
state_saver. If the cell returns tuples of states (i.e., `cell.state_size`
is a tuple) then `state_name` should be a tuple of strings having the same
length as `cell.state_size`.  Otherwise it should be a single string. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector size [batch_size]. See the
documentation for rnn() for more details about sequence_length. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<object>, object>">ValueTuple&lt;IList&lt;object&gt;, object&gt;</span></code>
					</dt>
					<dd>A pair (outputs, state) where:
outputs is a length T list of outputs (one for each input)
states is the final state 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="static_state_saving_rnn_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>static_state_saving_rnn_dyn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> inputs, <span title="System.object">object</span> state_saver, <span title="System.object">object</span> state_name, <span title="System.object">object</span> sequence_length, <span title="System.object">object</span> scope)
		</h4>
		<div class="content">RNN that accepts a state saver for time-truncated RNN calculation. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, stateful=True)`, which is equivalent to this API 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An instance of `RNNCell`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>A length T list of inputs, each a `Tensor` of shape `[batch_size,
input_size]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> state_saver
						</dt>
						<dd>A state saver object with methods `state` and `save_state`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> state_name
						</dt>
						<dd>Python string or tuple of strings.  The name to use with the
state_saver. If the cell returns tuples of states (i.e., `cell.state_size`
is a tuple) then `state_name` should be a tuple of strings having the same
length as `cell.state_size`.  Otherwise it should be a single string. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sequence_length
						</dt>
						<dd>(optional) An int32/int64 vector size [batch_size]. See the
documentation for rnn() for more details about sequence_length. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scope
						</dt>
						<dd>VariableScope for the created subgraph; defaults to "rnn". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A pair (outputs, state) where:
outputs is a length T list of outputs (one for each input)
states is the final state 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sufficient_statistics" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sufficient_statistics</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> shift, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keep_dims, <span title="System.string">string</span> name, <span title="System.object">object</span> keepdims)
		</h4>
		<div class="content">Calculate the sufficient statistics for the mean and variance of `x`. <p></p> These sufficient statistics are computed using the one pass algorithm on
an input that's optionally shifted. See:
https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>Array of ints. Axes along which to compute mean and variance. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> shift
						</dt>
						<dd>A `Tensor` containing the value by which to shift the data for
numerical stability, or `None` if no shift is to be performed. A shift
close to the true mean provides the most numerically stable results. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keep_dims
						</dt>
						<dd>produce statistics with the same dimensionality as the input. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Name used to scope the operations that compute the sufficient stats. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> keepdims
						</dt>
						<dd>Alias for keep_dims. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Four `Tensor` objects of the same type as `x`: <p></p> * the count (number of elements to average over).
* the (possibly shifted) sum of the elements in the array.
* the (possibly shifted) sum of squares of the elements in the array.
* the shift by which the mean must be corrected or None if `shift` is None. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sufficient_statistics_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sufficient_statistics_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axes, <span title="System.object">object</span> shift, <span title="System.object">object</span> keep_dims, <span title="System.object">object</span> name, <span title="System.object">object</span> keepdims)
		</h4>
		<div class="content">Calculate the sufficient statistics for the mean and variance of `x`. <p></p> These sufficient statistics are computed using the one pass algorithm on
an input that's optionally shifted. See:
https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axes
						</dt>
						<dd>Array of ints. Axes along which to compute mean and variance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> shift
						</dt>
						<dd>A `Tensor` containing the value by which to shift the data for
numerical stability, or `None` if no shift is to be performed. A shift
close to the true mean provides the most numerically stable results. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> keep_dims
						</dt>
						<dd>produce statistics with the same dimensionality as the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Name used to scope the operations that compute the sufficient stats. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> keepdims
						</dt>
						<dd>Alias for keep_dims. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Four `Tensor` objects of the same type as `x`: <p></p> * the count (number of elements to average over).
* the (possibly shifted) sum of the elements in the array.
* the (possibly shifted) sum of squares of the elements in the array.
* the shift by which the mean must be corrected or None if `shift` is None. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="swish" class="method">
		<h4>
			<span title="System.object">object</span> <strong>swish</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> features)
		</h4>
		<div class="content">Computes the Swish activation function: `x * sigmoid(x)`. <p></p> Source: "Searching for Activation Functions" (Ramachandran et al. 2017)
https://arxiv.org/abs/1710.05941 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> features
						</dt>
						<dd>A `Tensor` representing preactivation values. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The activation value. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="swish_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>swish_dyn</strong>(<span title="System.object">object</span> features)
		</h4>
		<div class="content">Computes the Swish activation function: `x * sigmoid(x)`. <p></p> Source: "Searching for Activation Functions" (Ramachandran et al. 2017)
https://arxiv.org/abs/1710.05941 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> features
						</dt>
						<dd>A `Tensor` representing preactivation values. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The activation value. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="top_k" class="method">
		<h4>
			<span title="System.object">object</span> <strong>top_k</strong>(<span title="System.object">object</span> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> k, <span title="System.bool">bool</span> sorted, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Finds values and indices of the `k` largest entries for the last dimension. <p></p> If the input is a vector (rank=1), finds the `k` largest entries in the vector
and outputs their values and indices as vectors.  Thus `values[j]` is the
`j`-th largest entry in `input`, and its index is `indices[j]`. <p></p> For matrices (resp. higher rank input), computes the top `k` entries in each
row (resp. vector along the last dimension).  Thus, <p></p> values.shape = indices.shape = input.shape[:-1] + [k] <p></p> If two elements are equal, the lower-index element appears first. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>1-D or higher `Tensor` with last dimension at least `k`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> k
						</dt>
						<dd>0-D `int32` `Tensor`.  Number of top elements to look for along the last
dimension (along each row for matrices). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> sorted
						</dt>
						<dd>If true the resulting `k` elements will be sorted by the values in
descending order. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="top_k" class="method">
		<h4>
			<span title="System.object">object</span> <strong>top_k</strong>(<span title="System.object">object</span> input, <span title="System.int">int</span> k, <span title="System.bool">bool</span> sorted, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Finds values and indices of the `k` largest entries for the last dimension. <p></p> If the input is a vector (rank=1), finds the `k` largest entries in the vector
and outputs their values and indices as vectors.  Thus `values[j]` is the
`j`-th largest entry in `input`, and its index is `indices[j]`. <p></p> For matrices (resp. higher rank input), computes the top `k` entries in each
row (resp. vector along the last dimension).  Thus, <p></p> values.shape = indices.shape = input.shape[:-1] + [k] <p></p> If two elements are equal, the lower-index element appears first. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>1-D or higher `Tensor` with last dimension at least `k`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> k
						</dt>
						<dd>0-D `int32` `Tensor`.  Number of top elements to look for along the last
dimension (along each row for matrices). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> sorted
						</dt>
						<dd>If true the resulting `k` elements will be sorted by the values in
descending order. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="top_k_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>top_k_dyn</strong>(<span title="System.object">object</span> input, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> k, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> sorted, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Finds values and indices of the `k` largest entries for the last dimension. <p></p> If the input is a vector (rank=1), finds the `k` largest entries in the vector
and outputs their values and indices as vectors.  Thus `values[j]` is the
`j`-th largest entry in `input`, and its index is `indices[j]`. <p></p> For matrices (resp. higher rank input), computes the top `k` entries in each
row (resp. vector along the last dimension).  Thus, <p></p> values.shape = indices.shape = input.shape[:-1] + [k] <p></p> If two elements are equal, the lower-index element appears first. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>1-D or higher `Tensor` with last dimension at least `k`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> k
						</dt>
						<dd>0-D `int32` `Tensor`.  Number of top elements to look for along the last
dimension (along each row for matrices). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> sorted
						</dt>
						<dd>If true the resulting `k` elements will be sorted by the values in
descending order. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name for the operation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="uniform_candidate_sampler" class="method">
		<h4>
			<span title="System.object">object</span> <strong>uniform_candidate_sampler</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> true_classes, <span title="System.object">object</span> num_true, <span title="System.object">object</span> num_sampled, <span title="System.object">object</span> unique, <span title="System.object">object</span> range_max, <span title="System.object">object</span> seed, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Samples a set of classes using a uniform base distribution. <p></p> This operation randomly samples a tensor of sampled classes
(`sampled_candidates`) from the range of integers `[0, range_max)`. <p></p> The elements of `sampled_candidates` are drawn without replacement
(if `unique=True`) or with replacement (if `unique=False`) from
the base distribution. <p></p> The base distribution for this operation is the uniform distribution
over the range of integers `[0, range_max)`. <p></p> In addition, this operation returns tensors `true_expected_count`
and `sampled_expected_count` representing the number of times each
of the target classes (`true_classes`) and the sampled
classes (`sampled_candidates`) is expected to occur in an average
tensor of sampled classes.  These values correspond to `Q(y|x)`
defined in [this
document](http://www.tensorflow.org/extras/candidate_sampling.pdf).
If `unique=True`, then these are post-rejection probabilities and we
compute them approximately. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample. The
`sampled_candidates` return value will have shape `[num_sampled]`. If
`unique=True`, `num_sampled` must be less than or equal to `range_max`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> unique
						</dt>
						<dd>A `bool`. Determines whether all sampled classes in a batch are
unique. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> range_max
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="uniform_candidate_sampler_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>uniform_candidate_sampler_dyn</strong>(<span title="System.object">object</span> true_classes, <span title="System.object">object</span> num_true, <span title="System.object">object</span> num_sampled, <span title="System.object">object</span> unique, <span title="System.object">object</span> range_max, <span title="System.object">object</span> seed, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Samples a set of classes using a uniform base distribution. <p></p> This operation randomly samples a tensor of sampled classes
(`sampled_candidates`) from the range of integers `[0, range_max)`. <p></p> The elements of `sampled_candidates` are drawn without replacement
(if `unique=True`) or with replacement (if `unique=False`) from
the base distribution. <p></p> The base distribution for this operation is the uniform distribution
over the range of integers `[0, range_max)`. <p></p> In addition, this operation returns tensors `true_expected_count`
and `sampled_expected_count` representing the number of times each
of the target classes (`true_classes`) and the sampled
classes (`sampled_candidates`) is expected to occur in an average
tensor of sampled classes.  These values correspond to `Q(y|x)`
defined in [this
document](http://www.tensorflow.org/extras/candidate_sampling.pdf).
If `unique=True`, then these are post-rejection probabilities and we
compute them approximately. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> true_classes
						</dt>
						<dd>A `Tensor` of type `int64` and shape `[batch_size,
num_true]`. The target classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_true
						</dt>
						<dd>An `int`.  The number of target classes per training example. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_sampled
						</dt>
						<dd>An `int`.  The number of classes to randomly sample. The
`sampled_candidates` return value will have shape `[num_sampled]`. If
`unique=True`, `num_sampled` must be less than or equal to `range_max`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> unique
						</dt>
						<dd>A `bool`. Determines whether all sampled classes in a batch are
unique. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> range_max
						</dt>
						<dd>An `int`. The number of possible classes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An `int`. An operation-specific seed. Default is 0. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="weighted_cross_entropy_with_logits" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>weighted_cross_entropy_with_logits</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> logits, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> pos_weight, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> targets)
		</h4>
		<div class="content">Computes a weighted cross entropy. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(targets)`. They will be removed in a future version.
Instructions for updating:
targets is deprecated, use labels instead <p></p> This is like `sigmoid_cross_entropy_with_logits()` except that `pos_weight`,
allows one to trade off recall and precision by up- or down-weighting the
cost of a positive error relative to a negative error. <p></p> The usual cross-entropy cost is defined as: <p></p> labels * -log(sigmoid(logits)) +
(1 - labels) * -log(1 - sigmoid(logits)) <p></p> A value `pos_weight > 1` decreases the false negative count, hence increasing
the recall.
Conversely setting `pos_weight < 1` decreases the false positive count and
increases the precision.
This can be seen from the fact that `pos_weight` is introduced as a
multiplicative coefficient for the positive labels term
in the loss expression: <p></p> labels * -log(sigmoid(logits)) * pos_weight +
(1 - labels) * -log(1 - sigmoid(logits)) <p></p> For brevity, let `x = logits`, `z = labels`, `q = pos_weight`.
The loss is: <p></p> qz * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
= qz * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
= qz * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
= qz * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
= (1 - z) * x + (qz +  1 - z) * log(1 + exp(-x))
= (1 - z) * x + (1 + (q - 1) * z) * log(1 + exp(-x)) <p></p> Setting `l = (1 + (q - 1) * z)`, to ensure stability and avoid overflow,
the implementation uses <p></p> (1 - z) * x + l * (log(1 + exp(-abs(x))) + max(-x, 0)) <p></p> `logits` and `labels` must have the same type and shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>A `Tensor` of the same type and shape as `logits`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> logits
						</dt>
						<dd>A `Tensor` of type `float32` or `float64`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<double>">Nullable&lt;double&gt;</span></code> pos_weight
						</dt>
						<dd>A coefficient to use on the positive examples. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> targets
						</dt>
						<dd>Deprecated alias for labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same shape as `logits` with the componentwise
weighted logistic losses. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="weighted_cross_entropy_with_logits_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>weighted_cross_entropy_with_logits_dyn</strong>(<span title="System.object">object</span> labels, <span title="System.object">object</span> logits, <span title="System.object">object</span> pos_weight, <span title="System.object">object</span> name, <span title="System.object">object</span> targets)
		</h4>
		<div class="content">Computes a weighted cross entropy. (deprecated arguments) <p></p> Warning: SOME ARGUMENTS ARE DEPRECATED: `(targets)`. They will be removed in a future version.
Instructions for updating:
targets is deprecated, use labels instead <p></p> This is like `sigmoid_cross_entropy_with_logits()` except that `pos_weight`,
allows one to trade off recall and precision by up- or down-weighting the
cost of a positive error relative to a negative error. <p></p> The usual cross-entropy cost is defined as: <p></p> labels * -log(sigmoid(logits)) +
(1 - labels) * -log(1 - sigmoid(logits)) <p></p> A value `pos_weight > 1` decreases the false negative count, hence increasing
the recall.
Conversely setting `pos_weight < 1` decreases the false positive count and
increases the precision.
This can be seen from the fact that `pos_weight` is introduced as a
multiplicative coefficient for the positive labels term
in the loss expression: <p></p> labels * -log(sigmoid(logits)) * pos_weight +
(1 - labels) * -log(1 - sigmoid(logits)) <p></p> For brevity, let `x = logits`, `z = labels`, `q = pos_weight`.
The loss is: <p></p> qz * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
= qz * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
= qz * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
= qz * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
= (1 - z) * x + (qz +  1 - z) * log(1 + exp(-x))
= (1 - z) * x + (1 + (q - 1) * z) * log(1 + exp(-x)) <p></p> Setting `l = (1 + (q - 1) * z)`, to ensure stability and avoid overflow,
the implementation uses <p></p> (1 - z) * x + l * (log(1 + exp(-abs(x))) + max(-x, 0)) <p></p> `logits` and `labels` must have the same type and shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>A `Tensor` of the same type and shape as `logits`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> logits
						</dt>
						<dd>A `Tensor` of type `float32` or `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> pos_weight
						</dt>
						<dd>A coefficient to use on the positive examples. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> targets
						</dt>
						<dd>Deprecated alias for labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of the same shape as `logits` with the componentwise
weighted logistic losses. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="weighted_moments" class="method">
		<h4>
			<span title="System.object">object</span> <strong>weighted_moments</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> frequency_weights, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keep_dims, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keepdims)
		</h4>
		<div class="content">Returns the frequency-weighted mean and variance of `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>1-d tensor of int32 values; these are the axes along which
to compute mean and variance. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> frequency_weights
						</dt>
						<dd>A tensor of positive weights which can be
broadcast with x. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Name used to scope the operation. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keep_dims
						</dt>
						<dd>Produce moments with the same dimensionality as the input. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keepdims
						</dt>
						<dd>Alias of keep_dims. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Two tensors: `weighted_mean` and `weighted_variance`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="weighted_moments" class="method">
		<h4>
			<span title="System.object">object</span> <strong>weighted_moments</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> frequency_weights, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keep_dims, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keepdims)
		</h4>
		<div class="content">Returns the frequency-weighted mean and variance of `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>1-d tensor of int32 values; these are the axes along which
to compute mean and variance. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> frequency_weights
						</dt>
						<dd>A tensor of positive weights which can be
broadcast with x. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Name used to scope the operation. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keep_dims
						</dt>
						<dd>Produce moments with the same dimensionality as the input. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keepdims
						</dt>
						<dd>Alias of keep_dims. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Two tensors: `weighted_mean` and `weighted_variance`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="weighted_moments" class="method">
		<h4>
			<span title="System.object">object</span> <strong>weighted_moments</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> frequency_weights, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keep_dims, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keepdims)
		</h4>
		<div class="content">Returns the frequency-weighted mean and variance of `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>1-d tensor of int32 values; these are the axes along which
to compute mean and variance. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> frequency_weights
						</dt>
						<dd>A tensor of positive weights which can be
broadcast with x. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Name used to scope the operation. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keep_dims
						</dt>
						<dd>Produce moments with the same dimensionality as the input. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keepdims
						</dt>
						<dd>Alias of keep_dims. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Two tensors: `weighted_mean` and `weighted_variance`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="weighted_moments" class="method">
		<h4>
			<span title="System.object">object</span> <strong>weighted_moments</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> frequency_weights, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keep_dims, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> keepdims)
		</h4>
		<div class="content">Returns the frequency-weighted mean and variance of `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>1-d tensor of int32 values; these are the axes along which
to compute mean and variance. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> frequency_weights
						</dt>
						<dd>A tensor of positive weights which can be
broadcast with x. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Name used to scope the operation. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keep_dims
						</dt>
						<dd>Produce moments with the same dimensionality as the input. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> keepdims
						</dt>
						<dd>Alias of keep_dims. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Two tensors: `weighted_mean` and `weighted_variance`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="weighted_moments_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>weighted_moments_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axes, <span title="System.object">object</span> frequency_weights, <span title="System.object">object</span> name, <span title="System.object">object</span> keep_dims, <span title="System.object">object</span> keepdims)
		</h4>
		<div class="content">Returns the frequency-weighted mean and variance of `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axes
						</dt>
						<dd>1-d tensor of int32 values; these are the axes along which
to compute mean and variance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> frequency_weights
						</dt>
						<dd>A tensor of positive weights which can be
broadcast with x. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Name used to scope the operation. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> keep_dims
						</dt>
						<dd>Produce moments with the same dimensionality as the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> keepdims
						</dt>
						<dd>Alias of keep_dims. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Two tensors: `weighted_mean` and `weighted_variance`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <span title="System.object">object</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <span title="System.int">int</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> input, <span title="System.object">object</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.int">int</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../numpy/ndarray.htm">ndarray</a> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <a href="../numpy/ndarray.htm">ndarray</a> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.object">object</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.object">object</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.object">object</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> input, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> dilation_rate, <span title="System.string">string</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.object">object</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <span title="System.int">int</span> dilation_rate, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> spatial_dims, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="with_space_to_batch_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>with_space_to_batch_dyn</strong>(<span title="System.object">object</span> input, <span title="System.object">object</span> dilation_rate, <span title="System.object">object</span> padding, <span title="System.object">object</span> op, <span title="System.object">object</span> filter_shape, <span title="System.object">object</span> spatial_dims, <span title="System.object">object</span> data_format)
		</h4>
		<div class="content">Performs `op` on the space-to-batch representation of `input`. <p></p> This has the effect of transforming sliding window operations into the
corresponding "atrous" operation in which the input is sampled at the
specified `dilation_rate`. <p></p> In the special case that `dilation_rate` is uniformly 1, this simply returns: <p></p> op(input, num_spatial_dims, padding) <p></p> Otherwise, it returns: <p></p> batch_to_space_nd(
op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings),
num_spatial_dims,
"VALID")
adjusted_dilation_rate,
adjusted_crops), <p></p> where: <p></p> adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)],
adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2] <p></p> defined as follows: <p></p> We first define two int64 tensors `paddings` and `crops` of shape
`[num_spatial_dims, 2]` based on the value of `padding` and the spatial
dimensions of the `input`: <p></p> If `padding = "VALID"`, then: <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate) <p></p> If `padding = "SAME"`, then: <p></p> dilated_filter_shape =
filter_shape + (filter_shape - 1) * (dilation_rate - 1) <p></p> paddings, crops = required_space_to_batch_paddings(
input_shape[spatial_dims],
dilation_rate,
[(dilated_filter_shape - 1) // 2,
dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2]) <p></p> Because `space_to_batch_nd` and `batch_to_space_nd` assume that the spatial
dimensions are contiguous starting at the second dimension, but the specified
`spatial_dims` may not be, we must adjust `dilation_rate`, `paddings` and
`crops` in order to be usable with these operations.  For a given dimension,
if the block size is 1, and both the starting and ending padding and crop
amounts are 0, then space_to_batch_nd effectively leaves that dimension alone,
which is what is needed for dimensions not part of `spatial_dims`.
Furthermore, `space_to_batch_nd` and `batch_to_space_nd` handle this case
efficiently for any number of leading and trailing dimensions. <p></p> For 0 <= i < len(spatial_dims), we assign: <p></p> adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i]
adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :]
adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :] <p></p> All unassigned values of `adjusted_dilation_rate` default to 1, while all
unassigned values of `adjusted_paddings` and `adjusted_crops` default to 0. <p></p> Note in the case that `dilation_rate` is not uniformly 1, specifying "VALID"
padding is equivalent to specifying `padding = "SAME"` with a filter_shape of
`[1]*N`. <p></p> Advanced usage. Note the following optimization: A sequence of
`with_space_to_batch` operations with identical (not uniformly 1)
`dilation_rate` parameters and "VALID" padding <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", op_1)
...
net = with_space_to_batch(net, dilation_rate, "VALID", op_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "VALID")
...
result = op_k(result, num_spatial_dims, "VALID") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) <p></p> This eliminates the overhead of `k-1` calls to `space_to_batch_nd` and
`batch_to_space_nd`. <p></p> Similarly, a sequence of `with_space_to_batch` operations with identical (not
uniformly 1) `dilation_rate` parameters, "SAME" padding, and odd filter
dimensions <p></p> net = with_space_to_batch(net, dilation_rate, "SAME", op_1, filter_shape_1)
...
net = with_space_to_batch(net, dilation_rate, "SAME", op_k, filter_shape_k) <p></p> can be combined into a single `with_space_to_batch` operation as follows: <p></p> def combined_op(converted_input, num_spatial_dims, _):
result = op_1(converted_input, num_spatial_dims, "SAME")
...
result = op_k(result, num_spatial_dims, "SAME") <p></p> net = with_space_to_batch(net, dilation_rate, "VALID", combined_op) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input
						</dt>
						<dd>Tensor of rank > max(spatial_dims). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dilation_rate
						</dt>
						<dd>int32 Tensor of *known* shape [num_spatial_dims]. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>str constant equal to "VALID" or "SAME" 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op
						</dt>
						<dd>Function that maps (input, num_spatial_dims, padding) -> output 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> filter_shape
						</dt>
						<dd>If padding = "SAME", specifies the shape of the convolution
kernel/pooling window as an integer Tensor of shape [>=num_spatial_dims].
If padding = "VALID", filter_shape is ignored and need not be specified. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> spatial_dims
						</dt>
						<dd>Monotonically increasing sequence of `num_spatial_dims`
integers (which are >= 1) specifying the spatial dimensions of `input`
and output.  Defaults to: `range(1, num_spatial_dims+1)`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>A string or None.  Specifies whether the channel dimension of
the `input` and output is the last dimension (default, or if `data_format`
does not start with "NC"), or the second dimension (if `data_format`
starts with "NC").  For N=1, the valid values are "NWC" (default) and
"NCW".  For N=2, the valid values are "NHWC" (default) and "NCHW".
For N=3, the valid values are "NDHWC" (default) and "NCDHW". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The output Tensor as described above, dimensions will vary based on the op
provided. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="xw_plus_b" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>xw_plus_b</strong>(<span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> weights, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> biases, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes matmul(x, weights) + biases. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> x
						</dt>
						<dd>a 2D tensor.  Dimensions typically: batch, in_units 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> weights
						</dt>
						<dd>a 2D tensor.  Dimensions typically: in_units, out_units 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> biases
						</dt>
						<dd>a 1D tensor.  Dimensions: out_units 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional).  If not specified
"xw_plus_b" is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 2-D Tensor computing matmul(x, weights) + biases.
Dimensions typically: batch, out_units. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="xw_plus_b" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>xw_plus_b</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> weights, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> biases, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes matmul(x, weights) + biases. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>a 2D tensor.  Dimensions typically: batch, in_units 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> weights
						</dt>
						<dd>a 2D tensor.  Dimensions typically: in_units, out_units 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> biases
						</dt>
						<dd>a 1D tensor.  Dimensions: out_units 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional).  If not specified
"xw_plus_b" is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 2-D Tensor computing matmul(x, weights) + biases.
Dimensions typically: batch, out_units. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="xw_plus_b" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>xw_plus_b</strong>(<span title="System.int">int</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> weights, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> biases, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes matmul(x, weights) + biases. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.int">int</span></code> x
						</dt>
						<dd>a 2D tensor.  Dimensions typically: batch, in_units 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> weights
						</dt>
						<dd>a 2D tensor.  Dimensions typically: in_units, out_units 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> biases
						</dt>
						<dd>a 1D tensor.  Dimensions: out_units 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional).  If not specified
"xw_plus_b" is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 2-D Tensor computing matmul(x, weights) + biases.
Dimensions typically: batch, out_units. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="xw_plus_b_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>xw_plus_b_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> weights, <span title="System.object">object</span> biases, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes matmul(x, weights) + biases. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>a 2D tensor.  Dimensions typically: batch, in_units 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> weights
						</dt>
						<dd>a 2D tensor.  Dimensions typically: in_units, out_units 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> biases
						</dt>
						<dd>a 1D tensor.  Dimensions: out_units 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional).  If not specified
"xw_plus_b" is used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 2-D Tensor computing matmul(x, weights) + biases.
Dimensions typically: batch, out_units. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="zero_fraction" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>zero_fraction</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> value, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the fraction of zeros in `value`. <p></p> If `value` is empty, the result is `nan`. <p></p> This is useful in summaries to measure and report sparsity.  For example, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> value
						</dt>
						<dd>A tensor of numeric type. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The fraction of zeros in `value`, with type `float32`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>z = tf.nn.relu(...)
            summ = tf.compat.v1.summary.scalar('sparsity', tf.nn.zero_fraction(z)) </pre>
</div>
		</div>
	</div>
	<div id="zero_fraction" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>zero_fraction</strong>(<a href="../numpy/ndarray.htm">ndarray</a> value, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the fraction of zeros in `value`. <p></p> If `value` is empty, the result is `nan`. <p></p> This is useful in summaries to measure and report sparsity.  For example, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> value
						</dt>
						<dd>A tensor of numeric type. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The fraction of zeros in `value`, with type `float32`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>z = tf.nn.relu(...)
            summ = tf.compat.v1.summary.scalar('sparsity', tf.nn.zero_fraction(z)) </pre>
</div>
		</div>
	</div>
	<div id="zero_fraction" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>zero_fraction</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> value, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the fraction of zeros in `value`. <p></p> If `value` is empty, the result is `nan`. <p></p> This is useful in summaries to measure and report sparsity.  For example, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> value
						</dt>
						<dd>A tensor of numeric type. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The fraction of zeros in `value`, with type `float32`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>z = tf.nn.relu(...)
            summ = tf.compat.v1.summary.scalar('sparsity', tf.nn.zero_fraction(z)) </pre>
</div>
		</div>
	</div>
	<div id="zero_fraction_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>zero_fraction_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Returns the fraction of zeros in `value`. <p></p> If `value` is empty, the result is `nan`. <p></p> This is useful in summaries to measure and report sparsity.  For example, 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A tensor of numeric type. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The fraction of zeros in `value`, with type `float32`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>z = tf.nn.relu(...)
            summ = tf.compat.v1.summary.scalar('sparsity', tf.nn.zero_fraction(z)) </pre>
</div>
		</div>
	</div>
	
	<h3 class="section">Public properties</h3>

	<div id="all_candidate_sampler_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>all_candidate_sampler_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="atrous_conv2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>atrous_conv2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="atrous_conv2d_transpose_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>atrous_conv2d_transpose_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="avg_pool_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>avg_pool_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="avg_pool_v2_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>avg_pool_v2_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="avg_pool1d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>avg_pool1d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="avg_pool3d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>avg_pool3d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="batch_norm_with_global_normalization_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>batch_norm_with_global_normalization_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="batch_normalization_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>batch_normalization_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="bias_add_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>bias_add_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="bidirectional_dynamic_rnn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>bidirectional_dynamic_rnn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="collapse_repeated_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>collapse_repeated_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="compute_accidental_hits_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>compute_accidental_hits_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="compute_average_loss_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>compute_average_loss_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv_transpose_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv_transpose_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv1d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv1d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv1d_transpose_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv1d_transpose_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv2d_backprop_filter_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv2d_backprop_filter_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv2d_backprop_input_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv2d_backprop_input_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv2d_transpose_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv2d_transpose_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv3d_backprop_filter_fn_" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv3d_backprop_filter_fn_</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv3d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv3d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv3d_transpose_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv3d_transpose_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="convolution_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>convolution_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="crelu_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>crelu_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ctc_beam_search_decoder_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ctc_beam_search_decoder_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ctc_beam_search_decoder_v2_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ctc_beam_search_decoder_v2_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ctc_greedy_decoder_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ctc_greedy_decoder_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ctc_loss_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ctc_loss_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ctc_loss_v2_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ctc_loss_v2_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ctc_unique_labels_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ctc_unique_labels_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="depthwise_conv2d_backprop_filter_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>depthwise_conv2d_backprop_filter_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="depthwise_conv2d_backprop_input_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>depthwise_conv2d_backprop_input_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="depthwise_conv2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>depthwise_conv2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="depthwise_conv2d_native_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>depthwise_conv2d_native_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="dilation2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>dilation2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="dropout_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>dropout_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="dynamic_rnn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>dynamic_rnn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="elu_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>elu_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="embedding_lookup_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>embedding_lookup_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="embedding_lookup_sparse_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>embedding_lookup_sparse_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="erosion2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>erosion2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="fixed_unigram_candidate_sampler_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>fixed_unigram_candidate_sampler_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="fractional_avg_pool_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>fractional_avg_pool_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="fractional_max_pool_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>fractional_max_pool_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="fused_batch_norm_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>fused_batch_norm_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="in_top_k_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>in_top_k_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="l2_loss_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>l2_loss_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="l2_normalize_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>l2_normalize_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="leaky_relu_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>leaky_relu_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="learned_unigram_candidate_sampler_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>learned_unigram_candidate_sampler_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="log_poisson_loss_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>log_poisson_loss_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="log_softmax_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>log_softmax_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="log_uniform_candidate_sampler_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>log_uniform_candidate_sampler_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="lrn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>lrn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="max_pool_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>max_pool_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="max_pool_v2_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>max_pool_v2_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="max_pool_with_argmax_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>max_pool_with_argmax_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="max_pool1d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>max_pool1d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="max_pool2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>max_pool2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="max_pool3d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>max_pool3d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="moments_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>moments_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="nce_loss_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>nce_loss_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="normalize_moments_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>normalize_moments_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="pool_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>pool_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="raw_rnn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>raw_rnn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="relu_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>relu_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="relu_layer_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>relu_layer_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="relu6_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>relu6_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="safe_embedding_lookup_sparse_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>safe_embedding_lookup_sparse_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sampled_softmax_loss_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sampled_softmax_loss_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="scale_regularization_loss_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>scale_regularization_loss_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="selu_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>selu_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="separable_conv2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>separable_conv2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sigmoid_cross_entropy_with_logits_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sigmoid_cross_entropy_with_logits_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>softmax_cross_entropy_with_logits_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="softmax_cross_entropy_with_logits_v2_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>softmax_cross_entropy_with_logits_v2_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="softmax_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>softmax_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="softplus_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>softplus_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="softsign_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>softsign_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sparse_softmax_cross_entropy_with_logits_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sparse_softmax_cross_entropy_with_logits_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="static_bidirectional_rnn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>static_bidirectional_rnn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="static_rnn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>static_rnn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="static_state_saving_rnn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>static_state_saving_rnn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sufficient_statistics_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sufficient_statistics_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="swish_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>swish_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="top_k_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>top_k_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="uniform_candidate_sampler_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>uniform_candidate_sampler_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="weighted_cross_entropy_with_logits_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>weighted_cross_entropy_with_logits_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="weighted_moments_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>weighted_moments_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="with_space_to_batch_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>with_space_to_batch_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="xw_plus_b_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>xw_plus_b_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="zero_fraction_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>zero_fraction_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>