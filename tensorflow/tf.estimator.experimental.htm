<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>tf.estimator.experimental - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow/AggregationMethod.htm">AggregationMethod</a>
        </li>
				<li>
            <a href="../tensorflow/ConditionalAccumulator.htm">ConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/ConditionalAccumulatorBase.htm">ConditionalAccumulatorBase</a>
        </li>
				<li>
            <a href="../tensorflow/constant_initializer.htm">constant_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/CriticalSection.htm">CriticalSection</a>
        </li>
				<li>
            <a href="../tensorflow/DeviceSpec.htm">DeviceSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Dimension.htm">Dimension</a>
        </li>
				<li>
            <a href="../tensorflow/DType.htm">DType</a>
        </li>
				<li>
            <a href="../tensorflow/FIFOQueue.htm">FIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLenFeature.htm">FixedLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLengthRecordReader.htm">FixedLengthRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLenSequenceFeature.htm">FixedLenSequenceFeature</a>
        </li>
				<li>
            <a href="../tensorflow/glorot_normal_initializer.htm">glorot_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/glorot_uniform_initializer.htm">glorot_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/GradientTape.htm">GradientTape</a>
        </li>
				<li>
            <a href="../tensorflow/Graph.htm">Graph</a>
        </li>
				<li>
            <a href="../tensorflow/Graph._ControlDependenciesController.htm">Graph._ControlDependenciesController</a>
        </li>
				<li>
            <a href="../tensorflow/Graph.I_ControlDependenciesController.htm">Graph.I_ControlDependenciesController</a>
        </li>
				<li>
            <a href="../tensorflow/GraphKeys.htm">GraphKeys</a>
        </li>
				<li>
            <a href="../tensorflow/HeadingAxes.htm">HeadingAxes</a>
        </li>
				<li>
            <a href="../tensorflow/IAggregationMethod.htm">IAggregationMethod</a>
        </li>
				<li>
            <a href="../tensorflow/IConditionalAccumulator.htm">IConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/IConditionalAccumulatorBase.htm">IConditionalAccumulatorBase</a>
        </li>
				<li>
            <a href="../tensorflow/Iconstant_initializer.htm">Iconstant_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/ICriticalSection.htm">ICriticalSection</a>
        </li>
				<li>
            <a href="../tensorflow/IdentityReader.htm">IdentityReader</a>
        </li>
				<li>
            <a href="../tensorflow/IDeviceSpec.htm">IDeviceSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IDimension.htm">IDimension</a>
        </li>
				<li>
            <a href="../tensorflow/IDType.htm">IDType</a>
        </li>
				<li>
            <a href="../tensorflow/IFIFOQueue.htm">IFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLenFeature.htm">IFixedLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLengthRecordReader.htm">IFixedLengthRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLenSequenceFeature.htm">IFixedLenSequenceFeature</a>
        </li>
				<li>
            <a href="../tensorflow/Iglorot_normal_initializer.htm">Iglorot_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Iglorot_uniform_initializer.htm">Iglorot_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IGradientTape.htm">IGradientTape</a>
        </li>
				<li>
            <a href="../tensorflow/IGraph.htm">IGraph</a>
        </li>
				<li>
            <a href="../tensorflow/IGraphKeys.htm">IGraphKeys</a>
        </li>
				<li>
            <a href="../tensorflow/IIdentityReader.htm">IIdentityReader</a>
        </li>
				<li>
            <a href="../tensorflow/IIndexedSlices.htm">IIndexedSlices</a>
        </li>
				<li>
            <a href="../tensorflow/IIndexedSlicesSpec.htm">IIndexedSlicesSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IInteractiveSession.htm">IInteractiveSession</a>
        </li>
				<li>
            <a href="../tensorflow/ILazyLoader.htm">ILazyLoader</a>
        </li>
				<li>
            <a href="../tensorflow/ILMDBReader.htm">ILMDBReader</a>
        </li>
				<li>
            <a href="../tensorflow/IModule.htm">IModule</a>
        </li>
				<li>
            <a href="../tensorflow/Iname_scope.htm">Iname_scope</a>
        </li>
				<li>
            <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a>
        </li>
				<li>
            <a href="../tensorflow/IndexedSlicesSpec.htm">IndexedSlicesSpec</a>
        </li>
				<li>
            <a href="../tensorflow/InteractiveSession.htm">InteractiveSession</a>
        </li>
				<li>
            <a href="../tensorflow/Iones_initializer.htm">Iones_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IOperation.htm">IOperation</a>
        </li>
				<li>
            <a href="../tensorflow/IOpError.htm">IOpError</a>
        </li>
				<li>
            <a href="../tensorflow/IOptionalSpec.htm">IOptionalSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Iorthogonal_initializer.htm">Iorthogonal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IPaddingFIFOQueue.htm">IPaddingFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IPriorityQueue.htm">IPriorityQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IQueueBase.htm">IQueueBase</a>
        </li>
				<li>
            <a href="../tensorflow/IRaggedTensor.htm">IRaggedTensor</a>
        </li>
				<li>
            <a href="../tensorflow/IRaggedTensorSpec.htm">IRaggedTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Irandom_normal_initializer.htm">Irandom_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Irandom_uniform_initializer.htm">Irandom_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IRandomShuffleQueue.htm">IRandomShuffleQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IReaderBase.htm">IReaderBase</a>
        </li>
				<li>
            <a href="../tensorflow/IRegisterGradient.htm">IRegisterGradient</a>
        </li>
				<li>
            <a href="../tensorflow/ISession.htm">ISession</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseConditionalAccumulator.htm">ISparseConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseFeature.htm">ISparseFeature</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensor.htm">ISparseTensor</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensorSpec.htm">ISparseTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensorValue.htm">ISparseTensorValue</a>
        </li>
				<li>
            <a href="../tensorflow/ITensor.htm">ITensor</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorArray.htm">ITensorArray</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorArraySpec.htm">ITensorArraySpec</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorShape.htm">ITensorShape</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorSpec.htm">ITensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/ITextLineReader.htm">ITextLineReader</a>
        </li>
				<li>
            <a href="../tensorflow/ITFRecordReader.htm">ITFRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/Itruncated_normal_initializer.htm">Itruncated_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/ITypeSpec.htm">ITypeSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IUnconnectedGradients.htm">IUnconnectedGradients</a>
        </li>
				<li>
            <a href="../tensorflow/Iuniform_unit_scaling_initializer.htm">Iuniform_unit_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IVariable.htm">IVariable</a>
        </li>
				<li>
            <a href="../tensorflow/Ivariable_scope.htm">Ivariable_scope</a>
        </li>
				<li>
            <a href="../tensorflow/IVariableScope.htm">IVariableScope</a>
        </li>
				<li>
            <a href="../tensorflow/Ivariance_scaling_initializer.htm">Ivariance_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IVarLenFeature.htm">IVarLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/IWholeFileReader.htm">IWholeFileReader</a>
        </li>
				<li>
            <a href="../tensorflow/Izeros_initializer.htm">Izeros_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/LazyLoader.htm">LazyLoader</a>
        </li>
				<li>
            <a href="../tensorflow/LMDBReader.htm">LMDBReader</a>
        </li>
				<li>
            <a href="../tensorflow/Module.htm">Module</a>
        </li>
				<li>
            <a href="../tensorflow/name_scope.htm">name_scope</a>
        </li>
				<li>
            <a href="../tensorflow/ones_initializer.htm">ones_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Operation.htm">Operation</a>
        </li>
				<li>
            <a href="../tensorflow/Operation._InputList.htm">Operation._InputList</a>
        </li>
				<li>
            <a href="../tensorflow/Operation.I_InputList.htm">Operation.I_InputList</a>
        </li>
				<li>
            <a href="../tensorflow/OpError.htm">OpError</a>
        </li>
				<li>
            <a href="../tensorflow/OptionalSpec.htm">OptionalSpec</a>
        </li>
				<li>
            <a href="../tensorflow/orthogonal_initializer.htm">orthogonal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/PaddingFIFOQueue.htm">PaddingFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/PriorityQueue.htm">PriorityQueue</a>
        </li>
				<li>
            <a href="../tensorflow/QueueBase.htm">QueueBase</a>
        </li>
				<li>
            <a href="../tensorflow/RaggedTensor.htm">RaggedTensor</a>
        </li>
				<li>
            <a href="../tensorflow/RaggedTensorSpec.htm">RaggedTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/random_normal_initializer.htm">random_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/random_uniform_initializer.htm">random_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/RandomShuffleQueue.htm">RandomShuffleQueue</a>
        </li>
				<li>
            <a href="../tensorflow/ReaderBase.htm">ReaderBase</a>
        </li>
				<li>
            <a href="../tensorflow/RegisterGradient.htm">RegisterGradient</a>
        </li>
				<li>
            <a href="../tensorflow/Session.htm">Session</a>
        </li>
				<li>
            <a href="../tensorflow/SparseConditionalAccumulator.htm">SparseConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/SparseFeature.htm">SparseFeature</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensor.htm">SparseTensor</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensorSpec.htm">SparseTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensorValue.htm">SparseTensorValue</a>
        </li>
				<li>
            <a href="../tensorflow/Tensor.htm">Tensor</a>
        </li>
				<li>
            <a href="../tensorflow/Tensor`1.htm">Tensor&lt;T&gt;</a>
        </li>
				<li>
            <a href="../tensorflow/TensorArray.htm">TensorArray</a>
        </li>
				<li>
            <a href="../tensorflow/TensorArraySpec.htm">TensorArraySpec</a>
        </li>
				<li>
            <a href="../tensorflow/TensorDimension.htm">TensorDimension</a>
        </li>
				<li>
            <a href="../tensorflow/TensorDimensionSlice.htm">TensorDimensionSlice</a>
        </li>
				<li>
            <a href="../tensorflow/TensorShape.htm">TensorShape</a>
        </li>
				<li>
            <a href="../tensorflow/TensorSpec.htm">TensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/TextLineReader.htm">TextLineReader</a>
        </li>
				<li>
            <a href="../tensorflow/tf.htm">tf</a>
        </li>
				<li>
            <a href="../tensorflow/tf.audio.htm">tf.audio</a>
        </li>
				<li>
            <a href="../tensorflow/tf.autograph.htm">tf.autograph</a>
        </li>
				<li>
            <a href="../tensorflow/tf.autograph.experimental.htm">tf.autograph.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.bitwise.htm">tf.bitwise</a>
        </li>
				<li>
            <a href="../tensorflow/tf.compat.htm">tf.compat</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.htm">tf.config</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.experimental.htm">tf.config.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.optimizer.htm">tf.config.optimizer</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.threading.htm">tf.config.threading</a>
        </li>
				<li>
            <a href="../tensorflow/tf.data.htm">tf.data</a>
        </li>
				<li>
            <a href="../tensorflow/tf.data.experimental.htm">tf.data.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.debugging.htm">tf.debugging</a>
        </li>
				<li>
            <a href="../tensorflow/tf.distribute.htm">tf.distribute</a>
        </li>
				<li>
            <a href="../tensorflow/tf.distributions.htm">tf.distributions</a>
        </li>
				<li>
            <a href="../tensorflow/tf.errors.htm">tf.errors</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.htm">tf.estimator</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.experimental.htm" class="current">tf.estimator.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.export.htm">tf.estimator.export</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.inputs.htm">tf.estimator.inputs</a>
        </li>
				<li>
            <a href="../tensorflow/tf.experimental.htm">tf.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.feature_column.htm">tf.feature_column</a>
        </li>
				<li>
            <a href="../tensorflow/tf.gfile.htm">tf.gfile</a>
        </li>
				<li>
            <a href="../tensorflow/tf.graph_util.htm">tf.graph_util</a>
        </li>
				<li>
            <a href="../tensorflow/tf.image.htm">tf.image</a>
        </li>
				<li>
            <a href="../tensorflow/tf.initializers.htm">tf.initializers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.io.htm">tf.io</a>
        </li>
				<li>
            <a href="../tensorflow/tf.io.gfile.htm">tf.io.gfile</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.htm">tf.keras</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.activations.htm">tf.keras.activations</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.htm">tf.keras.applications</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.densenet.htm">tf.keras.applications.densenet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.imagenet_utils.htm">tf.keras.applications.imagenet_utils</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.inception_resnet_v2.htm">tf.keras.applications.inception_resnet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.inception_v3.htm">tf.keras.applications.inception_v3</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.mobilenet.htm">tf.keras.applications.mobilenet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.mobilenet_v2.htm">tf.keras.applications.mobilenet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.nasnet.htm">tf.keras.applications.nasnet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.resnet.htm">tf.keras.applications.resnet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.resnet_v2.htm">tf.keras.applications.resnet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.vgg16.htm">tf.keras.applications.vgg16</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.vgg19.htm">tf.keras.applications.vgg19</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.xception.htm">tf.keras.applications.xception</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.backend.htm">tf.keras.backend</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.constraints.htm">tf.keras.constraints</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.htm">tf.keras.datasets</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.boston_housing.htm">tf.keras.datasets.boston_housing</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.cifar10.htm">tf.keras.datasets.cifar10</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.cifar100.htm">tf.keras.datasets.cifar100</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.fashion_mnist.htm">tf.keras.datasets.fashion_mnist</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.imdb.htm">tf.keras.datasets.imdb</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.mnist.htm">tf.keras.datasets.mnist</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.reuters.htm">tf.keras.datasets.reuters</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.estimator.htm">tf.keras.estimator</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.experimental.htm">tf.keras.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.initializers.htm">tf.keras.initializers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.layers.htm">tf.keras.layers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.losses.htm">tf.keras.losses</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.metrics.htm">tf.keras.metrics</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.mixed_precision.htm">tf.keras.mixed_precision</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.mixed_precision.experimental.htm">tf.keras.mixed_precision.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.models.htm">tf.keras.models</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.optimizers.htm">tf.keras.optimizers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.optimizers.schedules.htm">tf.keras.optimizers.schedules</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.preprocessing.htm">tf.keras.preprocessing</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.preprocessing.image.htm">tf.keras.preprocessing.image</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.regularizers.htm">tf.keras.regularizers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.utils.htm">tf.keras.utils</a>
        </li>
				<li>
            <a href="../tensorflow/tf.layers.htm">tf.layers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.layers.experimental.htm">tf.layers.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.linalg.htm">tf.linalg</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.htm">tf.lite</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.htm">tf.lite.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.htm">tf.lite.experimental.microfrontend</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.python.htm">tf.lite.experimental.microfrontend.python</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.python.ops.htm">tf.lite.experimental.microfrontend.python.ops</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.nn.htm">tf.lite.experimental.nn</a>
        </li>
				<li>
            <a href="../tensorflow/tf.logging.htm">tf.logging</a>
        </li>
				<li>
            <a href="../tensorflow/tf.losses.htm">tf.losses</a>
        </li>
				<li>
            <a href="../tensorflow/tf.math.htm">tf.math</a>
        </li>
				<li>
            <a href="../tensorflow/tf.metrics.htm">tf.metrics</a>
        </li>
				<li>
            <a href="../tensorflow/tf.nest.htm">tf.nest</a>
        </li>
				<li>
            <a href="../tensorflow/tf.nn.htm">tf.nn</a>
        </li>
				<li>
            <a href="../tensorflow/tf.profiler.htm">tf.profiler</a>
        </li>
				<li>
            <a href="../tensorflow/tf.quantization.htm">tf.quantization</a>
        </li>
				<li>
            <a href="../tensorflow/tf.ragged.htm">tf.ragged</a>
        </li>
				<li>
            <a href="../tensorflow/tf.random.htm">tf.random</a>
        </li>
				<li>
            <a href="../tensorflow/tf.random.experimental.htm">tf.random.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.resource_loader.htm">tf.resource_loader</a>
        </li>
				<li>
            <a href="../tensorflow/tf.saved_model.htm">tf.saved_model</a>
        </li>
				<li>
            <a href="../tensorflow/tf.saved_model.main_op.htm">tf.saved_model.main_op</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sets.htm">tf.sets</a>
        </li>
				<li>
            <a href="../tensorflow/tf.signal.htm">tf.signal</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sparse.htm">tf.sparse</a>
        </li>
				<li>
            <a href="../tensorflow/tf.strings.htm">tf.strings</a>
        </li>
				<li>
            <a href="../tensorflow/tf.summary.htm">tf.summary</a>
        </li>
				<li>
            <a href="../tensorflow/tf.summary.experimental.htm">tf.summary.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sysconfig.htm">tf.sysconfig</a>
        </li>
				<li>
            <a href="../tensorflow/tf.test.htm">tf.test</a>
        </li>
				<li>
            <a href="../tensorflow/tf.tpu.htm">tf.tpu</a>
        </li>
				<li>
            <a href="../tensorflow/tf.tpu.experimental.htm">tf.tpu.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.train.htm">tf.train</a>
        </li>
				<li>
            <a href="../tensorflow/tf.train.experimental.htm">tf.train.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.user_ops.htm">tf.user_ops</a>
        </li>
				<li>
            <a href="../tensorflow/tf.xla.htm">tf.xla</a>
        </li>
				<li>
            <a href="../tensorflow/tf.xla.experimental.htm">tf.xla.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/TFRecordReader.htm">TFRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/truncated_normal_initializer.htm">truncated_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/TypeSpec.htm">TypeSpec</a>
        </li>
				<li>
            <a href="../tensorflow/UnconnectedGradients.htm">UnconnectedGradients</a>
        </li>
				<li>
            <a href="../tensorflow/uniform_unit_scaling_initializer.htm">uniform_unit_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Variable.htm">Variable</a>
        </li>
				<li>
            <a href="../tensorflow/variable_scope.htm">variable_scope</a>
        </li>
				<li>
            <a href="../tensorflow/VariableAggregation.htm">VariableAggregation</a>
        </li>
				<li>
            <a href="../tensorflow/VariableScope.htm">VariableScope</a>
        </li>
				<li>
            <a href="../tensorflow/VariableSynchronization.htm">VariableSynchronization</a>
        </li>
				<li>
            <a href="../tensorflow/variance_scaling_initializer.htm">variance_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/VarLenFeature.htm">VarLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/WholeFileReader.htm">WholeFileReader</a>
        </li>
				<li>
            <a href="../tensorflow/zeros_initializer.htm">zeros_initializer</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> tf.estimator.experimental</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow</p>
		</header>
    <div class="sub-header">
		
		
			<h3 class="section">Methods</h3>
			<ul>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#build_raw_supervised_input_receiver_fn">build_raw_supervised_input_receiver_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#build_raw_supervised_input_receiver_fn">build_raw_supervised_input_receiver_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#build_raw_supervised_input_receiver_fn">build_raw_supervised_input_receiver_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#build_raw_supervised_input_receiver_fn">build_raw_supervised_input_receiver_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#build_raw_supervised_input_receiver_fn_dyn">build_raw_supervised_input_receiver_fn_dyn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#dnn_logit_fn_builder">dnn_logit_fn_builder</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#dnn_logit_fn_builder">dnn_logit_fn_builder</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#dnn_logit_fn_builder">dnn_logit_fn_builder</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#dnn_logit_fn_builder">dnn_logit_fn_builder</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#dnn_logit_fn_builder_dyn">dnn_logit_fn_builder_dyn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#linear_logit_fn_builder">linear_logit_fn_builder</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#linear_logit_fn_builder">linear_logit_fn_builder</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#linear_logit_fn_builder_dyn">linear_logit_fn_builder_dyn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#make_early_stopping_hook">make_early_stopping_hook</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#make_early_stopping_hook_dyn">make_early_stopping_hook_dyn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#make_stop_at_checkpoint_step_hook">make_stop_at_checkpoint_step_hook</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#make_stop_at_checkpoint_step_hook_dyn">make_stop_at_checkpoint_step_hook_dyn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_higher_hook">stop_if_higher_hook</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_higher_hook_dyn">stop_if_higher_hook_dyn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_lower_hook">stop_if_lower_hook</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_lower_hook_dyn">stop_if_lower_hook_dyn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_no_decrease_hook">stop_if_no_decrease_hook</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_no_decrease_hook_dyn">stop_if_no_decrease_hook_dyn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_no_increase_hook">stop_if_no_increase_hook</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_no_increase_hook_dyn">stop_if_no_increase_hook_dyn</a></li>
			</ul>
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#build_raw_supervised_input_receiver_fn_fn">build_raw_supervised_input_receiver_fn_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#call_logit_fn_fn">call_logit_fn_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#dnn_logit_fn_builder_fn">dnn_logit_fn_builder_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#linear_logit_fn_builder_fn">linear_logit_fn_builder_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#make_early_stopping_hook_fn">make_early_stopping_hook_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#make_stop_at_checkpoint_step_hook_fn">make_stop_at_checkpoint_step_hook_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_higher_hook_fn">stop_if_higher_hook_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_lower_hook_fn">stop_if_lower_hook_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_no_decrease_hook_fn">stop_if_no_decrease_hook_fn</a></li>
				<li><a href="../tensorflow/tf.estimator.experimental.htm#stop_if_no_increase_hook_fn">stop_if_no_increase_hook_fn</a></li>
			</ul>
		
	</div>
	
	
	<h3 class="section">Public static methods</h3>

	<div id="build_raw_supervised_input_receiver_fn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>build_raw_supervised_input_receiver_fn</strong>(<span title="System.object">object</span> features, <span title="System.object">object</span> labels, <span title="System.object">object</span> default_batch_size)
		</h4>
		<div class="content">Build a supervised_input_receiver_fn for raw features and labels. <p></p> This function wraps tensor placeholders in a supervised_receiver_fn
with the expectation that the features and labels appear precisely as
the model_fn expects them. Features and labels can therefore be dicts of
tensors, or raw tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> features
						</dt>
						<dd>a dict of string to `Tensor` or `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>a dict of string to `Tensor` or `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> default_batch_size
						</dt>
						<dd>the number of query examples expected per batch.
Leave unset for variable batch size (recommended). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A supervised_input_receiver_fn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="build_raw_supervised_input_receiver_fn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>build_raw_supervised_input_receiver_fn</strong>(<span title="System.object">object</span> features, <span title="System.Collections.Generic.IEnumerable<_DatasetInitializerHook>">IEnumerable&lt;_DatasetInitializerHook&gt;</span> labels, <span title="System.object">object</span> default_batch_size)
		</h4>
		<div class="content">Build a supervised_input_receiver_fn for raw features and labels. <p></p> This function wraps tensor placeholders in a supervised_receiver_fn
with the expectation that the features and labels appear precisely as
the model_fn expects them. Features and labels can therefore be dicts of
tensors, or raw tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> features
						</dt>
						<dd>a dict of string to `Tensor` or `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<_DatasetInitializerHook>">IEnumerable&lt;_DatasetInitializerHook&gt;</span></code> labels
						</dt>
						<dd>a dict of string to `Tensor` or `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> default_batch_size
						</dt>
						<dd>the number of query examples expected per batch.
Leave unset for variable batch size (recommended). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A supervised_input_receiver_fn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="build_raw_supervised_input_receiver_fn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>build_raw_supervised_input_receiver_fn</strong>(<span title="System.Collections.Generic.IEnumerable<_DatasetInitializerHook>">IEnumerable&lt;_DatasetInitializerHook&gt;</span> features, <span title="System.object">object</span> labels, <span title="System.object">object</span> default_batch_size)
		</h4>
		<div class="content">Build a supervised_input_receiver_fn for raw features and labels. <p></p> This function wraps tensor placeholders in a supervised_receiver_fn
with the expectation that the features and labels appear precisely as
the model_fn expects them. Features and labels can therefore be dicts of
tensors, or raw tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<_DatasetInitializerHook>">IEnumerable&lt;_DatasetInitializerHook&gt;</span></code> features
						</dt>
						<dd>a dict of string to `Tensor` or `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>a dict of string to `Tensor` or `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> default_batch_size
						</dt>
						<dd>the number of query examples expected per batch.
Leave unset for variable batch size (recommended). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A supervised_input_receiver_fn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="build_raw_supervised_input_receiver_fn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>build_raw_supervised_input_receiver_fn</strong>(<span title="System.Collections.Generic.IEnumerable<_DatasetInitializerHook>">IEnumerable&lt;_DatasetInitializerHook&gt;</span> features, <span title="System.Collections.Generic.IEnumerable<_DatasetInitializerHook>">IEnumerable&lt;_DatasetInitializerHook&gt;</span> labels, <span title="System.object">object</span> default_batch_size)
		</h4>
		<div class="content">Build a supervised_input_receiver_fn for raw features and labels. <p></p> This function wraps tensor placeholders in a supervised_receiver_fn
with the expectation that the features and labels appear precisely as
the model_fn expects them. Features and labels can therefore be dicts of
tensors, or raw tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<_DatasetInitializerHook>">IEnumerable&lt;_DatasetInitializerHook&gt;</span></code> features
						</dt>
						<dd>a dict of string to `Tensor` or `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<_DatasetInitializerHook>">IEnumerable&lt;_DatasetInitializerHook&gt;</span></code> labels
						</dt>
						<dd>a dict of string to `Tensor` or `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> default_batch_size
						</dt>
						<dd>the number of query examples expected per batch.
Leave unset for variable batch size (recommended). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A supervised_input_receiver_fn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="build_raw_supervised_input_receiver_fn_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>build_raw_supervised_input_receiver_fn_dyn</strong>(<span title="System.object">object</span> features, <span title="System.object">object</span> labels, <span title="System.object">object</span> default_batch_size)
		</h4>
		<div class="content">Build a supervised_input_receiver_fn for raw features and labels. <p></p> This function wraps tensor placeholders in a supervised_receiver_fn
with the expectation that the features and labels appear precisely as
the model_fn expects them. Features and labels can therefore be dicts of
tensors, or raw tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> features
						</dt>
						<dd>a dict of string to `Tensor` or `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>a dict of string to `Tensor` or `Tensor`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> default_batch_size
						</dt>
						<dd>the number of query examples expected per batch.
Leave unset for variable batch size (recommended). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A supervised_input_receiver_fn. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dnn_logit_fn_builder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dnn_logit_fn_builder</strong>(<span title="System.int">int</span> units, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> hidden_units, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> feature_columns, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> activation_fn, <span title="System.object">object</span> dropout, <span title="System.object">object</span> input_layer_partitioner, <span title="System.bool">bool</span> batch_norm)
		</h4>
		<div class="content">Function builder for a dnn logit_fn. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.int">int</span></code> units
						</dt>
						<dd>An int indicating the dimension of the logit layer.  In the
MultiHead case, this should be the sum of all component Heads' logit
dimensions. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> hidden_units
						</dt>
						<dd>Iterable of integer number of hidden units per layer. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> feature_columns
						</dt>
						<dd>Iterable of `feature_column._FeatureColumn` model inputs. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> activation_fn
						</dt>
						<dd>Activation function applied to each layer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dropout
						</dt>
						<dd>When not `None`, the probability we will drop out a given
coordinate. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_layer_partitioner
						</dt>
						<dd>Partitioner for input layer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> batch_norm
						</dt>
						<dd>Whether to use batch normalization after each hidden layer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A logit_fn (see below). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dnn_logit_fn_builder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dnn_logit_fn_builder</strong>(<span title="System.int">int</span> units, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> hidden_units, <span title="System.ValueTuple">ValueTuple</span> feature_columns, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> activation_fn, <span title="System.object">object</span> dropout, <span title="System.object">object</span> input_layer_partitioner, <span title="System.bool">bool</span> batch_norm)
		</h4>
		<div class="content">Function builder for a dnn logit_fn. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.int">int</span></code> units
						</dt>
						<dd>An int indicating the dimension of the logit layer.  In the
MultiHead case, this should be the sum of all component Heads' logit
dimensions. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> hidden_units
						</dt>
						<dd>Iterable of integer number of hidden units per layer. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple">ValueTuple</span></code> feature_columns
						</dt>
						<dd>Iterable of `feature_column._FeatureColumn` model inputs. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> activation_fn
						</dt>
						<dd>Activation function applied to each layer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dropout
						</dt>
						<dd>When not `None`, the probability we will drop out a given
coordinate. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_layer_partitioner
						</dt>
						<dd>Partitioner for input layer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> batch_norm
						</dt>
						<dd>Whether to use batch normalization after each hidden layer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A logit_fn (see below). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dnn_logit_fn_builder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dnn_logit_fn_builder</strong>(<span title="System.object">object</span> units, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> hidden_units, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> feature_columns, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> activation_fn, <span title="System.object">object</span> dropout, <span title="System.object">object</span> input_layer_partitioner, <span title="System.bool">bool</span> batch_norm)
		</h4>
		<div class="content">Function builder for a dnn logit_fn. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> units
						</dt>
						<dd>An int indicating the dimension of the logit layer.  In the
MultiHead case, this should be the sum of all component Heads' logit
dimensions. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> hidden_units
						</dt>
						<dd>Iterable of integer number of hidden units per layer. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> feature_columns
						</dt>
						<dd>Iterable of `feature_column._FeatureColumn` model inputs. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> activation_fn
						</dt>
						<dd>Activation function applied to each layer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dropout
						</dt>
						<dd>When not `None`, the probability we will drop out a given
coordinate. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_layer_partitioner
						</dt>
						<dd>Partitioner for input layer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> batch_norm
						</dt>
						<dd>Whether to use batch normalization after each hidden layer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A logit_fn (see below). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dnn_logit_fn_builder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dnn_logit_fn_builder</strong>(<span title="System.object">object</span> units, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> hidden_units, <span title="System.ValueTuple">ValueTuple</span> feature_columns, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> activation_fn, <span title="System.object">object</span> dropout, <span title="System.object">object</span> input_layer_partitioner, <span title="System.bool">bool</span> batch_norm)
		</h4>
		<div class="content">Function builder for a dnn logit_fn. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> units
						</dt>
						<dd>An int indicating the dimension of the logit layer.  In the
MultiHead case, this should be the sum of all component Heads' logit
dimensions. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> hidden_units
						</dt>
						<dd>Iterable of integer number of hidden units per layer. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple">ValueTuple</span></code> feature_columns
						</dt>
						<dd>Iterable of `feature_column._FeatureColumn` model inputs. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> activation_fn
						</dt>
						<dd>Activation function applied to each layer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dropout
						</dt>
						<dd>When not `None`, the probability we will drop out a given
coordinate. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_layer_partitioner
						</dt>
						<dd>Partitioner for input layer. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> batch_norm
						</dt>
						<dd>Whether to use batch normalization after each hidden layer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A logit_fn (see below). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dnn_logit_fn_builder_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dnn_logit_fn_builder_dyn</strong>(<span title="System.object">object</span> units, <span title="System.object">object</span> hidden_units, <span title="System.object">object</span> feature_columns, <span title="System.object">object</span> activation_fn, <span title="System.object">object</span> dropout, <span title="System.object">object</span> input_layer_partitioner, <span title="System.object">object</span> batch_norm)
		</h4>
		<div class="content">Function builder for a dnn logit_fn. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> units
						</dt>
						<dd>An int indicating the dimension of the logit layer.  In the
MultiHead case, this should be the sum of all component Heads' logit
dimensions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> hidden_units
						</dt>
						<dd>Iterable of integer number of hidden units per layer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> feature_columns
						</dt>
						<dd>Iterable of `feature_column._FeatureColumn` model inputs. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> activation_fn
						</dt>
						<dd>Activation function applied to each layer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dropout
						</dt>
						<dd>When not `None`, the probability we will drop out a given
coordinate. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_layer_partitioner
						</dt>
						<dd>Partitioner for input layer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> batch_norm
						</dt>
						<dd>Whether to use batch normalization after each hidden layer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A logit_fn (see below). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="linear_logit_fn_builder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>linear_logit_fn_builder</strong>(<span title="System.int">int</span> units, <span title="System.Collections.Generic.IEnumerable<NumericColumn>">IEnumerable&lt;NumericColumn&gt;</span> feature_columns, <span title="System.string">string</span> sparse_combiner)
		</h4>
		<div class="content">Function builder for a linear logit_fn. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.int">int</span></code> units
						</dt>
						<dd>An int indicating the dimension of the logit layer. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<NumericColumn>">IEnumerable&lt;NumericColumn&gt;</span></code> feature_columns
						</dt>
						<dd>An iterable containing all the feature columns used by
the model. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> sparse_combiner
						</dt>
						<dd>A string specifying how to reduce if a categorical column
is multivalent.  One of "mean", "sqrtn", and "sum". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A logit_fn (see below). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="linear_logit_fn_builder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>linear_logit_fn_builder</strong>(<span title="System.object">object</span> units, <span title="System.Collections.Generic.IEnumerable<NumericColumn>">IEnumerable&lt;NumericColumn&gt;</span> feature_columns, <span title="System.string">string</span> sparse_combiner)
		</h4>
		<div class="content">Function builder for a linear logit_fn. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> units
						</dt>
						<dd>An int indicating the dimension of the logit layer. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<NumericColumn>">IEnumerable&lt;NumericColumn&gt;</span></code> feature_columns
						</dt>
						<dd>An iterable containing all the feature columns used by
the model. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> sparse_combiner
						</dt>
						<dd>A string specifying how to reduce if a categorical column
is multivalent.  One of "mean", "sqrtn", and "sum". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A logit_fn (see below). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="linear_logit_fn_builder_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>linear_logit_fn_builder_dyn</strong>(<span title="System.object">object</span> units, <span title="System.object">object</span> feature_columns, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> sparse_combiner)
		</h4>
		<div class="content">Function builder for a linear logit_fn. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> units
						</dt>
						<dd>An int indicating the dimension of the logit layer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> feature_columns
						</dt>
						<dd>An iterable containing all the feature columns used by
the model. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> sparse_combiner
						</dt>
						<dd>A string specifying how to reduce if a categorical column
is multivalent.  One of "mean", "sqrtn", and "sum". 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A logit_fn (see below). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="make_early_stopping_hook" class="method">
		<h4>
			<span title="System.object">object</span> <strong>make_early_stopping_hook</strong>(<span title="System.object">object</span> estimator, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> should_stop_fn, <span title="System.int">int</span> run_every_secs, <span title="System.object">object</span> run_every_steps)
		</h4>
		<div class="content">Creates early-stopping hook. <p></p> Returns a `SessionRunHook` that stops training when `should_stop_fn` returns
`True`. <p></p> Usage example:
Caveat: Current implementation supports early-stopping both training and
evaluation in local mode. In distributed mode, training can be stopped but
evaluation (where it's a separate job) will indefinitely wait for new model
checkpoints to evaluate, so you will need other means to detect and stop it.
Early-stopping evaluation in distributed mode requires changes in
`train_and_evaluate` API and will be addressed in a future revision. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> estimator
						</dt>
						<dd>A <a href="..\..\..\tf\estimator\Estimator.md"><code>tf.estimator.Estimator</code></a> instance. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> should_stop_fn
						</dt>
						<dd>`callable`, function that takes no arguments and returns a
`bool`. If the function returns `True`, stopping will be initiated by the
chief. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> run_every_secs
						</dt>
						<dd>If specified, calls `should_stop_fn` at an interval of
`run_every_secs` seconds. Defaults to 60 seconds. Either this or
`run_every_steps` must be set. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> run_every_steps
						</dt>
						<dd>If specified, calls `should_stop_fn` every
`run_every_steps` steps. Either this or `run_every_secs` must be set. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `SessionRunHook` that periodically executes `should_stop_fn` and initiates
early stopping if the function returns `True`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>estimator =...
            hook = early_stopping.make_early_stopping_hook(
                estimator, should_stop_fn=make_stop_fn(...))
            train_spec = tf.estimator.TrainSpec(..., hooks=[hook])
            tf.estimator.train_and_evaluate(estimator, train_spec,...) </pre>
</div>
		</div>
	</div>
	<div id="make_early_stopping_hook_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>make_early_stopping_hook_dyn</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> should_stop_fn, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> run_every_secs, <span title="System.object">object</span> run_every_steps)
		</h4>
		<div class="content">Creates early-stopping hook. <p></p> Returns a `SessionRunHook` that stops training when `should_stop_fn` returns
`True`. <p></p> Usage example:
Caveat: Current implementation supports early-stopping both training and
evaluation in local mode. In distributed mode, training can be stopped but
evaluation (where it's a separate job) will indefinitely wait for new model
checkpoints to evaluate, so you will need other means to detect and stop it.
Early-stopping evaluation in distributed mode requires changes in
`train_and_evaluate` API and will be addressed in a future revision. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> estimator
						</dt>
						<dd>A <a href="..\..\..\tf\estimator\Estimator.md"><code>tf.estimator.Estimator</code></a> instance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> should_stop_fn
						</dt>
						<dd>`callable`, function that takes no arguments and returns a
`bool`. If the function returns `True`, stopping will be initiated by the
chief. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> run_every_secs
						</dt>
						<dd>If specified, calls `should_stop_fn` at an interval of
`run_every_secs` seconds. Defaults to 60 seconds. Either this or
`run_every_steps` must be set. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> run_every_steps
						</dt>
						<dd>If specified, calls `should_stop_fn` every
`run_every_steps` steps. Either this or `run_every_secs` must be set. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `SessionRunHook` that periodically executes `should_stop_fn` and initiates
early stopping if the function returns `True`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>estimator =...
            hook = early_stopping.make_early_stopping_hook(
                estimator, should_stop_fn=make_stop_fn(...))
            train_spec = tf.estimator.TrainSpec(..., hooks=[hook])
            tf.estimator.train_and_evaluate(estimator, train_spec,...) </pre>
</div>
		</div>
	</div>
	<div id="make_stop_at_checkpoint_step_hook" class="method">
		<h4>
			<span title="System.object">object</span> <strong>make_stop_at_checkpoint_step_hook</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> last_step, <span title="System.int">int</span> wait_after_file_check_secs)
		</h4>
		<div class="content">Creates a proper StopAtCheckpointStepHook based on chief status. 




		</div>
	</div>
	<div id="make_stop_at_checkpoint_step_hook_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>make_stop_at_checkpoint_step_hook_dyn</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> last_step, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> wait_after_file_check_secs)
		</h4>
		<div class="content">Creates a proper StopAtCheckpointStepHook based on chief status. 




		</div>
	</div>
	<div id="stop_if_higher_hook" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_if_higher_hook</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> metric_name, <span title="System.object">object</span> threshold, <span title="System.object">object</span> eval_dir, <span title="System.int">int</span> min_steps, <span title="System.int">int</span> run_every_secs, <span title="System.object">object</span> run_every_steps)
		</h4>
		<div class="content">Creates hook to stop if the given metric is higher than the threshold. <p></p> Usage example:
Caveat: Current implementation supports early-stopping both training and
evaluation in local mode. In distributed mode, training can be stopped but
evaluation (where it's a separate job) will indefinitely wait for new model
checkpoints to evaluate, so you will need other means to detect and stop it.
Early-stopping evaluation in distributed mode requires changes in
`train_and_evaluate` API and will be addressed in a future revision. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> estimator
						</dt>
						<dd>A <a href="..\..\..\tf\estimator\Estimator.md"><code>tf.estimator.Estimator</code></a> instance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> metric_name
						</dt>
						<dd>`str`, metric to track. "loss", "accuracy", etc. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> threshold
						</dt>
						<dd>Numeric threshold for the given metric. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> eval_dir
						</dt>
						<dd>If set, directory containing summary files with eval metrics. By
default, `estimator.eval_dir()` will be used. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_steps
						</dt>
						<dd>`int`, stop is never requested if global step is less than this
value. Defaults to 0. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> run_every_secs
						</dt>
						<dd>If specified, calls `should_stop_fn` at an interval of
`run_every_secs` seconds. Defaults to 60 seconds. Either this or
`run_every_steps` must be set. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> run_every_steps
						</dt>
						<dd>If specified, calls `should_stop_fn` every
`run_every_steps` steps. Either this or `run_every_secs` must be set. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An early-stopping hook of type `SessionRunHook` that periodically checks
if the given metric is higher than specified threshold and initiates
early stopping if true. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>estimator =...
            # Hook to stop training if accuracy becomes higher than 0.9.
            hook = early_stopping.stop_if_higher_hook(estimator, "accuracy", 0.9)
            train_spec = tf.estimator.TrainSpec(..., hooks=[hook])
            tf.estimator.train_and_evaluate(estimator, train_spec,...) </pre>
</div>
		</div>
	</div>
	<div id="stop_if_higher_hook_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_if_higher_hook_dyn</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> metric_name, <span title="System.object">object</span> threshold, <span title="System.object">object</span> eval_dir, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> min_steps, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> run_every_secs, <span title="System.object">object</span> run_every_steps)
		</h4>
		<div class="content">Creates hook to stop if the given metric is higher than the threshold. <p></p> Usage example:
Caveat: Current implementation supports early-stopping both training and
evaluation in local mode. In distributed mode, training can be stopped but
evaluation (where it's a separate job) will indefinitely wait for new model
checkpoints to evaluate, so you will need other means to detect and stop it.
Early-stopping evaluation in distributed mode requires changes in
`train_and_evaluate` API and will be addressed in a future revision. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> estimator
						</dt>
						<dd>A <a href="..\..\..\tf\estimator\Estimator.md"><code>tf.estimator.Estimator</code></a> instance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> metric_name
						</dt>
						<dd>`str`, metric to track. "loss", "accuracy", etc. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> threshold
						</dt>
						<dd>Numeric threshold for the given metric. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> eval_dir
						</dt>
						<dd>If set, directory containing summary files with eval metrics. By
default, `estimator.eval_dir()` will be used. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> min_steps
						</dt>
						<dd>`int`, stop is never requested if global step is less than this
value. Defaults to 0. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> run_every_secs
						</dt>
						<dd>If specified, calls `should_stop_fn` at an interval of
`run_every_secs` seconds. Defaults to 60 seconds. Either this or
`run_every_steps` must be set. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> run_every_steps
						</dt>
						<dd>If specified, calls `should_stop_fn` every
`run_every_steps` steps. Either this or `run_every_secs` must be set. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An early-stopping hook of type `SessionRunHook` that periodically checks
if the given metric is higher than specified threshold and initiates
early stopping if true. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>estimator =...
            # Hook to stop training if accuracy becomes higher than 0.9.
            hook = early_stopping.stop_if_higher_hook(estimator, "accuracy", 0.9)
            train_spec = tf.estimator.TrainSpec(..., hooks=[hook])
            tf.estimator.train_and_evaluate(estimator, train_spec,...) </pre>
</div>
		</div>
	</div>
	<div id="stop_if_lower_hook" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_if_lower_hook</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> metric_name, <span title="System.object">object</span> threshold, <span title="System.object">object</span> eval_dir, <span title="System.int">int</span> min_steps, <span title="System.int">int</span> run_every_secs, <span title="System.object">object</span> run_every_steps)
		</h4>
		<div class="content">Creates hook to stop if the given metric is lower than the threshold. <p></p> Usage example:
Caveat: Current implementation supports early-stopping both training and
evaluation in local mode. In distributed mode, training can be stopped but
evaluation (where it's a separate job) will indefinitely wait for new model
checkpoints to evaluate, so you will need other means to detect and stop it.
Early-stopping evaluation in distributed mode requires changes in
`train_and_evaluate` API and will be addressed in a future revision. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> estimator
						</dt>
						<dd>A <a href="..\..\..\tf\estimator\Estimator.md"><code>tf.estimator.Estimator</code></a> instance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> metric_name
						</dt>
						<dd>`str`, metric to track. "loss", "accuracy", etc. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> threshold
						</dt>
						<dd>Numeric threshold for the given metric. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> eval_dir
						</dt>
						<dd>If set, directory containing summary files with eval metrics. By
default, `estimator.eval_dir()` will be used. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_steps
						</dt>
						<dd>`int`, stop is never requested if global step is less than this
value. Defaults to 0. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> run_every_secs
						</dt>
						<dd>If specified, calls `should_stop_fn` at an interval of
`run_every_secs` seconds. Defaults to 60 seconds. Either this or
`run_every_steps` must be set. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> run_every_steps
						</dt>
						<dd>If specified, calls `should_stop_fn` every
`run_every_steps` steps. Either this or `run_every_secs` must be set. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An early-stopping hook of type `SessionRunHook` that periodically checks
if the given metric is lower than specified threshold and initiates
early stopping if true. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>estimator =...
            # Hook to stop training if loss becomes lower than 100.
            hook = early_stopping.stop_if_lower_hook(estimator, "loss", 100)
            train_spec = tf.estimator.TrainSpec(..., hooks=[hook])
            tf.estimator.train_and_evaluate(estimator, train_spec,...) </pre>
</div>
		</div>
	</div>
	<div id="stop_if_lower_hook_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_if_lower_hook_dyn</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> metric_name, <span title="System.object">object</span> threshold, <span title="System.object">object</span> eval_dir, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> min_steps, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> run_every_secs, <span title="System.object">object</span> run_every_steps)
		</h4>
		<div class="content">Creates hook to stop if the given metric is lower than the threshold. <p></p> Usage example:
Caveat: Current implementation supports early-stopping both training and
evaluation in local mode. In distributed mode, training can be stopped but
evaluation (where it's a separate job) will indefinitely wait for new model
checkpoints to evaluate, so you will need other means to detect and stop it.
Early-stopping evaluation in distributed mode requires changes in
`train_and_evaluate` API and will be addressed in a future revision. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> estimator
						</dt>
						<dd>A <a href="..\..\..\tf\estimator\Estimator.md"><code>tf.estimator.Estimator</code></a> instance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> metric_name
						</dt>
						<dd>`str`, metric to track. "loss", "accuracy", etc. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> threshold
						</dt>
						<dd>Numeric threshold for the given metric. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> eval_dir
						</dt>
						<dd>If set, directory containing summary files with eval metrics. By
default, `estimator.eval_dir()` will be used. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> min_steps
						</dt>
						<dd>`int`, stop is never requested if global step is less than this
value. Defaults to 0. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> run_every_secs
						</dt>
						<dd>If specified, calls `should_stop_fn` at an interval of
`run_every_secs` seconds. Defaults to 60 seconds. Either this or
`run_every_steps` must be set. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> run_every_steps
						</dt>
						<dd>If specified, calls `should_stop_fn` every
`run_every_steps` steps. Either this or `run_every_secs` must be set. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An early-stopping hook of type `SessionRunHook` that periodically checks
if the given metric is lower than specified threshold and initiates
early stopping if true. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>estimator =...
            # Hook to stop training if loss becomes lower than 100.
            hook = early_stopping.stop_if_lower_hook(estimator, "loss", 100)
            train_spec = tf.estimator.TrainSpec(..., hooks=[hook])
            tf.estimator.train_and_evaluate(estimator, train_spec,...) </pre>
</div>
		</div>
	</div>
	<div id="stop_if_no_decrease_hook" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_if_no_decrease_hook</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> metric_name, <span title="System.object">object</span> max_steps_without_decrease, <span title="System.object">object</span> eval_dir, <span title="System.int">int</span> min_steps, <span title="System.int">int</span> run_every_secs, <span title="System.object">object</span> run_every_steps)
		</h4>
		<div class="content">Creates hook to stop if metric does not decrease within given max steps. <p></p> Usage example:
Caveat: Current implementation supports early-stopping both training and
evaluation in local mode. In distributed mode, training can be stopped but
evaluation (where it's a separate job) will indefinitely wait for new model
checkpoints to evaluate, so you will need other means to detect and stop it.
Early-stopping evaluation in distributed mode requires changes in
`train_and_evaluate` API and will be addressed in a future revision. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> estimator
						</dt>
						<dd>A <a href="..\..\..\tf\estimator\Estimator.md"><code>tf.estimator.Estimator</code></a> instance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> metric_name
						</dt>
						<dd>`str`, metric to track. "loss", "accuracy", etc. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_steps_without_decrease
						</dt>
						<dd>`int`, maximum number of training steps with no
decrease in the given metric. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> eval_dir
						</dt>
						<dd>If set, directory containing summary files with eval metrics. By
default, `estimator.eval_dir()` will be used. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_steps
						</dt>
						<dd>`int`, stop is never requested if global step is less than this
value. Defaults to 0. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> run_every_secs
						</dt>
						<dd>If specified, calls `should_stop_fn` at an interval of
`run_every_secs` seconds. Defaults to 60 seconds. Either this or
`run_every_steps` must be set. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> run_every_steps
						</dt>
						<dd>If specified, calls `should_stop_fn` every
`run_every_steps` steps. Either this or `run_every_secs` must be set. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An early-stopping hook of type `SessionRunHook` that periodically checks
if the given metric shows no decrease over given maximum number of
training steps, and initiates early stopping if true. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>estimator =...
            # Hook to stop training if loss does not decrease in over 100000 steps.
            hook = early_stopping.stop_if_no_decrease_hook(estimator, "loss", 100000)
            train_spec = tf.estimator.TrainSpec(..., hooks=[hook])
            tf.estimator.train_and_evaluate(estimator, train_spec,...) </pre>
</div>
		</div>
	</div>
	<div id="stop_if_no_decrease_hook_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_if_no_decrease_hook_dyn</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> metric_name, <span title="System.object">object</span> max_steps_without_decrease, <span title="System.object">object</span> eval_dir, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> min_steps, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> run_every_secs, <span title="System.object">object</span> run_every_steps)
		</h4>
		<div class="content">Creates hook to stop if metric does not decrease within given max steps. <p></p> Usage example:
Caveat: Current implementation supports early-stopping both training and
evaluation in local mode. In distributed mode, training can be stopped but
evaluation (where it's a separate job) will indefinitely wait for new model
checkpoints to evaluate, so you will need other means to detect and stop it.
Early-stopping evaluation in distributed mode requires changes in
`train_and_evaluate` API and will be addressed in a future revision. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> estimator
						</dt>
						<dd>A <a href="..\..\..\tf\estimator\Estimator.md"><code>tf.estimator.Estimator</code></a> instance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> metric_name
						</dt>
						<dd>`str`, metric to track. "loss", "accuracy", etc. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_steps_without_decrease
						</dt>
						<dd>`int`, maximum number of training steps with no
decrease in the given metric. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> eval_dir
						</dt>
						<dd>If set, directory containing summary files with eval metrics. By
default, `estimator.eval_dir()` will be used. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> min_steps
						</dt>
						<dd>`int`, stop is never requested if global step is less than this
value. Defaults to 0. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> run_every_secs
						</dt>
						<dd>If specified, calls `should_stop_fn` at an interval of
`run_every_secs` seconds. Defaults to 60 seconds. Either this or
`run_every_steps` must be set. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> run_every_steps
						</dt>
						<dd>If specified, calls `should_stop_fn` every
`run_every_steps` steps. Either this or `run_every_secs` must be set. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An early-stopping hook of type `SessionRunHook` that periodically checks
if the given metric shows no decrease over given maximum number of
training steps, and initiates early stopping if true. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>estimator =...
            # Hook to stop training if loss does not decrease in over 100000 steps.
            hook = early_stopping.stop_if_no_decrease_hook(estimator, "loss", 100000)
            train_spec = tf.estimator.TrainSpec(..., hooks=[hook])
            tf.estimator.train_and_evaluate(estimator, train_spec,...) </pre>
</div>
		</div>
	</div>
	<div id="stop_if_no_increase_hook" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_if_no_increase_hook</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> metric_name, <span title="System.object">object</span> max_steps_without_increase, <span title="System.object">object</span> eval_dir, <span title="System.int">int</span> min_steps, <span title="System.int">int</span> run_every_secs, <span title="System.object">object</span> run_every_steps)
		</h4>
		<div class="content">Creates hook to stop if metric does not increase within given max steps. <p></p> Usage example:
Caveat: Current implementation supports early-stopping both training and
evaluation in local mode. In distributed mode, training can be stopped but
evaluation (where it's a separate job) will indefinitely wait for new model
checkpoints to evaluate, so you will need other means to detect and stop it.
Early-stopping evaluation in distributed mode requires changes in
`train_and_evaluate` API and will be addressed in a future revision. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> estimator
						</dt>
						<dd>A <a href="..\..\..\tf\estimator\Estimator.md"><code>tf.estimator.Estimator</code></a> instance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> metric_name
						</dt>
						<dd>`str`, metric to track. "loss", "accuracy", etc. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_steps_without_increase
						</dt>
						<dd>`int`, maximum number of training steps with no
increase in the given metric. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> eval_dir
						</dt>
						<dd>If set, directory containing summary files with eval metrics. By
default, `estimator.eval_dir()` will be used. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_steps
						</dt>
						<dd>`int`, stop is never requested if global step is less than this
value. Defaults to 0. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> run_every_secs
						</dt>
						<dd>If specified, calls `should_stop_fn` at an interval of
`run_every_secs` seconds. Defaults to 60 seconds. Either this or
`run_every_steps` must be set. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> run_every_steps
						</dt>
						<dd>If specified, calls `should_stop_fn` every
`run_every_steps` steps. Either this or `run_every_secs` must be set. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An early-stopping hook of type `SessionRunHook` that periodically checks
if the given metric shows no increase over given maximum number of
training steps, and initiates early stopping if true. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>estimator =...
            # Hook to stop training if accuracy does not increase in over 100000 steps.
            hook = early_stopping.stop_if_no_increase_hook(estimator, "accuracy", 100000)
            train_spec = tf.estimator.TrainSpec(..., hooks=[hook])
            tf.estimator.train_and_evaluate(estimator, train_spec,...) </pre>
</div>
		</div>
	</div>
	<div id="stop_if_no_increase_hook_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_if_no_increase_hook_dyn</strong>(<span title="System.object">object</span> estimator, <span title="System.object">object</span> metric_name, <span title="System.object">object</span> max_steps_without_increase, <span title="System.object">object</span> eval_dir, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> min_steps, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> run_every_secs, <span title="System.object">object</span> run_every_steps)
		</h4>
		<div class="content">Creates hook to stop if metric does not increase within given max steps. <p></p> Usage example:
Caveat: Current implementation supports early-stopping both training and
evaluation in local mode. In distributed mode, training can be stopped but
evaluation (where it's a separate job) will indefinitely wait for new model
checkpoints to evaluate, so you will need other means to detect and stop it.
Early-stopping evaluation in distributed mode requires changes in
`train_and_evaluate` API and will be addressed in a future revision. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> estimator
						</dt>
						<dd>A <a href="..\..\..\tf\estimator\Estimator.md"><code>tf.estimator.Estimator</code></a> instance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> metric_name
						</dt>
						<dd>`str`, metric to track. "loss", "accuracy", etc. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_steps_without_increase
						</dt>
						<dd>`int`, maximum number of training steps with no
increase in the given metric. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> eval_dir
						</dt>
						<dd>If set, directory containing summary files with eval metrics. By
default, `estimator.eval_dir()` will be used. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> min_steps
						</dt>
						<dd>`int`, stop is never requested if global step is less than this
value. Defaults to 0. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> run_every_secs
						</dt>
						<dd>If specified, calls `should_stop_fn` at an interval of
`run_every_secs` seconds. Defaults to 60 seconds. Either this or
`run_every_steps` must be set. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> run_every_steps
						</dt>
						<dd>If specified, calls `should_stop_fn` every
`run_every_steps` steps. Either this or `run_every_secs` must be set. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An early-stopping hook of type `SessionRunHook` that periodically checks
if the given metric shows no increase over given maximum number of
training steps, and initiates early stopping if true. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>estimator =...
            # Hook to stop training if accuracy does not increase in over 100000 steps.
            hook = early_stopping.stop_if_no_increase_hook(estimator, "accuracy", 100000)
            train_spec = tf.estimator.TrainSpec(..., hooks=[hook])
            tf.estimator.train_and_evaluate(estimator, train_spec,...) </pre>
</div>
		</div>
	</div>
	
	<h3 class="section">Public properties</h3>

	<div id="build_raw_supervised_input_receiver_fn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>build_raw_supervised_input_receiver_fn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="call_logit_fn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>call_logit_fn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="dnn_logit_fn_builder_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>dnn_logit_fn_builder_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="linear_logit_fn_builder_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>linear_logit_fn_builder_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="make_early_stopping_hook_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>make_early_stopping_hook_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="make_stop_at_checkpoint_step_hook_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>make_stop_at_checkpoint_step_hook_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="stop_if_higher_hook_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>stop_if_higher_hook_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="stop_if_lower_hook_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>stop_if_lower_hook_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="stop_if_no_decrease_hook_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>stop_if_no_decrease_hook_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="stop_if_no_increase_hook_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>stop_if_no_increase_hook_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>