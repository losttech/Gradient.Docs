<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>tf.keras.backend - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow/AggregationMethod.htm">AggregationMethod</a>
        </li>
				<li>
            <a href="../tensorflow/ConditionalAccumulator.htm">ConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/ConditionalAccumulatorBase.htm">ConditionalAccumulatorBase</a>
        </li>
				<li>
            <a href="../tensorflow/constant_initializer.htm">constant_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/CriticalSection.htm">CriticalSection</a>
        </li>
				<li>
            <a href="../tensorflow/DeviceSpec.htm">DeviceSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Dimension.htm">Dimension</a>
        </li>
				<li>
            <a href="../tensorflow/DType.htm">DType</a>
        </li>
				<li>
            <a href="../tensorflow/FIFOQueue.htm">FIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLenFeature.htm">FixedLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLengthRecordReader.htm">FixedLengthRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLenSequenceFeature.htm">FixedLenSequenceFeature</a>
        </li>
				<li>
            <a href="../tensorflow/glorot_normal_initializer.htm">glorot_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/glorot_uniform_initializer.htm">glorot_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/GradientTape.htm">GradientTape</a>
        </li>
				<li>
            <a href="../tensorflow/Graph.htm">Graph</a>
        </li>
				<li>
            <a href="../tensorflow/Graph._ControlDependenciesController.htm">Graph._ControlDependenciesController</a>
        </li>
				<li>
            <a href="../tensorflow/Graph.I_ControlDependenciesController.htm">Graph.I_ControlDependenciesController</a>
        </li>
				<li>
            <a href="../tensorflow/GraphKeys.htm">GraphKeys</a>
        </li>
				<li>
            <a href="../tensorflow/HeadingAxes.htm">HeadingAxes</a>
        </li>
				<li>
            <a href="../tensorflow/IAggregationMethod.htm">IAggregationMethod</a>
        </li>
				<li>
            <a href="../tensorflow/IConditionalAccumulator.htm">IConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/IConditionalAccumulatorBase.htm">IConditionalAccumulatorBase</a>
        </li>
				<li>
            <a href="../tensorflow/Iconstant_initializer.htm">Iconstant_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/ICriticalSection.htm">ICriticalSection</a>
        </li>
				<li>
            <a href="../tensorflow/IdentityReader.htm">IdentityReader</a>
        </li>
				<li>
            <a href="../tensorflow/IDeviceSpec.htm">IDeviceSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IDimension.htm">IDimension</a>
        </li>
				<li>
            <a href="../tensorflow/IDType.htm">IDType</a>
        </li>
				<li>
            <a href="../tensorflow/IFIFOQueue.htm">IFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLenFeature.htm">IFixedLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLengthRecordReader.htm">IFixedLengthRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLenSequenceFeature.htm">IFixedLenSequenceFeature</a>
        </li>
				<li>
            <a href="../tensorflow/Iglorot_normal_initializer.htm">Iglorot_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Iglorot_uniform_initializer.htm">Iglorot_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IGradientTape.htm">IGradientTape</a>
        </li>
				<li>
            <a href="../tensorflow/IGraph.htm">IGraph</a>
        </li>
				<li>
            <a href="../tensorflow/IGraphKeys.htm">IGraphKeys</a>
        </li>
				<li>
            <a href="../tensorflow/IIdentityReader.htm">IIdentityReader</a>
        </li>
				<li>
            <a href="../tensorflow/IIndexedSlices.htm">IIndexedSlices</a>
        </li>
				<li>
            <a href="../tensorflow/IIndexedSlicesSpec.htm">IIndexedSlicesSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IInteractiveSession.htm">IInteractiveSession</a>
        </li>
				<li>
            <a href="../tensorflow/ILazyLoader.htm">ILazyLoader</a>
        </li>
				<li>
            <a href="../tensorflow/ILMDBReader.htm">ILMDBReader</a>
        </li>
				<li>
            <a href="../tensorflow/IModule.htm">IModule</a>
        </li>
				<li>
            <a href="../tensorflow/Iname_scope.htm">Iname_scope</a>
        </li>
				<li>
            <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a>
        </li>
				<li>
            <a href="../tensorflow/IndexedSlicesSpec.htm">IndexedSlicesSpec</a>
        </li>
				<li>
            <a href="../tensorflow/InteractiveSession.htm">InteractiveSession</a>
        </li>
				<li>
            <a href="../tensorflow/Iones_initializer.htm">Iones_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IOperation.htm">IOperation</a>
        </li>
				<li>
            <a href="../tensorflow/IOpError.htm">IOpError</a>
        </li>
				<li>
            <a href="../tensorflow/IOptionalSpec.htm">IOptionalSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Iorthogonal_initializer.htm">Iorthogonal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IPaddingFIFOQueue.htm">IPaddingFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IPriorityQueue.htm">IPriorityQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IQueueBase.htm">IQueueBase</a>
        </li>
				<li>
            <a href="../tensorflow/IRaggedTensor.htm">IRaggedTensor</a>
        </li>
				<li>
            <a href="../tensorflow/IRaggedTensorSpec.htm">IRaggedTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Irandom_normal_initializer.htm">Irandom_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Irandom_uniform_initializer.htm">Irandom_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IRandomShuffleQueue.htm">IRandomShuffleQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IReaderBase.htm">IReaderBase</a>
        </li>
				<li>
            <a href="../tensorflow/IRegisterGradient.htm">IRegisterGradient</a>
        </li>
				<li>
            <a href="../tensorflow/ISession.htm">ISession</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseConditionalAccumulator.htm">ISparseConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseFeature.htm">ISparseFeature</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensor.htm">ISparseTensor</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensorSpec.htm">ISparseTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensorValue.htm">ISparseTensorValue</a>
        </li>
				<li>
            <a href="../tensorflow/ITensor.htm">ITensor</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorArray.htm">ITensorArray</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorArraySpec.htm">ITensorArraySpec</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorShape.htm">ITensorShape</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorSpec.htm">ITensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/ITextLineReader.htm">ITextLineReader</a>
        </li>
				<li>
            <a href="../tensorflow/ITFRecordReader.htm">ITFRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/Itruncated_normal_initializer.htm">Itruncated_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/ITypeSpec.htm">ITypeSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IUnconnectedGradients.htm">IUnconnectedGradients</a>
        </li>
				<li>
            <a href="../tensorflow/Iuniform_unit_scaling_initializer.htm">Iuniform_unit_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IVariable.htm">IVariable</a>
        </li>
				<li>
            <a href="../tensorflow/Ivariable_scope.htm">Ivariable_scope</a>
        </li>
				<li>
            <a href="../tensorflow/IVariableScope.htm">IVariableScope</a>
        </li>
				<li>
            <a href="../tensorflow/Ivariance_scaling_initializer.htm">Ivariance_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IVarLenFeature.htm">IVarLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/IWholeFileReader.htm">IWholeFileReader</a>
        </li>
				<li>
            <a href="../tensorflow/Izeros_initializer.htm">Izeros_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/LazyLoader.htm">LazyLoader</a>
        </li>
				<li>
            <a href="../tensorflow/LMDBReader.htm">LMDBReader</a>
        </li>
				<li>
            <a href="../tensorflow/Module.htm">Module</a>
        </li>
				<li>
            <a href="../tensorflow/name_scope.htm">name_scope</a>
        </li>
				<li>
            <a href="../tensorflow/ones_initializer.htm">ones_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Operation.htm">Operation</a>
        </li>
				<li>
            <a href="../tensorflow/Operation._InputList.htm">Operation._InputList</a>
        </li>
				<li>
            <a href="../tensorflow/Operation.I_InputList.htm">Operation.I_InputList</a>
        </li>
				<li>
            <a href="../tensorflow/OpError.htm">OpError</a>
        </li>
				<li>
            <a href="../tensorflow/OptionalSpec.htm">OptionalSpec</a>
        </li>
				<li>
            <a href="../tensorflow/orthogonal_initializer.htm">orthogonal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/PaddingFIFOQueue.htm">PaddingFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/PriorityQueue.htm">PriorityQueue</a>
        </li>
				<li>
            <a href="../tensorflow/QueueBase.htm">QueueBase</a>
        </li>
				<li>
            <a href="../tensorflow/RaggedTensor.htm">RaggedTensor</a>
        </li>
				<li>
            <a href="../tensorflow/RaggedTensorSpec.htm">RaggedTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/random_normal_initializer.htm">random_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/random_uniform_initializer.htm">random_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/RandomShuffleQueue.htm">RandomShuffleQueue</a>
        </li>
				<li>
            <a href="../tensorflow/ReaderBase.htm">ReaderBase</a>
        </li>
				<li>
            <a href="../tensorflow/RegisterGradient.htm">RegisterGradient</a>
        </li>
				<li>
            <a href="../tensorflow/Session.htm">Session</a>
        </li>
				<li>
            <a href="../tensorflow/SparseConditionalAccumulator.htm">SparseConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/SparseFeature.htm">SparseFeature</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensor.htm">SparseTensor</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensorSpec.htm">SparseTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensorValue.htm">SparseTensorValue</a>
        </li>
				<li>
            <a href="../tensorflow/Tensor.htm">Tensor</a>
        </li>
				<li>
            <a href="../tensorflow/Tensor`1.htm">Tensor&lt;T&gt;</a>
        </li>
				<li>
            <a href="../tensorflow/TensorArray.htm">TensorArray</a>
        </li>
				<li>
            <a href="../tensorflow/TensorArraySpec.htm">TensorArraySpec</a>
        </li>
				<li>
            <a href="../tensorflow/TensorDimension.htm">TensorDimension</a>
        </li>
				<li>
            <a href="../tensorflow/TensorDimensionSlice.htm">TensorDimensionSlice</a>
        </li>
				<li>
            <a href="../tensorflow/TensorShape.htm">TensorShape</a>
        </li>
				<li>
            <a href="../tensorflow/TensorSpec.htm">TensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/TextLineReader.htm">TextLineReader</a>
        </li>
				<li>
            <a href="../tensorflow/tf.htm">tf</a>
        </li>
				<li>
            <a href="../tensorflow/tf.audio.htm">tf.audio</a>
        </li>
				<li>
            <a href="../tensorflow/tf.autograph.htm">tf.autograph</a>
        </li>
				<li>
            <a href="../tensorflow/tf.autograph.experimental.htm">tf.autograph.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.bitwise.htm">tf.bitwise</a>
        </li>
				<li>
            <a href="../tensorflow/tf.compat.htm">tf.compat</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.htm">tf.config</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.experimental.htm">tf.config.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.optimizer.htm">tf.config.optimizer</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.threading.htm">tf.config.threading</a>
        </li>
				<li>
            <a href="../tensorflow/tf.data.htm">tf.data</a>
        </li>
				<li>
            <a href="../tensorflow/tf.data.experimental.htm">tf.data.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.debugging.htm">tf.debugging</a>
        </li>
				<li>
            <a href="../tensorflow/tf.distribute.htm">tf.distribute</a>
        </li>
				<li>
            <a href="../tensorflow/tf.distributions.htm">tf.distributions</a>
        </li>
				<li>
            <a href="../tensorflow/tf.errors.htm">tf.errors</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.htm">tf.estimator</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.experimental.htm">tf.estimator.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.export.htm">tf.estimator.export</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.inputs.htm">tf.estimator.inputs</a>
        </li>
				<li>
            <a href="../tensorflow/tf.experimental.htm">tf.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.feature_column.htm">tf.feature_column</a>
        </li>
				<li>
            <a href="../tensorflow/tf.gfile.htm">tf.gfile</a>
        </li>
				<li>
            <a href="../tensorflow/tf.graph_util.htm">tf.graph_util</a>
        </li>
				<li>
            <a href="../tensorflow/tf.image.htm">tf.image</a>
        </li>
				<li>
            <a href="../tensorflow/tf.initializers.htm">tf.initializers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.io.htm">tf.io</a>
        </li>
				<li>
            <a href="../tensorflow/tf.io.gfile.htm">tf.io.gfile</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.htm">tf.keras</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.activations.htm">tf.keras.activations</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.htm">tf.keras.applications</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.densenet.htm">tf.keras.applications.densenet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.imagenet_utils.htm">tf.keras.applications.imagenet_utils</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.inception_resnet_v2.htm">tf.keras.applications.inception_resnet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.inception_v3.htm">tf.keras.applications.inception_v3</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.mobilenet.htm">tf.keras.applications.mobilenet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.mobilenet_v2.htm">tf.keras.applications.mobilenet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.nasnet.htm">tf.keras.applications.nasnet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.resnet.htm">tf.keras.applications.resnet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.resnet_v2.htm">tf.keras.applications.resnet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.vgg16.htm">tf.keras.applications.vgg16</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.vgg19.htm">tf.keras.applications.vgg19</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.xception.htm">tf.keras.applications.xception</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.backend.htm" class="current">tf.keras.backend</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.constraints.htm">tf.keras.constraints</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.htm">tf.keras.datasets</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.boston_housing.htm">tf.keras.datasets.boston_housing</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.cifar10.htm">tf.keras.datasets.cifar10</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.cifar100.htm">tf.keras.datasets.cifar100</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.fashion_mnist.htm">tf.keras.datasets.fashion_mnist</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.imdb.htm">tf.keras.datasets.imdb</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.mnist.htm">tf.keras.datasets.mnist</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.reuters.htm">tf.keras.datasets.reuters</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.estimator.htm">tf.keras.estimator</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.experimental.htm">tf.keras.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.initializers.htm">tf.keras.initializers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.layers.htm">tf.keras.layers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.losses.htm">tf.keras.losses</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.metrics.htm">tf.keras.metrics</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.mixed_precision.htm">tf.keras.mixed_precision</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.mixed_precision.experimental.htm">tf.keras.mixed_precision.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.models.htm">tf.keras.models</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.optimizers.htm">tf.keras.optimizers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.optimizers.schedules.htm">tf.keras.optimizers.schedules</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.preprocessing.htm">tf.keras.preprocessing</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.preprocessing.image.htm">tf.keras.preprocessing.image</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.regularizers.htm">tf.keras.regularizers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.utils.htm">tf.keras.utils</a>
        </li>
				<li>
            <a href="../tensorflow/tf.layers.htm">tf.layers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.layers.experimental.htm">tf.layers.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.linalg.htm">tf.linalg</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.htm">tf.lite</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.htm">tf.lite.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.htm">tf.lite.experimental.microfrontend</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.python.htm">tf.lite.experimental.microfrontend.python</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.python.ops.htm">tf.lite.experimental.microfrontend.python.ops</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.nn.htm">tf.lite.experimental.nn</a>
        </li>
				<li>
            <a href="../tensorflow/tf.logging.htm">tf.logging</a>
        </li>
				<li>
            <a href="../tensorflow/tf.losses.htm">tf.losses</a>
        </li>
				<li>
            <a href="../tensorflow/tf.math.htm">tf.math</a>
        </li>
				<li>
            <a href="../tensorflow/tf.metrics.htm">tf.metrics</a>
        </li>
				<li>
            <a href="../tensorflow/tf.nest.htm">tf.nest</a>
        </li>
				<li>
            <a href="../tensorflow/tf.nn.htm">tf.nn</a>
        </li>
				<li>
            <a href="../tensorflow/tf.profiler.htm">tf.profiler</a>
        </li>
				<li>
            <a href="../tensorflow/tf.quantization.htm">tf.quantization</a>
        </li>
				<li>
            <a href="../tensorflow/tf.ragged.htm">tf.ragged</a>
        </li>
				<li>
            <a href="../tensorflow/tf.random.htm">tf.random</a>
        </li>
				<li>
            <a href="../tensorflow/tf.random.experimental.htm">tf.random.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.resource_loader.htm">tf.resource_loader</a>
        </li>
				<li>
            <a href="../tensorflow/tf.saved_model.htm">tf.saved_model</a>
        </li>
				<li>
            <a href="../tensorflow/tf.saved_model.main_op.htm">tf.saved_model.main_op</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sets.htm">tf.sets</a>
        </li>
				<li>
            <a href="../tensorflow/tf.signal.htm">tf.signal</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sparse.htm">tf.sparse</a>
        </li>
				<li>
            <a href="../tensorflow/tf.strings.htm">tf.strings</a>
        </li>
				<li>
            <a href="../tensorflow/tf.summary.htm">tf.summary</a>
        </li>
				<li>
            <a href="../tensorflow/tf.summary.experimental.htm">tf.summary.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sysconfig.htm">tf.sysconfig</a>
        </li>
				<li>
            <a href="../tensorflow/tf.test.htm">tf.test</a>
        </li>
				<li>
            <a href="../tensorflow/tf.tpu.htm">tf.tpu</a>
        </li>
				<li>
            <a href="../tensorflow/tf.tpu.experimental.htm">tf.tpu.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.train.htm">tf.train</a>
        </li>
				<li>
            <a href="../tensorflow/tf.train.experimental.htm">tf.train.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.user_ops.htm">tf.user_ops</a>
        </li>
				<li>
            <a href="../tensorflow/tf.xla.htm">tf.xla</a>
        </li>
				<li>
            <a href="../tensorflow/tf.xla.experimental.htm">tf.xla.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/TFRecordReader.htm">TFRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/truncated_normal_initializer.htm">truncated_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/TypeSpec.htm">TypeSpec</a>
        </li>
				<li>
            <a href="../tensorflow/UnconnectedGradients.htm">UnconnectedGradients</a>
        </li>
				<li>
            <a href="../tensorflow/uniform_unit_scaling_initializer.htm">uniform_unit_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Variable.htm">Variable</a>
        </li>
				<li>
            <a href="../tensorflow/variable_scope.htm">variable_scope</a>
        </li>
				<li>
            <a href="../tensorflow/VariableAggregation.htm">VariableAggregation</a>
        </li>
				<li>
            <a href="../tensorflow/VariableScope.htm">VariableScope</a>
        </li>
				<li>
            <a href="../tensorflow/VariableSynchronization.htm">VariableSynchronization</a>
        </li>
				<li>
            <a href="../tensorflow/variance_scaling_initializer.htm">variance_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/VarLenFeature.htm">VarLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/WholeFileReader.htm">WholeFileReader</a>
        </li>
				<li>
            <a href="../tensorflow/zeros_initializer.htm">zeros_initializer</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> tf.keras.backend</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow</p>
		</header>
    <div class="sub-header">
		
		
			<h3 class="section">Methods</h3>
			<ul>
				<li><a href="../tensorflow/tf.keras.backend.htm#abs">abs</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#abs_dyn">abs_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#all">all</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#all">all</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#all">all</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#all_dyn">all_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#any">any</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#any">any</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#any">any</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#any">any</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#any">any</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#any_dyn">any_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#arange">arange</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#arange_dyn">arange_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#argmax">argmax</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#argmax_dyn">argmax_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#argmin">argmin</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#argmin_dyn">argmin_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#backend_">backend_</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#backend__dyn">backend__dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot">batch_dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot_dyn">batch_dot_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_flatten">batch_flatten</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_flatten_dyn">batch_flatten_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_get_value">batch_get_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_get_value_dyn">batch_get_value_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization">batch_normalization</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization_dyn">batch_normalization_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_set_value">batch_set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_set_value_dyn">batch_set_value_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#bias_add">bias_add</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#bias_add_dyn">bias_add_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy">binary_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy">binary_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy">binary_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy">binary_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy">binary_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy">binary_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy">binary_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy">binary_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy">binary_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy">binary_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy_dyn">binary_crossentropy_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cast">cast</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cast">cast</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cast_dyn">cast_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cast_to_floatx">cast_to_floatx</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cast_to_floatx">cast_to_floatx</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cast_to_floatx">cast_to_floatx</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cast_to_floatx_dyn">cast_to_floatx_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#categorical_crossentropy">categorical_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#categorical_crossentropy">categorical_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#categorical_crossentropy">categorical_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#categorical_crossentropy">categorical_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#categorical_crossentropy">categorical_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#categorical_crossentropy_dyn">categorical_crossentropy_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clear_session">clear_session</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clear_session_dyn">clear_session_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip">clip</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip_dyn">clip_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#concatenate">concatenate</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#concatenate">concatenate</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#concatenate_dyn">concatenate_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#constant">constant</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#constant">constant</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#constant">constant</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv1d">conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv1d">conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv1d_dyn">conv1d_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d">conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_dyn">conv2d_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose">conv2d_transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose_dyn">conv2d_transpose_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv3d">conv3d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv3d_dyn">conv3d_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cos">cos</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cos_dyn">cos_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#count_params">count_params</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost">ctc_batch_cost</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost_dyn">ctc_batch_cost_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_decode">ctc_decode</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_decode">ctc_decode</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_decode_dyn">ctc_decode_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_label_dense_to_sparse">ctc_label_dense_to_sparse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_label_dense_to_sparse">ctc_label_dense_to_sparse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_label_dense_to_sparse">ctc_label_dense_to_sparse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_label_dense_to_sparse">ctc_label_dense_to_sparse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_label_dense_to_sparse">ctc_label_dense_to_sparse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_label_dense_to_sparse">ctc_label_dense_to_sparse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_label_dense_to_sparse">ctc_label_dense_to_sparse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_label_dense_to_sparse">ctc_label_dense_to_sparse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_label_dense_to_sparse_dyn">ctc_label_dense_to_sparse_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cumprod">cumprod</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cumprod_dyn">cumprod_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cumsum">cumsum</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cumsum_dyn">cumsum_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dot">dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dot">dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dot">dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dot">dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dot">dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dot">dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dot">dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dot">dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dot">dot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dropout">dropout</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dropout_dyn">dropout_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dtype">dtype</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dtype">dtype</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dtype_dyn">dtype_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#elu">elu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#elu">elu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#elu">elu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#epsilon">epsilon</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#epsilon_dyn">epsilon_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#equal">equal</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#equal_dyn">equal_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#eval">eval</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#exp">exp</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#exp_dyn">exp_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#expand_dims">expand_dims</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#expand_dims">expand_dims</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#expand_dims">expand_dims</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#expand_dims">expand_dims</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#expand_dims_dyn">expand_dims_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#eye">eye</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#eye_dyn">eye_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#flatten">flatten</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#flatten">flatten</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#flatten">flatten</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#floatx">floatx</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#floatx_dyn">floatx_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#foldl">foldl</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#foldr">foldr</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#foldr_dyn">foldr_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function">function</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function_dyn">function_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#get_session">get_session</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#get_session">get_session</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#get_session_dyn">get_session_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#get_uid">get_uid</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#get_uid_dyn">get_uid_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#get_value">get_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#get_value">get_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#gradients">gradients</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#gradients">gradients</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#gradients_dyn">gradients_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#greater">greater</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#greater_dyn">greater_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#greater_equal">greater_equal</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#greater_equal_dyn">greater_equal_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#image_data_format">image_data_format</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#image_data_format_dyn">image_data_format_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_test_phase">in_test_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_test_phase_dyn">in_test_phase_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_top_k">in_top_k</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_top_k_dyn">in_top_k_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase">in_train_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase_dyn">in_train_phase_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#int_shape">int_shape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#int_shape">int_shape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#int_shape">int_shape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#int_shape_dyn">int_shape_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#is_sparse">is_sparse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#is_sparse">is_sparse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#l2_normalize">l2_normalize</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#l2_normalize_dyn">l2_normalize_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#learning_phase">learning_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#learning_phase_dyn">learning_phase_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#learning_phase_scope">learning_phase_scope</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#learning_phase_scope">learning_phase_scope</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#learning_phase_scope_dyn">learning_phase_scope_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#less">less</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#less">less</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#less_dyn">less_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#less_equal">less_equal</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#less_equal_dyn">less_equal_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d">local_conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d">local_conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d">local_conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d">local_conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d">local_conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d">local_conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d">local_conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d">local_conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d">local_conv1d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d_dyn">local_conv1d_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d">local_conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d">local_conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d">local_conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d">local_conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d">local_conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d">local_conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d">local_conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d">local_conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d">local_conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d_dyn">local_conv2d_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#log">log</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#log_dyn">log_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#manual_variable_initialization">manual_variable_initialization</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#manual_variable_initialization_dyn">manual_variable_initialization_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#map_fn">map_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#map_fn_dyn">map_fn_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#max">max</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#max">max</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#max">max</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#max">max</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#max_dyn">max_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#maximum">maximum</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#maximum_dyn">maximum_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#mean">mean</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#mean">mean</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#mean">mean</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#mean">mean</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#mean_dyn">mean_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#min">min</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#min_dyn">min_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#minimum">minimum</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#minimum_dyn">minimum_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#moving_average_update">moving_average_update</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#moving_average_update_dyn">moving_average_update_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#name_scope">name_scope</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ndim">ndim</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ndim">ndim</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ndim">ndim</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ndim_dyn">ndim_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#normalize_batch_in_training">normalize_batch_in_training</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#normalize_batch_in_training_dyn">normalize_batch_in_training_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#not_equal">not_equal</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#not_equal_dyn">not_equal_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#one_hot">one_hot</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#one_hot_dyn">one_hot_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ones">ones</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ones_dyn">ones_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ones_like">ones_like</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ones_like">ones_like</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#permute_dimensions">permute_dimensions</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#permute_dimensions">permute_dimensions</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#permute_dimensions_dyn">permute_dimensions_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#placeholder">placeholder</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#placeholder">placeholder</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#placeholder">placeholder</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#placeholder">placeholder</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#placeholder">placeholder</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#placeholder">placeholder</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#placeholder_dyn">placeholder_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#pool2d">pool2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#pool2d_dyn">pool2d_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#pool3d">pool3d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#pool3d_dyn">pool3d_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#pow">pow</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#pow">pow</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#pow_dyn">pow_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#print_tensor">print_tensor</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#print_tensor_dyn">print_tensor_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#prod">prod</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#prod_dyn">prod_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_binomial">random_binomial</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_binomial_dyn">random_binomial_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_normal">random_normal</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_normal">random_normal</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_normal_dyn">random_normal_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_normal_variable">random_normal_variable</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_normal_variable">random_normal_variable</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_normal_variable">random_normal_variable</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_normal_variable">random_normal_variable</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_normal_variable_dyn">random_normal_variable_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_uniform">random_uniform</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_uniform_dyn">random_uniform_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_uniform_variable">random_uniform_variable</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_uniform_variable_dyn">random_uniform_variable_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu">relu</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#repeat">repeat</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#repeat">repeat</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#repeat_dyn">repeat_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#repeat_elements">repeat_elements</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#repeat_elements">repeat_elements</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#repeat_elements_dyn">repeat_elements_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reset_uids">reset_uids</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reset_uids_dyn">reset_uids_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape">reshape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape_dyn">reshape_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#resize_images">resize_images</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#resize_images">resize_images</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#resize_images_dyn">resize_images_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#resize_volumes">resize_volumes</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#resize_volumes">resize_volumes</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#resize_volumes_dyn">resize_volumes_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reverse">reverse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reverse">reverse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reverse">reverse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reverse">reverse</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reverse_dyn">reverse_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn">rnn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn_dyn">rnn_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#round">round</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#round_dyn">round_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#separable_conv2d">separable_conv2d</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#separable_conv2d_dyn">separable_conv2d_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_epsilon">set_epsilon</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_epsilon_dyn">set_epsilon_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_floatx">set_floatx</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_floatx_dyn">set_floatx_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_image_data_format">set_image_data_format</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_image_data_format_dyn">set_image_data_format_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_learning_phase">set_learning_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_learning_phase">set_learning_phase</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_learning_phase_dyn">set_learning_phase_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_session">set_session</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_session">set_session</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_session_dyn">set_session_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value">set_value</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value_dyn">set_value_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#shape">shape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#shape">shape</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#shape_dyn">shape_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sigmoid">sigmoid</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sign">sign</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sign_dyn">sign_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sin">sin</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sin_dyn">sin_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#softmax">softmax</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#softplus">softplus</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#softsign">softsign</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sparse_categorical_crossentropy">sparse_categorical_crossentropy</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sparse_categorical_crossentropy_dyn">sparse_categorical_crossentropy_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_2d_padding">spatial_2d_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_2d_padding">spatial_2d_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_2d_padding">spatial_2d_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_2d_padding">spatial_2d_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_2d_padding_dyn">spatial_2d_padding_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_3d_padding">spatial_3d_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_3d_padding">spatial_3d_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_3d_padding">spatial_3d_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_3d_padding">spatial_3d_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_3d_padding_dyn">spatial_3d_padding_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sqrt">sqrt</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sqrt">sqrt</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sqrt_dyn">sqrt_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#square">square</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#square_dyn">square_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#squeeze">squeeze</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#squeeze_dyn">squeeze_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#stack">stack</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#stack_dyn">stack_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#std">std</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#std_dyn">std_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#stop_gradient">stop_gradient</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#stop_gradient">stop_gradient</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#stop_gradient">stop_gradient</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#stop_gradient_dyn">stop_gradient_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sum">sum</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sum">sum</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sum_dyn">sum_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch">switch</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#tanh">tanh</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#tanh_dyn">tanh_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#temporal_padding">temporal_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#temporal_padding">temporal_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#temporal_padding">temporal_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#temporal_padding">temporal_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#temporal_padding">temporal_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#temporal_padding">temporal_padding</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#temporal_padding_dyn">temporal_padding_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#tile">tile</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#tile">tile</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#tile">tile</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#tile_dyn">tile_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#to_dense">to_dense</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#to_dense">to_dense</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#to_dense">to_dense</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#to_dense_dyn">to_dense_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#transpose">transpose</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#transpose_dyn">transpose_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#truncated_normal">truncated_normal</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#truncated_normal_dyn">truncated_normal_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#update">update</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#update">update</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#update_add">update_add</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#update_add_dyn">update_add_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#update_sub">update_sub</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#update_sub_dyn">update_sub_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#var">var</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#var_dyn">var_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#variable">variable</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#variable_dyn">variable_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#zeros">zeros</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#zeros">zeros</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#zeros">zeros</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#zeros_dyn">zeros_dyn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#zeros_like">zeros_like</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#zeros_like">zeros_like</a></li>
			</ul>
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow/tf.keras.backend.htm#abs_fn">abs_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#all_fn">all_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#any_fn">any_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#arange_fn">arange_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#argmax_fn">argmax_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#argmin_fn">argmin_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#backend__fn">backend__fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_dot_fn">batch_dot_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_flatten_fn">batch_flatten_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_get_value_fn">batch_get_value_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_normalization_fn">batch_normalization_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#batch_set_value_fn">batch_set_value_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#bias_add_fn">bias_add_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#binary_crossentropy_fn">binary_crossentropy_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cast_fn">cast_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cast_to_floatx_fn">cast_to_floatx_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#categorical_crossentropy_fn">categorical_crossentropy_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clear_session_fn">clear_session_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#clip_fn">clip_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#concatenate_fn">concatenate_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#constant_fn">constant_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv1d_fn">conv1d_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_fn">conv2d_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv2d_transpose_fn">conv2d_transpose_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#conv3d_fn">conv3d_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cos_fn">cos_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#count_params_fn">count_params_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_batch_cost_fn">ctc_batch_cost_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_decode_fn">ctc_decode_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ctc_label_dense_to_sparse_fn">ctc_label_dense_to_sparse_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cumprod_fn">cumprod_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#cumsum_fn">cumsum_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dot_fn">dot_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dropout_fn">dropout_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#dtype_fn">dtype_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#elu_fn">elu_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#epsilon_fn">epsilon_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#equal_fn">equal_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#eval_fn">eval_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#exp_fn">exp_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#expand_dims_fn">expand_dims_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#eye_fn">eye_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#flatten_fn">flatten_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#floatx_fn">floatx_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#foldl_fn">foldl_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#foldr_fn">foldr_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#function_fn">function_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#gather_fn">gather_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#get_session_fn">get_session_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#get_uid_fn">get_uid_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#get_value_fn">get_value_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#gradients_fn">gradients_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#greater_equal_fn">greater_equal_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#greater_fn">greater_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#hard_sigmoid_fn">hard_sigmoid_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#image_data_format_fn">image_data_format_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_test_phase_fn">in_test_phase_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_top_k_fn">in_top_k_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#in_train_phase_fn">in_train_phase_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#int_shape_fn">int_shape_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#is_sparse_fn">is_sparse_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#l2_normalize_fn">l2_normalize_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#learning_phase_fn">learning_phase_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#learning_phase_scope_fn">learning_phase_scope_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#less_equal_fn">less_equal_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#less_fn">less_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv1d_fn">local_conv1d_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#local_conv2d_fn">local_conv2d_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#log_fn">log_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#manual_variable_initialization_fn">manual_variable_initialization_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#map_fn_fn">map_fn_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#max_fn">max_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#maximum_fn">maximum_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#mean_fn">mean_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#min_fn">min_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#minimum_fn">minimum_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#moving_average_update_fn">moving_average_update_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#name_scope_fn">name_scope_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ndim_fn">ndim_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#normalize_batch_in_training_fn">normalize_batch_in_training_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#not_equal_fn">not_equal_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#one_hot_fn">one_hot_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ones_fn">ones_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#ones_like_fn">ones_like_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#permute_dimensions_fn">permute_dimensions_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#placeholder_fn">placeholder_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#pool2d_fn">pool2d_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#pool3d_fn">pool3d_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#pow_fn">pow_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#print_tensor_fn">print_tensor_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#prod_fn">prod_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_binomial_fn">random_binomial_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_normal_fn">random_normal_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_normal_variable_fn">random_normal_variable_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_uniform_fn">random_uniform_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#random_uniform_variable_fn">random_uniform_variable_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#relu_fn">relu_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#repeat_elements_fn">repeat_elements_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#repeat_fn">repeat_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reset_uids_fn">reset_uids_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reshape_fn">reshape_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#resize_images_fn">resize_images_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#resize_volumes_fn">resize_volumes_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#reverse_fn">reverse_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#rnn_fn">rnn_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#round_fn">round_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#separable_conv2d_fn">separable_conv2d_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_epsilon__fn">set_epsilon__fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_floatx__fn">set_floatx__fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_image_data_format__fn">set_image_data_format__fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_learning_phase__fn">set_learning_phase__fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_session_fn">set_session_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#set_value_fn">set_value_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#shape_fn">shape_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sigmoid_fn">sigmoid_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sign_fn">sign_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sin_fn">sin_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#softmax_fn">softmax_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#softplus_fn">softplus_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#softsign_fn">softsign_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sparse_categorical_crossentropy_fn">sparse_categorical_crossentropy_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_2d_padding_fn">spatial_2d_padding_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#spatial_3d_padding_fn">spatial_3d_padding_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sqrt_fn">sqrt_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#square_fn">square_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#squeeze_fn">squeeze_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#stack_fn">stack_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#std_fn">std_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#stop_gradient_fn">stop_gradient_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#sum_fn">sum_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#switch_fn">switch_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#tanh_fn">tanh_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#temporal_padding_fn">temporal_padding_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#tile_fn">tile_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#to_dense_fn">to_dense_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#transpose_fn">transpose_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#truncated_normal_fn">truncated_normal_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#update_add_fn">update_add_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#update_fn">update_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#update_sub_fn">update_sub_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#var_fn">var_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#variable_fn">variable_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#zeros_fn">zeros_fn</a></li>
				<li><a href="../tensorflow/tf.keras.backend.htm#zeros_like_fn">zeros_like_fn</a></li>
			</ul>
		
	</div>
	
	
	<h3 class="section">Public static methods</h3>

	<div id="abs" class="method">
		<h4>
			<span title="System.object">object</span> <strong>abs</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise absolute value. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="abs_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>abs_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise absolute value. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="all" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>all</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Bitwise reduction (logical AND). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>whether the drop or broadcast the reduction axes. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A uint8 tensor (0s and 1s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="all" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>all</strong>(<span title="System.Collections.Generic.IEnumerator<bool>">IEnumerator&lt;bool&gt;</span> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Bitwise reduction (logical AND). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerator<bool>">IEnumerator&lt;bool&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>whether the drop or broadcast the reduction axes. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A uint8 tensor (0s and 1s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="all" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>all</strong>(<span title="System.Collections.Generic.IEnumerable<Nullable<int>>">IEnumerable&lt;Nullable&lt;int&gt;&gt;</span> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Bitwise reduction (logical AND). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<Nullable<int>>">IEnumerable&lt;Nullable&lt;int&gt;&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>whether the drop or broadcast the reduction axes. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A uint8 tensor (0s and 1s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="all_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>all_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims)
		</h4>
		<div class="content">Bitwise reduction (logical AND). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>whether the drop or broadcast the reduction axes. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A uint8 tensor (0s and 1s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="any" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>any</strong>(<span title="System.object">object</span> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Bitwise reduction (logical OR). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>whether the drop or broadcast the reduction axes. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A uint8 tensor (0s and 1s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="any" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>any</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Bitwise reduction (logical OR). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>whether the drop or broadcast the reduction axes. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A uint8 tensor (0s and 1s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="any" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>any</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Bitwise reduction (logical OR). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>whether the drop or broadcast the reduction axes. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A uint8 tensor (0s and 1s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="any" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>any</strong>(<span title="System.Collections.Generic.IEnumerator<bool>">IEnumerator&lt;bool&gt;</span> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Bitwise reduction (logical OR). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerator<bool>">IEnumerator&lt;bool&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>whether the drop or broadcast the reduction axes. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A uint8 tensor (0s and 1s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="any" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>any</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Bitwise reduction (logical OR). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>whether the drop or broadcast the reduction axes. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A uint8 tensor (0s and 1s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="any_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>any_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims)
		</h4>
		<div class="content">Bitwise reduction (logical OR). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>whether the drop or broadcast the reduction axes. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A uint8 tensor (0s and 1s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="arange" class="method">
		<h4>
			<span title="System.object">object</span> <strong>arange</strong>(<span title="System.object">object</span> start, <span title="System.object">object</span> stop, <span title="System.int">int</span> step, <span title="System.string">string</span> dtype)
		</h4>
		<div class="content">Creates a 1D tensor containing a sequence of integers. <p></p> The function arguments use the same convention as
Theano's arange: if only one argument is provided,
it is in fact the "stop" argument and "start" is 0. <p></p> The default type of the returned tensor is `'int32'` to
match TensorFlow's default. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> start
						</dt>
						<dd>Start value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> stop
						</dt>
						<dd>Stop value. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> step
						</dt>
						<dd>Difference between two successive values. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> dtype
						</dt>
						<dd>Integer dtype to use. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An integer tensor. <p></p> Example:
```python
>>> tf.keras.backend.arange(start=0, stop=10, step=1.5)
<tf.Tensor: id=96, shape=(7,), dtype=float32,
numpy=array([0. , 1.5, 3. , 4.5, 6. , 7.5, 9. ], dtype=float32)> <p></p> ``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="arange_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>arange_dyn</strong>(<span title="System.object">object</span> start, <span title="System.object">object</span> stop, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> step, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dtype)
		</h4>
		<div class="content">Creates a 1D tensor containing a sequence of integers. <p></p> The function arguments use the same convention as
Theano's arange: if only one argument is provided,
it is in fact the "stop" argument and "start" is 0. <p></p> The default type of the returned tensor is `'int32'` to
match TensorFlow's default. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> start
						</dt>
						<dd>Start value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> stop
						</dt>
						<dd>Stop value. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> step
						</dt>
						<dd>Difference between two successive values. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dtype
						</dt>
						<dd>Integer dtype to use. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An integer tensor. <p></p> Example:
```python
>>> tf.keras.backend.arange(start=0, stop=10, step=1.5)
<tf.Tensor: id=96, shape=(7,), dtype=float32,
numpy=array([0. , 1.5, 3. , 4.5, 6. , 7.5, 9. ], dtype=float32)> <p></p> ``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="argmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>argmax</strong>(<span title="System.object">object</span> x, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Returns the index of the maximum value along an axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="argmax_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>argmax_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis)
		</h4>
		<div class="content">Returns the index of the maximum value along an axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="argmin" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>argmin</strong>(<span title="System.object">object</span> x, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Returns the index of the minimum value along an axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="argmin_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>argmin_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis)
		</h4>
		<div class="content">Returns the index of the minimum value along an axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>axis along which to perform the reduction. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="backend_" class="method">
		<h4>
			<span title="System.string">string</span> <strong>backend_</strong>()
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="backend__dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>backend__dyn</strong>()
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> y, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> y, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> y, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> y, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> y, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> y, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> y, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> y, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> y, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> y, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> y, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> y, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_dot</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_dot_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_dot_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y, <span title="System.object">object</span> axes)
		</h4>
		<div class="content">Batchwise dot product. <p></p> `batch_dot` is used to compute dot product of `x` and `y` when
`x` and `y` are data in batch, i.e. in a shape of
`(batch_size, :)`.
`batch_dot` results in a tensor or variable with less dimensions
than the input. If the number of dimensions is reduced to 1,
we use `expand_dims` to make sure that ndim is at least 2. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Keras tensor or variable with `ndim >= 2`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axes
						</dt>
						<dd>list of (or single) int with target dimensions.
The lengths of `axes[0]` and `axes[1]` should be the same. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with shape equal to the concatenation of `x`'s shape
(less the dimension that was summed over) and `y`'s shape
(less the batch dimension and the dimension that was summed over).
If the final rank is 1, we reshape it to `(batch_size, 1)`. <p></p> Examples:
Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
`batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
of `x.dot(y.T)`, although we never have to calculate the off-diagonal
elements. <p></p> Shape inference:
Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
If `axes` is (1, 2), to find the output shape of resultant tensor,
loop through each dimension in `x`'s shape and `y`'s shape: <p></p> * `x.shape[0]` : 100 : append to output shape
* `x.shape[1]` : 20 : do not append to output shape,
dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
* `y.shape[0]` : 100 : do not append to output shape,
always ignore first dimension of `y`
* `y.shape[1]` : 30 : append to output shape
* `y.shape[2]` : 20 : do not append to output shape,
dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
`output_shape` = `(100, 30)` <p></p> ```python
>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_flatten" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>batch_flatten</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x)
		</h4>
		<div class="content">Turn a nD tensor into a 2D tensor with same 0th dimension. <p></p> In other words, it flattens each data samples of a batch. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Examples:
Flattening a 3D tensor to 2D by collapsing the last dimension. <p></p> ```python
>>> from tensorflow.keras import backend as K
>>> x_batch = K.ones(shape=(2, 3, 4, 5))
>>> x_batch_flatten = K.batch_flatten(x_batch)
>>> K.int_shape(x_batch_flatten)
(2, 60)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_flatten_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_flatten_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Turn a nD tensor into a 2D tensor with same 0th dimension. <p></p> In other words, it flattens each data samples of a batch. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. <p></p> Examples:
Flattening a 3D tensor to 2D by collapsing the last dimension. <p></p> ```python
>>> from tensorflow.keras import backend as K
>>> x_batch = K.ones(shape=(2, 3, 4, 5))
>>> x_batch_flatten = K.batch_flatten(x_batch)
>>> K.int_shape(x_batch_flatten)
(2, 60)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_get_value" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_get_value</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> tensors)
		</h4>
		<div class="content">Returns the value of more than one tensor variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> tensors
						</dt>
						<dd>list of ops to run. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A list of Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_get_value_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_get_value_dyn</strong>(<span title="System.object">object</span> tensors)
		</h4>
		<div class="content">Returns the value of more than one tensor variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> tensors
						</dt>
						<dd>list of ops to run. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A list of Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> mean, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> var, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> beta, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <span title="System.int">int</span> axis, <span title="System.double">double</span> epsilon)
		</h4>
		<div class="content">Applies batch normalization on x given mean, var, beta and gamma. <p></p> I.e. returns:
`output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> mean
						</dt>
						<dd>Mean of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> var
						</dt>
						<dd>Variance of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Integer, the axis that should be normalized.
(typically the features axis). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> mean, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> var, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> beta, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <span title="System.int">int</span> axis, <span title="System.double">double</span> epsilon)
		</h4>
		<div class="content">Applies batch normalization on x given mean, var, beta and gamma. <p></p> I.e. returns:
`output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> mean
						</dt>
						<dd>Mean of batch. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> var
						</dt>
						<dd>Variance of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Integer, the axis that should be normalized.
(typically the features axis). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> mean, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> var, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> beta, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <span title="System.int">int</span> axis, <span title="System.double">double</span> epsilon)
		</h4>
		<div class="content">Applies batch normalization on x given mean, var, beta and gamma. <p></p> I.e. returns:
`output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> mean
						</dt>
						<dd>Mean of batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> var
						</dt>
						<dd>Variance of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Integer, the axis that should be normalized.
(typically the features axis). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> mean, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> var, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> beta, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <span title="System.int">int</span> axis, <span title="System.double">double</span> epsilon)
		</h4>
		<div class="content">Applies batch normalization on x given mean, var, beta and gamma. <p></p> I.e. returns:
`output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> mean
						</dt>
						<dd>Mean of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> var
						</dt>
						<dd>Variance of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Integer, the axis that should be normalized.
(typically the features axis). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> mean, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> var, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> beta, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <span title="System.int">int</span> axis, <span title="System.double">double</span> epsilon)
		</h4>
		<div class="content">Applies batch normalization on x given mean, var, beta and gamma. <p></p> I.e. returns:
`output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> mean
						</dt>
						<dd>Mean of batch. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> var
						</dt>
						<dd>Variance of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Integer, the axis that should be normalized.
(typically the features axis). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> mean, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> var, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> beta, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <span title="System.int">int</span> axis, <span title="System.double">double</span> epsilon)
		</h4>
		<div class="content">Applies batch normalization on x given mean, var, beta and gamma. <p></p> I.e. returns:
`output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> mean
						</dt>
						<dd>Mean of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> var
						</dt>
						<dd>Variance of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Integer, the axis that should be normalized.
(typically the features axis). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> mean, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> var, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> beta, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <span title="System.int">int</span> axis, <span title="System.double">double</span> epsilon)
		</h4>
		<div class="content">Applies batch normalization on x given mean, var, beta and gamma. <p></p> I.e. returns:
`output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> mean
						</dt>
						<dd>Mean of batch. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> var
						</dt>
						<dd>Variance of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Integer, the axis that should be normalized.
(typically the features axis). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> mean, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> var, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> beta, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <span title="System.int">int</span> axis, <span title="System.double">double</span> epsilon)
		</h4>
		<div class="content">Applies batch normalization on x given mean, var, beta and gamma. <p></p> I.e. returns:
`output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> mean
						</dt>
						<dd>Mean of batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> var
						</dt>
						<dd>Variance of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Integer, the axis that should be normalized.
(typically the features axis). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> mean, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> var, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> beta, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <span title="System.int">int</span> axis, <span title="System.double">double</span> epsilon)
		</h4>
		<div class="content">Applies batch normalization on x given mean, var, beta and gamma. <p></p> I.e. returns:
`output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> mean
						</dt>
						<dd>Mean of batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> var
						</dt>
						<dd>Variance of batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Integer, the axis that should be normalized.
(typically the features axis). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_normalization_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_normalization_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> mean, <span title="System.object">object</span> var, <span title="System.object">object</span> beta, <span title="System.object">object</span> gamma, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> epsilon)
		</h4>
		<div class="content">Applies batch normalization on x given mean, var, beta and gamma. <p></p> I.e. returns:
`output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>Mean of batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> var
						</dt>
						<dd>Variance of batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>Integer, the axis that should be normalized.
(typically the features axis). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="batch_set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>batch_set_value</strong>(<span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> tuples)
		</h4>
		<div class="content">Sets the values of many tensor variables at once. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> tuples
						</dt>
						<dd>a list of tuples `(tensor, value)`.
`value` should be a Numpy array. 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="batch_set_value_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_set_value_dyn</strong>(<span title="System.object">object</span> tuples)
		</h4>
		<div class="content">Sets the values of many tensor variables at once. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> tuples
						</dt>
						<dd>a list of tuples `(tensor, value)`.
`value` should be a Numpy array. 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<span title="System.object">object</span> <strong>bias_add</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> bias, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Adds a bias vector to a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> bias
						</dt>
						<dd>Bias tensor to add. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add" class="method">
		<h4>
			<span title="System.object">object</span> <strong>bias_add</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> bias, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Adds a bias vector to a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> bias
						</dt>
						<dd>Bias tensor to add. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bias_add_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>bias_add_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> bias, <span title="System.object">object</span> data_format)
		</h4>
		<div class="content">Adds a bias vector to a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> bias
						</dt>
						<dd>Bias tensor to add. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>binary_crossentropy</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>binary_crossentropy</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> output, <span title="System.bool">bool</span> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>binary_crossentropy</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>binary_crossentropy</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> target, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> output, <span title="System.bool">bool</span> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>binary_crossentropy</strong>(<span title="System.object">object</span> target, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> output, <span title="System.bool">bool</span> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>binary_crossentropy</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>binary_crossentropy</strong>(<span title="System.object">object</span> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>binary_crossentropy</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>binary_crossentropy</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> target, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> output, <span title="System.bool">bool</span> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>binary_crossentropy</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> target, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> output, <span title="System.bool">bool</span> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="binary_crossentropy_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>binary_crossentropy_dyn</strong>(<span title="System.object">object</span> target, <span title="System.object">object</span> output, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> from_logits)
		</h4>
		<div class="content">Binary crossentropy between an output tensor and a target tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> target
						</dt>
						<dd>A tensor with the same shape as `output`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output
						</dt>
						<dd>A tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> from_logits
						</dt>
						<dd>Whether `output` is expected to be a logits tensor.
By default, we consider that `output`
encodes a probability distribution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cast" class="method">
		<h4>
			<span title="System.object">object</span> <strong>cast</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../tensorflow/DType.htm">DType</a> dtype)
		</h4>
		<div class="content">Casts a tensor to a different dtype and returns it. <p></p> You can cast a Keras variable but it still returns a Keras tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Keras tensor (or variable). 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, either (`'float16'`, `'float32'`, or `'float64'`). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Keras tensor with dtype `dtype`. <p></p> Examples:
Cast a float32 variable to a float64 tensor <p></p> ```python
>>> import tensorflow as tf
>>> from tensorflow.keras import backend as K
>>> input = K.ones(shape=(1,3))
>>> print(input)
>>> cast_input = K.cast(input, dtype='float64')
>>> print(cast_input) <p></p> <tf.Variable 'Variable:0' shape=(1, 3) dtype=float32,
numpy=array([[1., 1., 1.]], dtype=float32)>
tf.Tensor([[1. 1. 1.]], shape=(1, 3), dtype=float64)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cast" class="method">
		<h4>
			<span title="System.object">object</span> <strong>cast</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <a href="../tensorflow/DType.htm">DType</a> dtype)
		</h4>
		<div class="content">Casts a tensor to a different dtype and returns it. <p></p> You can cast a Keras variable but it still returns a Keras tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Keras tensor (or variable). 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, either (`'float16'`, `'float32'`, or `'float64'`). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Keras tensor with dtype `dtype`. <p></p> Examples:
Cast a float32 variable to a float64 tensor <p></p> ```python
>>> import tensorflow as tf
>>> from tensorflow.keras import backend as K
>>> input = K.ones(shape=(1,3))
>>> print(input)
>>> cast_input = K.cast(input, dtype='float64')
>>> print(cast_input) <p></p> <tf.Variable 'Variable:0' shape=(1, 3) dtype=float32,
numpy=array([[1., 1., 1.]], dtype=float32)>
tf.Tensor([[1. 1. 1.]], shape=(1, 3), dtype=float64)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cast_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>cast_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> dtype)
		</h4>
		<div class="content">Casts a tensor to a different dtype and returns it. <p></p> You can cast a Keras variable but it still returns a Keras tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Keras tensor (or variable). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>String, either (`'float16'`, `'float32'`, or `'float64'`). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Keras tensor with dtype `dtype`. <p></p> Examples:
Cast a float32 variable to a float64 tensor <p></p> ```python
>>> import tensorflow as tf
>>> from tensorflow.keras import backend as K
>>> input = K.ones(shape=(1,3))
>>> print(input)
>>> cast_input = K.cast(input, dtype='float64')
>>> print(cast_input) <p></p> <tf.Variable 'Variable:0' shape=(1, 3) dtype=float32,
numpy=array([[1., 1., 1.]], dtype=float32)>
tf.Tensor([[1. 1. 1.]], shape=(1, 3), dtype=float64)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cast_to_floatx" class="method">
		<h4>
			<a href="../numpy/ndarray.htm">ndarray</a> <strong>cast_to_floatx</strong>(<span title="System.int">int</span> x)
		</h4>
		<div class="content">Cast a Numpy array to the default Keras float type. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.int">int</span></code> x
						</dt>
						<dd>Numpy array. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../numpy/ndarray.htm">ndarray</a></code>
					</dt>
					<dd>The same Numpy array, cast to its new type. <p></p> Example:
```python
>>> from tensorflow.keras import backend as K
>>> K.floatx()
'float32'
>>> arr = numpy.array([1.0, 2.0], dtype='float64')
>>> arr.dtype
dtype('float64')
>>> new_arr = K.cast_to_floatx(arr)
>>> new_arr
array([ 1.,  2.], dtype=float32)
>>> new_arr.dtype
dtype('float32')
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cast_to_floatx" class="method">
		<h4>
			<a href="../numpy/ndarray.htm">ndarray</a> <strong>cast_to_floatx</strong>(<a href="../numpy/ndarray.htm">ndarray</a> x)
		</h4>
		<div class="content">Cast a Numpy array to the default Keras float type. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> x
						</dt>
						<dd>Numpy array. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../numpy/ndarray.htm">ndarray</a></code>
					</dt>
					<dd>The same Numpy array, cast to its new type. <p></p> Example:
```python
>>> from tensorflow.keras import backend as K
>>> K.floatx()
'float32'
>>> arr = numpy.array([1.0, 2.0], dtype='float64')
>>> arr.dtype
dtype('float64')
>>> new_arr = K.cast_to_floatx(arr)
>>> new_arr
array([ 1.,  2.], dtype=float32)
>>> new_arr.dtype
dtype('float32')
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cast_to_floatx" class="method">
		<h4>
			<a href="../numpy/ndarray.htm">ndarray</a> <strong>cast_to_floatx</strong>(<span title="System.double">double</span> x)
		</h4>
		<div class="content">Cast a Numpy array to the default Keras float type. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.double">double</span></code> x
						</dt>
						<dd>Numpy array. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../numpy/ndarray.htm">ndarray</a></code>
					</dt>
					<dd>The same Numpy array, cast to its new type. <p></p> Example:
```python
>>> from tensorflow.keras import backend as K
>>> K.floatx()
'float32'
>>> arr = numpy.array([1.0, 2.0], dtype='float64')
>>> arr.dtype
dtype('float64')
>>> new_arr = K.cast_to_floatx(arr)
>>> new_arr
array([ 1.,  2.], dtype=float32)
>>> new_arr.dtype
dtype('float32')
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cast_to_floatx_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>cast_to_floatx_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Cast a Numpy array to the default Keras float type. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Numpy array. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The same Numpy array, cast to its new type. <p></p> Example:
```python
>>> from tensorflow.keras import backend as K
>>> K.floatx()
'float32'
>>> arr = numpy.array([1.0, 2.0], dtype='float64')
>>> arr.dtype
dtype('float64')
>>> new_arr = K.cast_to_floatx(arr)
>>> new_arr
array([ 1.,  2.], dtype=float32)
>>> new_arr.dtype
dtype('float32')
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="categorical_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>categorical_crossentropy</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Computes the categorical crossentropy loss. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> target
						</dt>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `y_pred` is expected to be a logits tensor. By default,
we assume that `y_pred` encodes a probability distribution. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Categorical crossentropy loss value. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="categorical_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>categorical_crossentropy</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Computes the categorical crossentropy loss. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> target
						</dt>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `y_pred` is expected to be a logits tensor. By default,
we assume that `y_pred` encodes a probability distribution. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Categorical crossentropy loss value. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="categorical_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>categorical_crossentropy</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Computes the categorical crossentropy loss. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> target
						</dt>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `y_pred` is expected to be a logits tensor. By default,
we assume that `y_pred` encodes a probability distribution. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Categorical crossentropy loss value. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="categorical_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>categorical_crossentropy</strong>(<span title="System.object">object</span> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Computes the categorical crossentropy loss. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> target
						</dt>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `y_pred` is expected to be a logits tensor. By default,
we assume that `y_pred` encodes a probability distribution. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Categorical crossentropy loss value. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="categorical_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>categorical_crossentropy</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Computes the categorical crossentropy loss. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target
						</dt>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Whether `y_pred` is expected to be a logits tensor. By default,
we assume that `y_pred` encodes a probability distribution. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Categorical crossentropy loss value. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="categorical_crossentropy_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>categorical_crossentropy_dyn</strong>(<span title="System.object">object</span> target, <span title="System.object">object</span> output, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> from_logits, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis)
		</h4>
		<div class="content">Computes the categorical crossentropy loss. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> target
						</dt>
						<dt>
							<code><span title="System.object">object</span></code> output
						</dt>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> from_logits
						</dt>
						<dd>Whether `y_pred` is expected to be a logits tensor. By default,
we assume that `y_pred` encodes a probability distribution. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Categorical crossentropy loss value. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clear_session" class="method">
		<h4>
			<span title="System.void">void</span> <strong>clear_session</strong>()
		</h4>
		<div class="content">Destroys the current TF graph and creates a new one. <p></p> Useful to avoid clutter from old models / layers. 




		</div>
	</div>
	<div id="clear_session_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>clear_session_dyn</strong>()
		</h4>
		<div class="content">Destroys the current TF graph and creates a new one. <p></p> Useful to avoid clutter from old models / layers. 




		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.double">double</span> min_value, <span title="System.double">double</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> min_value, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> min_value, <span title="System.double">double</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.int">int</span> min_value, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> min_value, <span title="System.double">double</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.int">int</span> min_value, <span title="System.double">double</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.double">double</span> min_value, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.double">double</span> min_value, <span title="System.double">double</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.int">int</span> min_value, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.int">int</span> min_value, <span title="System.double">double</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.double">double</span> min_value, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip" class="method">
		<h4>
			<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> <strong>clip</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> min_value, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="clip_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>clip_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> min_value, <span title="System.object">object</span> max_value)
		</h4>
		<div class="content">Element-wise value clipping. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> min_value
						</dt>
						<dd>Python float or integer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_value
						</dt>
						<dd>Python float or integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="concatenate" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>concatenate</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> tensors, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Concatenates a list of tensors alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> tensors
						</dt>
						<dd>list of tensors to concatenate. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>concatenation axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
>>> b = tf.constant([[10, 20, 30], [40, 50, 60], [70, 80, 90]])
>>> tf.keras.backend.concatenate((a, b), axis=-1)
<tf.Tensor: id=14, shape=(3, 6), dtype=int32, numpy=
array([[ 1,  2,  3, 10, 20, 30],
[ 4,  5,  6, 40, 50, 60],
[ 7,  8,  9, 70, 80, 90]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="concatenate" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>concatenate</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> tensors, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Concatenates a list of tensors alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> tensors
						</dt>
						<dd>list of tensors to concatenate. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>concatenation axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
>>> b = tf.constant([[10, 20, 30], [40, 50, 60], [70, 80, 90]])
>>> tf.keras.backend.concatenate((a, b), axis=-1)
<tf.Tensor: id=14, shape=(3, 6), dtype=int32, numpy=
array([[ 1,  2,  3, 10, 20, 30],
[ 4,  5,  6, 40, 50, 60],
[ 7,  8,  9, 70, 80, 90]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="concatenate_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>concatenate_dyn</strong>(<span title="System.object">object</span> tensors, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis)
		</h4>
		<div class="content">Concatenates a list of tensors alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> tensors
						</dt>
						<dd>list of tensors to concatenate. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>concatenation axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
>>> b = tf.constant([[10, 20, 30], [40, 50, 60], [70, 80, 90]])
>>> tf.keras.backend.concatenate((a, b), axis=-1)
<tf.Tensor: id=14, shape=(3, 6), dtype=int32, numpy=
array([[ 1,  2,  3, 10, 20, 30],
[ 4,  5,  6, 40, 50, 60],
[ 7,  8,  9, 70, 80, 90]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="constant" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>constant</strong>(<span title="System.int">int</span> value, <span title="System.string">string</span> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> shape, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Creates a constant tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.int">int</span></code> value
						</dt>
						<dd>A constant value (or list) 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> dtype
						</dt>
						<dd>The type of the elements of the resulting tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> shape
						</dt>
						<dd>Optional dimensions of resulting tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A Constant Tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="constant" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>constant</strong>(<span title="System.double">double</span> value, <span title="System.string">string</span> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> shape, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Creates a constant tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.double">double</span></code> value
						</dt>
						<dd>A constant value (or list) 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> dtype
						</dt>
						<dd>The type of the elements of the resulting tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> shape
						</dt>
						<dd>Optional dimensions of resulting tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A Constant Tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="constant" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>constant</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> value, <span title="System.string">string</span> dtype, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> shape, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Creates a constant tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> value
						</dt>
						<dd>A constant value (or list) 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> dtype
						</dt>
						<dd>The type of the elements of the resulting tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> shape
						</dt>
						<dd>Optional dimensions of resulting tensor. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name for the tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A Constant Tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv1d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.int">int</span> dilation_rate)
		</h4>
		<div class="content">1D convolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> strides
						</dt>
						<dd>stride integer. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"`, `"causal"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, one of "channels_last", "channels_first". 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>integer dilate rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 1D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv1d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.int">int</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.int">int</span> dilation_rate)
		</h4>
		<div class="content">1D convolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> strides
						</dt>
						<dd>stride integer. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"`, `"causal"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, one of "channels_last", "channels_first". 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> dilation_rate
						</dt>
						<dd>integer dilate rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 1D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv1d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv1d_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> kernel, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <span title="System.object">object</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">1D convolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>stride integer. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>string, `"same"`, `"causal"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>string, one of "channels_last", "channels_first". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>integer dilate rate. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 1D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate)
		</h4>
		<div class="content">2D convolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>`"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate)
		</h4>
		<div class="content">2D convolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>`"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> dilation_rate)
		</h4>
		<div class="content">2D convolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>`"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> dilation_rate
						</dt>
						<dd>tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate)
		</h4>
		<div class="content">2D convolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>`"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> kernel, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <span title="System.object">object</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D convolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>`"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int>">ValueTuple&lt;int&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span> output_shape, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, IEnumerable<object>>">ValueTuple&lt;object, IEnumerable&lt;object&gt;&gt;</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv2d_transpose_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv2d_transpose_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> kernel, <span title="System.object">object</span> output_shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <span title="System.object">object</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D deconvolution (i.e. <p></p> transposed convolution). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>1D int tensor for the output shape. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>Tuple of 2 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of transposed 2D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> dilation_rate)
		</h4>
		<div class="content">3D convolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> dilation_rate
						</dt>
						<dd>tuple of 3 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 3D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="conv3d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>conv3d_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> kernel, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <span title="System.object">object</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">3D convolution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel
						</dt>
						<dd>kernel tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>tuple of 3 integers. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 3D convolution. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cos" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>cos</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Computes cos of x element-wise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cos_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>cos_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Computes cos of x element-wise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="count_params" class="method">
		<h4>
			<span title="System.object">object</span> <strong>count_params</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x)
		</h4>
		<div class="content">Returns the static number of elements in a variable or tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Variable or tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Integer, the number of scalars in `x`. <p></p> Example:
```python
>>> kvar = K.zeros((2,3))
>>> K.count_params(kvar)
6
>>> K.eval(kvar)
array([[ 0.,  0.,  0.],
[ 0.,  0.,  0.]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_true, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_pred, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_length, <a href="../numpy/ndarray.htm">ndarray</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_true, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_pred, <a href="../numpy/ndarray.htm">ndarray</a> input_length, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_true, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_pred, <a href="../numpy/ndarray.htm">ndarray</a> input_length, <a href="../numpy/ndarray.htm">ndarray</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_true, <a href="../numpy/ndarray.htm">ndarray</a> y_pred, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_length, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_true, <a href="../numpy/ndarray.htm">ndarray</a> y_pred, <a href="../numpy/ndarray.htm">ndarray</a> input_length, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_true, <a href="../numpy/ndarray.htm">ndarray</a> y_pred, <a href="../numpy/ndarray.htm">ndarray</a> input_length, <a href="../numpy/ndarray.htm">ndarray</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../numpy/ndarray.htm">ndarray</a> y_true, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_pred, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_length, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../numpy/ndarray.htm">ndarray</a> y_true, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_pred, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_length, <a href="../numpy/ndarray.htm">ndarray</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../numpy/ndarray.htm">ndarray</a> y_true, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_pred, <a href="../numpy/ndarray.htm">ndarray</a> input_length, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../numpy/ndarray.htm">ndarray</a> y_true, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_pred, <a href="../numpy/ndarray.htm">ndarray</a> input_length, <a href="../numpy/ndarray.htm">ndarray</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../numpy/ndarray.htm">ndarray</a> y_true, <a href="../numpy/ndarray.htm">ndarray</a> y_pred, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_length, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../numpy/ndarray.htm">ndarray</a> y_true, <a href="../numpy/ndarray.htm">ndarray</a> y_pred, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_length, <a href="../numpy/ndarray.htm">ndarray</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../numpy/ndarray.htm">ndarray</a> y_true, <a href="../numpy/ndarray.htm">ndarray</a> y_pred, <a href="../numpy/ndarray.htm">ndarray</a> input_length, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_true, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_pred, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_length, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_true, <a href="../numpy/ndarray.htm">ndarray</a> y_pred, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_length, <a href="../numpy/ndarray.htm">ndarray</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ctc_batch_cost</strong>(<a href="../numpy/ndarray.htm">ndarray</a> y_true, <a href="../numpy/ndarray.htm">ndarray</a> y_pred, <a href="../numpy/ndarray.htm">ndarray</a> input_length, <a href="../numpy/ndarray.htm">ndarray</a> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_batch_cost_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_batch_cost_dyn</strong>(<span title="System.object">object</span> y_true, <span title="System.object">object</span> y_pred, <span title="System.object">object</span> input_length, <span title="System.object">object</span> label_length)
		</h4>
		<div class="content">Runs CTC loss algorithm on each batch element. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> y_true
						</dt>
						<dd>tensor `(samples, max_string_length)`
containing the truth labels. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> label_length
						</dt>
						<dd>tensor `(samples, 1)` containing the sequence length for
each batch item in `y_true`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor with shape (samples,1) containing the
CTC loss of each element. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_decode" class="method">
		<h4>
			<span title="System.ValueTuple<IList<Tensor>, object>">ValueTuple&lt;IList&lt;Tensor&gt;, object&gt;</span> <strong>ctc_decode</strong>(<span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span> y_pred, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_length, <span title="System.bool">bool</span> greedy, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths)
		</h4>
		<div class="content">Decodes the output of a softmax. <p></p> Can use either greedy search (also known as best path)
or a constrained dictionary search. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ndarray>">IEnumerable&lt;ndarray&gt;</span></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_length
						</dt>
						<dd>tensor `(samples, )` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> greedy
						</dt>
						<dd>perform much faster best-path search if `true`.
This does not use a dictionary. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>if `greedy` is `false`: a beam search decoder will be used
with a beam of this width. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>if `greedy` is `false`,
how many of the most probable paths will be returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<Tensor>, object>">ValueTuple&lt;IList&lt;Tensor&gt;, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_decode" class="method">
		<h4>
			<span title="System.ValueTuple<IList<Tensor>, object>">ValueTuple&lt;IList&lt;Tensor&gt;, object&gt;</span> <strong>ctc_decode</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y_pred, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_length, <span title="System.bool">bool</span> greedy, <span title="System.int">int</span> beam_width, <span title="System.int">int</span> top_paths)
		</h4>
		<div class="content">Decodes the output of a softmax. <p></p> Can use either greedy search (also known as best path)
or a constrained dictionary search. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_length
						</dt>
						<dd>tensor `(samples, )` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> greedy
						</dt>
						<dd>perform much faster best-path search if `true`.
This does not use a dictionary. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> beam_width
						</dt>
						<dd>if `greedy` is `false`: a beam search decoder will be used
with a beam of this width. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> top_paths
						</dt>
						<dd>if `greedy` is `false`,
how many of the most probable paths will be returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<IList<Tensor>, object>">ValueTuple&lt;IList&lt;Tensor&gt;, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_decode_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_decode_dyn</strong>(<span title="System.object">object</span> y_pred, <span title="System.object">object</span> input_length, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> greedy, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> beam_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> top_paths)
		</h4>
		<div class="content">Decodes the output of a softmax. <p></p> Can use either greedy search (also known as best path)
or a constrained dictionary search. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> y_pred
						</dt>
						<dd>tensor `(samples, time_steps, num_categories)`
containing the prediction, or output of the softmax. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>tensor `(samples, )` containing the sequence length for
each batch item in `y_pred`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> greedy
						</dt>
						<dd>perform much faster best-path search if `true`.
This does not use a dictionary. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> beam_width
						</dt>
						<dd>if `greedy` is `false`: a beam search decoder will be used
with a beam of this width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> top_paths
						</dt>
						<dd>if `greedy` is `false`,
how many of the most probable paths will be returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_label_dense_to_sparse" class="method">
		<h4>
			<a href="../tensorflow/SparseTensor.htm">SparseTensor</a> <strong>ctc_label_dense_to_sparse</strong>(<a href="../numpy/ndarray.htm">ndarray</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> label_lengths)
		</h4>
		<div class="content">Converts CTC labels from dense to sparse. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> labels
						</dt>
						<dd>dense CTC labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> label_lengths
						</dt>
						<dd>length of the labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/SparseTensor.htm">SparseTensor</a></code>
					</dt>
					<dd>A sparse tensor representation of the labels. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_label_dense_to_sparse" class="method">
		<h4>
			<a href="../tensorflow/SparseTensor.htm">SparseTensor</a> <strong>ctc_label_dense_to_sparse</strong>(<a href="../numpy/ndarray.htm">ndarray</a> labels, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> label_lengths)
		</h4>
		<div class="content">Converts CTC labels from dense to sparse. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> labels
						</dt>
						<dd>dense CTC labels. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> label_lengths
						</dt>
						<dd>length of the labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/SparseTensor.htm">SparseTensor</a></code>
					</dt>
					<dd>A sparse tensor representation of the labels. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_label_dense_to_sparse" class="method">
		<h4>
			<a href="../tensorflow/SparseTensor.htm">SparseTensor</a> <strong>ctc_label_dense_to_sparse</strong>(<a href="../numpy/ndarray.htm">ndarray</a> labels, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> label_lengths)
		</h4>
		<div class="content">Converts CTC labels from dense to sparse. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> labels
						</dt>
						<dd>dense CTC labels. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> label_lengths
						</dt>
						<dd>length of the labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/SparseTensor.htm">SparseTensor</a></code>
					</dt>
					<dd>A sparse tensor representation of the labels. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_label_dense_to_sparse" class="method">
		<h4>
			<a href="../tensorflow/SparseTensor.htm">SparseTensor</a> <strong>ctc_label_dense_to_sparse</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_lengths)
		</h4>
		<div class="content">Converts CTC labels from dense to sparse. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>dense CTC labels. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_lengths
						</dt>
						<dd>length of the labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/SparseTensor.htm">SparseTensor</a></code>
					</dt>
					<dd>A sparse tensor representation of the labels. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_label_dense_to_sparse" class="method">
		<h4>
			<a href="../tensorflow/SparseTensor.htm">SparseTensor</a> <strong>ctc_label_dense_to_sparse</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> label_lengths)
		</h4>
		<div class="content">Converts CTC labels from dense to sparse. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>dense CTC labels. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> label_lengths
						</dt>
						<dd>length of the labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/SparseTensor.htm">SparseTensor</a></code>
					</dt>
					<dd>A sparse tensor representation of the labels. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_label_dense_to_sparse" class="method">
		<h4>
			<a href="../tensorflow/SparseTensor.htm">SparseTensor</a> <strong>ctc_label_dense_to_sparse</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> label_lengths)
		</h4>
		<div class="content">Converts CTC labels from dense to sparse. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>dense CTC labels. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> label_lengths
						</dt>
						<dd>length of the labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/SparseTensor.htm">SparseTensor</a></code>
					</dt>
					<dd>A sparse tensor representation of the labels. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_label_dense_to_sparse" class="method">
		<h4>
			<a href="../tensorflow/SparseTensor.htm">SparseTensor</a> <strong>ctc_label_dense_to_sparse</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> labels, <a href="../numpy/ndarray.htm">ndarray</a> label_lengths)
		</h4>
		<div class="content">Converts CTC labels from dense to sparse. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> labels
						</dt>
						<dd>dense CTC labels. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> label_lengths
						</dt>
						<dd>length of the labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/SparseTensor.htm">SparseTensor</a></code>
					</dt>
					<dd>A sparse tensor representation of the labels. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_label_dense_to_sparse" class="method">
		<h4>
			<a href="../tensorflow/SparseTensor.htm">SparseTensor</a> <strong>ctc_label_dense_to_sparse</strong>(<a href="../numpy/ndarray.htm">ndarray</a> labels, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> label_lengths)
		</h4>
		<div class="content">Converts CTC labels from dense to sparse. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> labels
						</dt>
						<dd>dense CTC labels. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> label_lengths
						</dt>
						<dd>length of the labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/SparseTensor.htm">SparseTensor</a></code>
					</dt>
					<dd>A sparse tensor representation of the labels. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ctc_label_dense_to_sparse_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ctc_label_dense_to_sparse_dyn</strong>(<span title="System.object">object</span> labels, <span title="System.object">object</span> label_lengths)
		</h4>
		<div class="content">Converts CTC labels from dense to sparse. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> labels
						</dt>
						<dd>dense CTC labels. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> label_lengths
						</dt>
						<dd>length of the labels. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A sparse tensor representation of the labels. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cumprod" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>cumprod</strong>(<span title="System.object">object</span> x, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Cumulative product of the values in a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>An integer, the axis to compute the product. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor of the cumulative product of values of `x` along `axis`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cumprod_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>cumprod_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis)
		</h4>
		<div class="content">Cumulative product of the values in a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>An integer, the axis to compute the product. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor of the cumulative product of values of `x` along `axis`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cumsum" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>cumsum</strong>(<span title="System.object">object</span> x, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Cumulative sum of the values in a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>An integer, the axis to compute the sum. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor of the cumulative sum of values of `x` along `axis`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cumsum_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>cumsum_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis)
		</h4>
		<div class="content">Cumulative sum of the values in a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>An integer, the axis to compute the sum. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor of the cumulative sum of values of `x` along `axis`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dot</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> y)
		</h4>
		<div class="content">Multiplies 2 tensors (and/or variables) and returns a *tensor*. <p></p> When attempting to multiply a nD tensor
with a nD tensor, it reproduces the Theano behavior.
(e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, dot product of `x` and `y`. <p></p> Examples:
```python
# dot product between tensors
>>> x = K.placeholder(shape=(2, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>
``` <p></p> ```python
# dot product between tensors
>>> x = K.placeholder(shape=(32, 28, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>
``` <p></p> ```python
# Theano-like behavior example
>>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)
>>> y = K.ones((4, 3, 5))
>>> xy = K.dot(x, y)
>>> K.int_shape(xy)
(2, 4, 5)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dot</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y)
		</h4>
		<div class="content">Multiplies 2 tensors (and/or variables) and returns a *tensor*. <p></p> When attempting to multiply a nD tensor
with a nD tensor, it reproduces the Theano behavior.
(e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, dot product of `x` and `y`. <p></p> Examples:
```python
# dot product between tensors
>>> x = K.placeholder(shape=(2, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>
``` <p></p> ```python
# dot product between tensors
>>> x = K.placeholder(shape=(32, 28, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>
``` <p></p> ```python
# Theano-like behavior example
>>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)
>>> y = K.ones((4, 3, 5))
>>> xy = K.dot(x, y)
>>> K.int_shape(xy)
(2, 4, 5)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dot</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y)
		</h4>
		<div class="content">Multiplies 2 tensors (and/or variables) and returns a *tensor*. <p></p> When attempting to multiply a nD tensor
with a nD tensor, it reproduces the Theano behavior.
(e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, dot product of `x` and `y`. <p></p> Examples:
```python
# dot product between tensors
>>> x = K.placeholder(shape=(2, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>
``` <p></p> ```python
# dot product between tensors
>>> x = K.placeholder(shape=(32, 28, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>
``` <p></p> ```python
# Theano-like behavior example
>>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)
>>> y = K.ones((4, 3, 5))
>>> xy = K.dot(x, y)
>>> K.int_shape(xy)
(2, 4, 5)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dot</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> x, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> y)
		</h4>
		<div class="content">Multiplies 2 tensors (and/or variables) and returns a *tensor*. <p></p> When attempting to multiply a nD tensor
with a nD tensor, it reproduces the Theano behavior.
(e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, dot product of `x` and `y`. <p></p> Examples:
```python
# dot product between tensors
>>> x = K.placeholder(shape=(2, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>
``` <p></p> ```python
# dot product between tensors
>>> x = K.placeholder(shape=(32, 28, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>
``` <p></p> ```python
# Theano-like behavior example
>>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)
>>> y = K.ones((4, 3, 5))
>>> xy = K.dot(x, y)
>>> K.int_shape(xy)
(2, 4, 5)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dot</strong>(<span title="System.object">object</span> x, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> y)
		</h4>
		<div class="content">Multiplies 2 tensors (and/or variables) and returns a *tensor*. <p></p> When attempting to multiply a nD tensor
with a nD tensor, it reproduces the Theano behavior.
(e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, dot product of `x` and `y`. <p></p> Examples:
```python
# dot product between tensors
>>> x = K.placeholder(shape=(2, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>
``` <p></p> ```python
# dot product between tensors
>>> x = K.placeholder(shape=(32, 28, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>
``` <p></p> ```python
# Theano-like behavior example
>>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)
>>> y = K.ones((4, 3, 5))
>>> xy = K.dot(x, y)
>>> K.int_shape(xy)
(2, 4, 5)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dot</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y)
		</h4>
		<div class="content">Multiplies 2 tensors (and/or variables) and returns a *tensor*. <p></p> When attempting to multiply a nD tensor
with a nD tensor, it reproduces the Theano behavior.
(e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, dot product of `x` and `y`. <p></p> Examples:
```python
# dot product between tensors
>>> x = K.placeholder(shape=(2, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>
``` <p></p> ```python
# dot product between tensors
>>> x = K.placeholder(shape=(32, 28, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>
``` <p></p> ```python
# Theano-like behavior example
>>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)
>>> y = K.ones((4, 3, 5))
>>> xy = K.dot(x, y)
>>> K.int_shape(xy)
(2, 4, 5)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dot</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> x, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> y)
		</h4>
		<div class="content">Multiplies 2 tensors (and/or variables) and returns a *tensor*. <p></p> When attempting to multiply a nD tensor
with a nD tensor, it reproduces the Theano behavior.
(e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, dot product of `x` and `y`. <p></p> Examples:
```python
# dot product between tensors
>>> x = K.placeholder(shape=(2, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>
``` <p></p> ```python
# dot product between tensors
>>> x = K.placeholder(shape=(32, 28, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>
``` <p></p> ```python
# Theano-like behavior example
>>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)
>>> y = K.ones((4, 3, 5))
>>> xy = K.dot(x, y)
>>> K.int_shape(xy)
(2, 4, 5)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dot</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> y)
		</h4>
		<div class="content">Multiplies 2 tensors (and/or variables) and returns a *tensor*. <p></p> When attempting to multiply a nD tensor
with a nD tensor, it reproduces the Theano behavior.
(e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, dot product of `x` and `y`. <p></p> Examples:
```python
# dot product between tensors
>>> x = K.placeholder(shape=(2, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>
``` <p></p> ```python
# dot product between tensors
>>> x = K.placeholder(shape=(32, 28, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>
``` <p></p> ```python
# Theano-like behavior example
>>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)
>>> y = K.ones((4, 3, 5))
>>> xy = K.dot(x, y)
>>> K.int_shape(xy)
(2, 4, 5)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dot</strong>(<span title="System.object">object</span> x, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> y)
		</h4>
		<div class="content">Multiplies 2 tensors (and/or variables) and returns a *tensor*. <p></p> When attempting to multiply a nD tensor
with a nD tensor, it reproduces the Theano behavior.
(e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, dot product of `x` and `y`. <p></p> Examples:
```python
# dot product between tensors
>>> x = K.placeholder(shape=(2, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>
``` <p></p> ```python
# dot product between tensors
>>> x = K.placeholder(shape=(32, 28, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
<tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>
``` <p></p> ```python
# Theano-like behavior example
>>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)
>>> y = K.ones((4, 3, 5))
>>> xy = K.dot(x, y)
>>> K.int_shape(xy)
(2, 4, 5)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>dropout</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> level, <span title="System.Nullable<ValueTuple<int, int>>">Nullable&lt;ValueTuple&lt;int, int&gt;&gt;</span> noise_shape, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Sets entries in `x` to zero at random, while scaling the entire tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>tensor 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> level
						</dt>
						<dd>fraction of the entries in the tensor
that will be set to 0. 
						</dd>
						<dt>
							<code><span title="System.Nullable<ValueTuple<int, int>>">Nullable&lt;ValueTuple&lt;int, int&gt;&gt;</span></code> noise_shape
						</dt>
						<dd>shape for randomly generated keep/drop flags,
must be broadcastable to the shape of `x` 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>random seed to ensure determinism. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dropout_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dropout_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> level, <span title="System.object">object</span> noise_shape, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Sets entries in `x` to zero at random, while scaling the entire tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>tensor 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> level
						</dt>
						<dd>fraction of the entries in the tensor
that will be set to 0. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> noise_shape
						</dt>
						<dd>shape for randomly generated keep/drop flags,
must be broadcastable to the shape of `x` 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>random seed to ensure determinism. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dtype" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dtype</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x)
		</h4>
		<div class="content">Returns the dtype of a Keras tensor or variable, as a string. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>String, dtype of `x`. <p></p> Examples:
```python
>>> from keras import backend as K
>>> K.dtype(K.placeholder(shape=(2,4,5)))
'float32'
>>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))
'float32'
>>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))
'float64'
# Keras variable
>>> kvar = K.variable(np.array([[1, 2], [3, 4]]))
>>> K.dtype(kvar)
'float32'
>>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')
>>> K.dtype(kvar)
'float32'
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dtype" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dtype</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Returns the dtype of a Keras tensor or variable, as a string. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>String, dtype of `x`. <p></p> Examples:
```python
>>> from keras import backend as K
>>> K.dtype(K.placeholder(shape=(2,4,5)))
'float32'
>>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))
'float32'
>>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))
'float64'
# Keras variable
>>> kvar = K.variable(np.array([[1, 2], [3, 4]]))
>>> K.dtype(kvar)
'float32'
>>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')
>>> K.dtype(kvar)
'float32'
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="dtype_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>dtype_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Returns the dtype of a Keras tensor or variable, as a string. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>String, dtype of `x`. <p></p> Examples:
```python
>>> from keras import backend as K
>>> K.dtype(K.placeholder(shape=(2,4,5)))
'float32'
>>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))
'float32'
>>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))
'float64'
# Keras variable
>>> kvar = K.variable(np.array([[1, 2], [3, 4]]))
>>> K.dtype(kvar)
'float32'
>>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')
>>> K.dtype(kvar)
'float32'
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="elu" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>elu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha)
		</h4>
		<div class="content">Exponential linear unit. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable to compute the activation function for. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="elu" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>elu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> alpha)
		</h4>
		<div class="content">Exponential linear unit. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable to compute the activation function for. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="elu" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>elu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha)
		</h4>
		<div class="content">Exponential linear unit. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable to compute the activation function for. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="epsilon" class="method">
		<h4>
			<span title="System.double">double</span> <strong>epsilon</strong>()
		</h4>
		<div class="content">Returns the value of the fuzz factor used in numeric expressions. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.double">double</span></code>
					</dt>
					<dd>A float. <p></p> Example:
```python
keras.backend.epsilon() >>>1e-07
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="epsilon_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>epsilon_dyn</strong>()
		</h4>
		<div class="content">Returns the value of the fuzz factor used in numeric expressions. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A float. <p></p> Example:
```python
keras.backend.epsilon() >>>1e-07
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="equal" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>equal</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y)
		</h4>
		<div class="content">Element-wise equality between two tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="equal_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>equal_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise equality between two tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="eval" class="method">
		<h4>
			<span title="System.object">object</span> <strong>eval</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x)
		</h4>
		<div class="content">Evaluates the value of a variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>A variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Numpy array. <p></p> Examples:
```python
>>> from keras import backend as K
>>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')
>>> K.eval(kvar)
array([[ 1.,  2.],
[ 3.,  4.]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="exp" class="method">
		<h4>
			<span title="System.object">object</span> <strong>exp</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x)
		</h4>
		<div class="content">Element-wise exponential. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="exp_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>exp_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Calculate the exponential of all elements in the input array. 




		</div>
	</div>
	<div id="expand_dims" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>expand_dims</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> x, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Adds a 1-sized dimension at index "axis". 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Position where to add a new axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with expanded dimensions. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="expand_dims" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>expand_dims</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Adds a 1-sized dimension at index "axis". 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Position where to add a new axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with expanded dimensions. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="expand_dims" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>expand_dims</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Adds a 1-sized dimension at index "axis". 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Position where to add a new axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with expanded dimensions. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="expand_dims" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>expand_dims</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Adds a 1-sized dimension at index "axis". 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Position where to add a new axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with expanded dimensions. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="expand_dims_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>expand_dims_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis)
		</h4>
		<div class="content">Adds a 1-sized dimension at index "axis". 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>Position where to add a new axis. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with expanded dimensions. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="eye" class="method">
		<h4>
			<span title="System.object">object</span> <strong>eye</strong>(<span title="System.int">int</span> size, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Instantiate an identity matrix and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.int">int</span></code> size
						</dt>
						<dd>Integer, number of rows/columns. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, data type of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, an identity matrix. <p></p> Example:
```python
>>> from keras import backend as K
>>> kvar = K.eye(3)
>>> K.eval(kvar)
array([[ 1.,  0.,  0.],
[ 0.,  1.,  0.],
[ 0.,  0.,  1.]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="eye_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>eye_dyn</strong>(<span title="System.object">object</span> size, <span title="System.object">object</span> dtype, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Instantiate an identity matrix and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> size
						</dt>
						<dd>Integer, number of rows/columns. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>String, data type of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, an identity matrix. <p></p> Example:
```python
>>> from keras import backend as K
>>> kvar = K.eye(3)
>>> K.eval(kvar)
array([[ 1.,  0.,  0.],
[ 0.,  1.,  0.],
[ 0.,  0.,  1.]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="flatten" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>flatten</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x)
		</h4>
		<div class="content">Flatten a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, reshaped into 1-D <p></p> Example:
```python
>>> b = tf.constant([[1, 2], [3, 4]])
>>> b
<tf.Tensor: id=102, shape=(2, 2), dtype=int32, numpy=
array([[1, 2],
[3, 4]], dtype=int32)>
>>> tf.keras.backend.flatten(b)
<tf.Tensor: id=105, shape=(4,), dtype=int32,
numpy=array([1, 2, 3, 4], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="flatten" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>flatten</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x)
		</h4>
		<div class="content">Flatten a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, reshaped into 1-D <p></p> Example:
```python
>>> b = tf.constant([[1, 2], [3, 4]])
>>> b
<tf.Tensor: id=102, shape=(2, 2), dtype=int32, numpy=
array([[1, 2],
[3, 4]], dtype=int32)>
>>> tf.keras.backend.flatten(b)
<tf.Tensor: id=105, shape=(4,), dtype=int32,
numpy=array([1, 2, 3, 4], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="flatten" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>flatten</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x)
		</h4>
		<div class="content">Flatten a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor, reshaped into 1-D <p></p> Example:
```python
>>> b = tf.constant([[1, 2], [3, 4]])
>>> b
<tf.Tensor: id=102, shape=(2, 2), dtype=int32, numpy=
array([[1, 2],
[3, 4]], dtype=int32)>
>>> tf.keras.backend.flatten(b)
<tf.Tensor: id=105, shape=(4,), dtype=int32,
numpy=array([1, 2, 3, 4], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="floatx" class="method">
		<h4>
			<span title="System.string">string</span> <strong>floatx</strong>()
		</h4>
		<div class="content">Returns the default float type, as a string. <p></p> E.g. 'float16', 'float32', 'float64'. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.string">string</span></code>
					</dt>
					<dd>String, the current default float type. <p></p> Example:
```python
keras.backend.floatx() >>> 'float32'
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="floatx_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>floatx_dyn</strong>()
		</h4>
		<div class="content">Returns the default float type, as a string. <p></p> E.g. 'float16', 'float32', 'float64'. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>String, the current default float type. <p></p> Example:
```python
keras.backend.floatx() >>> 'float32'
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="foldl" class="method">
		<h4>
			<span title="System.object">object</span> <strong>foldl</strong>(<span title="System.object">object</span> fn, <span title="System.object">object</span> elems, <span title="System.object">object</span> initializer, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Reduce elems using fn to combine them from left to right. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> fn
						</dt>
						<dd>Callable that will be called upon each element in elems and an
accumulator, for instance `lambda acc, x: acc + x` 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> elems
						</dt>
						<dd>tensor 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initializer
						</dt>
						<dd>The first value used (`elems[0]` in case of None) 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A string name for the foldl node in the graph 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor with same type and shape as `initializer`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="foldr" class="method">
		<h4>
			<span title="System.object">object</span> <strong>foldr</strong>(<span title="System.object">object</span> fn, <span title="System.object">object</span> elems, <span title="System.object">object</span> initializer, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Reduce elems using fn to combine them from right to left. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> fn
						</dt>
						<dd>Callable that will be called upon each element in elems and an
accumulator, for instance `lambda acc, x: acc + x` 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> elems
						</dt>
						<dd>tensor 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initializer
						</dt>
						<dd>The first value used (`elems[-1]` in case of None) 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A string name for the foldr node in the graph 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Same type and shape as initializer 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="foldr_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>foldr_dyn</strong>(<span title="System.object">object</span> fn, <span title="System.object">object</span> elems, <span title="System.object">object</span> initializer, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Reduce elems using fn to combine them from right to left. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> fn
						</dt>
						<dd>Callable that will be called upon each element in elems and an
accumulator, for instance `lambda acc, x: acc + x` 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> elems
						</dt>
						<dd>tensor 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initializer
						</dt>
						<dd>The first value used (`elems[-1]` in case of None) 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A string name for the foldr node in the graph 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Same type and shape as initializer 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.Collections.Generic.IDictionary<object, IGraphNodeBase>">IDictionary&lt;object, IGraphNodeBase&gt;</span> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, IGraphNodeBase>">IDictionary&lt;object, IGraphNodeBase&gt;</span></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.Collections.Generic.IDictionary<object, IGraphNodeBase>">IDictionary&lt;object, IGraphNodeBase&gt;</span> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, IGraphNodeBase>">IDictionary&lt;object, IGraphNodeBase&gt;</span></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.object">object</span> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> inputs, <span title="System.object">object</span> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> inputs, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> inputs, <span title="System.Collections.Generic.IDictionary<object, IGraphNodeBase>">IDictionary&lt;object, IGraphNodeBase&gt;</span> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, IGraphNodeBase>">IDictionary&lt;object, IGraphNodeBase&gt;</span></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <span title="System.object">object</span> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> outputs, <span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span> updates, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<ValueTuple<object, object>>">IEnumerable&lt;ValueTuple&lt;object, object&gt;&gt;</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="function_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>function_dyn</strong>(<span title="System.object">object</span> inputs, <span title="System.object">object</span> outputs, <span title="System.object">object</span> updates, <span title="System.object">object</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> kwargs)
		</h4>
		<div class="content">Instantiates a Keras function. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>List of placeholder tensors. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> outputs
						</dt>
						<dd>List of output tensors. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> updates
						</dt>
						<dd>List of update ops. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>String, name of function. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> kwargs
						</dt>
						<dd>Passed to <a href="..\..\..\tf\InteractiveSession\run.md"><code>tf.Session.run</code></a>. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output values as Numpy arrays. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="get_session" class="method">
		<h4>
			<a href="../tensorflow.python.client.session/BaseSession.htm">BaseSession</a> <strong>get_session</strong>(<a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> op_input_list)
		</h4>
		<div class="content">Returns the TF session to be used by the backend. <p></p> If a default TensorFlow session is available, we will return it. <p></p> Else, we will return the global Keras session assuming it matches
the current graph. <p></p> If no global Keras session exists at this point:
we will create a new global session. <p></p> Note that you can manually set the global session
via `K.set_session(sess)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> op_input_list
						</dt>
						<dd>An option sequence of tensors or ops, which will be used
to determine the current graph. Otherwise the default graph will be
used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow.python.client.session/BaseSession.htm">BaseSession</a></code>
					</dt>
					<dd>A TensorFlow session. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="get_session" class="method">
		<h4>
			<a href="../tensorflow.python.client.session/BaseSession.htm">BaseSession</a> <strong>get_session</strong>(<span title="System.object">object</span> op_input_list)
		</h4>
		<div class="content">Returns the TF session to be used by the backend. <p></p> If a default TensorFlow session is available, we will return it. <p></p> Else, we will return the global Keras session assuming it matches
the current graph. <p></p> If no global Keras session exists at this point:
we will create a new global session. <p></p> Note that you can manually set the global session
via `K.set_session(sess)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> op_input_list
						</dt>
						<dd>An option sequence of tensors or ops, which will be used
to determine the current graph. Otherwise the default graph will be
used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow.python.client.session/BaseSession.htm">BaseSession</a></code>
					</dt>
					<dd>A TensorFlow session. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="get_session_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>get_session_dyn</strong>(<a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> op_input_list)
		</h4>
		<div class="content">Returns the TF session to be used by the backend. <p></p> If a default TensorFlow session is available, we will return it. <p></p> Else, we will return the global Keras session assuming it matches
the current graph. <p></p> If no global Keras session exists at this point:
we will create a new global session. <p></p> Note that you can manually set the global session
via `K.set_session(sess)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> op_input_list
						</dt>
						<dd>An option sequence of tensors or ops, which will be used
to determine the current graph. Otherwise the default graph will be
used. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A TensorFlow session. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="get_uid" class="method">
		<h4>
			<span title="System.object">object</span> <strong>get_uid</strong>(<span title="System.string">string</span> prefix)
		</h4>
		<div class="content">Associates a string prefix with an integer counter in a TensorFlow graph. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.string">string</span></code> prefix
						</dt>
						<dd>String prefix to index. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Unique integer ID. <p></p> Example: <p></p> ```
>>> get_uid('dense')
1
>>> get_uid('dense')
2
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="get_uid_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>get_uid_dyn</strong>(<a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> prefix)
		</h4>
		<div class="content">Associates a string prefix with an integer counter in a TensorFlow graph. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> prefix
						</dt>
						<dd>String prefix to index. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Unique integer ID. <p></p> Example: <p></p> ```
>>> get_uid('dense')
1
>>> get_uid('dense')
2
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="get_value" class="method">
		<h4>
			<span title="System.object">object</span> <strong>get_value</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x)
		</h4>
		<div class="content">Returns the value of a variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>input variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Numpy array. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="get_value" class="method">
		<h4>
			<span title="System.object">object</span> <strong>get_value</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x)
		</h4>
		<div class="content">Returns the value of a variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>input variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Numpy array. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="gradients" class="method">
		<h4>
			<span title="System.Collections.Generic.IList<Tensor>">IList&lt;Tensor&gt;</span> <strong>gradients</strong>(<span title="System.object">object</span> loss, <span title="System.Collections.Generic.IEnumerable<Variable>">IEnumerable&lt;Variable&gt;</span> variables)
		</h4>
		<div class="content">Returns the gradients of `loss` w.r.t. `variables`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> loss
						</dt>
						<dd>Scalar tensor to minimize. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<Variable>">IEnumerable&lt;Variable&gt;</span></code> variables
						</dt>
						<dd>List of variables. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IList<Tensor>">IList&lt;Tensor&gt;</span></code>
					</dt>
					<dd>A gradients tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="gradients" class="method">
		<h4>
			<span title="System.Collections.Generic.IList<Tensor>">IList&lt;Tensor&gt;</span> <strong>gradients</strong>(<span title="System.double">double</span> loss, <span title="System.Collections.Generic.IEnumerable<Variable>">IEnumerable&lt;Variable&gt;</span> variables)
		</h4>
		<div class="content">Returns the gradients of `loss` w.r.t. `variables`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.double">double</span></code> loss
						</dt>
						<dd>Scalar tensor to minimize. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<Variable>">IEnumerable&lt;Variable&gt;</span></code> variables
						</dt>
						<dd>List of variables. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IList<Tensor>">IList&lt;Tensor&gt;</span></code>
					</dt>
					<dd>A gradients tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="gradients_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>gradients_dyn</strong>(<span title="System.object">object</span> loss, <span title="System.object">object</span> variables)
		</h4>
		<div class="content">Returns the gradients of `loss` w.r.t. `variables`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> loss
						</dt>
						<dd>Scalar tensor to minimize. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> variables
						</dt>
						<dd>List of variables. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A gradients tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="greater" class="method">
		<h4>
			<span title="System.object">object</span> <strong>greater</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y)
		</h4>
		<div class="content">Element-wise truth value of (x > y). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="greater_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>greater_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise truth value of (x > y). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="greater_equal" class="method">
		<h4>
			<span title="System.object">object</span> <strong>greater_equal</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise truth value of (x >= y). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="greater_equal_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>greater_equal_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise truth value of (x >= y). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="image_data_format" class="method">
		<h4>
			<span title="System.string">string</span> <strong>image_data_format</strong>()
		</h4>
		<div class="content">Returns the default image data format convention. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.string">string</span></code>
					</dt>
					<dd>A string, either `'channels_first'` or `'channels_last'` <p></p> Example:
```python
keras.backend.image_data_format() >>> 'channels_first'
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="image_data_format_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>image_data_format_dyn</strong>()
		</h4>
		<div class="content">Returns the default image data format convention. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A string, either `'channels_first'` or `'channels_last'` <p></p> Example:
```python
keras.backend.image_data_format() >>> 'channels_first'
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_test_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_test_phase</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> alt, <span title="System.object">object</span> training)
		</h4>
		<div class="content">Selects `x` in test phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in test phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on `K.learning_phase`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_test_phase_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_test_phase_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> alt, <span title="System.object">object</span> training)
		</h4>
		<div class="content">Selects `x` in test phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in test phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on `K.learning_phase`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_top_k" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>in_top_k</strong>(<span title="System.object">object</span> predictions, <span title="System.object">object</span> targets, <span title="System.object">object</span> k)
		</h4>
		<div class="content">Returns whether the `targets` are in the top `k` `predictions`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> predictions
						</dt>
						<dd>A tensor of shape `(batch_size, classes)` and type `float32`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> targets
						</dt>
						<dd>A 1D tensor of length `batch_size` and type `int32` or `int64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> k
						</dt>
						<dd>An `int`, number of top elements to consider. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 1D tensor of length `batch_size` and type `bool`.
`output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`
values of `predictions[i]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_top_k_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_top_k_dyn</strong>(<span title="System.object">object</span> predictions, <span title="System.object">object</span> targets, <span title="System.object">object</span> k)
		</h4>
		<div class="content">Returns whether the `targets` are in the top `k` `predictions`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> predictions
						</dt>
						<dd>A tensor of shape `(batch_size, classes)` and type `float32`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> targets
						</dt>
						<dd>A 1D tensor of length `batch_size` and type `int32` or `int64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> k
						</dt>
						<dd>An `int`, number of top elements to consider. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 1D tensor of length `batch_size` and type `bool`.
`output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`
values of `predictions[i]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> alt, <span title="System.bool">bool</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> alt, <span title="System.int">int</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> alt, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> alt, <span title="System.bool">bool</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> alt, <span title="System.int">int</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> alt, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> alt, <span title="System.int">int</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <span title="System.object">object</span> alt, <span title="System.int">int</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <span title="System.object">object</span> alt, <span title="System.bool">bool</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> alt, <span title="System.bool">bool</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> alt, <span title="System.bool">bool</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> alt, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<span title="System.object">object</span> x, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> alt, <span title="System.int">int</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<span title="System.object">object</span> x, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> alt, <span title="System.bool">bool</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<span title="System.object">object</span> x, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> alt, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> alt, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> alt, <span title="System.int">int</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <span title="System.object">object</span> alt, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="in_train_phase_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>in_train_phase_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> alt, <span title="System.object">object</span> training)
		</h4>
		<div class="content">Selects `x` in train phase, and `alt` otherwise. <p></p> Note that `alt` should have the *same shape* as `x`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>What to return in train phase
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> alt
						</dt>
						<dd>What to return otherwise
(tensor or callable that returns a tensor). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> training
						</dt>
						<dd>Optional scalar tensor
(or Python boolean, or Python integer)
specifying the learning phase. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Either `x` or `alt` based on the `training` flag.
the `training` flag defaults to `K.learning_phase()`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="int_shape" class="method">
		<h4>
			<span title="System.object">object</span> <strong>int_shape</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x)
		</h4>
		<div class="content">Returns the shape of tensor or variable as a tuple of int or None entries. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of integers (or None entries). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input = K.placeholder(shape=(2, 4, 5))
>>> K.int_shape(input)
(2, 4, 5)
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.int_shape(kvar)
(2, 2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="int_shape" class="method">
		<h4>
			<span title="System.object">object</span> <strong>int_shape</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x)
		</h4>
		<div class="content">Returns the shape of tensor or variable as a tuple of int or None entries. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of integers (or None entries). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input = K.placeholder(shape=(2, 4, 5))
>>> K.int_shape(input)
(2, 4, 5)
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.int_shape(kvar)
(2, 2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="int_shape" class="method">
		<h4>
			<span title="System.object">object</span> <strong>int_shape</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Returns the shape of tensor or variable as a tuple of int or None entries. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of integers (or None entries). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input = K.placeholder(shape=(2, 4, 5))
>>> K.int_shape(input)
(2, 4, 5)
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.int_shape(kvar)
(2, 2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="int_shape_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>int_shape_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Returns the shape of tensor or variable as a tuple of int or None entries. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of integers (or None entries). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input = K.placeholder(shape=(2, 4, 5))
>>> K.int_shape(input)
(2, 4, 5)
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.int_shape(kvar)
(2, 2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="is_sparse" class="method">
		<h4>
			<span title="System.bool">bool</span> <strong>is_sparse</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> tensor)
		</h4>
		<div class="content">Returns whether a tensor is a sparse tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> tensor
						</dt>
						<dd>A tensor instance. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.bool">bool</span></code>
					</dt>
					<dd>A boolean. <p></p> Example:
```python
>>> from keras import backend as K
>>> a = K.placeholder((2, 2), sparse=False)
>>> print(K.is_sparse(a))
False
>>> b = K.placeholder((2, 2), sparse=True)
>>> print(K.is_sparse(b))
True
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="is_sparse" class="method">
		<h4>
			<span title="System.bool">bool</span> <strong>is_sparse</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> tensor)
		</h4>
		<div class="content">Returns whether a tensor is a sparse tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> tensor
						</dt>
						<dd>A tensor instance. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.bool">bool</span></code>
					</dt>
					<dd>A boolean. <p></p> Example:
```python
>>> from keras import backend as K
>>> a = K.placeholder((2, 2), sparse=False)
>>> print(K.is_sparse(a))
False
>>> b = K.placeholder((2, 2), sparse=True)
>>> print(K.is_sparse(b))
True
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="l2_normalize" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>l2_normalize</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Normalizes a tensor wrt the L2 norm alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>axis along which to perform normalization. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="l2_normalize_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>l2_normalize_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Normalizes a tensor wrt the L2 norm alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>axis along which to perform normalization. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="learning_phase" class="method">
		<h4>
			<span title="System.object">object</span> <strong>learning_phase</strong>()
		</h4>
		<div class="content">Returns the learning phase flag. <p></p> The learning phase flag is a bool tensor (0 = test, 1 = train)
to be passed as input to any Keras function
that uses a different behavior at train time and test time. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Learning phase (scalar integer tensor or Python integer). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="learning_phase_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>learning_phase_dyn</strong>()
		</h4>
		<div class="content">Returns the learning phase flag. <p></p> The learning phase flag is a bool tensor (0 = test, 1 = train)
to be passed as input to any Keras function
that uses a different behavior at train time and test time. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Learning phase (scalar integer tensor or Python integer). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="learning_phase_scope" class="method">
		<h4>
			<a href="../LostTech.Gradient/IContextManager`1.htm">IContextManager&lt;T&gt;</a> <strong>learning_phase_scope</strong>(<span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> value)
		</h4>
		<div class="content">Provides a scope within which the learning phase is equal to `value`. <p></p> The learning phase gets restored to its original value upon exiting the scope. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> value
						</dt>
						<dd>Learning phase value, either 0 or 1 (integers). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="learning_phase_scope" class="method">
		<h4>
			<a href="../LostTech.Gradient/IContextManager`1.htm">IContextManager&lt;T&gt;</a> <strong>learning_phase_scope</strong>(<span title="System.int">int</span> value)
		</h4>
		<div class="content">Provides a scope within which the learning phase is equal to `value`. <p></p> The learning phase gets restored to its original value upon exiting the scope. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.int">int</span></code> value
						</dt>
						<dd>Learning phase value, either 0 or 1 (integers). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="learning_phase_scope_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>learning_phase_scope_dyn</strong>(<span title="System.object">object</span> value)
		</h4>
		<div class="content">Provides a scope within which the learning phase is equal to `value`. <p></p> The learning phase gets restored to its original value upon exiting the scope. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Learning phase value, either 0 or 1 (integers). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="less" class="method">
		<h4>
			<span title="System.object">object</span> <strong>less</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y)
		</h4>
		<div class="content">Element-wise truth value of (x < y). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="less" class="method">
		<h4>
			<span title="System.object">object</span> <strong>less</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> y)
		</h4>
		<div class="content">Element-wise truth value of (x < y). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="less_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>less_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise truth value of (x < y). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="less_equal" class="method">
		<h4>
			<span title="System.object">object</span> <strong>less_equal</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise truth value of (x <= y). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="less_equal_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>less_equal_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise truth value of (x <= y). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv1d</strong>(<a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 1D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> inputs
						</dt>
						<dd>3D tensor with shape:
(batch_size, steps, input_dim)
if data_format is "channels_last" or
(batch_size, input_dim, steps)
if data_format is "channels_first". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_length, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of a single integer,
specifying the length of the 1D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of a single integer,
specifying the stride length of the convolution. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 3d tensor with shape:
(batch_size, output_length, filters)
if data_format='channels_first'
or 3D tensor with shape:
(batch_size, filters, output_length)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv1d</strong>(<a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 1D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> inputs
						</dt>
						<dd>3D tensor with shape:
(batch_size, steps, input_dim)
if data_format is "channels_last" or
(batch_size, input_dim, steps)
if data_format is "channels_first". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_length, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of a single integer,
specifying the length of the 1D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of a single integer,
specifying the stride length of the convolution. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 3d tensor with shape:
(batch_size, output_length, filters)
if data_format='channels_first'
or 3D tensor with shape:
(batch_size, filters, output_length)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv1d</strong>(<a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> inputs, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 1D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> inputs
						</dt>
						<dd>3D tensor with shape:
(batch_size, steps, input_dim)
if data_format is "channels_last" or
(batch_size, input_dim, steps)
if data_format is "channels_first". 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_length, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of a single integer,
specifying the length of the 1D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of a single integer,
specifying the stride length of the convolution. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 3d tensor with shape:
(batch_size, output_length, filters)
if data_format='channels_first'
or 3D tensor with shape:
(batch_size, filters, output_length)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv1d</strong>(<a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> inputs, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 1D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> inputs
						</dt>
						<dd>3D tensor with shape:
(batch_size, steps, input_dim)
if data_format is "channels_last" or
(batch_size, input_dim, steps)
if data_format is "channels_first". 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_length, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of a single integer,
specifying the length of the 1D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of a single integer,
specifying the stride length of the convolution. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 3d tensor with shape:
(batch_size, output_length, filters)
if data_format='channels_first'
or 3D tensor with shape:
(batch_size, filters, output_length)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv1d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 1D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3D tensor with shape:
(batch_size, steps, input_dim)
if data_format is "channels_last" or
(batch_size, input_dim, steps)
if data_format is "channels_first". 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_length, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of a single integer,
specifying the length of the 1D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of a single integer,
specifying the stride length of the convolution. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 3d tensor with shape:
(batch_size, output_length, filters)
if data_format='channels_first'
or 3D tensor with shape:
(batch_size, filters, output_length)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv1d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 1D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3D tensor with shape:
(batch_size, steps, input_dim)
if data_format is "channels_last" or
(batch_size, input_dim, steps)
if data_format is "channels_first". 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_length, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of a single integer,
specifying the length of the 1D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of a single integer,
specifying the stride length of the convolution. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 3d tensor with shape:
(batch_size, output_length, filters)
if data_format='channels_first'
or 3D tensor with shape:
(batch_size, filters, output_length)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv1d</strong>(<a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> inputs, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 1D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> inputs
						</dt>
						<dd>3D tensor with shape:
(batch_size, steps, input_dim)
if data_format is "channels_last" or
(batch_size, input_dim, steps)
if data_format is "channels_first". 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_length, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of a single integer,
specifying the length of the 1D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of a single integer,
specifying the stride length of the convolution. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 3d tensor with shape:
(batch_size, output_length, filters)
if data_format='channels_first'
or 3D tensor with shape:
(batch_size, filters, output_length)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv1d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 1D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>3D tensor with shape:
(batch_size, steps, input_dim)
if data_format is "channels_last" or
(batch_size, input_dim, steps)
if data_format is "channels_first". 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_length, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of a single integer,
specifying the length of the 1D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of a single integer,
specifying the stride length of the convolution. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 3d tensor with shape:
(batch_size, output_length, filters)
if data_format='channels_first'
or 3D tensor with shape:
(batch_size, filters, output_length)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv1d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv1d</strong>(<a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> inputs, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 1D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> inputs
						</dt>
						<dd>3D tensor with shape:
(batch_size, steps, input_dim)
if data_format is "channels_last" or
(batch_size, input_dim, steps)
if data_format is "channels_first". 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_length, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of a single integer,
specifying the length of the 1D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of a single integer,
specifying the stride length of the convolution. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 3d tensor with shape:
(batch_size, output_length, filters)
if data_format='channels_first'
or 3D tensor with shape:
(batch_size, filters, output_length)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv1d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv1d_dyn</strong>(<span title="System.object">object</span> inputs, <span title="System.object">object</span> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> data_format)
		</h4>
		<div class="content">Apply 1D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>3D tensor with shape:
(batch_size, steps, input_dim)
if data_format is "channels_last" or
(batch_size, input_dim, steps)
if data_format is "channels_first". 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_length, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of a single integer,
specifying the length of the 1D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of a single integer,
specifying the stride length of the convolution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 3d tensor with shape:
(batch_size, output_length, filters)
if data_format='channels_first'
or 3D tensor with shape:
(batch_size, filters, output_length)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv2d</strong>(<a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> inputs, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> output_shape, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 2D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> inputs
						</dt>
						<dd>4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_items, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of 2 integers, specifying the
width and height of the 2D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of 2 integers, specifying the strides
of the convolution along the width and height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>a tuple with (output_row, output_col). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> output_shape, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 2D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_items, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of 2 integers, specifying the
width and height of the 2D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of 2 integers, specifying the strides
of the convolution along the width and height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>a tuple with (output_row, output_col). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv2d</strong>(<a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> output_shape, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 2D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> inputs
						</dt>
						<dd>4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_items, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of 2 integers, specifying the
width and height of the 2D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of 2 integers, specifying the strides
of the convolution along the width and height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>a tuple with (output_row, output_col). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv2d</strong>(<a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> inputs, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> output_shape, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 2D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> inputs
						</dt>
						<dd>4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_items, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of 2 integers, specifying the
width and height of the 2D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of 2 integers, specifying the strides
of the convolution along the width and height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>a tuple with (output_row, output_col). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv2d</strong>(<a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> inputs, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> output_shape, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 2D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> inputs
						</dt>
						<dd>4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_items, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of 2 integers, specifying the
width and height of the 2D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of 2 integers, specifying the strides
of the convolution along the width and height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>a tuple with (output_row, output_col). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> output_shape, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 2D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_items, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of 2 integers, specifying the
width and height of the 2D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of 2 integers, specifying the strides
of the convolution along the width and height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>a tuple with (output_row, output_col). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv2d</strong>(<a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> output_shape, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 2D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> inputs
						</dt>
						<dd>4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_items, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of 2 integers, specifying the
width and height of the 2D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of 2 integers, specifying the strides
of the convolution along the width and height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>a tuple with (output_row, output_col). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> inputs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> output_shape, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 2D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> inputs
						</dt>
						<dd>4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_items, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of 2 integers, specifying the
width and height of the 2D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of 2 integers, specifying the strides
of the convolution along the width and height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>a tuple with (output_row, output_col). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv2d</strong>(<a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> inputs, <a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> output_shape, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Apply 2D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> inputs
						</dt>
						<dd>4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
						</dd>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_items, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of 2 integers, specifying the
width and height of the 2D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of 2 integers, specifying the strides
of the convolution along the width and height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>a tuple with (output_row, output_col). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="local_conv2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>local_conv2d_dyn</strong>(<span title="System.object">object</span> inputs, <span title="System.object">object</span> kernel, <span title="System.object">object</span> kernel_size, <span title="System.object">object</span> strides, <span title="System.object">object</span> output_shape, <span title="System.object">object</span> data_format)
		</h4>
		<div class="content">Apply 2D conv with un-shared weights. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel
						</dt>
						<dd>the unshared weight for convolution,
with shape (output_items, feature_dim, filters). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> kernel_size
						</dt>
						<dd>a tuple of 2 integers, specifying the
width and height of the 2D convolution window. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>a tuple of 2 integers, specifying the strides
of the convolution along the width and height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_shape
						</dt>
						<dd>a tuple with (output_row, output_col). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>the data format, channels_first or channels_last. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4D tensor with shape:
(batch_size, filters, new_rows, new_cols)
if data_format='channels_first'
or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters)
if data_format='channels_last'. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log" class="method">
		<h4>
			<span title="System.object">object</span> <strong>log</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise log. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="log_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>log_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise log. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="manual_variable_initialization" class="method">
		<h4>
			<span title="System.void">void</span> <strong>manual_variable_initialization</strong>(<span title="System.bool">bool</span> value)
		</h4>
		<div class="content">Sets the manual variable initialization flag. <p></p> This boolean flag determines whether
variables should be initialized
as they are instantiated (default), or if
the user should handle the initialization
(e.g. via `tf.compat.v1.initialize_all_variables()`). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.bool">bool</span></code> value
						</dt>
						<dd>Python boolean. 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="manual_variable_initialization_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>manual_variable_initialization_dyn</strong>(<span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the manual variable initialization flag. <p></p> This boolean flag determines whether
variables should be initialized
as they are instantiated (default), or if
the user should handle the initialization
(e.g. via `tf.compat.v1.initialize_all_variables()`). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Python boolean. 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="map_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>map_fn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> fn, <span title="System.object">object</span> elems, <span title="System.string">string</span> name, <a href="../tensorflow/DType.htm">DType</a> dtype)
		</h4>
		<div class="content">Map the function fn over the elements elems and return the outputs. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> fn
						</dt>
						<dd>Callable that will be called upon each element in elems 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> elems
						</dt>
						<dd>tensor 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A string name for the map node in the graph 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>Output data type. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code>
					</dt>
					<dd>Tensor with dtype `dtype`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="map_fn_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>map_fn_dyn</strong>(<span title="System.object">object</span> fn, <span title="System.object">object</span> elems, <span title="System.object">object</span> name, <span title="System.object">object</span> dtype)
		</h4>
		<div class="content">Map the function fn over the elements elems and return the outputs. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> fn
						</dt>
						<dd>Callable that will be called upon each element in elems 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> elems
						</dt>
						<dd>tensor 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A string name for the map node in the graph 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>Output data type. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor with dtype `dtype`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Maximum value in a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>An integer, the axis to find maximum values. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with maximum values of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Maximum value in a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>An integer, the axis to find maximum values. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with maximum values of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Maximum value in a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>An integer, the axis to find maximum values. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with maximum values of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>max</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Maximum value in a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>An integer, the axis to find maximum values. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with maximum values of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="max_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>max_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims)
		</h4>
		<div class="content">Maximum value in a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>An integer, the axis to find maximum values. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with maximum values of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="maximum" class="method">
		<h4>
			<span title="System.object">object</span> <strong>maximum</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise maximum of two tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with the element wise maximum value(s) of `x` and `y`. <p></p> Examples:
```python
# maximum of two tensors
>>> x = tf.Variable([[1, 2], [3, 4]])
>>> y = tf.Variable([[2, 1], [0, -1]])
>>> m = tf.keras.backend.maximum(x, y)
>>> m
<tf.Tensor: id=42, shape=(2, 2), dtype=int32, numpy=
array([[2, 2],
[3, 4]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="maximum_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>maximum_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise maximum of two tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with the element wise maximum value(s) of `x` and `y`. <p></p> Examples:
```python
# maximum of two tensors
>>> x = tf.Variable([[1, 2], [3, 4]])
>>> y = tf.Variable([[2, 1], [0, -1]])
>>> m = tf.keras.backend.maximum(x, y)
>>> m
<tf.Tensor: id=42, shape=(2, 2), dtype=int32, numpy=
array([[2, 2],
[3, 4]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="mean" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>mean</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Mean of a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>A list of integer. Axes to compute the mean. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1 for each entry in `axis`. If `keepdims` is `True`,
the reduced dimensions are retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with the mean of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="mean" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>mean</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Mean of a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>A list of integer. Axes to compute the mean. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1 for each entry in `axis`. If `keepdims` is `True`,
the reduced dimensions are retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with the mean of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="mean" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>mean</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Mean of a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>A list of integer. Axes to compute the mean. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1 for each entry in `axis`. If `keepdims` is `True`,
the reduced dimensions are retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with the mean of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="mean" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>mean</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Mean of a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>A list of integer. Axes to compute the mean. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1 for each entry in `axis`. If `keepdims` is `True`,
the reduced dimensions are retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with the mean of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="mean_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>mean_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims)
		</h4>
		<div class="content">Mean of a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>A list of integer. Axes to compute the mean. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1 for each entry in `axis`. If `keepdims` is `True`,
the reduced dimensions are retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with the mean of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="min" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>min</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Minimum value in a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>An integer, the axis to find minimum values. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with minimum values of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="min_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>min_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims)
		</h4>
		<div class="content">Minimum value in a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>An integer, the axis to find minimum values. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with minimum values of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="minimum" class="method">
		<h4>
			<span title="System.object">object</span> <strong>minimum</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y)
		</h4>
		<div class="content">Element-wise minimum of two tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="minimum_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>minimum_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise minimum of two tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="moving_average_update" class="method">
		<h4>
			<span title="System.object">object</span> <strong>moving_average_update</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> value, <span title="System.object">object</span> momentum)
		</h4>
		<div class="content">Compute the moving average of a variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A Variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A tensor with the same shape as `variable`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> momentum
						</dt>
						<dd>The moving average momentum. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An Operation to update the variable. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="moving_average_update_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>moving_average_update_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> value, <span title="System.object">object</span> momentum)
		</h4>
		<div class="content">Compute the moving average of a variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A Variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>A tensor with the same shape as `variable`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> momentum
						</dt>
						<dd>The moving average momentum. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>An Operation to update the variable. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="name_scope" class="method">
		<h4>
			<a href="../tensorflow.compat.v2/name_scope.htm">name_scope</a> <strong>name_scope</strong>(<span title="System.Collections.Generic.IEnumerator<object>">IEnumerator&lt;object&gt;</span> name)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="ndim" class="method">
		<h4>
			<span title="System.Nullable<int>">Nullable&lt;int&gt;</span> <strong>ndim</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x)
		</h4>
		<div class="content">Returns the number of axes in a tensor, as an integer. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code>
					</dt>
					<dd>Integer (scalar), number of axes. <p></p> Examples:
```python
>>> from keras import backend as K
>>> input = K.placeholder(shape=(2, 4, 5))
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.ndim(input)
3
>>> K.ndim(kvar)
2
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ndim" class="method">
		<h4>
			<span title="System.Nullable<int>">Nullable&lt;int&gt;</span> <strong>ndim</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x)
		</h4>
		<div class="content">Returns the number of axes in a tensor, as an integer. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code>
					</dt>
					<dd>Integer (scalar), number of axes. <p></p> Examples:
```python
>>> from keras import backend as K
>>> input = K.placeholder(shape=(2, 4, 5))
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.ndim(input)
3
>>> K.ndim(kvar)
2
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ndim" class="method">
		<h4>
			<span title="System.Nullable<int>">Nullable&lt;int&gt;</span> <strong>ndim</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Returns the number of axes in a tensor, as an integer. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code>
					</dt>
					<dd>Integer (scalar), number of axes. <p></p> Examples:
```python
>>> from keras import backend as K
>>> input = K.placeholder(shape=(2, 4, 5))
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.ndim(input)
3
>>> K.ndim(kvar)
2
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ndim_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ndim_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Returns the number of axes in a tensor, as an integer. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Integer (scalar), number of axes. <p></p> Examples:
```python
>>> from keras import backend as K
>>> input = K.placeholder(shape=(2, 4, 5))
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.ndim(input)
3
>>> K.ndim(kvar)
2
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="normalize_batch_in_training" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>normalize_batch_in_training</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> beta, <span title="System.ValueTuple<int, int, int>">ValueTuple&lt;int, int, int&gt;</span> reduction_axes, <span title="System.double">double</span> epsilon)
		</h4>
		<div class="content">Computes mean and std for batch then apply batch_normalization on batch. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, int>">ValueTuple&lt;int, int, int&gt;</span></code> reduction_axes
						</dt>
						<dd>iterable of integers,
axes over which to normalize. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple length of 3, `(normalized_tensor, mean, variance)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="normalize_batch_in_training_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>normalize_batch_in_training_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> gamma, <span title="System.object">object</span> beta, <span title="System.object">object</span> reduction_axes, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> epsilon)
		</h4>
		<div class="content">Computes mean and std for batch then apply batch_normalization on batch. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Input tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> gamma
						</dt>
						<dd>Tensor by which to scale the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> beta
						</dt>
						<dd>Tensor with which to center the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> reduction_axes
						</dt>
						<dd>iterable of integers,
axes over which to normalize. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> epsilon
						</dt>
						<dd>Fuzz factor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple length of 3, `(normalized_tensor, mean, variance)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="not_equal" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>not_equal</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise inequality between two tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="not_equal_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>not_equal_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y)
		</h4>
		<div class="content">Element-wise inequality between two tensors. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A bool tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="one_hot" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>one_hot</strong>(<span title="System.object">object</span> indices, <span title="System.object">object</span> num_classes)
		</h4>
		<div class="content">Computes the one-hot representation of an integer tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> indices
						</dt>
						<dd>nD integer tensor of shape
`(batch_size, dim1, dim2,... dim(n-1))` 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_classes
						</dt>
						<dd>Integer, number of classes to consider. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>(n + 1)D one hot representation of the input
with shape `(batch_size, dim1, dim2,... dim(n-1), num_classes)` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="one_hot_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>one_hot_dyn</strong>(<span title="System.object">object</span> indices, <span title="System.object">object</span> num_classes)
		</h4>
		<div class="content">Computes the one-hot representation of an integer tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> indices
						</dt>
						<dd>nD integer tensor of shape
`(batch_size, dim1, dim2,... dim(n-1))` 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_classes
						</dt>
						<dd>Integer, number of classes to consider. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>(n + 1)D one hot representation of the input
with shape `(batch_size, dim1, dim2,... dim(n-1), num_classes)` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ones" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ones</strong>(<span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span> shape, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Instantiates an all-ones variable and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span></code> shape
						</dt>
						<dd>Tuple of integers, shape of returned Keras variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, data type of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, filled with `1.0`.
Note that if `shape` was symbolic, we cannot return a variable,
and will return a dynamically-shaped tensor instead. <p></p> Example:
```python
>>> from keras import backend as K
>>> kvar = K.ones((3,4))
>>> K.eval(kvar)
array([[ 1.,  1.,  1.,  1.],
[ 1.,  1.,  1.,  1.],
[ 1.,  1.,  1.,  1.]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ones_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ones_dyn</strong>(<span title="System.object">object</span> shape, <span title="System.object">object</span> dtype, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Instantiates an all-ones variable and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> shape
						</dt>
						<dd>Tuple of integers, shape of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>String, data type of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, filled with `1.0`.
Note that if `shape` was symbolic, we cannot return a variable,
and will return a dynamically-shaped tensor instead. <p></p> Example:
```python
>>> from keras import backend as K
>>> kvar = K.ones((3,4))
>>> K.eval(kvar)
array([[ 1.,  1.,  1.,  1.],
[ 1.,  1.,  1.,  1.],
[ 1.,  1.,  1.,  1.]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ones_like" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ones_like</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Instantiates an all-ones variable of the same shape as another tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Keras variable or tensor. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned Keras variable.
None uses the dtype of x. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name for the variable to create. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A Keras variable with the shape of x filled with ones. <p></p> Example:
```python
>>> from keras import backend as K
>>> kvar = K.variable(np.random.random((2,3)))
>>> kvar_ones = K.ones_like(kvar)
>>> K.eval(kvar_ones)
array([[ 1.,  1.,  1.],
[ 1.,  1.,  1.]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ones_like" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ones_like</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Instantiates an all-ones variable of the same shape as another tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Keras variable or tensor. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned Keras variable.
None uses the dtype of x. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name for the variable to create. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A Keras variable with the shape of x filled with ones. <p></p> Example:
```python
>>> from keras import backend as K
>>> kvar = K.variable(np.random.random((2,3)))
>>> kvar_ones = K.ones_like(kvar)
>>> K.eval(kvar_ones)
array([[ 1.,  1.,  1.],
[ 1.,  1.,  1.]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="permute_dimensions" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>permute_dimensions</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> pattern)
		</h4>
		<div class="content">Permutes axes in a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> pattern
						</dt>
						<dd>A tuple of
dimension indices, e.g. `(0, 2, 1)`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=49, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.permute_dimensions(a, pattern=(1, 0))
<tf.Tensor: id=52, shape=(3, 4), dtype=int32, numpy=
array([[ 1,  4,  7, 10],
[ 2,  5,  8, 11],
[ 3,  6,  9, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="permute_dimensions" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>permute_dimensions</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> pattern)
		</h4>
		<div class="content">Permutes axes in a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> pattern
						</dt>
						<dd>A tuple of
dimension indices, e.g. `(0, 2, 1)`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=49, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.permute_dimensions(a, pattern=(1, 0))
<tf.Tensor: id=52, shape=(3, 4), dtype=int32, numpy=
array([[ 1,  4,  7, 10],
[ 2,  5,  8, 11],
[ 3,  6,  9, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="permute_dimensions_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>permute_dimensions_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> pattern)
		</h4>
		<div class="content">Permutes axes in a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> pattern
						</dt>
						<dd>A tuple of
dimension indices, e.g. `(0, 2, 1)`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=49, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.permute_dimensions(a, pattern=(1, 0))
<tf.Tensor: id=52, shape=(3, 4), dtype=int32, numpy=
array([[ 1,  4,  7, 10],
[ 2,  5,  8, 11],
[ 3,  6,  9, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="placeholder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>placeholder</strong>(<a href="../tensorflow/TensorShape.htm">TensorShape</a> shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> ndim, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> dtype, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> sparse, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> ragged)
		</h4>
		<div class="content">Instantiates a placeholder tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/TensorShape.htm">TensorShape</a></code> shape
						</dt>
						<dd>Shape of the placeholder
(integer tuple, may include `None` entries). 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> ndim
						</dt>
						<dd>Number of axes of the tensor.
At least one of {`shape`, `ndim`} must be specified.
If both are specified, `shape` is used. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> dtype
						</dt>
						<dd>Placeholder type. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> sparse
						</dt>
						<dd>Boolean, whether the placeholder should have a sparse type. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name string for the placeholder. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> ragged
						</dt>
						<dd>Boolean, whether the placeholder should have a ragged type.
In this case, values of 'None' in the 'shape' argument represent
ragged dimensions. For more information about RaggedTensors, see this
[guide](https://www.tensorflow.org/guide/ragged_tensors). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor instance (with Keras metadata included). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input_ph = K.placeholder(shape=(2, 4, 5))
>>> input_ph
<tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="placeholder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>placeholder</strong>(<a href="../tensorflow/TensorShape.htm">TensorShape</a> shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> ndim, <a href="../numpy/dtype.htm">dtype</a> dtype, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> sparse, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> ragged)
		</h4>
		<div class="content">Instantiates a placeholder tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/TensorShape.htm">TensorShape</a></code> shape
						</dt>
						<dd>Shape of the placeholder
(integer tuple, may include `None` entries). 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> ndim
						</dt>
						<dd>Number of axes of the tensor.
At least one of {`shape`, `ndim`} must be specified.
If both are specified, `shape` is used. 
						</dd>
						<dt>
							<code><a href="../numpy/dtype.htm">dtype</a></code> dtype
						</dt>
						<dd>Placeholder type. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> sparse
						</dt>
						<dd>Boolean, whether the placeholder should have a sparse type. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name string for the placeholder. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> ragged
						</dt>
						<dd>Boolean, whether the placeholder should have a ragged type.
In this case, values of 'None' in the 'shape' argument represent
ragged dimensions. For more information about RaggedTensors, see this
[guide](https://www.tensorflow.org/guide/ragged_tensors). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor instance (with Keras metadata included). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input_ph = K.placeholder(shape=(2, 4, 5))
>>> input_ph
<tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="placeholder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>placeholder</strong>(<a href="../tensorflow/TensorShape.htm">TensorShape</a> shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> ndim, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> sparse, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> ragged)
		</h4>
		<div class="content">Instantiates a placeholder tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/TensorShape.htm">TensorShape</a></code> shape
						</dt>
						<dd>Shape of the placeholder
(integer tuple, may include `None` entries). 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> ndim
						</dt>
						<dd>Number of axes of the tensor.
At least one of {`shape`, `ndim`} must be specified.
If both are specified, `shape` is used. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>Placeholder type. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> sparse
						</dt>
						<dd>Boolean, whether the placeholder should have a sparse type. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name string for the placeholder. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> ragged
						</dt>
						<dd>Boolean, whether the placeholder should have a ragged type.
In this case, values of 'None' in the 'shape' argument represent
ragged dimensions. For more information about RaggedTensors, see this
[guide](https://www.tensorflow.org/guide/ragged_tensors). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor instance (with Keras metadata included). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input_ph = K.placeholder(shape=(2, 4, 5))
>>> input_ph
<tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="placeholder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>placeholder</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> ndim, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> sparse, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> ragged)
		</h4>
		<div class="content">Instantiates a placeholder tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> shape
						</dt>
						<dd>Shape of the placeholder
(integer tuple, may include `None` entries). 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> ndim
						</dt>
						<dd>Number of axes of the tensor.
At least one of {`shape`, `ndim`} must be specified.
If both are specified, `shape` is used. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>Placeholder type. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> sparse
						</dt>
						<dd>Boolean, whether the placeholder should have a sparse type. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name string for the placeholder. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> ragged
						</dt>
						<dd>Boolean, whether the placeholder should have a ragged type.
In this case, values of 'None' in the 'shape' argument represent
ragged dimensions. For more information about RaggedTensors, see this
[guide](https://www.tensorflow.org/guide/ragged_tensors). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor instance (with Keras metadata included). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input_ph = K.placeholder(shape=(2, 4, 5))
>>> input_ph
<tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="placeholder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>placeholder</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> ndim, <a href="../numpy/dtype.htm">dtype</a> dtype, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> sparse, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> ragged)
		</h4>
		<div class="content">Instantiates a placeholder tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> shape
						</dt>
						<dd>Shape of the placeholder
(integer tuple, may include `None` entries). 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> ndim
						</dt>
						<dd>Number of axes of the tensor.
At least one of {`shape`, `ndim`} must be specified.
If both are specified, `shape` is used. 
						</dd>
						<dt>
							<code><a href="../numpy/dtype.htm">dtype</a></code> dtype
						</dt>
						<dd>Placeholder type. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> sparse
						</dt>
						<dd>Boolean, whether the placeholder should have a sparse type. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name string for the placeholder. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> ragged
						</dt>
						<dd>Boolean, whether the placeholder should have a ragged type.
In this case, values of 'None' in the 'shape' argument represent
ragged dimensions. For more information about RaggedTensors, see this
[guide](https://www.tensorflow.org/guide/ragged_tensors). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor instance (with Keras metadata included). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input_ph = K.placeholder(shape=(2, 4, 5))
>>> input_ph
<tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="placeholder" class="method">
		<h4>
			<span title="System.object">object</span> <strong>placeholder</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> shape, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> ndim, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> dtype, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> sparse, <span title="System.string">string</span> name, <span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span> ragged)
		</h4>
		<div class="content">Instantiates a placeholder tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> shape
						</dt>
						<dd>Shape of the placeholder
(integer tuple, may include `None` entries). 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> ndim
						</dt>
						<dd>Number of axes of the tensor.
At least one of {`shape`, `ndim`} must be specified.
If both are specified, `shape` is used. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> dtype
						</dt>
						<dd>Placeholder type. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> sparse
						</dt>
						<dd>Boolean, whether the placeholder should have a sparse type. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name string for the placeholder. 
						</dd>
						<dt>
							<code><span title="System.Nullable<bool>">Nullable&lt;bool&gt;</span></code> ragged
						</dt>
						<dd>Boolean, whether the placeholder should have a ragged type.
In this case, values of 'None' in the 'shape' argument represent
ragged dimensions. For more information about RaggedTensors, see this
[guide](https://www.tensorflow.org/guide/ragged_tensors). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor instance (with Keras metadata included). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input_ph = K.placeholder(shape=(2, 4, 5))
>>> input_ph
<tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="placeholder_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>placeholder_dyn</strong>(<span title="System.object">object</span> shape, <span title="System.object">object</span> ndim, <span title="System.object">object</span> dtype, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> sparse, <span title="System.object">object</span> name, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> ragged)
		</h4>
		<div class="content">Instantiates a placeholder tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> shape
						</dt>
						<dd>Shape of the placeholder
(integer tuple, may include `None` entries). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> ndim
						</dt>
						<dd>Number of axes of the tensor.
At least one of {`shape`, `ndim`} must be specified.
If both are specified, `shape` is used. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>Placeholder type. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> sparse
						</dt>
						<dd>Boolean, whether the placeholder should have a sparse type. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name string for the placeholder. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> ragged
						</dt>
						<dd>Boolean, whether the placeholder should have a ragged type.
In this case, values of 'None' in the 'shape' argument represent
ragged dimensions. For more information about RaggedTensors, see this
[guide](https://www.tensorflow.org/guide/ragged_tensors). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor instance (with Keras metadata included). <p></p> Examples:
```python
>>> from keras import backend as K
>>> input_ph = K.placeholder(shape=(2, 4, 5))
>>> input_ph
<tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> pool_size, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> pool_mode)
		</h4>
		<div class="content">2D Pooling. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> pool_size
						</dt>
						<dd>tuple of 2 integers. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>tuple of 2 integers. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pool_mode
						</dt>
						<dd>string, `"max"` or `"avg"`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 2D pooling. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool2d_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> pool_size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <span title="System.object">object</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> pool_mode)
		</h4>
		<div class="content">2D Pooling. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> pool_size
						</dt>
						<dd>tuple of 2 integers. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>tuple of 2 integers. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> pool_mode
						</dt>
						<dd>string, `"max"` or `"avg"`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 2D pooling. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool3d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool3d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> pool_size, <span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.string">string</span> pool_mode)
		</h4>
		<div class="content">3D Pooling. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> pool_size
						</dt>
						<dd>tuple of 3 integers. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object, object>">ValueTuple&lt;int, object, object&gt;</span></code> strides
						</dt>
						<dd>tuple of 3 integers. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> pool_mode
						</dt>
						<dd>string, `"max"` or `"avg"`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 3D pooling. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pool3d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pool3d_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> pool_size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <span title="System.object">object</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> pool_mode)
		</h4>
		<div class="content">3D Pooling. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> pool_size
						</dt>
						<dd>tuple of 3 integers. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>tuple of 3 integers. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> pool_mode
						</dt>
						<dd>string, `"max"` or `"avg"`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor, result of 3D pooling. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pow" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pow</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> a)
		</h4>
		<div class="content">Element-wise exponentiation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> a
						</dt>
						<dd>Python integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pow" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pow</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> a)
		</h4>
		<div class="content">Element-wise exponentiation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> a
						</dt>
						<dd>Python integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pow_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pow_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> a)
		</h4>
		<div class="content">Element-wise exponentiation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> a
						</dt>
						<dd>Python integer. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="print_tensor" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>print_tensor</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.string">string</span> message)
		</h4>
		<div class="content">Prints `message` and the tensor value when evaluated. <p></p> Note that `print_tensor` returns a new tensor identical to `x`
which should be used in the following code. Otherwise the
print operation is not taken into account during evaluation. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor to print. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> message
						</dt>
						<dd>Message to print jointly with the tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The same tensor `x`, unchanged. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>>>> x = K.print_tensor(x, message="x is: ") </pre>
</div>
		</div>
	</div>
	<div id="print_tensor_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>print_tensor_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> message)
		</h4>
		<div class="content">Prints `message` and the tensor value when evaluated. <p></p> Note that `print_tensor` returns a new tensor identical to `x`
which should be used in the following code. Otherwise the
print operation is not taken into account during evaluation. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor to print. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> message
						</dt>
						<dd>Message to print jointly with the tensor. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The same tensor `x`, unchanged. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>>>> x = K.print_tensor(x, message="x is: ") </pre>
</div>
		</div>
	</div>
	<div id="prod" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>prod</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Multiplies the values in a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>An integer, the axis to compute the product. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with the product of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="prod_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>prod_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims)
		</h4>
		<div class="content">Multiplies the values in a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>An integer, the axis to compute the product. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with the product of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_binomial" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>random_binomial</strong>(<span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> shape, <span title="System.double">double</span> p, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Returns a tensor with random binomial distribution of values. <p></p> The binomial distribution with parameters `n` and `p` is the probability
distribution of the number of successful Bernoulli process. Only supports
`n` = 1 for now. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> shape
						</dt>
						<dd>A tuple of integers, the shape of tensor to create. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> p
						</dt>
						<dd>A float, `0. <= p <= 1`, probability of binomial distribution. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_binomial_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_binomial_dyn</strong>(<span title="System.object">object</span> shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> p, <span title="System.object">object</span> dtype, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Returns a tensor with random binomial distribution of values. <p></p> The binomial distribution with parameters `n` and `p` is the probability
distribution of the number of successful Bernoulli process. Only supports
`n` = 1 for now. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> shape
						</dt>
						<dd>A tuple of integers, the shape of tensor to create. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> p
						</dt>
						<dd>A float, `0. <= p <= 1`, probability of binomial distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>String, dtype of returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_normal" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>random_normal</strong>(<span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> shape, <span title="System.double">double</span> mean, <span title="System.double">double</span> stddev, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Returns a tensor with normal distribution of values. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> shape
						</dt>
						<dd>A tuple of integers, the shape of tensor to create. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> mean
						</dt>
						<dd>A float, mean of the normal distribution to draw samples. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> stddev
						</dt>
						<dd>A float, standard deviation of the normal distribution
to draw samples. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_normal" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>random_normal</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> shape, <span title="System.double">double</span> mean, <span title="System.double">double</span> stddev, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Returns a tensor with normal distribution of values. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> shape
						</dt>
						<dd>A tuple of integers, the shape of tensor to create. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> mean
						</dt>
						<dd>A float, mean of the normal distribution to draw samples. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> stddev
						</dt>
						<dd>A float, standard deviation of the normal distribution
to draw samples. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_normal_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_normal_dyn</strong>(<span title="System.object">object</span> shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> mean, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> stddev, <span title="System.object">object</span> dtype, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Returns a tensor with normal distribution of values. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> shape
						</dt>
						<dd>A tuple of integers, the shape of tensor to create. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> mean
						</dt>
						<dd>A float, mean of the normal distribution to draw samples. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> stddev
						</dt>
						<dd>A float, standard deviation of the normal distribution
to draw samples. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>String, dtype of returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_normal_variable" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_normal_variable</strong>(<span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span> shape, <span title="System.int">int</span> mean, <span title="System.double">double</span> scale, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed)
		</h4>
		<div class="content">Instantiates a variable with values drawn from a normal distribution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span></code> shape
						</dt>
						<dd>Tuple of integers, shape of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mean
						</dt>
						<dd>Float, mean of the normal distribution. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> scale
						</dt>
						<dd>Float, standard deviation of the normal distribution. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, filled with drawn samples. <p></p> Example:
```python
# TensorFlow example
>>> kvar = K.random_normal_variable((2,3), 0, 1)
>>> kvar
<tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>
>>> K.eval(kvar)
array([[ 1.19591331,  0.68685907, -0.63814116],
[ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_normal_variable" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_normal_variable</strong>(<span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span> shape, <span title="System.int">int</span> mean, <span title="System.int">int</span> scale, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed)
		</h4>
		<div class="content">Instantiates a variable with values drawn from a normal distribution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span></code> shape
						</dt>
						<dd>Tuple of integers, shape of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mean
						</dt>
						<dd>Float, mean of the normal distribution. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> scale
						</dt>
						<dd>Float, standard deviation of the normal distribution. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, filled with drawn samples. <p></p> Example:
```python
# TensorFlow example
>>> kvar = K.random_normal_variable((2,3), 0, 1)
>>> kvar
<tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>
>>> K.eval(kvar)
array([[ 1.19591331,  0.68685907, -0.63814116],
[ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_normal_variable" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_normal_variable</strong>(<span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span> shape, <span title="System.double">double</span> mean, <span title="System.int">int</span> scale, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed)
		</h4>
		<div class="content">Instantiates a variable with values drawn from a normal distribution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span></code> shape
						</dt>
						<dd>Tuple of integers, shape of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> mean
						</dt>
						<dd>Float, mean of the normal distribution. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> scale
						</dt>
						<dd>Float, standard deviation of the normal distribution. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, filled with drawn samples. <p></p> Example:
```python
# TensorFlow example
>>> kvar = K.random_normal_variable((2,3), 0, 1)
>>> kvar
<tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>
>>> K.eval(kvar)
array([[ 1.19591331,  0.68685907, -0.63814116],
[ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_normal_variable" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_normal_variable</strong>(<span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span> shape, <span title="System.double">double</span> mean, <span title="System.double">double</span> scale, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed)
		</h4>
		<div class="content">Instantiates a variable with values drawn from a normal distribution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span></code> shape
						</dt>
						<dd>Tuple of integers, shape of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> mean
						</dt>
						<dd>Float, mean of the normal distribution. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> scale
						</dt>
						<dd>Float, standard deviation of the normal distribution. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, filled with drawn samples. <p></p> Example:
```python
# TensorFlow example
>>> kvar = K.random_normal_variable((2,3), 0, 1)
>>> kvar
<tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>
>>> K.eval(kvar)
array([[ 1.19591331,  0.68685907, -0.63814116],
[ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_normal_variable_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_normal_variable_dyn</strong>(<span title="System.object">object</span> shape, <span title="System.object">object</span> mean, <span title="System.object">object</span> scale, <span title="System.object">object</span> dtype, <span title="System.object">object</span> name, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Instantiates a variable with values drawn from a normal distribution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> shape
						</dt>
						<dd>Tuple of integers, shape of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mean
						</dt>
						<dd>Float, mean of the normal distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scale
						</dt>
						<dd>Float, standard deviation of the normal distribution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>String, dtype of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, filled with drawn samples. <p></p> Example:
```python
# TensorFlow example
>>> kvar = K.random_normal_variable((2,3), 0, 1)
>>> kvar
<tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>
>>> K.eval(kvar)
array([[ 1.19591331,  0.68685907, -0.63814116],
[ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_uniform" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>random_uniform</strong>(<span title="System.Nullable<ValueTuple<int, object>>">Nullable&lt;ValueTuple&lt;int, object&gt;&gt;</span> shape, <span title="System.double">double</span> minval, <span title="System.double">double</span> maxval, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Returns a tensor with uniform distribution of values. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Nullable<ValueTuple<int, object>>">Nullable&lt;ValueTuple&lt;int, object&gt;&gt;</span></code> shape
						</dt>
						<dd>A tuple of integers, the shape of tensor to create. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> minval
						</dt>
						<dd>A float, lower boundary of the uniform distribution
to draw samples. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> maxval
						</dt>
						<dd>A float, upper boundary of the uniform distribution
to draw samples. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_uniform_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_uniform_dyn</strong>(<span title="System.object">object</span> shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> minval, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> maxval, <span title="System.object">object</span> dtype, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Returns a tensor with uniform distribution of values. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> shape
						</dt>
						<dd>A tuple of integers, the shape of tensor to create. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> minval
						</dt>
						<dd>A float, lower boundary of the uniform distribution
to draw samples. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> maxval
						</dt>
						<dd>A float, upper boundary of the uniform distribution
to draw samples. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>String, dtype of returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_uniform_variable" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_uniform_variable</strong>(<span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span> shape, <span title="System.int">int</span> low, <span title="System.int">int</span> high, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed)
		</h4>
		<div class="content">Instantiates a variable with values drawn from a uniform distribution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<int, int>">ValueTuple&lt;int, int&gt;</span></code> shape
						</dt>
						<dd>Tuple of integers, shape of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> low
						</dt>
						<dd>Float, lower boundary of the output interval. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> high
						</dt>
						<dd>Float, upper boundary of the output interval. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, filled with drawn samples. <p></p> Example:
```python
# TensorFlow example
>>> kvar = K.random_uniform_variable((2,3), 0, 1)
>>> kvar
<tensorflow.python.ops.variables.Variable object at 0x10ab40b10>
>>> K.eval(kvar)
array([[ 0.10940075,  0.10047495,  0.476143  ],
[ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_uniform_variable_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_uniform_variable_dyn</strong>(<span title="System.object">object</span> shape, <span title="System.object">object</span> low, <span title="System.object">object</span> high, <span title="System.object">object</span> dtype, <span title="System.object">object</span> name, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Instantiates a variable with values drawn from a uniform distribution. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> shape
						</dt>
						<dd>Tuple of integers, shape of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> low
						</dt>
						<dd>Float, lower boundary of the output interval. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> high
						</dt>
						<dd>Float, upper boundary of the output interval. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>String, dtype of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>String, name of returned Keras variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Keras variable, filled with drawn samples. <p></p> Example:
```python
# TensorFlow example
>>> kvar = K.random_uniform_variable((2,3), 0, 1)
>>> kvar
<tensorflow.python.ops.variables.Variable object at 0x10ab40b10>
>>> K.eval(kvar)
array([[ 0.10940075,  0.10047495,  0.476143  ],
[ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.double">double</span> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> alpha, <span title="System.int">int</span> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> alpha, <span title="System.int">int</span> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.double">double</span> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.double">double</span> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.double">double</span> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.double">double</span> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> alpha, <span title="System.int">int</span> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.int">int</span> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.int">int</span> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> alpha, <span title="System.double">double</span> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> alpha, <span title="System.double">double</span> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> alpha, <span title="System.double">double</span> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> alpha, <span title="System.int">int</span> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> alpha, <span title="System.int">int</span> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.int">int</span> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.int">int</span> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> alpha, <span title="System.double">double</span> max_value, <span title="System.double">double</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <a href="../numpy/ndarray.htm">ndarray</a> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> alpha, <span title="System.double">double</span> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.int">int</span> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.int">int</span> max_value, <a href="../numpy/ndarray.htm">ndarray</a> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.double">double</span> alpha, <span title="System.double">double</span> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> alpha, <span title="System.int">int</span> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="relu" class="method">
		<h4>
			<span title="System.object">object</span> <strong>relu</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../numpy/ndarray.htm">ndarray</a> alpha, <span title="System.double">double</span> max_value, <span title="System.int">int</span> threshold)
		</h4>
		<div class="content">Rectified linear unit. <p></p> With default values, it returns element-wise `max(x, 0)`. <p></p> Otherwise, it follows:
`f(x) = max_value` for `x >= max_value`,
`f(x) = x` for `threshold <= x < max_value`,
`f(x) = alpha * (x - threshold)` otherwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> alpha
						</dt>
						<dd>A scalar, slope of negative section (default=`0.`). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_value
						</dt>
						<dd>float. Saturation threshold. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> threshold
						</dt>
						<dd>float. Threshold value for thresholded activation. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="repeat" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>repeat</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> n)
		</h4>
		<div class="content">Repeats a 2D tensor. <p></p> if `x` has shape (samples, dim) and `n` is `2`,
the output will have shape `(samples, 2, dim)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> n
						</dt>
						<dd>Python integer, number of times to repeat. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> b = tf.constant([[1, 2], [3, 4]])
>>> b
<tf.Tensor: id=78, shape=(2, 2), dtype=int32, numpy=
array([[1, 2],
[3, 4]], dtype=int32)>
>>> tf.keras.backend.repeat(b, n=2)
<tf.Tensor: id=82, shape=(2, 2, 2), dtype=int32, numpy=
array([[[1, 2],
[1, 2]],
[[3, 4],
[3, 4]]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="repeat" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>repeat</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> n)
		</h4>
		<div class="content">Repeats a 2D tensor. <p></p> if `x` has shape (samples, dim) and `n` is `2`,
the output will have shape `(samples, 2, dim)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> n
						</dt>
						<dd>Python integer, number of times to repeat. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> b = tf.constant([[1, 2], [3, 4]])
>>> b
<tf.Tensor: id=78, shape=(2, 2), dtype=int32, numpy=
array([[1, 2],
[3, 4]], dtype=int32)>
>>> tf.keras.backend.repeat(b, n=2)
<tf.Tensor: id=82, shape=(2, 2, 2), dtype=int32, numpy=
array([[[1, 2],
[1, 2]],
[[3, 4],
[3, 4]]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="repeat_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>repeat_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> n)
		</h4>
		<div class="content">Repeats a 2D tensor. <p></p> if `x` has shape (samples, dim) and `n` is `2`,
the output will have shape `(samples, 2, dim)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> n
						</dt>
						<dd>Python integer, number of times to repeat. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> b = tf.constant([[1, 2], [3, 4]])
>>> b
<tf.Tensor: id=78, shape=(2, 2), dtype=int32, numpy=
array([[1, 2],
[3, 4]], dtype=int32)>
>>> tf.keras.backend.repeat(b, n=2)
<tf.Tensor: id=82, shape=(2, 2, 2), dtype=int32, numpy=
array([[[1, 2],
[1, 2]],
[[3, 4],
[3, 4]]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="repeat_elements" class="method">
		<h4>
			<span title="System.object">object</span> <strong>repeat_elements</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> rep, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Repeats the elements of a tensor along an axis, like `np.repeat`. <p></p> If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output
will have shape `(s1, s2 * rep, s3)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rep
						</dt>
						<dd>Python integer, number of times to repeat. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Axis along which to repeat. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> b = tf.constant([1, 2, 3])
>>> tf.keras.backend.repeat_elements(b, rep=2, axis=0)
<tf.Tensor: id=70, shape=(6,), dtype=int32,
numpy=array([1, 1, 2, 2, 3, 3], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="repeat_elements" class="method">
		<h4>
			<span title="System.object">object</span> <strong>repeat_elements</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> rep, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Repeats the elements of a tensor along an axis, like `np.repeat`. <p></p> If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output
will have shape `(s1, s2 * rep, s3)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> rep
						</dt>
						<dd>Python integer, number of times to repeat. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Axis along which to repeat. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> b = tf.constant([1, 2, 3])
>>> tf.keras.backend.repeat_elements(b, rep=2, axis=0)
<tf.Tensor: id=70, shape=(6,), dtype=int32,
numpy=array([1, 1, 2, 2, 3, 3], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="repeat_elements_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>repeat_elements_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> rep, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Repeats the elements of a tensor along an axis, like `np.repeat`. <p></p> If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output
will have shape `(s1, s2 * rep, s3)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rep
						</dt>
						<dd>Python integer, number of times to repeat. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Axis along which to repeat. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> b = tf.constant([1, 2, 3])
>>> tf.keras.backend.repeat_elements(b, rep=2, axis=0)
<tf.Tensor: id=70, shape=(6,), dtype=int32,
numpy=array([1, 1, 2, 2, 3, 3], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reset_uids" class="method">
		<h4>
			<span title="System.void">void</span> <strong>reset_uids</strong>()
		</h4>
		<div class="content">Resets graph identifiers. <p></p> 




		</div>
	</div>
	<div id="reset_uids_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reset_uids_dyn</strong>()
		</h4>
		<div class="content">Resets graph identifiers. <p></p> 




		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<span title="System.object">object</span> x, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<span title="System.object">object</span> x, <span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../tensorflow/TensorShape.htm">TensorShape</a> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow/TensorShape.htm">TensorShape</a></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../tensorflow/TensorShape.htm">TensorShape</a> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow/TensorShape.htm">TensorShape</a></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<span title="System.object">object</span> x, <a href="../tensorflow/TensorShape.htm">TensorShape</a> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow/TensorShape.htm">TensorShape</a></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <a href="../tensorflow/TensorShape.htm">TensorShape</a> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../tensorflow/TensorShape.htm">TensorShape</a></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<span title="System.object">object</span> x, <span title="System.int">int</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <span title="System.int">int</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reshape</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> x, <span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object>">ValueTuple&lt;object&gt;</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reshape_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reshape_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> shape)
		</h4>
		<div class="content">Reshapes a tensor to the specified shape. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> shape
						</dt>
						<dd>Target shape tuple. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
>>> a
<tf.Tensor: id=32, shape=(4, 3), dtype=int32, numpy=
array([[ 1,  2,  3],
[ 4,  5,  6],
[ 7,  8,  9],
[10, 11, 12]], dtype=int32)>
>>> tf.keras.backend.reshape(a, shape=(2, 6))
<tf.Tensor: id=35, shape=(2, 6), dtype=int32, numpy=
array([[ 1,  2,  3,  4,  5,  6],
[ 7,  8,  9, 10, 11, 12]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_images" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_images</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> height_factor, <span title="System.int">int</span> width_factor, <span title="System.string">string</span> data_format, <span title="System.string">string</span> interpolation)
		</h4>
		<div class="content">Resizes the images contained in a 4D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable to resize. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> height_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> width_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `"channels_first"`, `"channels_last"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> interpolation
						</dt>
						<dd>A string, one of `nearest` or `bilinear`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_images" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_images</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> height_factor, <span title="System.int">int</span> width_factor, <span title="System.string">string</span> data_format, <span title="System.string">string</span> interpolation)
		</h4>
		<div class="content">Resizes the images contained in a 4D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable to resize. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> height_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> width_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `"channels_first"`, `"channels_last"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> interpolation
						</dt>
						<dd>A string, one of `nearest` or `bilinear`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_images_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_images_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> height_factor, <span title="System.object">object</span> width_factor, <span title="System.object">object</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> interpolation)
		</h4>
		<div class="content">Resizes the images contained in a 4D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable to resize. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> height_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> width_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>One of `"channels_first"`, `"channels_last"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> interpolation
						</dt>
						<dd>A string, one of `nearest` or `bilinear`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_volumes" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_volumes</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> depth_factor, <span title="System.int">int</span> height_factor, <span title="System.int">int</span> width_factor, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Resizes the volume contained in a 5D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable to resize. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> depth_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> height_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> width_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `"channels_first"`, `"channels_last"`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_volumes" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_volumes</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> depth_factor, <span title="System.int">int</span> height_factor, <span title="System.int">int</span> width_factor, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Resizes the volume contained in a 5D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable to resize. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> depth_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> height_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> width_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `"channels_first"`, `"channels_last"`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_volumes_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_volumes_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> depth_factor, <span title="System.object">object</span> height_factor, <span title="System.object">object</span> width_factor, <span title="System.object">object</span> data_format)
		</h4>
		<div class="content">Resizes the volume contained in a 5D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable to resize. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> depth_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> height_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> width_factor
						</dt>
						<dd>Positive integer. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>One of `"channels_first"`, `"channels_last"`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reverse" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reverse</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Reverse a tensor along the specified axes. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor to reverse. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>Integer or iterable of integers.
Axes to reverse. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reverse" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reverse</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Reverse a tensor along the specified axes. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Tensor to reverse. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>Integer or iterable of integers.
Axes to reverse. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reverse" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reverse</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Reverse a tensor along the specified axes. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Tensor to reverse. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>Integer or iterable of integers.
Axes to reverse. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reverse" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reverse</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> axes)
		</h4>
		<div class="content">Reverse a tensor along the specified axes. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor to reverse. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axes
						</dt>
						<dd>Integer or iterable of integers.
Axes to reverse. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reverse_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reverse_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axes)
		</h4>
		<div class="content">Reverse a tensor along the specified axes. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor to reverse. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axes
						</dt>
						<dd>Integer or iterable of integers.
Axes to reverse. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.object">object</span> inputs, <span title="System.object">object</span> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.object">object</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.object">object</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.object">object</span> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> inputs, <span title="System.object">object</span> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.object">object</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.object">object</span> inputs, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.object">object</span> inputs, <span title="System.object">object</span> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.object">object</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.object">object</span> inputs, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.object">object</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.object">object</span> inputs, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.object">object</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn" class="method">
		<h4>
			<span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> <strong>rnn</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> step_function, <span title="System.object">object</span> inputs, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> initial_states, <span title="System.bool">bool</span> go_backwards, <span title="System.object">object</span> mask, <span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> constants, <span title="System.bool">bool</span> unroll, <span title="System.object">object</span> input_length, <span title="System.bool">bool</span> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rnn_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>rnn_dyn</strong>(<span title="System.object">object</span> step_function, <span title="System.object">object</span> inputs, <span title="System.object">object</span> initial_states, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> go_backwards, <span title="System.object">object</span> mask, <span title="System.object">object</span> constants, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> unroll, <span title="System.object">object</span> input_length, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> time_major, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> zero_output_for_mask)
		</h4>
		<div class="content">Iterates over the time dimension of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> step_function
						</dt>
						<dd>RNN step function.
Args;
input; Tensor with shape `(samples,...)` (no time dimension),
representing input for the batch of samples at a certain
time step.
states; List of tensors.
Returns;
output; Tensor with shape `(samples, output_dim)`
(no time dimension).
new_states; List of tensors, same length and shapes
as 'states'. The first state in the list must be the
output tensor at the previous timestep. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> inputs
						</dt>
						<dd>Tensor of temporal data of shape `(samples, time,...)`
(at least 3D), or nested tensors, and each of which has shape
`(samples, time,...)`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_states
						</dt>
						<dd>Tensor with shape `(samples, state_size)`
(no time dimension), containing the initial values for the states used
in the step function. In the case that state_size is in a nested
shape, the shape of initial_states will also follow the nested
structure. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> go_backwards
						</dt>
						<dd>Boolean. If True, do the iteration over the time
dimension in reverse order and return the reversed sequence. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> mask
						</dt>
						<dd>Binary tensor with shape `(samples, time, 1)`,
with a zero for every element that is masked. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> constants
						</dt>
						<dd>List of constant values passed at each step. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> unroll
						</dt>
						<dd>Whether to unroll the RNN or to use a symbolic `while_loop`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>If specified, assume time dimension is of this length. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> time_major
						</dt>
						<dd>Boolean. If true, the inputs and outputs will be in shape
`(timesteps, batch,...)`, whereas in the False case, it will be
`(batch, timesteps,...)`. Using `time_major = True` is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> zero_output_for_mask
						</dt>
						<dd>Boolean. If True, the output for masked timestep
will be zeros, whereas in the False case, output from previous
timestep is returned. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple, `(last_output, outputs, new_states)`.
last_output: the latest output of the rnn, of shape `(samples,...)`
outputs: tensor with shape `(samples, time,...)` where each
entry `outputs[s, t]` is the output of the step function
at time `t` for sample `s`.
new_states: list of tensors, latest states returned by
the step function, of shape `(samples,...)`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="round" class="method">
		<h4>
			<span title="System.object">object</span> <strong>round</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise rounding to the closest integer. <p></p> In case of tie, the rounding mode used is "half to even". 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="round_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>round_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise rounding to the closest integer. <p></p> In case of tie, the rounding mode used is "half to even". 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d" class="method">
		<h4>
			<span title="System.object">object</span> <strong>separable_conv2d</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> depthwise_kernel, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> pointwise_kernel, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> strides, <span title="System.string">string</span> padding, <span title="System.string">string</span> data_format, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> dilation_rate)
		</h4>
		<div class="content">2D convolution with separable filters. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>input tensor 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> depthwise_kernel
						</dt>
						<dd>convolution kernel for the depthwise convolution. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> pointwise_kernel
						</dt>
						<dd>kernel for the 1x1 convolution. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> strides
						</dt>
						<dd>strides tuple (length 2). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> dilation_rate
						</dt>
						<dd>tuple of integers,
dilation rates for the separable convolution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="separable_conv2d_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>separable_conv2d_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> depthwise_kernel, <span title="System.object">object</span> pointwise_kernel, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> strides, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <span title="System.object">object</span> data_format, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> dilation_rate)
		</h4>
		<div class="content">2D convolution with separable filters. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>input tensor 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> depthwise_kernel
						</dt>
						<dd>convolution kernel for the depthwise convolution. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> pointwise_kernel
						</dt>
						<dd>kernel for the 1x1 convolution. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> strides
						</dt>
						<dd>strides tuple (length 2). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>string, `"same"` or `"valid"`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>string, `"channels_last"` or `"channels_first"`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> dilation_rate
						</dt>
						<dd>tuple of integers,
dilation rates for the separable convolution. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="set_epsilon" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_epsilon</strong>(<span title="System.double">double</span> value)
		</h4>
		<div class="content">Sets the value of the fuzz factor used in numeric expressions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.double">double</span></code> value
						</dt>
						<dd>float. New value of epsilon.
Example: ```python from keras import backend as K K.epsilon() >>> 1e-07
K.set_epsilon(1e-05) K.epsilon() >>> 1e-05 ``` 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_epsilon_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>set_epsilon_dyn</strong>(<span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the value of the fuzz factor used in numeric expressions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>float. New value of epsilon.
Example: ```python from keras import backend as K K.epsilon() >>> 1e-07
K.set_epsilon(1e-05) K.epsilon() >>> 1e-05 ``` 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_floatx" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_floatx</strong>(<span title="System.string">string</span> value)
		</h4>
		<div class="content">Sets the default float type. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.string">string</span></code> value
						</dt>
						<dd>String; 'float16', 'float32', or 'float64'.
Example: ```python from keras import backend as K K.floatx() >>> 'float32'
K.set_floatx('float16') K.floatx() >>> 'float16' ``` 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_floatx_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>set_floatx_dyn</strong>(<span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the default float type. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>String; 'float16', 'float32', or 'float64'.
Example: ```python from keras import backend as K K.floatx() >>> 'float32'
K.set_floatx('float16') K.floatx() >>> 'float16' ``` 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_image_data_format" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_image_data_format</strong>(<span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Sets the value of the image data format convention. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>string. `'channels_first'` or `'channels_last'`.
Example: ```python from keras import backend as K K.image_data_format() >>>
'channels_first' K.set_image_data_format('channels_last')
K.image_data_format() >>> 'channels_last' ``` 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_image_data_format_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>set_image_data_format_dyn</strong>(<span title="System.object">object</span> data_format)
		</h4>
		<div class="content">Sets the value of the image data format convention. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>string. `'channels_first'` or `'channels_last'`.
Example: ```python from keras import backend as K K.image_data_format() >>>
'channels_first' K.set_image_data_format('channels_last')
K.image_data_format() >>> 'channels_last' ``` 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_learning_phase" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_learning_phase</strong>(<span title="System.Nullable<int>">Nullable&lt;int&gt;</span> value)
		</h4>
		<div class="content">Sets the learning phase to a fixed value. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> value
						</dt>
						<dd>Learning phase value, either 0 or 1 (integers). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_learning_phase" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_learning_phase</strong>(<span title="System.bool">bool</span> value)
		</h4>
		<div class="content">Sets the learning phase to a fixed value. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.bool">bool</span></code> value
						</dt>
						<dd>Learning phase value, either 0 or 1 (integers). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_learning_phase_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>set_learning_phase_dyn</strong>(<span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the learning phase to a fixed value. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Learning phase value, either 0 or 1 (integers). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_session" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_session</strong>(<a href="../tensorflow.python.debug/LocalCLIDebugWrapperSession.htm">LocalCLIDebugWrapperSession</a> session)
		</h4>
		<div class="content">Sets the global TensorFlow session. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.debug/LocalCLIDebugWrapperSession.htm">LocalCLIDebugWrapperSession</a></code> session
						</dt>
						<dd>A TF Session. 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_session" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_session</strong>(<a href="../tensorflow/Session.htm">Session</a> session)
		</h4>
		<div class="content">Sets the global TensorFlow session. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> session
						</dt>
						<dd>A TF Session. 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_session_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>set_session_dyn</strong>(<span title="System.object">object</span> session)
		</h4>
		<div class="content">Sets the global TensorFlow session. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> session
						</dt>
						<dd>A TF Session. 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> x, <span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> x, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../numpy/_ArrayLike.htm">_ArrayLike</a> x, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/_ArrayLike.htm">_ArrayLike</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> x, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../tensorflow.python.training.tracking.base/Trackable.htm">Trackable</a> x, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.training.tracking.base/Trackable.htm">Trackable</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../tensorflow.python.training.tracking.base/Trackable.htm">Trackable</a> x, <span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.training.tracking.base/Trackable.htm">Trackable</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../numpy/ndarray.htm">ndarray</a> x, <span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a> x, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.contrib.tpu.python.tpu.keras_tpu_variables/ReplicatedVariable.htm">ReplicatedVariable</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a> x, <span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.ops.resource_variable_ops/ResourceVariable.htm">ResourceVariable</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../numpy/_ArrayLike.htm">_ArrayLike</a> x, <span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/_ArrayLike.htm">_ArrayLike</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value" class="method">
		<h4>
			<span title="System.void">void</span> <strong>set_value</strong>(<a href="../numpy/ndarray.htm">ndarray</a> x, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="set_value_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>set_value_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> value)
		</h4>
		<div class="content">Sets the value of a variable, from a Numpy array. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor to set to a new value. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Value to set the tensor to, as a Numpy array
(of the same shape). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	<div id="shape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>shape</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x)
		</h4>
		<div class="content">Returns the symbolic shape of a tensor or variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A symbolic shape (which is itself a tensor). <p></p> Examples: <p></p> ```python
# TensorFlow example
>>> from keras import backend as K
>>> tf_session = K.get_session()
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> input = keras.backend.placeholder(shape=(2, 4, 5))
>>> K.shape(kvar)
<tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>
>>> K.shape(input)
<tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>
# To get integer shape (Instead, you can use K.int_shape(x))
>>> K.shape(kvar).eval(session=tf_session)
array([2, 2], dtype=int32)
>>> K.shape(input).eval(session=tf_session)
array([2, 4, 5], dtype=int32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="shape" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>shape</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x)
		</h4>
		<div class="content">Returns the symbolic shape of a tensor or variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A symbolic shape (which is itself a tensor). <p></p> Examples: <p></p> ```python
# TensorFlow example
>>> from keras import backend as K
>>> tf_session = K.get_session()
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> input = keras.backend.placeholder(shape=(2, 4, 5))
>>> K.shape(kvar)
<tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>
>>> K.shape(input)
<tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>
# To get integer shape (Instead, you can use K.int_shape(x))
>>> K.shape(kvar).eval(session=tf_session)
array([2, 2], dtype=int32)
>>> K.shape(input).eval(session=tf_session)
array([2, 4, 5], dtype=int32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="shape_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>shape_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Returns the symbolic shape of a tensor or variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A symbolic shape (which is itself a tensor). <p></p> Examples: <p></p> ```python
# TensorFlow example
>>> from keras import backend as K
>>> tf_session = K.get_session()
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> input = keras.backend.placeholder(shape=(2, 4, 5))
>>> K.shape(kvar)
<tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>
>>> K.shape(input)
<tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>
# To get integer shape (Instead, you can use K.int_shape(x))
>>> K.shape(kvar).eval(session=tf_session)
array([2, 2], dtype=int32)
>>> K.shape(input).eval(session=tf_session)
array([2, 4, 5], dtype=int32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sigmoid" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sigmoid</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x)
		</h4>
		<div class="content">Element-wise sigmoid. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sign" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sign</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise sign. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sign_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sign_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise sign. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sin" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sin</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Computes sin of x element-wise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sin_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sin_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Computes sin of x element-wise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softmax" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softmax</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Softmax of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimension softmax would be performed on.
The default is -1 which indicates the last dimension. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softplus" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softplus</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Softplus of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="softsign" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>softsign</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Softsign of a tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_categorical_crossentropy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sparse_categorical_crossentropy</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> output, <span title="System.bool">bool</span> from_logits, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Categorical crossentropy with integer targets. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target
						</dt>
						<dd>An integer tensor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> output
						</dt>
						<dd>A tensor resulting from a softmax
(unless `from_logits` is True, in which
case `output` is expected to be the logits). 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> from_logits
						</dt>
						<dd>Boolean, whether `output` is the
result of a softmax, or is a tensor of logits. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>Int specifying the channels axis. `axis=-1` corresponds to data
format `channels_last', and `axis=1` corresponds to data format
`channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sparse_categorical_crossentropy_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sparse_categorical_crossentropy_dyn</strong>(<span title="System.object">object</span> target, <span title="System.object">object</span> output, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> from_logits, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis)
		</h4>
		<div class="content">Categorical crossentropy with integer targets. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> target
						</dt>
						<dd>An integer tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output
						</dt>
						<dd>A tensor resulting from a softmax
(unless `from_logits` is True, in which
case `output` is expected to be the logits). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> from_logits
						</dt>
						<dd>Boolean, whether `output` is the
result of a softmax, or is a tensor of logits. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>Int specifying the channels axis. `axis=-1` corresponds to data
format `channels_last', and `axis=1` corresponds to data format
`channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Output tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="spatial_2d_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>spatial_2d_padding</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> padding, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Pads the 2nd and 3rd dimensions of a 4D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Tuple of 2 tuples, padding pattern. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `channels_last` or `channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 4D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="spatial_2d_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>spatial_2d_padding</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> padding, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Pads the 2nd and 3rd dimensions of a 4D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code> padding
						</dt>
						<dd>Tuple of 2 tuples, padding pattern. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `channels_last` or `channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 4D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="spatial_2d_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>spatial_2d_padding</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> padding, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Pads the 2nd and 3rd dimensions of a 4D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Tuple of 2 tuples, padding pattern. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `channels_last` or `channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 4D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="spatial_2d_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>spatial_2d_padding</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> padding, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Pads the 2nd and 3rd dimensions of a 4D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code> padding
						</dt>
						<dd>Tuple of 2 tuples, padding pattern. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `channels_last` or `channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 4D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="spatial_2d_padding_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>spatial_2d_padding_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <span title="System.object">object</span> data_format)
		</h4>
		<div class="content">Pads the 2nd and 3rd dimensions of a 4D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>Tuple of 2 tuples, padding pattern. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>One of `channels_last` or `channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A padded 4D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="spatial_3d_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>spatial_3d_padding</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> padding, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Pads 5D tensor with zeros along the depth, height, width dimensions. <p></p> Pads these dimensions with respectively
"padding[0]", "padding[1]" and "padding[2]" zeros left and right. <p></p> For 'channels_last' data_format,
the 2nd, 3rd and 4th dimension will be padded.
For 'channels_first' data_format,
the 3rd, 4th and 5th dimension will be padded. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Tuple of 3 tuples, padding pattern. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `channels_last` or `channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 5D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="spatial_3d_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>spatial_3d_padding</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> padding, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Pads 5D tensor with zeros along the depth, height, width dimensions. <p></p> Pads these dimensions with respectively
"padding[0]", "padding[1]" and "padding[2]" zeros left and right. <p></p> For 'channels_last' data_format,
the 2nd, 3rd and 4th dimension will be padded.
For 'channels_first' data_format,
the 3rd, 4th and 5th dimension will be padded. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code> padding
						</dt>
						<dd>Tuple of 3 tuples, padding pattern. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `channels_last` or `channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 5D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="spatial_3d_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>spatial_3d_padding</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> padding, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Pads 5D tensor with zeros along the depth, height, width dimensions. <p></p> Pads these dimensions with respectively
"padding[0]", "padding[1]" and "padding[2]" zeros left and right. <p></p> For 'channels_last' data_format,
the 2nd, 3rd and 4th dimension will be padded.
For 'channels_first' data_format,
the 3rd, 4th and 5th dimension will be padded. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Tuple of 3 tuples, padding pattern. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `channels_last` or `channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 5D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="spatial_3d_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>spatial_3d_padding</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span> padding, <span title="System.string">string</span> data_format)
		</h4>
		<div class="content">Pads 5D tensor with zeros along the depth, height, width dimensions. <p></p> Pads these dimensions with respectively
"padding[0]", "padding[1]" and "padding[2]" zeros left and right. <p></p> For 'channels_last' data_format,
the 2nd, 3rd and 4th dimension will be padded.
For 'channels_first' data_format,
the 3rd, 4th and 5th dimension will be padded. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<object, object, object>">ValueTuple&lt;object, object, object&gt;</span></code> padding
						</dt>
						<dd>Tuple of 3 tuples, padding pattern. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> data_format
						</dt>
						<dd>One of `channels_last` or `channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 5D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="spatial_3d_padding_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>spatial_3d_padding_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding, <span title="System.object">object</span> data_format)
		</h4>
		<div class="content">Pads 5D tensor with zeros along the depth, height, width dimensions. <p></p> Pads these dimensions with respectively
"padding[0]", "padding[1]" and "padding[2]" zeros left and right. <p></p> For 'channels_last' data_format,
the 2nd, 3rd and 4th dimension will be padded.
For 'channels_first' data_format,
the 3rd, 4th and 5th dimension will be padded. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>Tuple of 3 tuples, padding pattern. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> data_format
						</dt>
						<dd>One of `channels_last` or `channels_first`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A padded 5D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sqrt" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sqrt</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x)
		</h4>
		<div class="content">Element-wise square root. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sqrt" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sqrt</strong>(<a href="../numpy/_ArrayLike.htm">_ArrayLike</a> x)
		</h4>
		<div class="content">Element-wise square root. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/_ArrayLike.htm">_ArrayLike</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sqrt_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sqrt_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise square root. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="square" class="method">
		<h4>
			<span title="System.object">object</span> <strong>square</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise square. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="square_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>square_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise square. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="squeeze" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>squeeze</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Removes a 1-dimension from the tensor at index "axis". 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Axis to drop. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with the same data as `x` but reduced dimensions. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="squeeze_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>squeeze_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis)
		</h4>
		<div class="content">Removes a 1-dimension from the tensor at index "axis". 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>Axis to drop. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with the same data as `x` but reduced dimensions. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="stack" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>stack</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <span title="System.int">int</span> axis)
		</h4>
		<div class="content">Join a sequence of arrays along a new axis. 




		</div>
	</div>
	<div id="stack_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stack_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis)
		</h4>
		<div class="content">Stacks a list of rank `R` tensors into a rank `R+1` tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>List of tensors. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>Axis along which to perform stacking. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. <p></p> Example:
```python
>>> a = tf.constant([[1, 2],[3, 4]])
>>> b = tf.constant([[10, 20],[30, 40]])
>>> tf.keras.backend.stack((a, b))
<tf.Tensor: id=146, shape=(2, 2, 2), dtype=int32, numpy=
array([[[ 1,  2],
[ 3,  4]],
[[10, 20],
[30, 40]]], dtype=int32)>
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>std</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Standard deviation of a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>An integer, the axis to compute the standard deviation. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with the standard deviation of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="std_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>std_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims)
		</h4>
		<div class="content">Standard deviation of a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>An integer, the axis to compute the standard deviation. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with the standard deviation of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="stop_gradient" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_gradient</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> variables)
		</h4>
		<div class="content">Returns `variables` but with zero gradient w.r.t. every other variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> variables
						</dt>
						<dd>Tensor or list of tensors to consider constant with respect
to any other variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A single tensor or a list of tensors (depending on the passed argument)
that has no gradient with respect to any other variable. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="stop_gradient" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_gradient</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> variables)
		</h4>
		<div class="content">Returns `variables` but with zero gradient w.r.t. every other variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> variables
						</dt>
						<dd>Tensor or list of tensors to consider constant with respect
to any other variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A single tensor or a list of tensors (depending on the passed argument)
that has no gradient with respect to any other variable. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="stop_gradient" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_gradient</strong>(<span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> variables)
		</h4>
		<div class="content">Returns `variables` but with zero gradient w.r.t. every other variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span></code> variables
						</dt>
						<dd>Tensor or list of tensors to consider constant with respect
to any other variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A single tensor or a list of tensors (depending on the passed argument)
that has no gradient with respect to any other variable. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="stop_gradient_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>stop_gradient_dyn</strong>(<span title="System.object">object</span> variables)
		</h4>
		<div class="content">Returns `variables` but with zero gradient w.r.t. every other variable. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> variables
						</dt>
						<dd>Tensor or list of tensors to consider constant with respect
to any other variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A single tensor or a list of tensors (depending on the passed argument)
that has no gradient with respect to any other variable. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sum" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sum</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Sum of the values in a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>An integer, the axis to sum over. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with sum of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sum" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sum</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Sum of the values in a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> axis
						</dt>
						<dd>An integer, the axis to sum over. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor with sum of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sum_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sum_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims)
		</h4>
		<div class="content">Sum of the values in a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>An integer, the axis to sum over. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with sum of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.bool">bool</span> condition, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.bool">bool</span> condition, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.bool">bool</span> condition, <span title="System.object">object</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> condition, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> condition, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> condition, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> condition, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> condition, <span title="System.object">object</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> condition, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> condition, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> condition, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> condition, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> condition, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> condition, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> condition, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> condition, <span title="System.object">object</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> condition, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> condition, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.bool">bool</span> condition, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> condition, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> condition, <span title="System.object">object</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.int">int</span> condition, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.int">int</span> condition, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.int">int</span> condition, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.int">int</span> condition, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> condition, <span title="System.object">object</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> condition, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.bool">bool</span> condition, <span title="System.ValueTuple<IEnumerable<object>, object>">ValueTuple&lt;IEnumerable&lt;object&gt;, object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> condition, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="switch" class="method">
		<h4>
			<span title="System.object">object</span> <strong>switch</strong>(<span title="System.int">int</span> condition, <span title="System.object">object</span> then_expression, <span title="System.object">object</span> else_expression)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="tanh" class="method">
		<h4>
			<span title="System.object">object</span> <strong>tanh</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise tanh. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="tanh_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>tanh_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Element-wise tanh. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="temporal_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>temporal_padding</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> padding)
		</h4>
		<div class="content">Pads the middle dimension of a 3D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> padding
						</dt>
						<dd>Tuple of 2 integers, how many zeros to
add at the start and end of dim 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 3D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="temporal_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>temporal_padding</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding)
		</h4>
		<div class="content">Pads the middle dimension of a 3D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>Tuple of 2 integers, how many zeros to
add at the start and end of dim 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 3D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="temporal_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>temporal_padding</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> padding)
		</h4>
		<div class="content">Pads the middle dimension of a 3D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> padding
						</dt>
						<dd>Tuple of 2 integers, how many zeros to
add at the start and end of dim 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 3D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="temporal_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>temporal_padding</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding)
		</h4>
		<div class="content">Pads the middle dimension of a 3D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>Tuple of 2 integers, how many zeros to
add at the start and end of dim 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 3D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="temporal_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>temporal_padding</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> x, <span title="System.int">int</span> padding)
		</h4>
		<div class="content">Pads the middle dimension of a 3D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Tuple of 2 integers, how many zeros to
add at the start and end of dim 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 3D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="temporal_padding" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>temporal_padding</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> padding)
		</h4>
		<div class="content">Pads the middle dimension of a 3D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> padding
						</dt>
						<dd>Tuple of 2 integers, how many zeros to
add at the start and end of dim 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A padded 3D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="temporal_padding_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>temporal_padding_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> padding)
		</h4>
		<div class="content">Pads the middle dimension of a 3D tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> padding
						</dt>
						<dd>Tuple of 2 integers, how many zeros to
add at the start and end of dim 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A padded 3D tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="tile" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>tile</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> n)
		</h4>
		<div class="content">Creates a tensor by tiling `x` by `n`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> n
						</dt>
						<dd>A list of integer. The length must be the same as the number of
dimensions in `x`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tiled tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="tile" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>tile</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> n)
		</h4>
		<div class="content">Creates a tensor by tiling `x` by `n`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> n
						</dt>
						<dd>A list of integer. The length must be the same as the number of
dimensions in `x`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tiled tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="tile" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>tile</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> n)
		</h4>
		<div class="content">Creates a tensor by tiling `x` by `n`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A tensor or variable 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> n
						</dt>
						<dd>A list of integer. The length must be the same as the number of
dimensions in `x`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tiled tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="tile_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>tile_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> n)
		</h4>
		<div class="content">Construct an array by repeating A the number of times given by reps. 




		</div>
	</div>
	<div id="to_dense" class="method">
		<h4>
			<span title="System.object">object</span> <strong>to_dense</strong>(<span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span> tensor)
		</h4>
		<div class="content">Converts a sparse tensor into a dense tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<IGraphNodeBase>">IEnumerable&lt;IGraphNodeBase&gt;</span></code> tensor
						</dt>
						<dd>A tensor instance (potentially sparse). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor. <p></p> Examples:
```python
>>> from keras import backend as K
>>> b = K.placeholder((2, 2), sparse=True)
>>> print(K.is_sparse(b))
True
>>> c = K.to_dense(b)
>>> print(K.is_sparse(c))
False
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="to_dense" class="method">
		<h4>
			<span title="System.object">object</span> <strong>to_dense</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> tensor)
		</h4>
		<div class="content">Converts a sparse tensor into a dense tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> tensor
						</dt>
						<dd>A tensor instance (potentially sparse). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor. <p></p> Examples:
```python
>>> from keras import backend as K
>>> b = K.placeholder((2, 2), sparse=True)
>>> print(K.is_sparse(b))
True
>>> c = K.to_dense(b)
>>> print(K.is_sparse(c))
False
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="to_dense" class="method">
		<h4>
			<span title="System.object">object</span> <strong>to_dense</strong>(<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> tensor)
		</h4>
		<div class="content">Converts a sparse tensor into a dense tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> tensor
						</dt>
						<dd>A tensor instance (potentially sparse). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor. <p></p> Examples:
```python
>>> from keras import backend as K
>>> b = K.placeholder((2, 2), sparse=True)
>>> print(K.is_sparse(b))
True
>>> c = K.to_dense(b)
>>> print(K.is_sparse(c))
False
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="to_dense_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>to_dense_dyn</strong>(<span title="System.object">object</span> tensor)
		</h4>
		<div class="content">Converts a sparse tensor into a dense tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> tensor
						</dt>
						<dd>A tensor instance (potentially sparse). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A dense tensor. <p></p> Examples:
```python
>>> from keras import backend as K
>>> b = K.placeholder((2, 2), sparse=True)
>>> print(K.is_sparse(b))
True
>>> c = K.to_dense(b)
>>> print(K.is_sparse(c))
False
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x)
		</h4>
		<div class="content">Transposes a tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. <p></p> Examples:
```python
>>> var = K.variable([[1, 2, 3], [4, 5, 6]])
>>> K.eval(var)
array([[ 1.,  2.,  3.],
[ 4.,  5.,  6.]], dtype=float32)
>>> var_transposed = K.transpose(var)
>>> K.eval(var_transposed)
array([[ 1.,  4.],
[ 2.,  5.],
[ 3.,  6.]], dtype=float32)
``` <p></p> ```python
>>> input = K.placeholder((2, 3))
>>> input
<tf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32>
>>> input_transposed = K.transpose(input)
>>> input_transposed
<tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32> <p></p> ``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="transpose_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>transpose_dyn</strong>(<span title="System.object">object</span> x)
		</h4>
		<div class="content">Transposes a tensor and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>Tensor or variable. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. <p></p> Examples:
```python
>>> var = K.variable([[1, 2, 3], [4, 5, 6]])
>>> K.eval(var)
array([[ 1.,  2.,  3.],
[ 4.,  5.,  6.]], dtype=float32)
>>> var_transposed = K.transpose(var)
>>> K.eval(var_transposed)
array([[ 1.,  4.],
[ 2.,  5.],
[ 3.,  6.]], dtype=float32)
``` <p></p> ```python
>>> input = K.placeholder((2, 3))
>>> input
<tf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32>
>>> input_transposed = K.transpose(input)
>>> input_transposed
<tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32> <p></p> ``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="truncated_normal" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>truncated_normal</strong>(<span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> shape, <span title="System.double">double</span> mean, <span title="System.double">double</span> stddev, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Returns a tensor with truncated random normal distribution of values. <p></p> The generated values follow a normal distribution
with specified mean and standard deviation,
except that values whose magnitude is more than
two standard deviations from the mean are dropped and re-picked. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> shape
						</dt>
						<dd>A tuple of integers, the shape of tensor to create. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> mean
						</dt>
						<dd>Mean of the values. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> stddev
						</dt>
						<dd>Standard deviation of the values. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>String, dtype of returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="truncated_normal_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>truncated_normal_dyn</strong>(<span title="System.object">object</span> shape, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> mean, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> stddev, <span title="System.object">object</span> dtype, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Returns a tensor with truncated random normal distribution of values. <p></p> The generated values follow a normal distribution
with specified mean and standard deviation,
except that values whose magnitude is more than
two standard deviations from the mean are dropped and re-picked. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> shape
						</dt>
						<dd>A tuple of integers, the shape of tensor to create. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> mean
						</dt>
						<dd>Mean of the values. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> stddev
						</dt>
						<dd>Standard deviation of the values. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>String, dtype of returned tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>Integer, random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="update" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>update</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> new_x)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="update" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>update</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.double">double</span> new_x)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="update_add" class="method">
		<h4>
			<span title="System.object">object</span> <strong>update_add</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> increment)
		</h4>
		<div class="content">Update the value of `x` by adding `increment`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A Variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> increment
						</dt>
						<dd>A tensor of same shape as `x`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The variable `x` updated. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="update_add_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>update_add_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> increment)
		</h4>
		<div class="content">Update the value of `x` by adding `increment`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A Variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> increment
						</dt>
						<dd>A tensor of same shape as `x`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The variable `x` updated. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="update_sub" class="method">
		<h4>
			<span title="System.object">object</span> <strong>update_sub</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> decrement)
		</h4>
		<div class="content">Update the value of `x` by subtracting `decrement`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A Variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> decrement
						</dt>
						<dd>A tensor of same shape as `x`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The variable `x` updated. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="update_sub_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>update_sub_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> decrement)
		</h4>
		<div class="content">Update the value of `x` by subtracting `decrement`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A Variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> decrement
						</dt>
						<dd>A tensor of same shape as `x`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The variable `x` updated. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="var" class="method">
		<h4>
			<span title="System.object">object</span> <strong>var</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <span title="System.bool">bool</span> keepdims)
		</h4>
		<div class="content">Variance of a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>An integer, the axis to compute the variance. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with the variance of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="var_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>var_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims)
		</h4>
		<div class="content">Variance of a tensor, alongside the specified axis. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A tensor or variable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>An integer, the axis to compute the variance. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>A boolean, whether to keep the dimensions or not.
If `keepdims` is `False`, the rank of the tensor is reduced
by 1. If `keepdims` is `True`,
the reduced dimension is retained with length 1. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor with the variance of elements of `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="variable" class="method">
		<h4>
			<span title="System.object">object</span> <strong>variable</strong>(<span title="System.object">object</span> value, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name, <span title="System.object">object</span> constraint)
		</h4>
		<div class="content">Instantiates a variable and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Numpy array, initial value of the tensor. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>Tensor type. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Optional name string for the tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> constraint
						</dt>
						<dd>Optional projection function to be
applied to the variable after an optimizer update. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A variable instance (with Keras metadata included). <p></p> Examples:
```python
>>> import numpy as np
>>> from keras import backend as K
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val, dtype='float64', name='example_var')
>>> K.dtype(kvar)
'float64'
>>> print(kvar)
example_var
>>> kvar.eval()
array([[ 1.,  2.],
[ 3.,  4.]])
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="variable_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>variable_dyn</strong>(<span title="System.object">object</span> value, <span title="System.object">object</span> dtype, <span title="System.object">object</span> name, <span title="System.object">object</span> constraint)
		</h4>
		<div class="content">Instantiates a variable and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> value
						</dt>
						<dd>Numpy array, initial value of the tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>Tensor type. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Optional name string for the tensor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> constraint
						</dt>
						<dd>Optional projection function to be
applied to the variable after an optimizer update. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A variable instance (with Keras metadata included). <p></p> Examples:
```python
>>> import numpy as np
>>> from keras import backend as K
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val, dtype='float64', name='example_var')
>>> K.dtype(kvar)
'float64'
>>> print(kvar)
example_var
>>> kvar.eval()
array([[ 1.,  2.],
[ 3.,  4.]])
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="zeros" class="method">
		<h4>
			<span title="System.object">object</span> <strong>zeros</strong>(<span title="System.int">int</span> shape, <span title="System.string">string</span> dtype, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Instantiates an all-zeros variable and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.int">int</span></code> shape
						</dt>
						<dd>Tuple or list of integers, shape of returned Keras variable 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> dtype
						</dt>
						<dd>data type of returned Keras variable 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>name of returned Keras variable 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A variable (including Keras metadata), filled with `0.0`.
Note that if `shape` was symbolic, we cannot return a variable,
and will return a dynamically-shaped tensor instead. <p></p> Example: <p></p> ```python
from tensorflow.keras import backend as K
kvar = K.zeros((3,4))
K.eval(kvar)
# array([[ 0.,  0.,  0.,  0.], [ 0.,  0.,  0.,  0.],
#       [ 0.,  0.,  0.,  0.]], dtype=float32)
A = tf.constant([1,2,3])
kvar2 = K.zeros(A.shape) # [0., 0., 0.] float32 by default
kvar3 = K.zeros(A.shape,dtype=tf.int32) # [0, 0, 0] with int32 dtype
kvar4 = K.zeros([2,3]) # [[0., 0., 0.], [0., 0., 0.]]
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="zeros" class="method">
		<h4>
			<span title="System.object">object</span> <strong>zeros</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> shape, <span title="System.string">string</span> dtype, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Instantiates an all-zeros variable and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> shape
						</dt>
						<dd>Tuple or list of integers, shape of returned Keras variable 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> dtype
						</dt>
						<dd>data type of returned Keras variable 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>name of returned Keras variable 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A variable (including Keras metadata), filled with `0.0`.
Note that if `shape` was symbolic, we cannot return a variable,
and will return a dynamically-shaped tensor instead. <p></p> Example: <p></p> ```python
from tensorflow.keras import backend as K
kvar = K.zeros((3,4))
K.eval(kvar)
# array([[ 0.,  0.,  0.,  0.], [ 0.,  0.,  0.,  0.],
#       [ 0.,  0.,  0.,  0.]], dtype=float32)
A = tf.constant([1,2,3])
kvar2 = K.zeros(A.shape) # [0., 0., 0.] float32 by default
kvar3 = K.zeros(A.shape,dtype=tf.int32) # [0, 0, 0] with int32 dtype
kvar4 = K.zeros([2,3]) # [[0., 0., 0.], [0., 0., 0.]]
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="zeros" class="method">
		<h4>
			<span title="System.object">object</span> <strong>zeros</strong>(<a href="../tensorflow/TensorShape.htm">TensorShape</a> shape, <span title="System.string">string</span> dtype, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Instantiates an all-zeros variable and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/TensorShape.htm">TensorShape</a></code> shape
						</dt>
						<dd>Tuple or list of integers, shape of returned Keras variable 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> dtype
						</dt>
						<dd>data type of returned Keras variable 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>name of returned Keras variable 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A variable (including Keras metadata), filled with `0.0`.
Note that if `shape` was symbolic, we cannot return a variable,
and will return a dynamically-shaped tensor instead. <p></p> Example: <p></p> ```python
from tensorflow.keras import backend as K
kvar = K.zeros((3,4))
K.eval(kvar)
# array([[ 0.,  0.,  0.,  0.], [ 0.,  0.,  0.,  0.],
#       [ 0.,  0.,  0.,  0.]], dtype=float32)
A = tf.constant([1,2,3])
kvar2 = K.zeros(A.shape) # [0., 0., 0.] float32 by default
kvar3 = K.zeros(A.shape,dtype=tf.int32) # [0, 0, 0] with int32 dtype
kvar4 = K.zeros([2,3]) # [[0., 0., 0.], [0., 0., 0.]]
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="zeros_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>zeros_dyn</strong>(<span title="System.object">object</span> shape, <span title="System.object">object</span> dtype, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Instantiates an all-zeros variable and returns it. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> shape
						</dt>
						<dd>Tuple or list of integers, shape of returned Keras variable 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>data type of returned Keras variable 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>name of returned Keras variable 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A variable (including Keras metadata), filled with `0.0`.
Note that if `shape` was symbolic, we cannot return a variable,
and will return a dynamically-shaped tensor instead. <p></p> Example: <p></p> ```python
from tensorflow.keras import backend as K
kvar = K.zeros((3,4))
K.eval(kvar)
# array([[ 0.,  0.,  0.,  0.], [ 0.,  0.,  0.,  0.],
#       [ 0.,  0.,  0.,  0.]], dtype=float32)
A = tf.constant([1,2,3])
kvar2 = K.zeros(A.shape) # [0., 0., 0.] float32 by default
kvar3 = K.zeros(A.shape,dtype=tf.int32) # [0, 0, 0] with int32 dtype
kvar4 = K.zeros([2,3]) # [[0., 0., 0.], [0., 0., 0.]]
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="zeros_like" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>zeros_like</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> x, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Instantiates an all-zeros variable of the same shape as another tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> x
						</dt>
						<dd>Keras variable or Keras tensor. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>dtype of returned Keras variable.
`None` uses the dtype of `x`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>name for the variable to create. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A Keras variable with the shape of `x` filled with zeros. <p></p> Example: <p></p> ```python
from tensorflow.keras import backend as K
kvar = K.variable(np.random.random((2,3)))
kvar_zeros = K.zeros_like(kvar)
K.eval(kvar_zeros)
# array([[ 0.,  0.,  0.], [ 0.,  0.,  0.]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="zeros_like" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>zeros_like</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> x, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Instantiates an all-zeros variable of the same shape as another tensor. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> x
						</dt>
						<dd>Keras variable or Keras tensor. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>dtype of returned Keras variable.
`None` uses the dtype of `x`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>name for the variable to create. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A Keras variable with the shape of `x` filled with zeros. <p></p> Example: <p></p> ```python
from tensorflow.keras import backend as K
kvar = K.variable(np.random.random((2,3)))
kvar_zeros = K.zeros_like(kvar)
K.eval(kvar_zeros)
# array([[ 0.,  0.,  0.], [ 0.,  0.,  0.]], dtype=float32)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	
	<h3 class="section">Public properties</h3>

	<div id="abs_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>abs_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="all_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>all_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="any_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>any_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="arange_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>arange_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="argmax_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>argmax_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="argmin_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>argmin_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="backend__fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>backend__fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="batch_dot_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>batch_dot_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="batch_flatten_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>batch_flatten_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="batch_get_value_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>batch_get_value_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="batch_normalization_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>batch_normalization_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="batch_set_value_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>batch_set_value_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="bias_add_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>bias_add_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="binary_crossentropy_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>binary_crossentropy_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="cast_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>cast_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="cast_to_floatx_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>cast_to_floatx_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="categorical_crossentropy_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>categorical_crossentropy_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="clear_session_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>clear_session_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="clip_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>clip_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="concatenate_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>concatenate_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="constant_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>constant_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv1d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv1d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv2d_transpose_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv2d_transpose_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="conv3d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>conv3d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="cos_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>cos_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="count_params_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>count_params_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ctc_batch_cost_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ctc_batch_cost_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ctc_decode_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ctc_decode_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ctc_label_dense_to_sparse_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ctc_label_dense_to_sparse_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="cumprod_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>cumprod_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="cumsum_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>cumsum_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="dot_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>dot_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="dropout_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>dropout_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="dtype_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>dtype_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="elu_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>elu_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="epsilon_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>epsilon_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="equal_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>equal_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="eval_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>eval_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="exp_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>exp_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="expand_dims_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>expand_dims_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="eye_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>eye_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="flatten_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>flatten_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="floatx_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>floatx_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="foldl_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>foldl_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="foldr_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>foldr_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="function_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>function_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="gather_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>gather_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="get_session_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>get_session_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="get_uid_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>get_uid_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="get_value_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>get_value_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="gradients_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>gradients_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="greater_equal_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>greater_equal_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="greater_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>greater_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="hard_sigmoid_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>hard_sigmoid_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="image_data_format_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>image_data_format_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="in_test_phase_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>in_test_phase_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="in_top_k_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>in_top_k_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="in_train_phase_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>in_train_phase_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="int_shape_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>int_shape_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="is_sparse_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>is_sparse_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="l2_normalize_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>l2_normalize_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="learning_phase_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>learning_phase_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="learning_phase_scope_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>learning_phase_scope_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="less_equal_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>less_equal_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="less_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>less_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="local_conv1d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>local_conv1d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="local_conv2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>local_conv2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="log_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>log_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="manual_variable_initialization_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>manual_variable_initialization_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="map_fn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>map_fn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="max_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>max_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="maximum_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>maximum_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="mean_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>mean_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="min_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>min_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="minimum_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>minimum_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="moving_average_update_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>moving_average_update_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="name_scope_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>name_scope_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ndim_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ndim_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="normalize_batch_in_training_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>normalize_batch_in_training_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="not_equal_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>not_equal_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="one_hot_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>one_hot_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ones_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ones_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ones_like_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ones_like_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="permute_dimensions_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>permute_dimensions_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="placeholder_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>placeholder_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="pool2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>pool2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="pool3d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>pool3d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="pow_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>pow_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="print_tensor_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>print_tensor_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="prod_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>prod_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_binomial_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_binomial_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_normal_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_normal_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_normal_variable_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_normal_variable_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_uniform_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_uniform_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_uniform_variable_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_uniform_variable_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="relu_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>relu_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="repeat_elements_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>repeat_elements_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="repeat_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>repeat_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="reset_uids_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>reset_uids_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="reshape_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>reshape_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="resize_images_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>resize_images_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="resize_volumes_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>resize_volumes_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="reverse_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>reverse_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="rnn_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>rnn_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="round_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>round_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="separable_conv2d_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>separable_conv2d_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="set_epsilon__fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>set_epsilon__fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="set_floatx__fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>set_floatx__fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="set_image_data_format__fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>set_image_data_format__fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="set_learning_phase__fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>set_learning_phase__fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="set_session_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>set_session_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="set_value_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>set_value_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="shape_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>shape_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sigmoid_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sigmoid_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sign_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sign_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sin_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sin_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="softmax_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>softmax_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="softplus_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>softplus_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="softsign_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>softsign_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sparse_categorical_crossentropy_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sparse_categorical_crossentropy_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="spatial_2d_padding_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>spatial_2d_padding_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="spatial_3d_padding_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>spatial_3d_padding_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sqrt_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sqrt_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="square_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>square_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="squeeze_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>squeeze_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="stack_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>stack_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="std_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>std_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="stop_gradient_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>stop_gradient_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sum_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sum_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="switch_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>switch_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="tanh_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>tanh_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="temporal_padding_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>temporal_padding_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="tile_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>tile_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="to_dense_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>to_dense_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="transpose_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>transpose_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="truncated_normal_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>truncated_normal_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="update_add_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>update_add_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="update_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>update_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="update_sub_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>update_sub_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="var_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>var_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="variable_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>variable_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="zeros_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>zeros_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="zeros_like_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>zeros_like_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>