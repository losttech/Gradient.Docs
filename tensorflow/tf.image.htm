<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>tf.image - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow/AggregationMethod.htm">AggregationMethod</a>
        </li>
				<li>
            <a href="../tensorflow/ConditionalAccumulator.htm">ConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/ConditionalAccumulatorBase.htm">ConditionalAccumulatorBase</a>
        </li>
				<li>
            <a href="../tensorflow/constant_initializer.htm">constant_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/CriticalSection.htm">CriticalSection</a>
        </li>
				<li>
            <a href="../tensorflow/DeviceSpec.htm">DeviceSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Dimension.htm">Dimension</a>
        </li>
				<li>
            <a href="../tensorflow/DType.htm">DType</a>
        </li>
				<li>
            <a href="../tensorflow/FIFOQueue.htm">FIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLenFeature.htm">FixedLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLengthRecordReader.htm">FixedLengthRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLenSequenceFeature.htm">FixedLenSequenceFeature</a>
        </li>
				<li>
            <a href="../tensorflow/glorot_normal_initializer.htm">glorot_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/glorot_uniform_initializer.htm">glorot_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/GradientTape.htm">GradientTape</a>
        </li>
				<li>
            <a href="../tensorflow/Graph.htm">Graph</a>
        </li>
				<li>
            <a href="../tensorflow/Graph._ControlDependenciesController.htm">Graph._ControlDependenciesController</a>
        </li>
				<li>
            <a href="../tensorflow/Graph.I_ControlDependenciesController.htm">Graph.I_ControlDependenciesController</a>
        </li>
				<li>
            <a href="../tensorflow/GraphKeys.htm">GraphKeys</a>
        </li>
				<li>
            <a href="../tensorflow/HeadingAxes.htm">HeadingAxes</a>
        </li>
				<li>
            <a href="../tensorflow/IAggregationMethod.htm">IAggregationMethod</a>
        </li>
				<li>
            <a href="../tensorflow/IConditionalAccumulator.htm">IConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/IConditionalAccumulatorBase.htm">IConditionalAccumulatorBase</a>
        </li>
				<li>
            <a href="../tensorflow/Iconstant_initializer.htm">Iconstant_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/ICriticalSection.htm">ICriticalSection</a>
        </li>
				<li>
            <a href="../tensorflow/IdentityReader.htm">IdentityReader</a>
        </li>
				<li>
            <a href="../tensorflow/IDeviceSpec.htm">IDeviceSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IDimension.htm">IDimension</a>
        </li>
				<li>
            <a href="../tensorflow/IDType.htm">IDType</a>
        </li>
				<li>
            <a href="../tensorflow/IFIFOQueue.htm">IFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLenFeature.htm">IFixedLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLengthRecordReader.htm">IFixedLengthRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLenSequenceFeature.htm">IFixedLenSequenceFeature</a>
        </li>
				<li>
            <a href="../tensorflow/Iglorot_normal_initializer.htm">Iglorot_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Iglorot_uniform_initializer.htm">Iglorot_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IGradientTape.htm">IGradientTape</a>
        </li>
				<li>
            <a href="../tensorflow/IGraph.htm">IGraph</a>
        </li>
				<li>
            <a href="../tensorflow/IGraphKeys.htm">IGraphKeys</a>
        </li>
				<li>
            <a href="../tensorflow/IIdentityReader.htm">IIdentityReader</a>
        </li>
				<li>
            <a href="../tensorflow/IIndexedSlices.htm">IIndexedSlices</a>
        </li>
				<li>
            <a href="../tensorflow/IIndexedSlicesSpec.htm">IIndexedSlicesSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IInteractiveSession.htm">IInteractiveSession</a>
        </li>
				<li>
            <a href="../tensorflow/ILazyLoader.htm">ILazyLoader</a>
        </li>
				<li>
            <a href="../tensorflow/ILMDBReader.htm">ILMDBReader</a>
        </li>
				<li>
            <a href="../tensorflow/IModule.htm">IModule</a>
        </li>
				<li>
            <a href="../tensorflow/Iname_scope.htm">Iname_scope</a>
        </li>
				<li>
            <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a>
        </li>
				<li>
            <a href="../tensorflow/IndexedSlicesSpec.htm">IndexedSlicesSpec</a>
        </li>
				<li>
            <a href="../tensorflow/InteractiveSession.htm">InteractiveSession</a>
        </li>
				<li>
            <a href="../tensorflow/Iones_initializer.htm">Iones_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IOperation.htm">IOperation</a>
        </li>
				<li>
            <a href="../tensorflow/IOpError.htm">IOpError</a>
        </li>
				<li>
            <a href="../tensorflow/IOptionalSpec.htm">IOptionalSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Iorthogonal_initializer.htm">Iorthogonal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IPaddingFIFOQueue.htm">IPaddingFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IPriorityQueue.htm">IPriorityQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IQueueBase.htm">IQueueBase</a>
        </li>
				<li>
            <a href="../tensorflow/IRaggedTensor.htm">IRaggedTensor</a>
        </li>
				<li>
            <a href="../tensorflow/IRaggedTensorSpec.htm">IRaggedTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Irandom_normal_initializer.htm">Irandom_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Irandom_uniform_initializer.htm">Irandom_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IRandomShuffleQueue.htm">IRandomShuffleQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IReaderBase.htm">IReaderBase</a>
        </li>
				<li>
            <a href="../tensorflow/IRegisterGradient.htm">IRegisterGradient</a>
        </li>
				<li>
            <a href="../tensorflow/ISession.htm">ISession</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseConditionalAccumulator.htm">ISparseConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseFeature.htm">ISparseFeature</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensor.htm">ISparseTensor</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensorSpec.htm">ISparseTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensorValue.htm">ISparseTensorValue</a>
        </li>
				<li>
            <a href="../tensorflow/ITensor.htm">ITensor</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorArray.htm">ITensorArray</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorArraySpec.htm">ITensorArraySpec</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorShape.htm">ITensorShape</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorSpec.htm">ITensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/ITextLineReader.htm">ITextLineReader</a>
        </li>
				<li>
            <a href="../tensorflow/ITFRecordReader.htm">ITFRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/Itruncated_normal_initializer.htm">Itruncated_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/ITypeSpec.htm">ITypeSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IUnconnectedGradients.htm">IUnconnectedGradients</a>
        </li>
				<li>
            <a href="../tensorflow/Iuniform_unit_scaling_initializer.htm">Iuniform_unit_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IVariable.htm">IVariable</a>
        </li>
				<li>
            <a href="../tensorflow/Ivariable_scope.htm">Ivariable_scope</a>
        </li>
				<li>
            <a href="../tensorflow/IVariableScope.htm">IVariableScope</a>
        </li>
				<li>
            <a href="../tensorflow/Ivariance_scaling_initializer.htm">Ivariance_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IVarLenFeature.htm">IVarLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/IWholeFileReader.htm">IWholeFileReader</a>
        </li>
				<li>
            <a href="../tensorflow/Izeros_initializer.htm">Izeros_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/LazyLoader.htm">LazyLoader</a>
        </li>
				<li>
            <a href="../tensorflow/LMDBReader.htm">LMDBReader</a>
        </li>
				<li>
            <a href="../tensorflow/Module.htm">Module</a>
        </li>
				<li>
            <a href="../tensorflow/name_scope.htm">name_scope</a>
        </li>
				<li>
            <a href="../tensorflow/ones_initializer.htm">ones_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Operation.htm">Operation</a>
        </li>
				<li>
            <a href="../tensorflow/Operation._InputList.htm">Operation._InputList</a>
        </li>
				<li>
            <a href="../tensorflow/Operation.I_InputList.htm">Operation.I_InputList</a>
        </li>
				<li>
            <a href="../tensorflow/OpError.htm">OpError</a>
        </li>
				<li>
            <a href="../tensorflow/OptionalSpec.htm">OptionalSpec</a>
        </li>
				<li>
            <a href="../tensorflow/orthogonal_initializer.htm">orthogonal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/PaddingFIFOQueue.htm">PaddingFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/PriorityQueue.htm">PriorityQueue</a>
        </li>
				<li>
            <a href="../tensorflow/QueueBase.htm">QueueBase</a>
        </li>
				<li>
            <a href="../tensorflow/RaggedTensor.htm">RaggedTensor</a>
        </li>
				<li>
            <a href="../tensorflow/RaggedTensorSpec.htm">RaggedTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/random_normal_initializer.htm">random_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/random_uniform_initializer.htm">random_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/RandomShuffleQueue.htm">RandomShuffleQueue</a>
        </li>
				<li>
            <a href="../tensorflow/ReaderBase.htm">ReaderBase</a>
        </li>
				<li>
            <a href="../tensorflow/RegisterGradient.htm">RegisterGradient</a>
        </li>
				<li>
            <a href="../tensorflow/Session.htm">Session</a>
        </li>
				<li>
            <a href="../tensorflow/SparseConditionalAccumulator.htm">SparseConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/SparseFeature.htm">SparseFeature</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensor.htm">SparseTensor</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensorSpec.htm">SparseTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensorValue.htm">SparseTensorValue</a>
        </li>
				<li>
            <a href="../tensorflow/Tensor.htm">Tensor</a>
        </li>
				<li>
            <a href="../tensorflow/Tensor`1.htm">Tensor&lt;T&gt;</a>
        </li>
				<li>
            <a href="../tensorflow/TensorArray.htm">TensorArray</a>
        </li>
				<li>
            <a href="../tensorflow/TensorArraySpec.htm">TensorArraySpec</a>
        </li>
				<li>
            <a href="../tensorflow/TensorDimension.htm">TensorDimension</a>
        </li>
				<li>
            <a href="../tensorflow/TensorDimensionSlice.htm">TensorDimensionSlice</a>
        </li>
				<li>
            <a href="../tensorflow/TensorShape.htm">TensorShape</a>
        </li>
				<li>
            <a href="../tensorflow/TensorSpec.htm">TensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/TextLineReader.htm">TextLineReader</a>
        </li>
				<li>
            <a href="../tensorflow/tf.htm">tf</a>
        </li>
				<li>
            <a href="../tensorflow/tf.audio.htm">tf.audio</a>
        </li>
				<li>
            <a href="../tensorflow/tf.autograph.htm">tf.autograph</a>
        </li>
				<li>
            <a href="../tensorflow/tf.autograph.experimental.htm">tf.autograph.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.bitwise.htm">tf.bitwise</a>
        </li>
				<li>
            <a href="../tensorflow/tf.compat.htm">tf.compat</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.htm">tf.config</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.experimental.htm">tf.config.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.optimizer.htm">tf.config.optimizer</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.threading.htm">tf.config.threading</a>
        </li>
				<li>
            <a href="../tensorflow/tf.data.htm">tf.data</a>
        </li>
				<li>
            <a href="../tensorflow/tf.data.experimental.htm">tf.data.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.debugging.htm">tf.debugging</a>
        </li>
				<li>
            <a href="../tensorflow/tf.distribute.htm">tf.distribute</a>
        </li>
				<li>
            <a href="../tensorflow/tf.distributions.htm">tf.distributions</a>
        </li>
				<li>
            <a href="../tensorflow/tf.errors.htm">tf.errors</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.htm">tf.estimator</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.experimental.htm">tf.estimator.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.export.htm">tf.estimator.export</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.inputs.htm">tf.estimator.inputs</a>
        </li>
				<li>
            <a href="../tensorflow/tf.experimental.htm">tf.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.feature_column.htm">tf.feature_column</a>
        </li>
				<li>
            <a href="../tensorflow/tf.gfile.htm">tf.gfile</a>
        </li>
				<li>
            <a href="../tensorflow/tf.graph_util.htm">tf.graph_util</a>
        </li>
				<li>
            <a href="../tensorflow/tf.image.htm" class="current">tf.image</a>
        </li>
				<li>
            <a href="../tensorflow/tf.initializers.htm">tf.initializers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.io.htm">tf.io</a>
        </li>
				<li>
            <a href="../tensorflow/tf.io.gfile.htm">tf.io.gfile</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.htm">tf.keras</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.activations.htm">tf.keras.activations</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.htm">tf.keras.applications</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.densenet.htm">tf.keras.applications.densenet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.imagenet_utils.htm">tf.keras.applications.imagenet_utils</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.inception_resnet_v2.htm">tf.keras.applications.inception_resnet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.inception_v3.htm">tf.keras.applications.inception_v3</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.mobilenet.htm">tf.keras.applications.mobilenet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.mobilenet_v2.htm">tf.keras.applications.mobilenet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.nasnet.htm">tf.keras.applications.nasnet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.resnet.htm">tf.keras.applications.resnet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.resnet_v2.htm">tf.keras.applications.resnet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.vgg16.htm">tf.keras.applications.vgg16</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.vgg19.htm">tf.keras.applications.vgg19</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.xception.htm">tf.keras.applications.xception</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.backend.htm">tf.keras.backend</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.constraints.htm">tf.keras.constraints</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.htm">tf.keras.datasets</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.boston_housing.htm">tf.keras.datasets.boston_housing</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.cifar10.htm">tf.keras.datasets.cifar10</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.cifar100.htm">tf.keras.datasets.cifar100</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.fashion_mnist.htm">tf.keras.datasets.fashion_mnist</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.imdb.htm">tf.keras.datasets.imdb</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.mnist.htm">tf.keras.datasets.mnist</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.reuters.htm">tf.keras.datasets.reuters</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.estimator.htm">tf.keras.estimator</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.experimental.htm">tf.keras.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.initializers.htm">tf.keras.initializers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.layers.htm">tf.keras.layers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.losses.htm">tf.keras.losses</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.metrics.htm">tf.keras.metrics</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.mixed_precision.htm">tf.keras.mixed_precision</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.mixed_precision.experimental.htm">tf.keras.mixed_precision.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.models.htm">tf.keras.models</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.optimizers.htm">tf.keras.optimizers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.optimizers.schedules.htm">tf.keras.optimizers.schedules</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.preprocessing.htm">tf.keras.preprocessing</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.preprocessing.image.htm">tf.keras.preprocessing.image</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.regularizers.htm">tf.keras.regularizers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.utils.htm">tf.keras.utils</a>
        </li>
				<li>
            <a href="../tensorflow/tf.layers.htm">tf.layers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.layers.experimental.htm">tf.layers.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.linalg.htm">tf.linalg</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.htm">tf.lite</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.htm">tf.lite.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.htm">tf.lite.experimental.microfrontend</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.python.htm">tf.lite.experimental.microfrontend.python</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.python.ops.htm">tf.lite.experimental.microfrontend.python.ops</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.nn.htm">tf.lite.experimental.nn</a>
        </li>
				<li>
            <a href="../tensorflow/tf.logging.htm">tf.logging</a>
        </li>
				<li>
            <a href="../tensorflow/tf.losses.htm">tf.losses</a>
        </li>
				<li>
            <a href="../tensorflow/tf.math.htm">tf.math</a>
        </li>
				<li>
            <a href="../tensorflow/tf.metrics.htm">tf.metrics</a>
        </li>
				<li>
            <a href="../tensorflow/tf.nest.htm">tf.nest</a>
        </li>
				<li>
            <a href="../tensorflow/tf.nn.htm">tf.nn</a>
        </li>
				<li>
            <a href="../tensorflow/tf.profiler.htm">tf.profiler</a>
        </li>
				<li>
            <a href="../tensorflow/tf.quantization.htm">tf.quantization</a>
        </li>
				<li>
            <a href="../tensorflow/tf.ragged.htm">tf.ragged</a>
        </li>
				<li>
            <a href="../tensorflow/tf.random.htm">tf.random</a>
        </li>
				<li>
            <a href="../tensorflow/tf.random.experimental.htm">tf.random.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.resource_loader.htm">tf.resource_loader</a>
        </li>
				<li>
            <a href="../tensorflow/tf.saved_model.htm">tf.saved_model</a>
        </li>
				<li>
            <a href="../tensorflow/tf.saved_model.main_op.htm">tf.saved_model.main_op</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sets.htm">tf.sets</a>
        </li>
				<li>
            <a href="../tensorflow/tf.signal.htm">tf.signal</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sparse.htm">tf.sparse</a>
        </li>
				<li>
            <a href="../tensorflow/tf.strings.htm">tf.strings</a>
        </li>
				<li>
            <a href="../tensorflow/tf.summary.htm">tf.summary</a>
        </li>
				<li>
            <a href="../tensorflow/tf.summary.experimental.htm">tf.summary.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sysconfig.htm">tf.sysconfig</a>
        </li>
				<li>
            <a href="../tensorflow/tf.test.htm">tf.test</a>
        </li>
				<li>
            <a href="../tensorflow/tf.tpu.htm">tf.tpu</a>
        </li>
				<li>
            <a href="../tensorflow/tf.tpu.experimental.htm">tf.tpu.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.train.htm">tf.train</a>
        </li>
				<li>
            <a href="../tensorflow/tf.train.experimental.htm">tf.train.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.user_ops.htm">tf.user_ops</a>
        </li>
				<li>
            <a href="../tensorflow/tf.xla.htm">tf.xla</a>
        </li>
				<li>
            <a href="../tensorflow/tf.xla.experimental.htm">tf.xla.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/TFRecordReader.htm">TFRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/truncated_normal_initializer.htm">truncated_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/TypeSpec.htm">TypeSpec</a>
        </li>
				<li>
            <a href="../tensorflow/UnconnectedGradients.htm">UnconnectedGradients</a>
        </li>
				<li>
            <a href="../tensorflow/uniform_unit_scaling_initializer.htm">uniform_unit_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Variable.htm">Variable</a>
        </li>
				<li>
            <a href="../tensorflow/variable_scope.htm">variable_scope</a>
        </li>
				<li>
            <a href="../tensorflow/VariableAggregation.htm">VariableAggregation</a>
        </li>
				<li>
            <a href="../tensorflow/VariableScope.htm">VariableScope</a>
        </li>
				<li>
            <a href="../tensorflow/VariableSynchronization.htm">VariableSynchronization</a>
        </li>
				<li>
            <a href="../tensorflow/variance_scaling_initializer.htm">variance_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/VarLenFeature.htm">VarLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/WholeFileReader.htm">WholeFileReader</a>
        </li>
				<li>
            <a href="../tensorflow/zeros_initializer.htm">zeros_initializer</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> tf.image</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow</p>
		</header>
    <div class="sub-header">
		
		
			<h3 class="section">Methods</h3>
			<ul>
				<li><a href="../tensorflow/tf.image.htm#adjust_brightness">adjust_brightness</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_brightness">adjust_brightness</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_brightness_dyn">adjust_brightness_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_contrast">adjust_contrast</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_contrast">adjust_contrast</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_contrast">adjust_contrast</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_contrast">adjust_contrast</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_contrast">adjust_contrast</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_contrast">adjust_contrast</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_contrast_dyn">adjust_contrast_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_gamma">adjust_gamma</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_gamma">adjust_gamma</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_gamma">adjust_gamma</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_gamma_dyn">adjust_gamma_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_hue">adjust_hue</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_hue">adjust_hue</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_hue">adjust_hue</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_hue">adjust_hue</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_hue">adjust_hue</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_jpeg_quality">adjust_jpeg_quality</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_jpeg_quality_dyn">adjust_jpeg_quality_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_saturation">adjust_saturation</a></li>
				<li><a href="../tensorflow/tf.image.htm#central_crop">central_crop</a></li>
				<li><a href="../tensorflow/tf.image.htm#central_crop">central_crop</a></li>
				<li><a href="../tensorflow/tf.image.htm#central_crop">central_crop</a></li>
				<li><a href="../tensorflow/tf.image.htm#central_crop_dyn">central_crop_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#combined_non_max_suppression">combined_non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#combined_non_max_suppression">combined_non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#combined_non_max_suppression">combined_non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#combined_non_max_suppression">combined_non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#combined_non_max_suppression_dyn">combined_non_max_suppression_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#convert_image_dtype">convert_image_dtype</a></li>
				<li><a href="../tensorflow/tf.image.htm#convert_image_dtype">convert_image_dtype</a></li>
				<li><a href="../tensorflow/tf.image.htm#convert_image_dtype_dyn">convert_image_dtype_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_and_resize">crop_and_resize</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_and_resize_dyn">crop_and_resize_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box">crop_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box_dyn">crop_to_bounding_box_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#draw_bounding_boxes">draw_bounding_boxes</a></li>
				<li><a href="../tensorflow/tf.image.htm#encode_png">encode_png</a></li>
				<li><a href="../tensorflow/tf.image.htm#encode_png_dyn">encode_png_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#extract_glimpse">extract_glimpse</a></li>
				<li><a href="../tensorflow/tf.image.htm#extract_patches">extract_patches</a></li>
				<li><a href="../tensorflow/tf.image.htm#extract_patches_dyn">extract_patches_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#flip_left_right">flip_left_right</a></li>
				<li><a href="../tensorflow/tf.image.htm#flip_left_right_dyn">flip_left_right_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#flip_up_down">flip_up_down</a></li>
				<li><a href="../tensorflow/tf.image.htm#flip_up_down_dyn">flip_up_down_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#grayscale_to_rgb">grayscale_to_rgb</a></li>
				<li><a href="../tensorflow/tf.image.htm#grayscale_to_rgb_dyn">grayscale_to_rgb_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#hsv_to_rgb">hsv_to_rgb</a></li>
				<li><a href="../tensorflow/tf.image.htm#hsv_to_rgb_dyn">hsv_to_rgb_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#image_gradients">image_gradients</a></li>
				<li><a href="../tensorflow/tf.image.htm#image_gradients">image_gradients</a></li>
				<li><a href="../tensorflow/tf.image.htm#image_gradients_dyn">image_gradients_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression">non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression">non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression">non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression">non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression">non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression">non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression">non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression">non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression">non_max_suppression</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_dyn">non_max_suppression_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_overlaps">non_max_suppression_overlaps</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_overlaps_dyn">non_max_suppression_overlaps_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_padded">non_max_suppression_padded</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_padded">non_max_suppression_padded</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_padded">non_max_suppression_padded</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_padded">non_max_suppression_padded</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_padded">non_max_suppression_padded</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_padded">non_max_suppression_padded</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_padded">non_max_suppression_padded</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_padded">non_max_suppression_padded</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_padded_dyn">non_max_suppression_padded_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_with_scores">non_max_suppression_with_scores</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_with_scores">non_max_suppression_with_scores</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_with_scores">non_max_suppression_with_scores</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_with_scores">non_max_suppression_with_scores</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_with_scores">non_max_suppression_with_scores</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_with_scores">non_max_suppression_with_scores</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_with_scores">non_max_suppression_with_scores</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_with_scores">non_max_suppression_with_scores</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_with_scores_dyn">non_max_suppression_with_scores_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box">pad_to_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box_dyn">pad_to_bounding_box_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#per_image_standardization">per_image_standardization</a></li>
				<li><a href="../tensorflow/tf.image.htm#per_image_standardization_dyn">per_image_standardization_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#psnr">psnr</a></li>
				<li><a href="../tensorflow/tf.image.htm#psnr">psnr</a></li>
				<li><a href="../tensorflow/tf.image.htm#psnr">psnr</a></li>
				<li><a href="../tensorflow/tf.image.htm#psnr">psnr</a></li>
				<li><a href="../tensorflow/tf.image.htm#psnr">psnr</a></li>
				<li><a href="../tensorflow/tf.image.htm#psnr">psnr</a></li>
				<li><a href="../tensorflow/tf.image.htm#psnr">psnr</a></li>
				<li><a href="../tensorflow/tf.image.htm#psnr">psnr</a></li>
				<li><a href="../tensorflow/tf.image.htm#psnr_dyn">psnr_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_brightness">random_brightness</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_brightness_dyn">random_brightness_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_contrast">random_contrast</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_contrast_dyn">random_contrast_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_flip_left_right">random_flip_left_right</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_flip_left_right_dyn">random_flip_left_right_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_flip_up_down">random_flip_up_down</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_flip_up_down_dyn">random_flip_up_down_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_hue">random_hue</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_hue">random_hue</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_hue">random_hue</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_hue_dyn">random_hue_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_jpeg_quality">random_jpeg_quality</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_jpeg_quality_dyn">random_jpeg_quality_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_saturation">random_saturation</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_saturation_dyn">random_saturation_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize">resize</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize">resize</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize">resize</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize">resize</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize">resize</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize">resize</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_image_with_pad">resize_image_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_image_with_pad">resize_image_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_image_with_pad">resize_image_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_image_with_pad">resize_image_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_image_with_pad">resize_image_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_image_with_pad">resize_image_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_image_with_pad">resize_image_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_image_with_pad">resize_image_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_image_with_pad_dyn">resize_image_with_pad_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad">resize_with_crop_or_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad_dyn">resize_with_crop_or_pad_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_pad">resize_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_pad">resize_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_pad">resize_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_pad">resize_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_pad">resize_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_pad">resize_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_pad">resize_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_pad">resize_with_pad</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_pad_dyn">resize_with_pad_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_grayscale">rgb_to_grayscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_grayscale_dyn">rgb_to_grayscale_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_hsv">rgb_to_hsv</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_hsv_dyn">rgb_to_hsv_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_yiq">rgb_to_yiq</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_yiq_dyn">rgb_to_yiq_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_yuv">rgb_to_yuv</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_yuv_dyn">rgb_to_yuv_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#rot90">rot90</a></li>
				<li><a href="../tensorflow/tf.image.htm#rot90">rot90</a></li>
				<li><a href="../tensorflow/tf.image.htm#rot90_dyn">rot90_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#sample_distorted_bounding_box">sample_distorted_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#sample_distorted_bounding_box">sample_distorted_bounding_box</a></li>
				<li><a href="../tensorflow/tf.image.htm#sample_distorted_bounding_box_dyn">sample_distorted_bounding_box_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#sobel_edges">sobel_edges</a></li>
				<li><a href="../tensorflow/tf.image.htm#sobel_edges_dyn">sobel_edges_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim">ssim</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim">ssim</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim">ssim</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim">ssim</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim">ssim</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim">ssim</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim">ssim</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim">ssim</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_dyn">ssim_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale">ssim_multiscale</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale_dyn">ssim_multiscale_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#total_variation">total_variation</a></li>
				<li><a href="../tensorflow/tf.image.htm#total_variation_dyn">total_variation_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#transpose">transpose</a></li>
				<li><a href="../tensorflow/tf.image.htm#transpose_dyn">transpose_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#yiq_to_rgb">yiq_to_rgb</a></li>
				<li><a href="../tensorflow/tf.image.htm#yiq_to_rgb_dyn">yiq_to_rgb_dyn</a></li>
				<li><a href="../tensorflow/tf.image.htm#yuv_to_rgb">yuv_to_rgb</a></li>
				<li><a href="../tensorflow/tf.image.htm#yuv_to_rgb_dyn">yuv_to_rgb_dyn</a></li>
			</ul>
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow/tf.image.htm#adjust_brightness_fn">adjust_brightness_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_contrast_fn">adjust_contrast_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_gamma_fn">adjust_gamma_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_hue_fn">adjust_hue_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_jpeg_quality_fn">adjust_jpeg_quality_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#adjust_saturation_fn">adjust_saturation_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#central_crop_fn">central_crop_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#combined_non_max_suppression_fn">combined_non_max_suppression_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#convert_image_dtype_fn">convert_image_dtype_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_and_resize_fn">crop_and_resize_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#crop_to_bounding_box_fn">crop_to_bounding_box_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#draw_bounding_boxes_fn">draw_bounding_boxes_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#encode_png_fn">encode_png_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#extract_glimpse_fn">extract_glimpse_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#extract_patches_fn">extract_patches_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#flip_left_right_fn">flip_left_right_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#flip_up_down_fn">flip_up_down_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#grayscale_to_rgb_fn">grayscale_to_rgb_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#hsv_to_rgb_fn">hsv_to_rgb_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#image_gradients_fn">image_gradients_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_fn">non_max_suppression_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_overlaps_fn">non_max_suppression_overlaps_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_padded_fn">non_max_suppression_padded_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#non_max_suppression_with_scores_fn">non_max_suppression_with_scores_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#pad_to_bounding_box_fn">pad_to_bounding_box_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#per_image_standardization_fn">per_image_standardization_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#psnr_fn">psnr_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_brightness_fn">random_brightness_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_contrast_fn">random_contrast_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_flip_left_right_fn">random_flip_left_right_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_flip_up_down_fn">random_flip_up_down_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_hue_fn">random_hue_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_jpeg_quality_fn">random_jpeg_quality_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#random_saturation_fn">random_saturation_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_fn">resize_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_image_with_pad_fn">resize_image_with_pad_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_crop_or_pad_fn">resize_with_crop_or_pad_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#resize_with_pad_fn">resize_with_pad_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_grayscale_fn">rgb_to_grayscale_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_hsv_fn">rgb_to_hsv_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_yiq_fn">rgb_to_yiq_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#rgb_to_yuv_fn">rgb_to_yuv_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#rot90_fn">rot90_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#sample_distorted_bounding_box_fn">sample_distorted_bounding_box_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#sobel_edges_fn">sobel_edges_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_fn">ssim_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#ssim_multiscale_fn">ssim_multiscale_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#total_variation_fn">total_variation_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#transpose_fn">transpose_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#yiq_to_rgb_fn">yiq_to_rgb_fn</a></li>
				<li><a href="../tensorflow/tf.image.htm#yuv_to_rgb_fn">yuv_to_rgb_fn</a></li>
			</ul>
		
	</div>
	
	
	<h3 class="section">Public static methods</h3>

	<div id="adjust_brightness" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_brightness</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> delta)
		</h4>
		<div class="content">Adjust the brightness of RGB or Grayscale images. <p></p> This is a convenience method that converts RGB images to float
representation, adjusts their brightness, and then converts them back to the
original data type. If several adjustments are chained, it is advisable to
minimize the number of redundant conversions. <p></p> The value `delta` is added to all components of the tensor `image`. `image` is
converted to `float` and scaled appropriately if it is in fixed-point
representation, and `delta` is converted to the same data type. For regular
images, `delta` should be in the range `[0,1)`, as it is added to the image in
floating point representation, where pixel values are in the `[0,1)` range. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>RGB image or images to adjust. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> delta
						</dt>
						<dd>A scalar. Amount to add to the pixel values. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A brightness-adjusted tensor of the same shape and type as `image`. <p></p> Usage Example:
```python
import tensorflow as tf
x = tf.random.normal(shape=(256, 256, 3))
tf.image.adjust_brightness(x, delta=0.1)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_brightness" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_brightness</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.double">double</span> delta)
		</h4>
		<div class="content">Adjust the brightness of RGB or Grayscale images. <p></p> This is a convenience method that converts RGB images to float
representation, adjusts their brightness, and then converts them back to the
original data type. If several adjustments are chained, it is advisable to
minimize the number of redundant conversions. <p></p> The value `delta` is added to all components of the tensor `image`. `image` is
converted to `float` and scaled appropriately if it is in fixed-point
representation, and `delta` is converted to the same data type. For regular
images, `delta` should be in the range `[0,1)`, as it is added to the image in
floating point representation, where pixel values are in the `[0,1)` range. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>RGB image or images to adjust. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> delta
						</dt>
						<dd>A scalar. Amount to add to the pixel values. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A brightness-adjusted tensor of the same shape and type as `image`. <p></p> Usage Example:
```python
import tensorflow as tf
x = tf.random.normal(shape=(256, 256, 3))
tf.image.adjust_brightness(x, delta=0.1)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_brightness_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_brightness_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> delta)
		</h4>
		<div class="content">Adjust the brightness of RGB or Grayscale images. <p></p> This is a convenience method that converts RGB images to float
representation, adjusts their brightness, and then converts them back to the
original data type. If several adjustments are chained, it is advisable to
minimize the number of redundant conversions. <p></p> The value `delta` is added to all components of the tensor `image`. `image` is
converted to `float` and scaled appropriately if it is in fixed-point
representation, and `delta` is converted to the same data type. For regular
images, `delta` should be in the range `[0,1)`, as it is added to the image in
floating point representation, where pixel values are in the `[0,1)` range. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>RGB image or images to adjust. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> delta
						</dt>
						<dd>A scalar. Amount to add to the pixel values. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A brightness-adjusted tensor of the same shape and type as `image`. <p></p> Usage Example:
```python
import tensorflow as tf
x = tf.random.normal(shape=(256, 256, 3))
tf.image.adjust_brightness(x, delta=0.1)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_contrast" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_contrast</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <span title="System.double">double</span> contrast_factor)
		</h4>
		<div class="content">Adjust contrast of RGB or grayscale images. <p></p> This is a convenience method that converts RGB images to float
representation, adjusts their contrast, and then converts them back to the
original data type. If several adjustments are chained, it is advisable to
minimize the number of redundant conversions. <p></p> `images` is a tensor of at least 3 dimensions.  The last 3 dimensions are
interpreted as `[height, width, channels]`.  The other dimensions only
represent a collection of images, such as `[batch, height, width, channels].` <p></p> Contrast is adjusted independently for each channel of each image. <p></p> For each channel, this Op computes the mean of the image pixels in the
channel and then adjusts each component `x` of each pixel to
`(x - mean) * contrast_factor + mean`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>Images to adjust.  At least 3-D. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> contrast_factor
						</dt>
						<dd>A float multiplier for adjusting contrast. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The contrast-adjusted image or images. <p></p> Usage Example:
```python
import tensorflow as tf
x = tf.random.normal(shape=(256, 256, 3))
tf.image.adjust_contrast(x,2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_contrast" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_contrast</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> contrast_factor)
		</h4>
		<div class="content">Adjust contrast of RGB or grayscale images. <p></p> This is a convenience method that converts RGB images to float
representation, adjusts their contrast, and then converts them back to the
original data type. If several adjustments are chained, it is advisable to
minimize the number of redundant conversions. <p></p> `images` is a tensor of at least 3 dimensions.  The last 3 dimensions are
interpreted as `[height, width, channels]`.  The other dimensions only
represent a collection of images, such as `[batch, height, width, channels].` <p></p> Contrast is adjusted independently for each channel of each image. <p></p> For each channel, this Op computes the mean of the image pixels in the
channel and then adjusts each component `x` of each pixel to
`(x - mean) * contrast_factor + mean`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>Images to adjust.  At least 3-D. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> contrast_factor
						</dt>
						<dd>A float multiplier for adjusting contrast. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The contrast-adjusted image or images. <p></p> Usage Example:
```python
import tensorflow as tf
x = tf.random.normal(shape=(256, 256, 3))
tf.image.adjust_contrast(x,2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_contrast" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_contrast</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> contrast_factor)
		</h4>
		<div class="content">Adjust contrast of RGB or grayscale images. <p></p> This is a convenience method that converts RGB images to float
representation, adjusts their contrast, and then converts them back to the
original data type. If several adjustments are chained, it is advisable to
minimize the number of redundant conversions. <p></p> `images` is a tensor of at least 3 dimensions.  The last 3 dimensions are
interpreted as `[height, width, channels]`.  The other dimensions only
represent a collection of images, such as `[batch, height, width, channels].` <p></p> Contrast is adjusted independently for each channel of each image. <p></p> For each channel, this Op computes the mean of the image pixels in the
channel and then adjusts each component `x` of each pixel to
`(x - mean) * contrast_factor + mean`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>Images to adjust.  At least 3-D. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> contrast_factor
						</dt>
						<dd>A float multiplier for adjusting contrast. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The contrast-adjusted image or images. <p></p> Usage Example:
```python
import tensorflow as tf
x = tf.random.normal(shape=(256, 256, 3))
tf.image.adjust_contrast(x,2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_contrast" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_contrast</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> images, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> contrast_factor)
		</h4>
		<div class="content">Adjust contrast of RGB or grayscale images. <p></p> This is a convenience method that converts RGB images to float
representation, adjusts their contrast, and then converts them back to the
original data type. If several adjustments are chained, it is advisable to
minimize the number of redundant conversions. <p></p> `images` is a tensor of at least 3 dimensions.  The last 3 dimensions are
interpreted as `[height, width, channels]`.  The other dimensions only
represent a collection of images, such as `[batch, height, width, channels].` <p></p> Contrast is adjusted independently for each channel of each image. <p></p> For each channel, this Op computes the mean of the image pixels in the
channel and then adjusts each component `x` of each pixel to
`(x - mean) * contrast_factor + mean`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> images
						</dt>
						<dd>Images to adjust.  At least 3-D. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> contrast_factor
						</dt>
						<dd>A float multiplier for adjusting contrast. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The contrast-adjusted image or images. <p></p> Usage Example:
```python
import tensorflow as tf
x = tf.random.normal(shape=(256, 256, 3))
tf.image.adjust_contrast(x,2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_contrast" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_contrast</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> images, <span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span> contrast_factor)
		</h4>
		<div class="content">Adjust contrast of RGB or grayscale images. <p></p> This is a convenience method that converts RGB images to float
representation, adjusts their contrast, and then converts them back to the
original data type. If several adjustments are chained, it is advisable to
minimize the number of redundant conversions. <p></p> `images` is a tensor of at least 3 dimensions.  The last 3 dimensions are
interpreted as `[height, width, channels]`.  The other dimensions only
represent a collection of images, such as `[batch, height, width, channels].` <p></p> Contrast is adjusted independently for each channel of each image. <p></p> For each channel, this Op computes the mean of the image pixels in the
channel and then adjusts each component `x` of each pixel to
`(x - mean) * contrast_factor + mean`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> images
						</dt>
						<dd>Images to adjust.  At least 3-D. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<double>">IEnumerable&lt;double&gt;</span></code> contrast_factor
						</dt>
						<dd>A float multiplier for adjusting contrast. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The contrast-adjusted image or images. <p></p> Usage Example:
```python
import tensorflow as tf
x = tf.random.normal(shape=(256, 256, 3))
tf.image.adjust_contrast(x,2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_contrast" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_contrast</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> images, <span title="System.double">double</span> contrast_factor)
		</h4>
		<div class="content">Adjust contrast of RGB or grayscale images. <p></p> This is a convenience method that converts RGB images to float
representation, adjusts their contrast, and then converts them back to the
original data type. If several adjustments are chained, it is advisable to
minimize the number of redundant conversions. <p></p> `images` is a tensor of at least 3 dimensions.  The last 3 dimensions are
interpreted as `[height, width, channels]`.  The other dimensions only
represent a collection of images, such as `[batch, height, width, channels].` <p></p> Contrast is adjusted independently for each channel of each image. <p></p> For each channel, this Op computes the mean of the image pixels in the
channel and then adjusts each component `x` of each pixel to
`(x - mean) * contrast_factor + mean`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> images
						</dt>
						<dd>Images to adjust.  At least 3-D. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> contrast_factor
						</dt>
						<dd>A float multiplier for adjusting contrast. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The contrast-adjusted image or images. <p></p> Usage Example:
```python
import tensorflow as tf
x = tf.random.normal(shape=(256, 256, 3))
tf.image.adjust_contrast(x,2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_contrast_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_contrast_dyn</strong>(<span title="System.object">object</span> images, <span title="System.object">object</span> contrast_factor)
		</h4>
		<div class="content">Adjust contrast of RGB or grayscale images. <p></p> This is a convenience method that converts RGB images to float
representation, adjusts their contrast, and then converts them back to the
original data type. If several adjustments are chained, it is advisable to
minimize the number of redundant conversions. <p></p> `images` is a tensor of at least 3 dimensions.  The last 3 dimensions are
interpreted as `[height, width, channels]`.  The other dimensions only
represent a collection of images, such as `[batch, height, width, channels].` <p></p> Contrast is adjusted independently for each channel of each image. <p></p> For each channel, this Op computes the mean of the image pixels in the
channel and then adjusts each component `x` of each pixel to
`(x - mean) * contrast_factor + mean`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>Images to adjust.  At least 3-D. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> contrast_factor
						</dt>
						<dd>A float multiplier for adjusting contrast. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The contrast-adjusted image or images. <p></p> Usage Example:
```python
import tensorflow as tf
x = tf.random.normal(shape=(256, 256, 3))
tf.image.adjust_contrast(x,2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_gamma" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_gamma</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> gamma, <span title="System.int">int</span> gain)
		</h4>
		<div class="content">Performs Gamma Correction on the input image. <p></p> Also known as Power Law Transform. This function converts the
input images at first to float representation, then transforms them
pixelwise according to the equation `Out = gain * In**gamma`,
and then converts the back to the original data type. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor. A Gamma-adjusted tensor of the same shape and type as `image`.
Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_gamma(x, 0.2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_gamma" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_gamma</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.double">double</span> gamma, <span title="System.int">int</span> gain)
		</h4>
		<div class="content">Performs Gamma Correction on the input image. <p></p> Also known as Power Law Transform. This function converts the
input images at first to float representation, then transforms them
pixelwise according to the equation `Out = gain * In**gamma`,
and then converts the back to the original data type. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor. A Gamma-adjusted tensor of the same shape and type as `image`.
Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_gamma(x, 0.2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_gamma" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_gamma</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> gamma, <span title="System.int">int</span> gain)
		</h4>
		<div class="content">Performs Gamma Correction on the input image. <p></p> Also known as Power Law Transform. This function converts the
input images at first to float representation, then transforms them
pixelwise according to the equation `Out = gain * In**gamma`,
and then converts the back to the original data type. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor. A Gamma-adjusted tensor of the same shape and type as `image`.
Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_gamma(x, 0.2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_gamma_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_gamma_dyn</strong>(<span title="System.object">object</span> image, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> gamma, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> gain)
		</h4>
		<div class="content">Performs Gamma Correction on the input image. <p></p> Also known as Power Law Transform. This function converts the
input images at first to float representation, then transforms them
pixelwise according to the equation `Out = gain * In**gamma`,
and then converts the back to the original data type. 



			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A Tensor. A Gamma-adjusted tensor of the same shape and type as `image`.
Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_gamma(x, 0.2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_hue" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_hue</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> image, <span title="System.double">double</span> delta, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adjust hue of RGB images. <p></p> This is a convenience method that converts an RGB image to float
representation, converts it to HSV, add an offset to the hue channel, converts
back to RGB and then back to the original data type. If several adjustments
are chained it is advisable to minimize the number of redundant conversions. <p></p> `image` is an RGB image.  The image hue is adjusted by converting the
image(s) to HSV and rotating the hue channel (H) by
`delta`.  The image is then converted back to RGB. <p></p> `delta` must be in the interval `[-1, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> delta
						</dt>
						<dd>float.  How much to add to the hue channel. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_hue(x, 0.2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_hue" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_hue</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> delta, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adjust hue of RGB images. <p></p> This is a convenience method that converts an RGB image to float
representation, converts it to HSV, add an offset to the hue channel, converts
back to RGB and then back to the original data type. If several adjustments
are chained it is advisable to minimize the number of redundant conversions. <p></p> `image` is an RGB image.  The image hue is adjusted by converting the
image(s) to HSV and rotating the hue channel (H) by
`delta`.  The image is then converted back to RGB. <p></p> `delta` must be in the interval `[-1, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> delta
						</dt>
						<dd>float.  How much to add to the hue channel. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_hue(x, 0.2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_hue" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_hue</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> image, <span title="System.double">double</span> delta, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adjust hue of RGB images. <p></p> This is a convenience method that converts an RGB image to float
representation, converts it to HSV, add an offset to the hue channel, converts
back to RGB and then back to the original data type. If several adjustments
are chained it is advisable to minimize the number of redundant conversions. <p></p> `image` is an RGB image.  The image hue is adjusted by converting the
image(s) to HSV and rotating the hue channel (H) by
`delta`.  The image is then converted back to RGB. <p></p> `delta` must be in the interval `[-1, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> delta
						</dt>
						<dd>float.  How much to add to the hue channel. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_hue(x, 0.2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_hue" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_hue</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> delta, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adjust hue of RGB images. <p></p> This is a convenience method that converts an RGB image to float
representation, converts it to HSV, add an offset to the hue channel, converts
back to RGB and then back to the original data type. If several adjustments
are chained it is advisable to minimize the number of redundant conversions. <p></p> `image` is an RGB image.  The image hue is adjusted by converting the
image(s) to HSV and rotating the hue channel (H) by
`delta`.  The image is then converted back to RGB. <p></p> `delta` must be in the interval `[-1, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> delta
						</dt>
						<dd>float.  How much to add to the hue channel. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_hue(x, 0.2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_hue" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_hue</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.double">double</span> delta, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adjust hue of RGB images. <p></p> This is a convenience method that converts an RGB image to float
representation, converts it to HSV, add an offset to the hue channel, converts
back to RGB and then back to the original data type. If several adjustments
are chained it is advisable to minimize the number of redundant conversions. <p></p> `image` is an RGB image.  The image hue is adjusted by converting the
image(s) to HSV and rotating the hue channel (H) by
`delta`.  The image is then converted back to RGB. <p></p> `delta` must be in the interval `[-1, 1]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> delta
						</dt>
						<dd>float.  How much to add to the hue channel. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_hue(x, 0.2)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_jpeg_quality" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_jpeg_quality</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> jpeg_quality, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adjust jpeg encoding quality of an RGB image. <p></p> This is a convenience method that adjusts jpeg encoding quality of an
RGB image. <p></p> `image` is an RGB image.  The image's encoding quality is adjusted
to `jpeg_quality`.
`jpeg_quality` must be in the interval `[0, 100]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> jpeg_quality
						</dt>
						<dd>Python int or Tensor of type int32.  jpeg encoding quality. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_jpeg_quality(x, 75)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_jpeg_quality_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_jpeg_quality_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> jpeg_quality, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Adjust jpeg encoding quality of an RGB image. <p></p> This is a convenience method that adjusts jpeg encoding quality of an
RGB image. <p></p> `image` is an RGB image.  The image's encoding quality is adjusted
to `jpeg_quality`.
`jpeg_quality` must be in the interval `[0, 100]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> jpeg_quality
						</dt>
						<dd>Python int or Tensor of type int32.  jpeg encoding quality. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_jpeg_quality(x, 75)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="adjust_saturation" class="method">
		<h4>
			<span title="System.object">object</span> <strong>adjust_saturation</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.double">double</span> saturation_factor, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Adjust saturation of RGB images. <p></p> This is a convenience method that converts RGB images to float
representation, converts them to HSV, add an offset to the saturation channel,
converts back to RGB and then back to the original data type. If several
adjustments are chained it is advisable to minimize the number of redundant
conversions. <p></p> `image` is an RGB image or images.  The image saturation is adjusted by
converting the images to HSV and multiplying the saturation (S) channel by
`saturation_factor` and clipping. The images are then converted back to RGB. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> saturation_factor
						</dt>
						<dd>float. Factor to multiply the saturation by. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3))
>> tf.image.adjust_saturation(x, 0.5)
``` <p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="central_crop" class="method">
		<h4>
			<span title="System.object">object</span> <strong>central_crop</strong>(<a href="../numpy/ndarray.htm">ndarray</a> image, <span title="System.double">double</span> central_fraction)
		</h4>
		<div class="content">Crop the central region of the image(s). <p></p> Remove the outer parts of an image but retain the central region of the image
along each dimension. If we specify central_fraction = 0.5, this function
returns the region marked with "X" in the below diagram. <p></p> --------
|        |
|  XXXX  |
|  XXXX  |
|        |   where "X" is the central 50% of the image.
-------- <p></p> This function works on either a single image (`image` is a 3-D Tensor), or a
batch of images (`image` is a 4-D Tensor). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> image
						</dt>
						<dd>Either a 3-D float Tensor of shape [height, width, depth], or a 4-D
Tensor of shape [batch_size, height, width, depth]. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> central_fraction
						</dt>
						<dd>float (0, 1], fraction of size to crop
Usage Example: ```python >> import tensorflow as tf >> x =
tf.random.normal(shape=(256, 256, 3)) >> tf.image.central_crop(x, 0.5) ``` 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>3-D / 4-D float Tensor, as per the input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="central_crop" class="method">
		<h4>
			<span title="System.object">object</span> <strong>central_crop</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.double">double</span> central_fraction)
		</h4>
		<div class="content">Crop the central region of the image(s). <p></p> Remove the outer parts of an image but retain the central region of the image
along each dimension. If we specify central_fraction = 0.5, this function
returns the region marked with "X" in the below diagram. <p></p> --------
|        |
|  XXXX  |
|  XXXX  |
|        |   where "X" is the central 50% of the image.
-------- <p></p> This function works on either a single image (`image` is a 3-D Tensor), or a
batch of images (`image` is a 4-D Tensor). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>Either a 3-D float Tensor of shape [height, width, depth], or a 4-D
Tensor of shape [batch_size, height, width, depth]. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> central_fraction
						</dt>
						<dd>float (0, 1], fraction of size to crop
Usage Example: ```python >> import tensorflow as tf >> x =
tf.random.normal(shape=(256, 256, 3)) >> tf.image.central_crop(x, 0.5) ``` 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>3-D / 4-D float Tensor, as per the input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="central_crop" class="method">
		<h4>
			<span title="System.object">object</span> <strong>central_crop</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> image, <span title="System.double">double</span> central_fraction)
		</h4>
		<div class="content">Crop the central region of the image(s). <p></p> Remove the outer parts of an image but retain the central region of the image
along each dimension. If we specify central_fraction = 0.5, this function
returns the region marked with "X" in the below diagram. <p></p> --------
|        |
|  XXXX  |
|  XXXX  |
|        |   where "X" is the central 50% of the image.
-------- <p></p> This function works on either a single image (`image` is a 3-D Tensor), or a
batch of images (`image` is a 4-D Tensor). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>Either a 3-D float Tensor of shape [height, width, depth], or a 4-D
Tensor of shape [batch_size, height, width, depth]. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> central_fraction
						</dt>
						<dd>float (0, 1], fraction of size to crop
Usage Example: ```python >> import tensorflow as tf >> x =
tf.random.normal(shape=(256, 256, 3)) >> tf.image.central_crop(x, 0.5) ``` 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>3-D / 4-D float Tensor, as per the input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="central_crop_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>central_crop_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> central_fraction)
		</h4>
		<div class="content">Crop the central region of the image(s). <p></p> Remove the outer parts of an image but retain the central region of the image
along each dimension. If we specify central_fraction = 0.5, this function
returns the region marked with "X" in the below diagram. <p></p> --------
|        |
|  XXXX  |
|  XXXX  |
|        |   where "X" is the central 50% of the image.
-------- <p></p> This function works on either a single image (`image` is a 3-D Tensor), or a
batch of images (`image` is a 4-D Tensor). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>Either a 3-D float Tensor of shape [height, width, depth], or a 4-D
Tensor of shape [batch_size, height, width, depth]. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> central_fraction
						</dt>
						<dd>float (0, 1], fraction of size to crop
Usage Example: ```python >> import tensorflow as tf >> x =
tf.random.normal(shape=(256, 256, 3)) >> tf.image.central_crop(x, 0.5) ``` 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>3-D / 4-D float Tensor, as per the input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="combined_non_max_suppression" class="method">
		<h4>
			<span title="System.object">object</span> <strong>combined_non_max_suppression</strong>(<span title="System.object">object</span> boxes, <span title="System.object">object</span> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size_per_class, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_total_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> score_threshold, <span title="System.bool">bool</span> pad_per_class, <span title="System.bool">bool</span> clip_boxes, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> This operation performs non_max_suppression on the inputs per batch, across
all classes.
Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system. Also note that
this algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is the final boxes, scores and classes tensor
returned after performing non_max_suppression. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> boxes
						</dt>
						<dd>A 4-D float `Tensor` of shape `[batch_size, num_boxes, q, 4]`. If `q`
is 1 then same boxes are used for all classes otherwise, if `q` is equal
to number of classes, class-specific boxes are used. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scores
						</dt>
						<dd>A 3-D float `Tensor` of shape `[batch_size, num_boxes, num_classes]`
representing a single score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size_per_class
						</dt>
						<dd>A scalar integer `Tensor` representing the
maximum number of boxes to be selected by non max suppression per class 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_total_size
						</dt>
						<dd>A scalar representing maximum number of boxes retained over
all classes. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_per_class
						</dt>
						<dd>If false, the output nmsed boxes, scores and classes are
padded/clipped to `max_total_size`. If true, the output nmsed boxes,
scores and classes are padded to be of length
`max_size_per_class`*`num_classes`, unless it exceeds `max_total_size` in
which case it is clipped to `max_total_size`. Defaults to false. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> clip_boxes
						</dt>
						<dd>If true, the coordinates of output nmsed boxes will be clipped
to [0, 1]. If false, output the box coordinates as it is. Defaults to
true. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor
containing the non-max suppressed boxes.
'nmsed_scores': A [batch_size, max_detections] float32 tensor containing
the scores for the boxes.
'nmsed_classes': A [batch_size, max_detections] float32 tensor
containing the class for boxes.
'valid_detections': A [batch_size] int32 tensor indicating the number of
valid detections per batch item. Only the top valid_detections[i] entries
in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the
entries are zero paddings. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="combined_non_max_suppression" class="method">
		<h4>
			<span title="System.object">object</span> <strong>combined_non_max_suppression</strong>(<span title="System.object">object</span> boxes, <span title="System.object">object</span> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size_per_class, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_total_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.bool">bool</span> pad_per_class, <span title="System.bool">bool</span> clip_boxes, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> This operation performs non_max_suppression on the inputs per batch, across
all classes.
Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system. Also note that
this algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is the final boxes, scores and classes tensor
returned after performing non_max_suppression. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> boxes
						</dt>
						<dd>A 4-D float `Tensor` of shape `[batch_size, num_boxes, q, 4]`. If `q`
is 1 then same boxes are used for all classes otherwise, if `q` is equal
to number of classes, class-specific boxes are used. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scores
						</dt>
						<dd>A 3-D float `Tensor` of shape `[batch_size, num_boxes, num_classes]`
representing a single score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size_per_class
						</dt>
						<dd>A scalar integer `Tensor` representing the
maximum number of boxes to be selected by non max suppression per class 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_total_size
						</dt>
						<dd>A scalar representing maximum number of boxes retained over
all classes. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_per_class
						</dt>
						<dd>If false, the output nmsed boxes, scores and classes are
padded/clipped to `max_total_size`. If true, the output nmsed boxes,
scores and classes are padded to be of length
`max_size_per_class`*`num_classes`, unless it exceeds `max_total_size` in
which case it is clipped to `max_total_size`. Defaults to false. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> clip_boxes
						</dt>
						<dd>If true, the coordinates of output nmsed boxes will be clipped
to [0, 1]. If false, output the box coordinates as it is. Defaults to
true. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor
containing the non-max suppressed boxes.
'nmsed_scores': A [batch_size, max_detections] float32 tensor containing
the scores for the boxes.
'nmsed_classes': A [batch_size, max_detections] float32 tensor
containing the class for boxes.
'valid_detections': A [batch_size] int32 tensor indicating the number of
valid detections per batch item. Only the top valid_detections[i] entries
in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the
entries are zero paddings. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="combined_non_max_suppression" class="method">
		<h4>
			<span title="System.object">object</span> <strong>combined_non_max_suppression</strong>(<span title="System.object">object</span> boxes, <span title="System.object">object</span> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size_per_class, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_total_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> score_threshold, <span title="System.bool">bool</span> pad_per_class, <span title="System.bool">bool</span> clip_boxes, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> This operation performs non_max_suppression on the inputs per batch, across
all classes.
Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system. Also note that
this algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is the final boxes, scores and classes tensor
returned after performing non_max_suppression. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> boxes
						</dt>
						<dd>A 4-D float `Tensor` of shape `[batch_size, num_boxes, q, 4]`. If `q`
is 1 then same boxes are used for all classes otherwise, if `q` is equal
to number of classes, class-specific boxes are used. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scores
						</dt>
						<dd>A 3-D float `Tensor` of shape `[batch_size, num_boxes, num_classes]`
representing a single score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size_per_class
						</dt>
						<dd>A scalar integer `Tensor` representing the
maximum number of boxes to be selected by non max suppression per class 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_total_size
						</dt>
						<dd>A scalar representing maximum number of boxes retained over
all classes. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_per_class
						</dt>
						<dd>If false, the output nmsed boxes, scores and classes are
padded/clipped to `max_total_size`. If true, the output nmsed boxes,
scores and classes are padded to be of length
`max_size_per_class`*`num_classes`, unless it exceeds `max_total_size` in
which case it is clipped to `max_total_size`. Defaults to false. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> clip_boxes
						</dt>
						<dd>If true, the coordinates of output nmsed boxes will be clipped
to [0, 1]. If false, output the box coordinates as it is. Defaults to
true. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor
containing the non-max suppressed boxes.
'nmsed_scores': A [batch_size, max_detections] float32 tensor containing
the scores for the boxes.
'nmsed_classes': A [batch_size, max_detections] float32 tensor
containing the class for boxes.
'valid_detections': A [batch_size] int32 tensor indicating the number of
valid detections per batch item. Only the top valid_detections[i] entries
in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the
entries are zero paddings. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="combined_non_max_suppression" class="method">
		<h4>
			<span title="System.object">object</span> <strong>combined_non_max_suppression</strong>(<span title="System.object">object</span> boxes, <span title="System.object">object</span> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size_per_class, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_total_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.bool">bool</span> pad_per_class, <span title="System.bool">bool</span> clip_boxes, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> This operation performs non_max_suppression on the inputs per batch, across
all classes.
Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system. Also note that
this algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is the final boxes, scores and classes tensor
returned after performing non_max_suppression. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> boxes
						</dt>
						<dd>A 4-D float `Tensor` of shape `[batch_size, num_boxes, q, 4]`. If `q`
is 1 then same boxes are used for all classes otherwise, if `q` is equal
to number of classes, class-specific boxes are used. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scores
						</dt>
						<dd>A 3-D float `Tensor` of shape `[batch_size, num_boxes, num_classes]`
representing a single score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size_per_class
						</dt>
						<dd>A scalar integer `Tensor` representing the
maximum number of boxes to be selected by non max suppression per class 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_total_size
						</dt>
						<dd>A scalar representing maximum number of boxes retained over
all classes. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_per_class
						</dt>
						<dd>If false, the output nmsed boxes, scores and classes are
padded/clipped to `max_total_size`. If true, the output nmsed boxes,
scores and classes are padded to be of length
`max_size_per_class`*`num_classes`, unless it exceeds `max_total_size` in
which case it is clipped to `max_total_size`. Defaults to false. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> clip_boxes
						</dt>
						<dd>If true, the coordinates of output nmsed boxes will be clipped
to [0, 1]. If false, output the box coordinates as it is. Defaults to
true. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor
containing the non-max suppressed boxes.
'nmsed_scores': A [batch_size, max_detections] float32 tensor containing
the scores for the boxes.
'nmsed_classes': A [batch_size, max_detections] float32 tensor
containing the class for boxes.
'valid_detections': A [batch_size] int32 tensor indicating the number of
valid detections per batch item. Only the top valid_detections[i] entries
in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the
entries are zero paddings. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="combined_non_max_suppression_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>combined_non_max_suppression_dyn</strong>(<span title="System.object">object</span> boxes, <span title="System.object">object</span> scores, <span title="System.object">object</span> max_output_size_per_class, <span title="System.object">object</span> max_total_size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> pad_per_class, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> clip_boxes, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> This operation performs non_max_suppression on the inputs per batch, across
all classes.
Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system. Also note that
this algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is the final boxes, scores and classes tensor
returned after performing non_max_suppression. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> boxes
						</dt>
						<dd>A 4-D float `Tensor` of shape `[batch_size, num_boxes, q, 4]`. If `q`
is 1 then same boxes are used for all classes otherwise, if `q` is equal
to number of classes, class-specific boxes are used. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scores
						</dt>
						<dd>A 3-D float `Tensor` of shape `[batch_size, num_boxes, num_classes]`
representing a single score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_output_size_per_class
						</dt>
						<dd>A scalar integer `Tensor` representing the
maximum number of boxes to be selected by non max suppression per class 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_total_size
						</dt>
						<dd>A scalar representing maximum number of boxes retained over
all classes. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> pad_per_class
						</dt>
						<dd>If false, the output nmsed boxes, scores and classes are
padded/clipped to `max_total_size`. If true, the output nmsed boxes,
scores and classes are padded to be of length
`max_size_per_class`*`num_classes`, unless it exceeds `max_total_size` in
which case it is clipped to `max_total_size`. Defaults to false. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> clip_boxes
						</dt>
						<dd>If true, the coordinates of output nmsed boxes will be clipped
to [0, 1]. If false, output the box coordinates as it is. Defaults to
true. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor
containing the non-max suppressed boxes.
'nmsed_scores': A [batch_size, max_detections] float32 tensor containing
the scores for the boxes.
'nmsed_classes': A [batch_size, max_detections] float32 tensor
containing the class for boxes.
'valid_detections': A [batch_size] int32 tensor indicating the number of
valid detections per batch item. Only the top valid_detections[i] entries
in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the
entries are zero paddings. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convert_image_dtype" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convert_image_dtype</strong>(<span title="System.object">object</span> image, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.bool">bool</span> saturate, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Convert `image` to `dtype`, scaling its values if needed. <p></p> Images that are represented using floating point values are expected to have
values in the range [0,1). Image data stored in integer data types are
expected to have values in the range `[0,MAX]`, where `MAX` is the largest
positive representable number for the data type. <p></p> This op converts between data types, scaling the values appropriately before
casting. <p></p> Note that converting from floating point inputs to integer types may lead to
over/underflow problems. Set saturate to `True` to avoid such problem in
problematic conversions. If enabled, saturation will clip the output into the
allowed range before performing a potentially dangerous cast (and only before
performing such a cast, i.e., when casting from a floating point to an integer
type, and when casting from a signed to an unsigned type; `saturate` has no
effect on casts between floats, or on casts that increase the type's range). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>An image. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>A `DType` to convert `image` to. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> saturate
						</dt>
						<dd>If `True`, clip the input before casting (if necessary). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>`image`, converted to `dtype`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3), dtype=tf.float32)
>> tf.image.convert_image_dtype(x, dtype=tf.float16, saturate=False)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convert_image_dtype" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convert_image_dtype</strong>(<span title="System.object">object</span> image, <a href="../tensorflow/DType.htm">DType</a> dtype, <span title="System.bool">bool</span> saturate, <a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> name)
		</h4>
		<div class="content">Convert `image` to `dtype`, scaling its values if needed. <p></p> Images that are represented using floating point values are expected to have
values in the range [0,1). Image data stored in integer data types are
expected to have values in the range `[0,MAX]`, where `MAX` is the largest
positive representable number for the data type. <p></p> This op converts between data types, scaling the values appropriately before
casting. <p></p> Note that converting from floating point inputs to integer types may lead to
over/underflow problems. Set saturate to `True` to avoid such problem in
problematic conversions. If enabled, saturation will clip the output into the
allowed range before performing a potentially dangerous cast (and only before
performing such a cast, i.e., when casting from a floating point to an integer
type, and when casting from a signed to an unsigned type; `saturate` has no
effect on casts between floats, or on casts that increase the type's range). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>An image. 
						</dd>
						<dt>
							<code><a href="../tensorflow/DType.htm">DType</a></code> dtype
						</dt>
						<dd>A `DType` to convert `image` to. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> saturate
						</dt>
						<dd>If `True`, clip the input before casting (if necessary). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>`image`, converted to `dtype`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3), dtype=tf.float32)
>> tf.image.convert_image_dtype(x, dtype=tf.float16, saturate=False)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="convert_image_dtype_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>convert_image_dtype_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> dtype, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> saturate, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Convert `image` to `dtype`, scaling its values if needed. <p></p> Images that are represented using floating point values are expected to have
values in the range [0,1). Image data stored in integer data types are
expected to have values in the range `[0,MAX]`, where `MAX` is the largest
positive representable number for the data type. <p></p> This op converts between data types, scaling the values appropriately before
casting. <p></p> Note that converting from floating point inputs to integer types may lead to
over/underflow problems. Set saturate to `True` to avoid such problem in
problematic conversions. If enabled, saturation will clip the output into the
allowed range before performing a potentially dangerous cast (and only before
performing such a cast, i.e., when casting from a floating point to an integer
type, and when casting from a signed to an unsigned type; `saturate` has no
effect on casts between floats, or on casts that increase the type's range). 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>An image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> dtype
						</dt>
						<dd>A `DType` to convert `image` to. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> saturate
						</dt>
						<dd>If `True`, clip the input before casting (if necessary). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>`image`, converted to `dtype`. <p></p> Usage Example:
```python
>> import tensorflow as tf
>> x = tf.random.normal(shape=(256, 256, 3), dtype=tf.float32)
>> tf.image.convert_image_dtype(x, dtype=tf.float16, saturate=False)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_and_resize" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_and_resize</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> box_ind, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> crop_size, <span title="System.string">string</span> method, <span title="System.int">int</span> extrapolation_value, <span title="System.string">string</span> name, <span title="System.object">object</span> box_indices)
		</h4>
		<div class="content">Extracts crops from the input image tensor and resizes them. <p></p> Extracts crops from the input image tensor and resizes them using bilinear
sampling or nearest neighbor sampling (possibly with aspect ratio change) to a
common output size specified by `crop_size`. This is more general than the
`crop_to_bounding_box` op which extracts a fixed size slice from the input image
and does not allow resizing or aspect ratio change. <p></p> Returns a tensor with `crops` from the input `image` at positions defined at the
bounding box locations in `boxes`. The cropped boxes are all resized (with
bilinear or nearest neighbor interpolation) to a fixed
`size = [crop_height, crop_width]`. The result is a 4-D tensor
`[num_boxes, crop_height, crop_width, depth]`. The resizing is corner aligned.
In particular, if `boxes = [[0, 0, 1, 1]]`, the method will give identical
results to using `tf.image.resize_bilinear()` or
`tf.image.resize_nearest_neighbor()`(depends on the `method` argument) with
`align_corners=True`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `uint8`, `uint16`, `int8`, `int16`, `int32`, `int64`, `half`, `float32`, `float64`.
A 4-D tensor of shape `[batch, image_height, image_width, depth]`.
Both `image_height` and `image_width` need to be positive. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A `Tensor` of type `float32`.
A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
specifies the coordinates of a box in the `box_ind[i]` image and is specified
in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
`y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
`[0, 1]` interval of normalized image height is mapped to
`[0, image_height - 1]` in image height coordinates. We do allow `y1` > `y2`, in
which case the sampled crop is an up-down flipped version of the original
image. The width dimension is treated similarly. Normalized coordinates
outside the `[0, 1]` range are allowed, in which case we use
`extrapolation_value` to extrapolate the input image values. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> box_ind
						</dt>
						<dd>A `Tensor` of type `int32`.
A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
The value of `box_ind[i]` specifies the image that the `i`-th box refers to. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> crop_size
						</dt>
						<dd>A `Tensor` of type `int32`.
A 1-D tensor of 2 elements, `size = [crop_height, crop_width]`. All
cropped image patches are resized to this size. The aspect ratio of the image
content is not preserved. Both `crop_height` and `crop_width` need to be
positive. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> method
						</dt>
						<dd>An optional `string` from: `"bilinear", "nearest"`. Defaults to `"bilinear"`.
A string specifying the sampling method for resizing. It can be either
`"bilinear"` or `"nearest"` and default to `"bilinear"`. Currently two sampling
methods are supported: Bilinear and Nearest Neighbor. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> extrapolation_value
						</dt>
						<dd>An optional `float`. Defaults to `0`.
Value used for extrapolation, when applicable. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> box_indices
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of type `float32`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_and_resize_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>crop_and_resize_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> boxes, <span title="System.object">object</span> box_ind, <span title="System.object">object</span> crop_size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> extrapolation_value, <span title="System.object">object</span> name, <span title="System.object">object</span> box_indices)
		</h4>
		<div class="content">Extracts crops from the input image tensor and resizes them. <p></p> Extracts crops from the input image tensor and resizes them using bilinear
sampling or nearest neighbor sampling (possibly with aspect ratio change) to a
common output size specified by `crop_size`. This is more general than the
`crop_to_bounding_box` op which extracts a fixed size slice from the input image
and does not allow resizing or aspect ratio change. <p></p> Returns a tensor with `crops` from the input `image` at positions defined at the
bounding box locations in `boxes`. The cropped boxes are all resized (with
bilinear or nearest neighbor interpolation) to a fixed
`size = [crop_height, crop_width]`. The result is a 4-D tensor
`[num_boxes, crop_height, crop_width, depth]`. The resizing is corner aligned.
In particular, if `boxes = [[0, 0, 1, 1]]`, the method will give identical
results to using `tf.image.resize_bilinear()` or
`tf.image.resize_nearest_neighbor()`(depends on the `method` argument) with
`align_corners=True`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `uint8`, `uint16`, `int8`, `int16`, `int32`, `int64`, `half`, `float32`, `float64`.
A 4-D tensor of shape `[batch, image_height, image_width, depth]`.
Both `image_height` and `image_width` need to be positive. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> boxes
						</dt>
						<dd>A `Tensor` of type `float32`.
A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
specifies the coordinates of a box in the `box_ind[i]` image and is specified
in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
`y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
`[0, 1]` interval of normalized image height is mapped to
`[0, image_height - 1]` in image height coordinates. We do allow `y1` > `y2`, in
which case the sampled crop is an up-down flipped version of the original
image. The width dimension is treated similarly. Normalized coordinates
outside the `[0, 1]` range are allowed, in which case we use
`extrapolation_value` to extrapolate the input image values. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> box_ind
						</dt>
						<dd>A `Tensor` of type `int32`.
A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
The value of `box_ind[i]` specifies the image that the `i`-th box refers to. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> crop_size
						</dt>
						<dd>A `Tensor` of type `int32`.
A 1-D tensor of 2 elements, `size = [crop_height, crop_width]`. All
cropped image patches are resized to this size. The aspect ratio of the image
content is not preserved. Both `crop_height` and `crop_width` need to be
positive. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>An optional `string` from: `"bilinear", "nearest"`. Defaults to `"bilinear"`.
A string specifying the sampling method for resizing. It can be either
`"bilinear"` or `"nearest"` and default to `"bilinear"`. Currently two sampling
methods are supported: Bilinear and Nearest Neighbor. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> extrapolation_value
						</dt>
						<dd>An optional `float`. Defaults to `0`.
Value used for extrapolation, when applicable. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> box_indices
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of type `float32`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> image, <span title="System.int">int</span> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> image, <span title="System.int">int</span> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> image, <span title="System.int">int</span> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> image, <span title="System.int">int</span> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> image, <span title="System.int">int</span> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>crop_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> image, <span title="System.int">int</span> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="crop_to_bounding_box_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>crop_to_bounding_box_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> offset_height, <span title="System.object">object</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops an image to a specified bounding box. <p></p> This op cuts a rectangular part out of `image`. The top-left corner of the
returned image is at `offset_height, offset_width` in `image`, and its
lower-right corner is at
`offset_height + target_height, offset_width + target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset_height
						</dt>
						<dd>Vertical coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset_width
						</dt>
						<dd>Horizontal coordinate of the top-left corner of the result in
the input. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of the result. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of the result. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="draw_bounding_boxes" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>draw_bounding_boxes</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <span title="System.string">string</span> name, <a href="../numpy/ndarray.htm">ndarray</a> colors)
		</h4>
		<div class="content">Draw bounding boxes on a batch of images. <p></p> Outputs a copy of `images` but draws on top of the pixels zero or more
bounding boxes specified by the locations in `boxes`. The coordinates of the
each bounding box in `boxes` are encoded as `[y_min, x_min, y_max, x_max]`.
The bounding box coordinates are floats in `[0.0, 1.0]` relative to the width
and height of the underlying image. <p></p> For example, if an image is 100 x 200 pixels (height x width) and the bounding
box is `[0.1, 0.2, 0.5, 0.9]`, the upper-left and bottom-right coordinates of
the bounding box will be `(40, 10)` to `(180, 50)` (in (x,y) coordinates). <p></p> Parts of the bounding box may fall outside the image. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float32`, `half`.
4-D with shape `[batch, height, width, depth]`. A batch of images. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A `Tensor` of type `float32`. 3-D with shape `[batch,
num_bounding_boxes, 4]` containing bounding boxes. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> colors
						</dt>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `images`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="encode_png" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>encode_png</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> compression, <span title="System.string">string</span> name)
		</h4>
		<div class="content">PNG-encode an image. <p></p> `image` is a 3-D uint8 or uint16 Tensor of shape `[height, width, channels]`
where `channels` is: <p></p> *   1: for grayscale.
*   2: for grayscale + alpha.
*   3: for RGB.
*   4: for RGBA. <p></p> The ZLIB compression level, `compression`, can be -1 for the PNG-encoder
default or a value from 0 to 9.  9 is the highest compression level, generating
the smallest output, but is slower. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `uint8`, `uint16`.
3-D with shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> compression
						</dt>
						<dd>An optional `int`. Defaults to `-1`. Compression level. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of type `string`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="encode_png_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>encode_png_dyn</strong>(<span title="System.object">object</span> image, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> compression, <span title="System.object">object</span> name)
		</h4>
		<div class="content">PNG-encode an image. <p></p> `image` is a 3-D uint8 or uint16 Tensor of shape `[height, width, channels]`
where `channels` is: <p></p> *   1: for grayscale.
*   2: for grayscale + alpha.
*   3: for RGB.
*   4: for RGBA. <p></p> The ZLIB compression level, `compression`, can be -1 for the PNG-encoder
default or a value from 0 to 9.  9 is the highest compression level, generating
the smallest output, but is slower. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `uint8`, `uint16`.
3-D with shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> compression
						</dt>
						<dd>An optional `int`. Defaults to `-1`. Compression level. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of type `string`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="extract_glimpse" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>extract_glimpse</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offsets, <span title="System.bool">bool</span> centered, <span title="System.bool">bool</span> normalized, <span title="System.bool">bool</span> uniform_noise, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Extracts a glimpse from the input tensor. <p></p> Returns a set of windows called glimpses extracted at location
`offsets` from the input tensor. If the windows only partially
overlaps the inputs, the non overlapping areas will be filled with
random noise. <p></p> The result is a 4-D tensor of shape `[batch_size, glimpse_height,
glimpse_width, channels]`. The channels and batch dimensions are the
same as that of the input tensor. The height and width of the output
windows are specified in the `size` parameter. <p></p> The argument `normalized` and `centered` controls how the windows are built: <p></p> * If the coordinates are normalized but not centered, 0.0 and 1.0
correspond to the minimum and maximum of each height and width
dimension.
* If the coordinates are both normalized and centered, they range from
-1.0 to 1.0. The coordinates (-1.0, -1.0) correspond to the upper
left corner, the lower right corner is located at (1.0, 1.0) and the
center is at (0, 0).
* If the coordinates are not normalized they are interpreted as
numbers of pixels. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input
						</dt>
						<dd>A `Tensor` of type `float32`. A 4-D float tensor of shape
`[batch_size, height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> size
						</dt>
						<dd>A `Tensor` of type `int32`. A 1-D tensor of 2 elements containing the
size of the glimpses to extract.  The glimpse height must be specified
first, following by the glimpse width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offsets
						</dt>
						<dd>A `Tensor` of type `float32`. A 2-D integer tensor of shape
`[batch_size, 2]` containing the y, x locations of the center of each
window. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> centered
						</dt>
						<dd>An optional `bool`. Defaults to `True`. indicates if the offset
coordinates are centered relative to the image, in which case the (0, 0)
offset is relative to the center of the input images. If false, the (0,0)
offset corresponds to the upper left corner of the input images. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> normalized
						</dt>
						<dd>An optional `bool`. Defaults to `True`. indicates if the offset
coordinates are normalized. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> uniform_noise
						</dt>
						<dd>An optional `bool`. Defaults to `True`. indicates if the
noise should be generated using a uniform distribution or a Gaussian
distribution. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of type `float32`. <p></p> Usage Example:
```python
BATCH_SIZE = 1
IMAGE_HEIGHT = 3
IMAGE_WIDTH = 3
CHANNELS = 1
GLIMPSE_SIZE = (2, 2)
image = tf.reshape(tf.range(9, delta=1, dtype=tf.float32),
shape=(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))
output = tf.image.extract_glimpse(image, size=GLIMPSE_SIZE,
offsets=[[1, 1]], centered=False, normalized=False)
``` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="extract_patches" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>extract_patches</strong>(<span title="System.object">object</span> images, <span title="System.object">object</span> sizes, <span title="System.object">object</span> strides, <span title="System.object">object</span> rates, <span title="System.object">object</span> padding, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Extract `patches` from `images`. <p></p> This op collects patches from the input image, as if applying a
convolution. All extracted patches are stacked in the depth (last) dimension
of the output. <p></p> Specifically, the op extracts patches of shape `sizes` which are `strides`
apart in the input image. The output is subsampled using the `rates` argument,
in the same manner as "atrous" or "dilated" convolutions. <p></p> The result is a 4D tensor which is indexed by batch, row, and column.
`output[i, x, y]` contains a flattened patch of size `sizes[1], sizes[2]`
which is taken from the input starting at
`images[i, x*strides[1], y*strides[2]]`. <p></p> Each output patch can be reshaped to `sizes[1], sizes[2], depth`, where
`depth` is `images.shape[3]`. <p></p> The output elements are taken from the input at intervals given by the `rate`
argument, as in dilated convolutions. <p></p> The `padding` argument has no effect on the size of each patch, it determines
how many patches are extracted. If `VALID`, only patches which are fully
contained in the input image are included. If `SAME`, all patches whose
starting point is inside the input are included, and areas outside the input
default to zero. <p></p> Example: <p></p> ```
n = 10
# images is a 1 x 10 x 10 x 1 array that contains the numbers 1 through 100
images = [[[[x * n + y + 1] for y in range(n)] for x in range(n)]] <p></p> # We generate two outputs as follows:
# 1. 3x3 patches with stride length 5
# 2. Same as above, but the rate is increased to 2
tf.extract_image_patches(images=images,
ksizes=[1, 3, 3, 1],
strides=[1, 5, 5, 1],
rates=[1, 1, 1, 1],
padding='VALID') <p></p> # Yields:
[[[[ 1  2  3 11 12 13 21 22 23]
[ 6  7  8 16 17 18 26 27 28]]
[[51 52 53 61 62 63 71 72 73]
[56 57 58 66 67 68 76 77 78]]]]
``` <p></p> If we mark the pixels in the input image which are taken for the output with
`*`, we see the pattern: <p></p> ```
*  *  *  4  5  *  *  *  9 10
*  *  * 14 15  *  *  * 19 20
*  *  * 24 25  *  *  * 29 30
31 32 33 34 35 36 37 38 39 40
41 42 43 44 45 46 47 48 49 50
*  *  * 54 55  *  *  * 59 60
*  *  * 64 65  *  *  * 69 70
*  *  * 74 75  *  *  * 79 80
81 82 83 84 85 86 87 88 89 90
91 92 93 94 95 96 97 98 99 100
``` <p></p> ```
tf.extract_image_patches(images=images,
sizes=[1, 3, 3, 1],
strides=[1, 5, 5, 1],
rates=[1, 2, 2, 1],
padding='VALID') <p></p> # Yields:
[[[[  1   3   5  21  23  25  41  43  45]
[  6   8  10  26  28  30  46  48  50]] <p></p> [[ 51  53  55  71  73  75  91  93  95]
[ 56  58  60  76  78  80  96  98 100]]]]
``` <p></p> We can again draw the effect, this time using the symbols `*`, `x`, `+` and
`o` to distinguish the patches: <p></p> ```
*  2  *  4  *  x  7  x  9  x
11 12 13 14 15 16 17 18 19 20
* 22  * 24  *  x 27  x 29  x
31 32 33 34 35 36 37 38 39 40
* 42  * 44  *  x 47  x 49  x
+ 52  + 54  +  o 57  o 59  o
61 62 63 64 65 66 67 68 69 70
+ 72  + 74  +  o 77  o 79  o
81 82 83 84 85 86 87 88 89 90
+ 92  + 94  +  o 97  o 99  o
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>A 4-D Tensor with shape `[batch, in_rows, in_cols, depth] 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sizes
						</dt>
						<dd>The size of the extracted patches. Must
be [1, size_rows, size_cols, 1]. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A 1-D Tensor of length 4. How far the centers of two consecutive
patches are in the images. Must be: `[1, stride_rows, stride_cols, 1]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rates
						</dt>
						<dd>A 1-D Tensor of length 4. Must be: `[1, rate_rows, rate_cols, 1]`.
This is the input stride, specifying how far two consecutive patch samples
are in the input. Equivalent to extracting patches with `patch_sizes_eff =
patch_sizes + (patch_sizes - 1) * (rates - 1)`, followed by subsampling
them spatially by a factor of `rates`. This is equivalent to `rate` in
dilated (a.k.a. Atrous) convolutions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A 4-D Tensor of the same type as the input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="extract_patches_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>extract_patches_dyn</strong>(<span title="System.object">object</span> images, <span title="System.object">object</span> sizes, <span title="System.object">object</span> strides, <span title="System.object">object</span> rates, <span title="System.object">object</span> padding, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Extract `patches` from `images`. <p></p> This op collects patches from the input image, as if applying a
convolution. All extracted patches are stacked in the depth (last) dimension
of the output. <p></p> Specifically, the op extracts patches of shape `sizes` which are `strides`
apart in the input image. The output is subsampled using the `rates` argument,
in the same manner as "atrous" or "dilated" convolutions. <p></p> The result is a 4D tensor which is indexed by batch, row, and column.
`output[i, x, y]` contains a flattened patch of size `sizes[1], sizes[2]`
which is taken from the input starting at
`images[i, x*strides[1], y*strides[2]]`. <p></p> Each output patch can be reshaped to `sizes[1], sizes[2], depth`, where
`depth` is `images.shape[3]`. <p></p> The output elements are taken from the input at intervals given by the `rate`
argument, as in dilated convolutions. <p></p> The `padding` argument has no effect on the size of each patch, it determines
how many patches are extracted. If `VALID`, only patches which are fully
contained in the input image are included. If `SAME`, all patches whose
starting point is inside the input are included, and areas outside the input
default to zero. <p></p> Example: <p></p> ```
n = 10
# images is a 1 x 10 x 10 x 1 array that contains the numbers 1 through 100
images = [[[[x * n + y + 1] for y in range(n)] for x in range(n)]] <p></p> # We generate two outputs as follows:
# 1. 3x3 patches with stride length 5
# 2. Same as above, but the rate is increased to 2
tf.extract_image_patches(images=images,
ksizes=[1, 3, 3, 1],
strides=[1, 5, 5, 1],
rates=[1, 1, 1, 1],
padding='VALID') <p></p> # Yields:
[[[[ 1  2  3 11 12 13 21 22 23]
[ 6  7  8 16 17 18 26 27 28]]
[[51 52 53 61 62 63 71 72 73]
[56 57 58 66 67 68 76 77 78]]]]
``` <p></p> If we mark the pixels in the input image which are taken for the output with
`*`, we see the pattern: <p></p> ```
*  *  *  4  5  *  *  *  9 10
*  *  * 14 15  *  *  * 19 20
*  *  * 24 25  *  *  * 29 30
31 32 33 34 35 36 37 38 39 40
41 42 43 44 45 46 47 48 49 50
*  *  * 54 55  *  *  * 59 60
*  *  * 64 65  *  *  * 69 70
*  *  * 74 75  *  *  * 79 80
81 82 83 84 85 86 87 88 89 90
91 92 93 94 95 96 97 98 99 100
``` <p></p> ```
tf.extract_image_patches(images=images,
sizes=[1, 3, 3, 1],
strides=[1, 5, 5, 1],
rates=[1, 2, 2, 1],
padding='VALID') <p></p> # Yields:
[[[[  1   3   5  21  23  25  41  43  45]
[  6   8  10  26  28  30  46  48  50]] <p></p> [[ 51  53  55  71  73  75  91  93  95]
[ 56  58  60  76  78  80  96  98 100]]]]
``` <p></p> We can again draw the effect, this time using the symbols `*`, `x`, `+` and
`o` to distinguish the patches: <p></p> ```
*  2  *  4  *  x  7  x  9  x
11 12 13 14 15 16 17 18 19 20
* 22  * 24  *  x 27  x 29  x
31 32 33 34 35 36 37 38 39 40
* 42  * 44  *  x 47  x 49  x
+ 52  + 54  +  o 57  o 59  o
61 62 63 64 65 66 67 68 69 70
+ 72  + 74  +  o 77  o 79  o
81 82 83 84 85 86 87 88 89 90
+ 92  + 94  +  o 97  o 99  o
``` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>A 4-D Tensor with shape `[batch, in_rows, in_cols, depth] 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> sizes
						</dt>
						<dd>The size of the extracted patches. Must
be [1, size_rows, size_cols, 1]. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> strides
						</dt>
						<dd>A 1-D Tensor of length 4. How far the centers of two consecutive
patches are in the images. Must be: `[1, stride_rows, stride_cols, 1]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> rates
						</dt>
						<dd>A 1-D Tensor of length 4. Must be: `[1, rate_rows, rate_cols, 1]`.
This is the input stride, specifying how far two consecutive patch samples
are in the input. Equivalent to extracting patches with `patch_sizes_eff =
patch_sizes + (patch_sizes - 1) * (rates - 1)`, followed by subsampling
them spatially by a factor of `rates`. This is equivalent to `rate` in
dilated (a.k.a. Atrous) convolutions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> padding
						</dt>
						<dd>The type of padding algorithm to use. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A 4-D Tensor of the same type as the input. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="flip_left_right" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>flip_left_right</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image)
		</h4>
		<div class="content">Flip an image horizontally (left to right). <p></p> Outputs the contents of `image` flipped along the width dimension. <p></p> See also `reverse()`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="flip_left_right_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>flip_left_right_dyn</strong>(<span title="System.object">object</span> image)
		</h4>
		<div class="content">Flip an image horizontally (left to right). <p></p> Outputs the contents of `image` flipped along the width dimension. <p></p> See also `reverse()`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="flip_up_down" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>flip_up_down</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image)
		</h4>
		<div class="content">Flip an image vertically (upside down). <p></p> Outputs the contents of `image` flipped along the height dimension. <p></p> See also `reverse()`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="flip_up_down_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>flip_up_down_dyn</strong>(<span title="System.object">object</span> image)
		</h4>
		<div class="content">Flip an image vertically (upside down). <p></p> Outputs the contents of `image` flipped along the height dimension. <p></p> See also `reverse()`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="grayscale_to_rgb" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>grayscale_to_rgb</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Converts one or more images from Grayscale to RGB. <p></p> Outputs a tensor of the same `DType` and rank as `images`.  The size of the
last dimension of the output is 3, containing the RGB value of the pixels.
The input images' last dimension must be size 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>The Grayscale tensor to convert. Last dimension must be size 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The converted grayscale image(s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="grayscale_to_rgb_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>grayscale_to_rgb_dyn</strong>(<span title="System.object">object</span> images, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Converts one or more images from Grayscale to RGB. <p></p> Outputs a tensor of the same `DType` and rank as `images`.  The size of the
last dimension of the output is 3, containing the RGB value of the pixels.
The input images' last dimension must be size 1. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>The Grayscale tensor to convert. Last dimension must be size 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The converted grayscale image(s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="hsv_to_rgb" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>hsv_to_rgb</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Convert one or more images from HSV to RGB. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the RGB
value of the pixels. The output is only well defined if the value in `images`
are in `[0,1]`. <p></p> See `rgb_to_hsv` for a description of the HSV encoding. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
1-D or higher rank. HSV data to convert. Last dimension must be size 3. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `images`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="hsv_to_rgb_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>hsv_to_rgb_dyn</strong>(<span title="System.object">object</span> images, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Convert one or more images from HSV to RGB. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the RGB
value of the pixels. The output is only well defined if the value in `images`
are in `[0,1]`. <p></p> See `rgb_to_hsv` for a description of the HSV encoding. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
1-D or higher rank. HSV data to convert. Last dimension must be size 3. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `images`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="image_gradients" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>image_gradients</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image)
		</h4>
		<div class="content">Returns image gradients (dy, dx) for each color channel. <p></p> Both output tensors have the same shape as the input: [batch_size, h, w,
d]. The gradient values are organized so that [I(x+1, y) - I(x, y)] is in
location (x, y). That means that dy will always have zeros in the last row,
and dx will always have zeros in the last column. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>Tensor with shape [batch_size, h, w, d]. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>Pair of tensors (dy, dx) holding the vertical and horizontal image
gradients (1-step finite difference). <p></p> Usage Example:
```python
BATCH_SIZE = 1
IMAGE_HEIGHT = 5
IMAGE_WIDTH = 5
CHANNELS = 1
image = tf.reshape(tf.range(IMAGE_HEIGHT * IMAGE_WIDTH * CHANNELS,
delta=1, dtype=tf.float32),
shape=(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))
dx, dy = tf.image.image_gradients(image)
print(image[0, :,:,0])
tf.Tensor(
[[ 0.  1.  2.  3.  4.]
[ 5.  6.  7.  8.  9.]
[10. 11. 12. 13. 14.]
[15. 16. 17. 18. 19.]
[20. 21. 22. 23. 24.]], shape=(5, 5), dtype=float32)
print(dx[0, :,:,0])
tf.Tensor(
[[5. 5. 5. 5. 5.]
[5. 5. 5. 5. 5.]
[5. 5. 5. 5. 5.]
[5. 5. 5. 5. 5.]
[0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)
print(dy[0, :,:,0])
tf.Tensor(
[[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]], shape=(5, 5), dtype=float32)
``` <p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="image_gradients" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>image_gradients</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> image)
		</h4>
		<div class="content">Returns image gradients (dy, dx) for each color channel. <p></p> Both output tensors have the same shape as the input: [batch_size, h, w,
d]. The gradient values are organized so that [I(x+1, y) - I(x, y)] is in
location (x, y). That means that dy will always have zeros in the last row,
and dx will always have zeros in the last column. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> image
						</dt>
						<dd>Tensor with shape [batch_size, h, w, d]. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd>Pair of tensors (dy, dx) holding the vertical and horizontal image
gradients (1-step finite difference). <p></p> Usage Example:
```python
BATCH_SIZE = 1
IMAGE_HEIGHT = 5
IMAGE_WIDTH = 5
CHANNELS = 1
image = tf.reshape(tf.range(IMAGE_HEIGHT * IMAGE_WIDTH * CHANNELS,
delta=1, dtype=tf.float32),
shape=(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))
dx, dy = tf.image.image_gradients(image)
print(image[0, :,:,0])
tf.Tensor(
[[ 0.  1.  2.  3.  4.]
[ 5.  6.  7.  8.  9.]
[10. 11. 12. 13. 14.]
[15. 16. 17. 18. 19.]
[20. 21. 22. 23. 24.]], shape=(5, 5), dtype=float32)
print(dx[0, :,:,0])
tf.Tensor(
[[5. 5. 5. 5. 5.]
[5. 5. 5. 5. 5.]
[5. 5. 5. 5. 5.]
[5. 5. 5. 5. 5.]
[0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)
print(dy[0, :,:,0])
tf.Tensor(
[[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]], shape=(5, 5), dtype=float32)
``` <p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="image_gradients_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>image_gradients_dyn</strong>(<span title="System.object">object</span> image)
		</h4>
		<div class="content">Returns image gradients (dy, dx) for each color channel. <p></p> Both output tensors have the same shape as the input: [batch_size, h, w,
d]. The gradient values are organized so that [I(x+1, y) - I(x, y)] is in
location (x, y). That means that dy will always have zeros in the last row,
and dx will always have zeros in the last column. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>Tensor with shape [batch_size, h, w, d]. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Pair of tensors (dy, dx) holding the vertical and horizontal image
gradients (1-step finite difference). <p></p> Usage Example:
```python
BATCH_SIZE = 1
IMAGE_HEIGHT = 5
IMAGE_WIDTH = 5
CHANNELS = 1
image = tf.reshape(tf.range(IMAGE_HEIGHT * IMAGE_WIDTH * CHANNELS,
delta=1, dtype=tf.float32),
shape=(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))
dx, dy = tf.image.image_gradients(image)
print(image[0, :,:,0])
tf.Tensor(
[[ 0.  1.  2.  3.  4.]
[ 5.  6.  7.  8.  9.]
[10. 11. 12. 13. 14.]
[15. 16. 17. 18. 19.]
[20. 21. 22. 23. 24.]], shape=(5, 5), dtype=float32)
print(dx[0, :,:,0])
tf.Tensor(
[[5. 5. 5. 5. 5.]
[5. 5. 5. 5. 5.]
[5. 5. 5. 5. 5.]
[5. 5. 5. 5. 5.]
[0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)
print(dy[0, :,:,0])
tf.Tensor(
[[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]
[1. 1. 1. 1. 0.]], shape=(5, 5), dtype=float32)
``` <p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="non_max_suppression" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <span title="System.int">int</span> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression(
                boxes, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression(
                boxes, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <span title="System.int">int</span> max_output_size, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression(
                boxes, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression(
                boxes, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression(
                boxes, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <span title="System.int">int</span> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression(
                boxes, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> max_output_size, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression(
                boxes, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression(
                boxes, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression(
                boxes, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>non_max_suppression_dyn</strong>(<span title="System.object">object</span> boxes, <span title="System.object">object</span> scores, <span title="System.object">object</span> max_output_size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression(
                boxes, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_overlaps" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression_overlaps</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> overlaps, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <span title="System.double">double</span> overlap_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high overlap with previously selected boxes.
N-by-n overlap values are supplied as square matrix.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> overlaps
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, num_boxes]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> overlap_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether
boxes overlap too much with respect to the provided overlap values. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression_overlaps(
                overlaps, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_overlaps_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>non_max_suppression_overlaps_dyn</strong>(<span title="System.object">object</span> overlaps, <span title="System.object">object</span> scores, <span title="System.object">object</span> max_output_size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> overlap_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high overlap with previously selected boxes.
N-by-n overlap values are supplied as square matrix.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> overlaps
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, num_boxes]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> overlap_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether
boxes overlap too much with respect to the provided overlap values. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices = tf.image.non_max_suppression_overlaps(
                overlaps, scores, max_output_size, iou_threshold)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_padded" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression_padded</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.bool">bool</span> pad_to_max_output_size, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Performs algorithmically equivalent operation to tf.image.non_max_suppression,
with the addition of an optional parameter which zero-pads the output to
be of size `max_output_size`.
The output of this operation is a tuple containing the set of integers
indexing into the input collection of bounding boxes representing the selected
boxes and the number of valid indices in the index set.  The bounding box
coordinates corresponding to the selected indices can then be obtained using
the <a href="..\..\tf\slice.md"><code>tf.slice</code></a> and <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operations. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_to_max_output_size
						</dt>
						<dd>bool.  If True, size of `selected_indices` output is
padded to `max_output_size`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(
                boxes, scores, max_output_size, iou_threshold,
                score_threshold, pad_to_max_output_size=True)
            selected_indices = tf.slice(
                selected_indices_padded, tf.constant([0]), num_valid)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_padded" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression_padded</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <span title="System.int">int</span> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.bool">bool</span> pad_to_max_output_size, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Performs algorithmically equivalent operation to tf.image.non_max_suppression,
with the addition of an optional parameter which zero-pads the output to
be of size `max_output_size`.
The output of this operation is a tuple containing the set of integers
indexing into the input collection of bounding boxes representing the selected
boxes and the number of valid indices in the index set.  The bounding box
coordinates corresponding to the selected indices can then be obtained using
the <a href="..\..\tf\slice.md"><code>tf.slice</code></a> and <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operations. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_to_max_output_size
						</dt>
						<dd>bool.  If True, size of `selected_indices` output is
padded to `max_output_size`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(
                boxes, scores, max_output_size, iou_threshold,
                score_threshold, pad_to_max_output_size=True)
            selected_indices = tf.slice(
                selected_indices_padded, tf.constant([0]), num_valid)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_padded" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression_padded</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <span title="System.int">int</span> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> score_threshold, <span title="System.bool">bool</span> pad_to_max_output_size, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Performs algorithmically equivalent operation to tf.image.non_max_suppression,
with the addition of an optional parameter which zero-pads the output to
be of size `max_output_size`.
The output of this operation is a tuple containing the set of integers
indexing into the input collection of bounding boxes representing the selected
boxes and the number of valid indices in the index set.  The bounding box
coordinates corresponding to the selected indices can then be obtained using
the <a href="..\..\tf\slice.md"><code>tf.slice</code></a> and <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operations. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_to_max_output_size
						</dt>
						<dd>bool.  If True, size of `selected_indices` output is
padded to `max_output_size`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(
                boxes, scores, max_output_size, iou_threshold,
                score_threshold, pad_to_max_output_size=True)
            selected_indices = tf.slice(
                selected_indices_padded, tf.constant([0]), num_valid)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_padded" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression_padded</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <span title="System.int">int</span> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.bool">bool</span> pad_to_max_output_size, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Performs algorithmically equivalent operation to tf.image.non_max_suppression,
with the addition of an optional parameter which zero-pads the output to
be of size `max_output_size`.
The output of this operation is a tuple containing the set of integers
indexing into the input collection of bounding boxes representing the selected
boxes and the number of valid indices in the index set.  The bounding box
coordinates corresponding to the selected indices can then be obtained using
the <a href="..\..\tf\slice.md"><code>tf.slice</code></a> and <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operations. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_to_max_output_size
						</dt>
						<dd>bool.  If True, size of `selected_indices` output is
padded to `max_output_size`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(
                boxes, scores, max_output_size, iou_threshold,
                score_threshold, pad_to_max_output_size=True)
            selected_indices = tf.slice(
                selected_indices_padded, tf.constant([0]), num_valid)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_padded" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression_padded</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> score_threshold, <span title="System.bool">bool</span> pad_to_max_output_size, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Performs algorithmically equivalent operation to tf.image.non_max_suppression,
with the addition of an optional parameter which zero-pads the output to
be of size `max_output_size`.
The output of this operation is a tuple containing the set of integers
indexing into the input collection of bounding boxes representing the selected
boxes and the number of valid indices in the index set.  The bounding box
coordinates corresponding to the selected indices can then be obtained using
the <a href="..\..\tf\slice.md"><code>tf.slice</code></a> and <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operations. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_to_max_output_size
						</dt>
						<dd>bool.  If True, size of `selected_indices` output is
padded to `max_output_size`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(
                boxes, scores, max_output_size, iou_threshold,
                score_threshold, pad_to_max_output_size=True)
            selected_indices = tf.slice(
                selected_indices_padded, tf.constant([0]), num_valid)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_padded" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression_padded</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> score_threshold, <span title="System.bool">bool</span> pad_to_max_output_size, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Performs algorithmically equivalent operation to tf.image.non_max_suppression,
with the addition of an optional parameter which zero-pads the output to
be of size `max_output_size`.
The output of this operation is a tuple containing the set of integers
indexing into the input collection of bounding boxes representing the selected
boxes and the number of valid indices in the index set.  The bounding box
coordinates corresponding to the selected indices can then be obtained using
the <a href="..\..\tf\slice.md"><code>tf.slice</code></a> and <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operations. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_to_max_output_size
						</dt>
						<dd>bool.  If True, size of `selected_indices` output is
padded to `max_output_size`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(
                boxes, scores, max_output_size, iou_threshold,
                score_threshold, pad_to_max_output_size=True)
            selected_indices = tf.slice(
                selected_indices_padded, tf.constant([0]), num_valid)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_padded" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression_padded</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <span title="System.int">int</span> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> score_threshold, <span title="System.bool">bool</span> pad_to_max_output_size, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Performs algorithmically equivalent operation to tf.image.non_max_suppression,
with the addition of an optional parameter which zero-pads the output to
be of size `max_output_size`.
The output of this operation is a tuple containing the set of integers
indexing into the input collection of bounding boxes representing the selected
boxes and the number of valid indices in the index set.  The bounding box
coordinates corresponding to the selected indices can then be obtained using
the <a href="..\..\tf\slice.md"><code>tf.slice</code></a> and <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operations. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_to_max_output_size
						</dt>
						<dd>bool.  If True, size of `selected_indices` output is
padded to `max_output_size`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(
                boxes, scores, max_output_size, iou_threshold,
                score_threshold, pad_to_max_output_size=True)
            selected_indices = tf.slice(
                selected_indices_padded, tf.constant([0]), num_valid)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_padded" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>non_max_suppression_padded</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.bool">bool</span> pad_to_max_output_size, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Performs algorithmically equivalent operation to tf.image.non_max_suppression,
with the addition of an optional parameter which zero-pads the output to
be of size `max_output_size`.
The output of this operation is a tuple containing the set of integers
indexing into the input collection of bounding boxes representing the selected
boxes and the number of valid indices in the index set.  The bounding box
coordinates corresponding to the selected indices can then be obtained using
the <a href="..\..\tf\slice.md"><code>tf.slice</code></a> and <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operations. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> pad_to_max_output_size
						</dt>
						<dd>bool.  If True, size of `selected_indices` output is
padded to `max_output_size`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(
                boxes, scores, max_output_size, iou_threshold,
                score_threshold, pad_to_max_output_size=True)
            selected_indices = tf.slice(
                selected_indices_padded, tf.constant([0]), num_valid)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_padded_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>non_max_suppression_padded_dyn</strong>(<span title="System.object">object</span> boxes, <span title="System.object">object</span> scores, <span title="System.object">object</span> max_output_size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> pad_to_max_output_size, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Performs algorithmically equivalent operation to tf.image.non_max_suppression,
with the addition of an optional parameter which zero-pads the output to
be of size `max_output_size`.
The output of this operation is a tuple containing the set of integers
indexing into the input collection of bounding boxes representing the selected
boxes and the number of valid indices in the index set.  The bounding box
coordinates corresponding to the selected indices can then be obtained using
the <a href="..\..\tf\slice.md"><code>tf.slice</code></a> and <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operations. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> pad_to_max_output_size
						</dt>
						<dd>bool.  If True, size of `selected_indices` output is
padded to `max_output_size`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(
                boxes, scores, max_output_size, iou_threshold,
                score_threshold, pad_to_max_output_size=True)
            selected_indices = tf.slice(
                selected_indices_padded, tf.constant([0]), num_valid)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_with_scores" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>non_max_suppression_with_scores</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> score_threshold, <span title="System.double">double</span> soft_nms_sigma, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation.
This function generalizes the <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> op by also
supporting a Soft-NMS (with Gaussian weighting) mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes instead of directly causing them to be pruned.
Consequently, in contrast to <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a>,
`tf.image.non_max_suppression_v2` returns the new scores of each input box in
the second output, `selected_scores`. <p></p> To enable this Soft-NMS mode, set the `soft_nms_sigma` parameter to be
larger than 0.  When `soft_nms_sigma` equals 0, the behavior of
`tf.image.non_max_suppression_v2` is identical to that of
<a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> (except for the extra output) both in function
and in running time. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> soft_nms_sigma
						</dt>
						<dd>A scalar float representing the Soft NMS sigma parameter;
See Bodla et al, https://arxiv.org/abs/1704.04503).  When
`soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)
NMS. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices, selected_scores = tf.image.non_max_suppression_v2(
                boxes, scores, max_output_size, iou_threshold=1.0, score_threshold=0.1,
                soft_nms_sigma=0.5)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_with_scores" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>non_max_suppression_with_scores</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> soft_nms_sigma, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation.
This function generalizes the <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> op by also
supporting a Soft-NMS (with Gaussian weighting) mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes instead of directly causing them to be pruned.
Consequently, in contrast to <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a>,
`tf.image.non_max_suppression_v2` returns the new scores of each input box in
the second output, `selected_scores`. <p></p> To enable this Soft-NMS mode, set the `soft_nms_sigma` parameter to be
larger than 0.  When `soft_nms_sigma` equals 0, the behavior of
`tf.image.non_max_suppression_v2` is identical to that of
<a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> (except for the extra output) both in function
and in running time. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> soft_nms_sigma
						</dt>
						<dd>A scalar float representing the Soft NMS sigma parameter;
See Bodla et al, https://arxiv.org/abs/1704.04503).  When
`soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)
NMS. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices, selected_scores = tf.image.non_max_suppression_v2(
                boxes, scores, max_output_size, iou_threshold=1.0, score_threshold=0.1,
                soft_nms_sigma=0.5)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_with_scores" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>non_max_suppression_with_scores</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.double">double</span> soft_nms_sigma, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation.
This function generalizes the <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> op by also
supporting a Soft-NMS (with Gaussian weighting) mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes instead of directly causing them to be pruned.
Consequently, in contrast to <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a>,
`tf.image.non_max_suppression_v2` returns the new scores of each input box in
the second output, `selected_scores`. <p></p> To enable this Soft-NMS mode, set the `soft_nms_sigma` parameter to be
larger than 0.  When `soft_nms_sigma` equals 0, the behavior of
`tf.image.non_max_suppression_v2` is identical to that of
<a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> (except for the extra output) both in function
and in running time. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> soft_nms_sigma
						</dt>
						<dd>A scalar float representing the Soft NMS sigma parameter;
See Bodla et al, https://arxiv.org/abs/1704.04503).  When
`soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)
NMS. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices, selected_scores = tf.image.non_max_suppression_v2(
                boxes, scores, max_output_size, iou_threshold=1.0, score_threshold=0.1,
                soft_nms_sigma=0.5)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_with_scores" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>non_max_suppression_with_scores</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> score_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> soft_nms_sigma, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation.
This function generalizes the <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> op by also
supporting a Soft-NMS (with Gaussian weighting) mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes instead of directly causing them to be pruned.
Consequently, in contrast to <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a>,
`tf.image.non_max_suppression_v2` returns the new scores of each input box in
the second output, `selected_scores`. <p></p> To enable this Soft-NMS mode, set the `soft_nms_sigma` parameter to be
larger than 0.  When `soft_nms_sigma` equals 0, the behavior of
`tf.image.non_max_suppression_v2` is identical to that of
<a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> (except for the extra output) both in function
and in running time. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> soft_nms_sigma
						</dt>
						<dd>A scalar float representing the Soft NMS sigma parameter;
See Bodla et al, https://arxiv.org/abs/1704.04503).  When
`soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)
NMS. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices, selected_scores = tf.image.non_max_suppression_v2(
                boxes, scores, max_output_size, iou_threshold=1.0, score_threshold=0.1,
                soft_nms_sigma=0.5)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_with_scores" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>non_max_suppression_with_scores</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> score_threshold, <span title="System.double">double</span> soft_nms_sigma, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation.
This function generalizes the <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> op by also
supporting a Soft-NMS (with Gaussian weighting) mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes instead of directly causing them to be pruned.
Consequently, in contrast to <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a>,
`tf.image.non_max_suppression_v2` returns the new scores of each input box in
the second output, `selected_scores`. <p></p> To enable this Soft-NMS mode, set the `soft_nms_sigma` parameter to be
larger than 0.  When `soft_nms_sigma` equals 0, the behavior of
`tf.image.non_max_suppression_v2` is identical to that of
<a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> (except for the extra output) both in function
and in running time. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> soft_nms_sigma
						</dt>
						<dd>A scalar float representing the Soft NMS sigma parameter;
See Bodla et al, https://arxiv.org/abs/1704.04503).  When
`soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)
NMS. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices, selected_scores = tf.image.non_max_suppression_v2(
                boxes, scores, max_output_size, iou_threshold=1.0, score_threshold=0.1,
                soft_nms_sigma=0.5)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_with_scores" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>non_max_suppression_with_scores</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> soft_nms_sigma, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation.
This function generalizes the <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> op by also
supporting a Soft-NMS (with Gaussian weighting) mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes instead of directly causing them to be pruned.
Consequently, in contrast to <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a>,
`tf.image.non_max_suppression_v2` returns the new scores of each input box in
the second output, `selected_scores`. <p></p> To enable this Soft-NMS mode, set the `soft_nms_sigma` parameter to be
larger than 0.  When `soft_nms_sigma` equals 0, the behavior of
`tf.image.non_max_suppression_v2` is identical to that of
<a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> (except for the extra output) both in function
and in running time. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> soft_nms_sigma
						</dt>
						<dd>A scalar float representing the Soft NMS sigma parameter;
See Bodla et al, https://arxiv.org/abs/1704.04503).  When
`soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)
NMS. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices, selected_scores = tf.image.non_max_suppression_v2(
                boxes, scores, max_output_size, iou_threshold=1.0, score_threshold=0.1,
                soft_nms_sigma=0.5)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_with_scores" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>non_max_suppression_with_scores</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <span title="System.double">double</span> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <span title="System.double">double</span> soft_nms_sigma, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation.
This function generalizes the <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> op by also
supporting a Soft-NMS (with Gaussian weighting) mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes instead of directly causing them to be pruned.
Consequently, in contrast to <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a>,
`tf.image.non_max_suppression_v2` returns the new scores of each input box in
the second output, `selected_scores`. <p></p> To enable this Soft-NMS mode, set the `soft_nms_sigma` parameter to be
larger than 0.  When `soft_nms_sigma` equals 0, the behavior of
`tf.image.non_max_suppression_v2` is identical to that of
<a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> (except for the extra output) both in function
and in running time. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> soft_nms_sigma
						</dt>
						<dd>A scalar float representing the Soft NMS sigma parameter;
See Bodla et al, https://arxiv.org/abs/1704.04503).  When
`soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)
NMS. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices, selected_scores = tf.image.non_max_suppression_v2(
                boxes, scores, max_output_size, iou_threshold=1.0, score_threshold=0.1,
                soft_nms_sigma=0.5)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_with_scores" class="method">
		<h4>
			<span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span> <strong>non_max_suppression_with_scores</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> boxes, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> scores, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> max_output_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> iou_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> score_threshold, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> soft_nms_sigma, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation.
This function generalizes the <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> op by also
supporting a Soft-NMS (with Gaussian weighting) mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes instead of directly causing them to be pruned.
Consequently, in contrast to <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a>,
`tf.image.non_max_suppression_v2` returns the new scores of each input box in
the second output, `selected_scores`. <p></p> To enable this Soft-NMS mode, set the `soft_nms_sigma` parameter to be
larger than 0.  When `soft_nms_sigma` equals 0, the behavior of
`tf.image.non_max_suppression_v2` is identical to that of
<a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> (except for the extra output) both in function
and in running time. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> soft_nms_sigma
						</dt>
						<dd>A scalar float representing the Soft NMS sigma parameter;
See Bodla et al, https://arxiv.org/abs/1704.04503).  When
`soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)
NMS. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.ValueTuple<object, object>">ValueTuple&lt;object, object&gt;</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices, selected_scores = tf.image.non_max_suppression_v2(
                boxes, scores, max_output_size, iou_threshold=1.0, score_threshold=0.1,
                soft_nms_sigma=0.5)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="non_max_suppression_with_scores_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>non_max_suppression_with_scores_dyn</strong>(<span title="System.object">object</span> boxes, <span title="System.object">object</span> scores, <span title="System.object">object</span> max_output_size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> iou_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> score_threshold, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> soft_nms_sigma, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Greedily selects a subset of bounding boxes in descending order of score. <p></p> Prunes away boxes that have high intersection-over-union (IOU) overlap
with previously selected boxes.  Bounding boxes are supplied as
`[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the coordinates of any
diagonal pair of box corners and the coordinates can be provided as normalized
(i.e., lying in the interval `[0, 1]`) or absolute.  Note that this algorithm
is agnostic to where the origin is in the coordinate system.  Note that this
algorithm is invariant to orthogonal transformations and translations
of the coordinate system; thus translating or reflections of the coordinate
system result in the same boxes being selected by the algorithm.
The output of this operation is a set of integers indexing into the input
collection of bounding boxes representing the selected boxes.  The bounding
box coordinates corresponding to the selected indices can then be obtained
using the <a href="..\..\tf\gather.md"><code>tf.gather</code></a> operation.
This function generalizes the <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> op by also
supporting a Soft-NMS (with Gaussian weighting) mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes instead of directly causing them to be pruned.
Consequently, in contrast to <a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a>,
`tf.image.non_max_suppression_v2` returns the new scores of each input box in
the second output, `selected_scores`. <p></p> To enable this Soft-NMS mode, set the `soft_nms_sigma` parameter to be
larger than 0.  When `soft_nms_sigma` equals 0, the behavior of
`tf.image.non_max_suppression_v2` is identical to that of
<a href="..\..\tf\image\non_max_suppression.md"><code>tf.image.non_max_suppression</code></a> (except for the extra output) both in function
and in running time. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> boxes
						</dt>
						<dd>A 2-D float `Tensor` of shape `[num_boxes, 4]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> scores
						</dt>
						<dd>A 1-D float `Tensor` of shape `[num_boxes]` representing a single
score corresponding to each box (each row of boxes). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_output_size
						</dt>
						<dd>A scalar integer `Tensor` representing the maximum number
of boxes to be selected by non max suppression. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> iou_threshold
						</dt>
						<dd>A float representing the threshold for deciding whether boxes
overlap too much with respect to IOU. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> score_threshold
						</dt>
						<dd>A float representing the threshold for deciding when to
remove boxes based on score. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> soft_nms_sigma
						</dt>
						<dd>A scalar float representing the Soft NMS sigma parameter;
See Bodla et al, https://arxiv.org/abs/1704.04503).  When
`soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)
NMS. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>selected_indices, selected_scores = tf.image.non_max_suppression_v2(
                boxes, scores, max_output_size, iou_threshold=1.0, score_threshold=0.1,
                soft_nms_sigma=0.5)
            selected_boxes = tf.gather(boxes, selected_indices) <p></p> </pre>
</div>
		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_height, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.int">int</span> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_height, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.int">int</span> offset_height, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.int">int</span> offset_height, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_height, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_height, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_height, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> offset_height, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> offset_height, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_height, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_height, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> offset_height, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_height, <span title="System.int">int</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>pad_to_bounding_box</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.int">int</span> offset_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="pad_to_bounding_box_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>pad_to_bounding_box_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> offset_height, <span title="System.object">object</span> offset_width, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Pad `image` with zeros to the specified `height` and `width`. <p></p> Adds `offset_height` rows of zeros on top, `offset_width` columns of
zeros on the left, and then pads the image on the bottom and right
with zeros until it has dimensions `target_height`, `target_width`. <p></p> This op does nothing if `offset_*` is zero and the image already has size
`target_height` by `target_width`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset_height
						</dt>
						<dd>Number of rows of zeros to add on top. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> offset_width
						</dt>
						<dd>Number of columns of zeros to add on the left. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Height of output image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Width of output image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, target_height, target_width, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[target_height, target_width, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="per_image_standardization" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>per_image_standardization</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image)
		</h4>
		<div class="content">Linearly scales each image in `image` to have mean 0 and variance 1. <p></p> For each 3-D image `x` in `image`, computes `(x - mean) / adjusted_stddev`,
where <p></p> - `mean` is the average of all values in `x`
- `adjusted_stddev = max(stddev, 1.0/sqrt(N))` is capped away from 0 to
protect against division by 0 when handling uniform images
- `N` is the number of elements in `x`
- `stddev` is the standard deviation of all values in `x` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>An n-D Tensor with at least 3 dimensions, the last 3 of which are the
dimensions of each image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` with same shape and dtype as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="per_image_standardization_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>per_image_standardization_dyn</strong>(<span title="System.object">object</span> image)
		</h4>
		<div class="content">Linearly scales each image in `image` to have mean 0 and variance 1. <p></p> For each 3-D image `x` in `image`, computes `(x - mean) / adjusted_stddev`,
where <p></p> - `mean` is the average of all values in `x`
- `adjusted_stddev = max(stddev, 1.0/sqrt(N))` is capped away from 0 to
protect against division by 0 when handling uniform images
- `N` is the number of elements in `x`
- `stddev` is the standard deviation of all values in `x` 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>An n-D Tensor with at least 3 dimensions, the last 3 of which are the
dimensions of each image. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` with same shape and dtype as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="psnr" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>psnr</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> a, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> b, <span title="System.int">int</span> max_val, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the Peak Signal-to-Noise Ratio between a and b. <p></p> This is intended to be used on signals (or images). Produces a PSNR value for
each image in batch. <p></p> The last three dimensions of input are expected to be [height, width, depth]. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> a
						</dt>
						<dd>First set of images. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> b
						</dt>
						<dd>Second set of images. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Namespace to embed the computation in. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The scalar PSNR between a and b. The returned tensor has type <a href="..\..\tf\dtypes\float32.md"><code>tf.float32</code></a>
and shape [batch_size, 1]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute PSNR over tf.uint8 Tensors.
            psnr1 = tf.image.psnr(im1, im2, max_val=255) <p></p> # Compute PSNR over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
psnr2 = tf.image.psnr(im1, im2, max_val=1.0)
# psnr1 and psnr2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="psnr" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>psnr</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> a, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> b, <span title="System.double">double</span> max_val, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the Peak Signal-to-Noise Ratio between a and b. <p></p> This is intended to be used on signals (or images). Produces a PSNR value for
each image in batch. <p></p> The last three dimensions of input are expected to be [height, width, depth]. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> a
						</dt>
						<dd>First set of images. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> b
						</dt>
						<dd>Second set of images. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Namespace to embed the computation in. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The scalar PSNR between a and b. The returned tensor has type <a href="..\..\tf\dtypes\float32.md"><code>tf.float32</code></a>
and shape [batch_size, 1]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute PSNR over tf.uint8 Tensors.
            psnr1 = tf.image.psnr(im1, im2, max_val=255) <p></p> # Compute PSNR over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
psnr2 = tf.image.psnr(im1, im2, max_val=1.0)
# psnr1 and psnr2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="psnr" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>psnr</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> a, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> b, <span title="System.double">double</span> max_val, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the Peak Signal-to-Noise Ratio between a and b. <p></p> This is intended to be used on signals (or images). Produces a PSNR value for
each image in batch. <p></p> The last three dimensions of input are expected to be [height, width, depth]. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> a
						</dt>
						<dd>First set of images. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> b
						</dt>
						<dd>Second set of images. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Namespace to embed the computation in. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The scalar PSNR between a and b. The returned tensor has type <a href="..\..\tf\dtypes\float32.md"><code>tf.float32</code></a>
and shape [batch_size, 1]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute PSNR over tf.uint8 Tensors.
            psnr1 = tf.image.psnr(im1, im2, max_val=255) <p></p> # Compute PSNR over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
psnr2 = tf.image.psnr(im1, im2, max_val=1.0)
# psnr1 and psnr2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="psnr" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>psnr</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> a, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> b, <span title="System.int">int</span> max_val, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the Peak Signal-to-Noise Ratio between a and b. <p></p> This is intended to be used on signals (or images). Produces a PSNR value for
each image in batch. <p></p> The last three dimensions of input are expected to be [height, width, depth]. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> a
						</dt>
						<dd>First set of images. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> b
						</dt>
						<dd>Second set of images. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Namespace to embed the computation in. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The scalar PSNR between a and b. The returned tensor has type <a href="..\..\tf\dtypes\float32.md"><code>tf.float32</code></a>
and shape [batch_size, 1]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute PSNR over tf.uint8 Tensors.
            psnr1 = tf.image.psnr(im1, im2, max_val=255) <p></p> # Compute PSNR over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
psnr2 = tf.image.psnr(im1, im2, max_val=1.0)
# psnr1 and psnr2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="psnr" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>psnr</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> a, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> b, <span title="System.double">double</span> max_val, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the Peak Signal-to-Noise Ratio between a and b. <p></p> This is intended to be used on signals (or images). Produces a PSNR value for
each image in batch. <p></p> The last three dimensions of input are expected to be [height, width, depth]. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> a
						</dt>
						<dd>First set of images. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> b
						</dt>
						<dd>Second set of images. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Namespace to embed the computation in. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The scalar PSNR between a and b. The returned tensor has type <a href="..\..\tf\dtypes\float32.md"><code>tf.float32</code></a>
and shape [batch_size, 1]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute PSNR over tf.uint8 Tensors.
            psnr1 = tf.image.psnr(im1, im2, max_val=255) <p></p> # Compute PSNR over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
psnr2 = tf.image.psnr(im1, im2, max_val=1.0)
# psnr1 and psnr2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="psnr" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>psnr</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> a, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> b, <span title="System.int">int</span> max_val, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the Peak Signal-to-Noise Ratio between a and b. <p></p> This is intended to be used on signals (or images). Produces a PSNR value for
each image in batch. <p></p> The last three dimensions of input are expected to be [height, width, depth]. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> a
						</dt>
						<dd>First set of images. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> b
						</dt>
						<dd>Second set of images. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Namespace to embed the computation in. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The scalar PSNR between a and b. The returned tensor has type <a href="..\..\tf\dtypes\float32.md"><code>tf.float32</code></a>
and shape [batch_size, 1]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute PSNR over tf.uint8 Tensors.
            psnr1 = tf.image.psnr(im1, im2, max_val=255) <p></p> # Compute PSNR over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
psnr2 = tf.image.psnr(im1, im2, max_val=1.0)
# psnr1 and psnr2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="psnr" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>psnr</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> a, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> b, <span title="System.double">double</span> max_val, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the Peak Signal-to-Noise Ratio between a and b. <p></p> This is intended to be used on signals (or images). Produces a PSNR value for
each image in batch. <p></p> The last three dimensions of input are expected to be [height, width, depth]. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> a
						</dt>
						<dd>First set of images. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> b
						</dt>
						<dd>Second set of images. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Namespace to embed the computation in. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The scalar PSNR between a and b. The returned tensor has type <a href="..\..\tf\dtypes\float32.md"><code>tf.float32</code></a>
and shape [batch_size, 1]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute PSNR over tf.uint8 Tensors.
            psnr1 = tf.image.psnr(im1, im2, max_val=255) <p></p> # Compute PSNR over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
psnr2 = tf.image.psnr(im1, im2, max_val=1.0)
# psnr1 and psnr2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="psnr" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>psnr</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> a, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> b, <span title="System.int">int</span> max_val, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the Peak Signal-to-Noise Ratio between a and b. <p></p> This is intended to be used on signals (or images). Produces a PSNR value for
each image in batch. <p></p> The last three dimensions of input are expected to be [height, width, depth]. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> a
						</dt>
						<dd>First set of images. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> b
						</dt>
						<dd>Second set of images. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>Namespace to embed the computation in. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The scalar PSNR between a and b. The returned tensor has type <a href="..\..\tf\dtypes\float32.md"><code>tf.float32</code></a>
and shape [batch_size, 1]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute PSNR over tf.uint8 Tensors.
            psnr1 = tf.image.psnr(im1, im2, max_val=255) <p></p> # Compute PSNR over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
psnr2 = tf.image.psnr(im1, im2, max_val=1.0)
# psnr1 and psnr2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="psnr_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>psnr_dyn</strong>(<span title="System.object">object</span> a, <span title="System.object">object</span> b, <span title="System.object">object</span> max_val, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Returns the Peak Signal-to-Noise Ratio between a and b. <p></p> This is intended to be used on signals (or images). Produces a PSNR value for
each image in batch. <p></p> The last three dimensions of input are expected to be [height, width, depth]. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> a
						</dt>
						<dd>First set of images. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> b
						</dt>
						<dd>Second set of images. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>Namespace to embed the computation in. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The scalar PSNR between a and b. The returned tensor has type <a href="..\..\tf\dtypes\float32.md"><code>tf.float32</code></a>
and shape [batch_size, 1]. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute PSNR over tf.uint8 Tensors.
            psnr1 = tf.image.psnr(im1, im2, max_val=255) <p></p> # Compute PSNR over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
psnr2 = tf.image.psnr(im1, im2, max_val=1.0)
# psnr1 and psnr2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="random_brightness" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_brightness</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> max_delta, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Adjust the brightness of images by a random factor. <p></p> Equivalent to `adjust_brightness()` using a `delta` randomly picked in the
interval `[-max_delta, max_delta)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>An image or images to adjust. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_delta
						</dt>
						<dd>float, must be non-negative. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>A Python integer. Used to create a random seed. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The brightness-adjusted image(s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_brightness_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_brightness_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> max_delta, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Adjust the brightness of images by a random factor. <p></p> Equivalent to `adjust_brightness()` using a `delta` randomly picked in the
interval `[-max_delta, max_delta)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>An image or images to adjust. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_delta
						</dt>
						<dd>float, must be non-negative. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>A Python integer. Used to create a random seed. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The brightness-adjusted image(s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_contrast" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_contrast</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.double">double</span> lower, <span title="System.double">double</span> upper, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Adjust the contrast of an image or images by a random factor. <p></p> Equivalent to `adjust_contrast()` but uses a `contrast_factor` randomly
picked in the interval `[lower, upper]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>An image tensor with 3 or more dimensions. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> lower
						</dt>
						<dd>float.  Lower bound for the random contrast factor. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> upper
						</dt>
						<dd>float.  Upper bound for the random contrast factor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>A Python integer. Used to create a random seed. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The contrast-adjusted image(s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_contrast_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_contrast_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> lower, <span title="System.object">object</span> upper, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Adjust the contrast of an image or images by a random factor. <p></p> Equivalent to `adjust_contrast()` but uses a `contrast_factor` randomly
picked in the interval `[lower, upper]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>An image tensor with 3 or more dimensions. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> lower
						</dt>
						<dd>float.  Lower bound for the random contrast factor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> upper
						</dt>
						<dd>float.  Upper bound for the random contrast factor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>A Python integer. Used to create a random seed. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The contrast-adjusted image(s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_flip_left_right" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_flip_left_right</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed)
		</h4>
		<div class="content">Randomly flip an image horizontally (left to right). <p></p> With a 1 in 2 chance, outputs the contents of `image` flipped along the
second dimension, which is `width`.  Otherwise output the image as-is. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create a random seed. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_flip_left_right_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_flip_left_right_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Randomly flip an image horizontally (left to right). <p></p> With a 1 in 2 chance, outputs the contents of `image` flipped along the
second dimension, which is `width`.  Otherwise output the image as-is. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>A Python integer. Used to create a random seed. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_flip_up_down" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_flip_up_down</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed)
		</h4>
		<div class="content">Randomly flips an image vertically (upside down). <p></p> With a 1 in 2 chance, outputs the contents of `image` flipped along the first
dimension, which is `height`.  Otherwise output the image as-is. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>A Python integer. Used to create a random seed. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_flip_up_down_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_flip_up_down_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Randomly flips an image vertically (upside down). <p></p> With a 1 in 2 chance, outputs the contents of `image` flipped along the first
dimension, which is `height`.  Otherwise output the image as-is. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>A Python integer. Used to create a random seed. See
`tf.compat.v1.set_random_seed` for behavior. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_hue" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_hue</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> image, <span title="System.double">double</span> max_delta, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Adjust the hue of RGB images by a random factor. <p></p> Equivalent to `adjust_hue()` but uses a `delta` randomly
picked in the interval `[-max_delta, max_delta]`. <p></p> `max_delta` must be in the interval `[0, 0.5]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_delta
						</dt>
						<dd>float.  Maximum value for the random delta. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An operation-specific seed. It will be used in conjunction with the
graph-level seed to determine the real seeds that will be used in this
operation. Please see the documentation of set_random_seed for its
interaction with the graph-level random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_hue" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_hue</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.double">double</span> max_delta, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Adjust the hue of RGB images by a random factor. <p></p> Equivalent to `adjust_hue()` but uses a `delta` randomly
picked in the interval `[-max_delta, max_delta]`. <p></p> `max_delta` must be in the interval `[0, 0.5]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_delta
						</dt>
						<dd>float.  Maximum value for the random delta. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An operation-specific seed. It will be used in conjunction with the
graph-level seed to determine the real seeds that will be used in this
operation. Please see the documentation of set_random_seed for its
interaction with the graph-level random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_hue" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_hue</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> image, <span title="System.double">double</span> max_delta, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Adjust the hue of RGB images by a random factor. <p></p> Equivalent to `adjust_hue()` but uses a `delta` randomly
picked in the interval `[-max_delta, max_delta]`. <p></p> `max_delta` must be in the interval `[0, 0.5]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_delta
						</dt>
						<dd>float.  Maximum value for the random delta. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An operation-specific seed. It will be used in conjunction with the
graph-level seed to determine the real seeds that will be used in this
operation. Please see the documentation of set_random_seed for its
interaction with the graph-level random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_hue_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_hue_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> max_delta, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Adjust the hue of RGB images by a random factor. <p></p> Equivalent to `adjust_hue()` but uses a `delta` randomly
picked in the interval `[-max_delta, max_delta]`. <p></p> `max_delta` must be in the interval `[0, 0.5]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_delta
						</dt>
						<dd>float.  Maximum value for the random delta. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An operation-specific seed. It will be used in conjunction with the
graph-level seed to determine the real seeds that will be used in this
operation. Please see the documentation of set_random_seed for its
interaction with the graph-level random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_jpeg_quality" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_jpeg_quality</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> min_jpeg_quality, <span title="System.int">int</span> max_jpeg_quality, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Randomly changes jpeg encoding quality for inducing jpeg noise. <p></p> `min_jpeg_quality` must be in the interval `[0, 100]` and less than
`max_jpeg_quality`.
`max_jpeg_quality` must be in the interval `[0, 100]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_jpeg_quality
						</dt>
						<dd>Minimum jpeg encoding quality to use. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_jpeg_quality
						</dt>
						<dd>Maximum jpeg encoding quality to use. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An operation-specific seed. It will be used in conjunction with the
graph-level seed to determine the real seeds that will be used in this
operation. Please see the documentation of set_random_seed for its
interaction with the graph-level random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_jpeg_quality_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_jpeg_quality_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> min_jpeg_quality, <span title="System.object">object</span> max_jpeg_quality, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Randomly changes jpeg encoding quality for inducing jpeg noise. <p></p> `min_jpeg_quality` must be in the interval `[0, 100]` and less than
`max_jpeg_quality`.
`max_jpeg_quality` must be in the interval `[0, 100]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> min_jpeg_quality
						</dt>
						<dd>Minimum jpeg encoding quality to use. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_jpeg_quality
						</dt>
						<dd>Maximum jpeg encoding quality to use. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An operation-specific seed. It will be used in conjunction with the
graph-level seed to determine the real seeds that will be used in this
operation. Please see the documentation of set_random_seed for its
interaction with the graph-level random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_saturation" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_saturation</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> lower, <span title="System.object">object</span> upper, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Adjust the saturation of RGB images by a random factor. <p></p> Equivalent to `adjust_saturation()` but uses a `saturation_factor` randomly
picked in the interval `[lower, upper]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> lower
						</dt>
						<dd>float.  Lower bound for the random saturation factor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> upper
						</dt>
						<dd>float.  Upper bound for the random saturation factor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An operation-specific seed. It will be used in conjunction with the
graph-level seed to determine the real seeds that will be used in this
operation. Please see the documentation of set_random_seed for its
interaction with the graph-level random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="random_saturation_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>random_saturation_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> lower, <span title="System.object">object</span> upper, <span title="System.object">object</span> seed)
		</h4>
		<div class="content">Adjust the saturation of RGB images by a random factor. <p></p> Equivalent to `adjust_saturation()` but uses a `saturation_factor` randomly
picked in the interval `[lower, upper]`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>RGB image or images. Size of the last dimension must be 3. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> lower
						</dt>
						<dd>float.  Lower bound for the random saturation factor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> upper
						</dt>
						<dd>float.  Upper bound for the random saturation factor. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An operation-specific seed. It will be used in conjunction with the
graph-level seed to determine the real seeds that will be used in this
operation. Please see the documentation of set_random_seed for its
interaction with the graph-level random seed. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Adjusted image(s), same shape and DType as `image`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> images, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> align_corners, <span title="System.bool">bool</span> preserve_aspect_ratio, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Resize `images` to `size` using the specified `method`. <p></p> Resized images will be distorted if their original aspect ratio is not
the same as `size`.  To avoid distortions see
`tf.compat.v1.image.resize_image_with_pad`. <p></p> `method` can be one of: <p></p> *   <b>`ResizeMethod.BILINEAR`</b>: [Bilinear interpolation.](
https://en.wikipedia.org/wiki/Bilinear_interpolation)
*   <b>`ResizeMethod.NEAREST_NEIGHBOR`</b>: [Nearest neighbor interpolation.](
https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation)
*   <b>`ResizeMethod.BICUBIC`</b>: [Bicubic interpolation.](
https://en.wikipedia.org/wiki/Bicubic_interpolation)
*   <b>`ResizeMethod.AREA`</b>: Area interpolation. <p></p> The return value has the same type as `images` if `method` is
`ResizeMethod.NEAREST_NEIGHBOR`. It will also have the same type as `images`
if the size of `images` can be statically determined to be the same as `size`,
because `images` is returned in this case. Otherwise, the return value has
type `float32`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> images
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> size
						</dt>
						<dd>A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The new
size for the images. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>ResizeMethod.  Defaults to `ResizeMethod.BILINEAR`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preserve_aspect_ratio
						</dt>
						<dd>Whether to preserve the aspect ratio. If this is set,
then `images` will be resized to a size that fits in `size` while
preserving the aspect ratio of the original image. Scales up the image if
`size` is bigger than the current size of the `image`. Defaults to False. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> images, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> size, <span title="System.string">string</span> method, <span title="System.bool">bool</span> align_corners, <span title="System.bool">bool</span> preserve_aspect_ratio, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Resize `images` to `size` using the specified `method`. <p></p> Resized images will be distorted if their original aspect ratio is not
the same as `size`.  To avoid distortions see
`tf.compat.v1.image.resize_image_with_pad`. <p></p> `method` can be one of: <p></p> *   <b>`ResizeMethod.BILINEAR`</b>: [Bilinear interpolation.](
https://en.wikipedia.org/wiki/Bilinear_interpolation)
*   <b>`ResizeMethod.NEAREST_NEIGHBOR`</b>: [Nearest neighbor interpolation.](
https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation)
*   <b>`ResizeMethod.BICUBIC`</b>: [Bicubic interpolation.](
https://en.wikipedia.org/wiki/Bicubic_interpolation)
*   <b>`ResizeMethod.AREA`</b>: Area interpolation. <p></p> The return value has the same type as `images` if `method` is
`ResizeMethod.NEAREST_NEIGHBOR`. It will also have the same type as `images`
if the size of `images` can be statically determined to be the same as `size`,
because `images` is returned in this case. Otherwise, the return value has
type `float32`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> images
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> size
						</dt>
						<dd>A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The new
size for the images. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> method
						</dt>
						<dd>ResizeMethod.  Defaults to `ResizeMethod.BILINEAR`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preserve_aspect_ratio
						</dt>
						<dd>Whether to preserve the aspect ratio. If this is set,
then `images` will be resized to a size that fits in `size` while
preserving the aspect ratio of the original image. Scales up the image if
`size` is bigger than the current size of the `image`. Defaults to False. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> images, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> align_corners, <span title="System.bool">bool</span> preserve_aspect_ratio, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Resize `images` to `size` using the specified `method`. <p></p> Resized images will be distorted if their original aspect ratio is not
the same as `size`.  To avoid distortions see
`tf.compat.v1.image.resize_image_with_pad`. <p></p> `method` can be one of: <p></p> *   <b>`ResizeMethod.BILINEAR`</b>: [Bilinear interpolation.](
https://en.wikipedia.org/wiki/Bilinear_interpolation)
*   <b>`ResizeMethod.NEAREST_NEIGHBOR`</b>: [Nearest neighbor interpolation.](
https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation)
*   <b>`ResizeMethod.BICUBIC`</b>: [Bicubic interpolation.](
https://en.wikipedia.org/wiki/Bicubic_interpolation)
*   <b>`ResizeMethod.AREA`</b>: Area interpolation. <p></p> The return value has the same type as `images` if `method` is
`ResizeMethod.NEAREST_NEIGHBOR`. It will also have the same type as `images`
if the size of `images` can be statically determined to be the same as `size`,
because `images` is returned in this case. Otherwise, the return value has
type `float32`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> images
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> size
						</dt>
						<dd>A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The new
size for the images. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>ResizeMethod.  Defaults to `ResizeMethod.BILINEAR`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preserve_aspect_ratio
						</dt>
						<dd>Whether to preserve the aspect ratio. If this is set,
then `images` will be resized to a size that fits in `size` while
preserving the aspect ratio of the original image. Scales up the image if
`size` is bigger than the current size of the `image`. Defaults to False. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> size, <span title="System.string">string</span> method, <span title="System.bool">bool</span> align_corners, <span title="System.bool">bool</span> preserve_aspect_ratio, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Resize `images` to `size` using the specified `method`. <p></p> Resized images will be distorted if their original aspect ratio is not
the same as `size`.  To avoid distortions see
`tf.compat.v1.image.resize_image_with_pad`. <p></p> `method` can be one of: <p></p> *   <b>`ResizeMethod.BILINEAR`</b>: [Bilinear interpolation.](
https://en.wikipedia.org/wiki/Bilinear_interpolation)
*   <b>`ResizeMethod.NEAREST_NEIGHBOR`</b>: [Nearest neighbor interpolation.](
https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation)
*   <b>`ResizeMethod.BICUBIC`</b>: [Bicubic interpolation.](
https://en.wikipedia.org/wiki/Bicubic_interpolation)
*   <b>`ResizeMethod.AREA`</b>: Area interpolation. <p></p> The return value has the same type as `images` if `method` is
`ResizeMethod.NEAREST_NEIGHBOR`. It will also have the same type as `images`
if the size of `images` can be statically determined to be the same as `size`,
because `images` is returned in this case. Otherwise, the return value has
type `float32`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> size
						</dt>
						<dd>A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The new
size for the images. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> method
						</dt>
						<dd>ResizeMethod.  Defaults to `ResizeMethod.BILINEAR`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preserve_aspect_ratio
						</dt>
						<dd>Whether to preserve the aspect ratio. If this is set,
then `images` will be resized to a size that fits in `size` while
preserving the aspect ratio of the original image. Scales up the image if
`size` is bigger than the current size of the `image`. Defaults to False. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> size, <span title="System.string">string</span> method, <span title="System.bool">bool</span> align_corners, <span title="System.bool">bool</span> preserve_aspect_ratio, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Resize `images` to `size` using the specified `method`. <p></p> Resized images will be distorted if their original aspect ratio is not
the same as `size`.  To avoid distortions see
`tf.compat.v1.image.resize_image_with_pad`. <p></p> `method` can be one of: <p></p> *   <b>`ResizeMethod.BILINEAR`</b>: [Bilinear interpolation.](
https://en.wikipedia.org/wiki/Bilinear_interpolation)
*   <b>`ResizeMethod.NEAREST_NEIGHBOR`</b>: [Nearest neighbor interpolation.](
https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation)
*   <b>`ResizeMethod.BICUBIC`</b>: [Bicubic interpolation.](
https://en.wikipedia.org/wiki/Bicubic_interpolation)
*   <b>`ResizeMethod.AREA`</b>: Area interpolation. <p></p> The return value has the same type as `images` if `method` is
`ResizeMethod.NEAREST_NEIGHBOR`. It will also have the same type as `images`
if the size of `images` can be statically determined to be the same as `size`,
because `images` is returned in this case. Otherwise, the return value has
type `float32`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> size
						</dt>
						<dd>A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The new
size for the images. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> method
						</dt>
						<dd>ResizeMethod.  Defaults to `ResizeMethod.BILINEAR`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preserve_aspect_ratio
						</dt>
						<dd>Whether to preserve the aspect ratio. If this is set,
then `images` will be resized to a size that fits in `size` while
preserving the aspect ratio of the original image. Scales up the image if
`size` is bigger than the current size of the `image`. Defaults to False. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> images, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> size, <span title="System.string">string</span> method, <span title="System.bool">bool</span> align_corners, <span title="System.bool">bool</span> preserve_aspect_ratio, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Resize `images` to `size` using the specified `method`. <p></p> Resized images will be distorted if their original aspect ratio is not
the same as `size`.  To avoid distortions see
`tf.compat.v1.image.resize_image_with_pad`. <p></p> `method` can be one of: <p></p> *   <b>`ResizeMethod.BILINEAR`</b>: [Bilinear interpolation.](
https://en.wikipedia.org/wiki/Bilinear_interpolation)
*   <b>`ResizeMethod.NEAREST_NEIGHBOR`</b>: [Nearest neighbor interpolation.](
https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation)
*   <b>`ResizeMethod.BICUBIC`</b>: [Bicubic interpolation.](
https://en.wikipedia.org/wiki/Bicubic_interpolation)
*   <b>`ResizeMethod.AREA`</b>: Area interpolation. <p></p> The return value has the same type as `images` if `method` is
`ResizeMethod.NEAREST_NEIGHBOR`. It will also have the same type as `images`
if the size of `images` can be statically determined to be the same as `size`,
because `images` is returned in this case. Otherwise, the return value has
type `float32`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> images
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> size
						</dt>
						<dd>A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The new
size for the images. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> method
						</dt>
						<dd>ResizeMethod.  Defaults to `ResizeMethod.BILINEAR`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> preserve_aspect_ratio
						</dt>
						<dd>Whether to preserve the aspect ratio. If this is set,
then `images` will be resized to a size that fits in `size` while
preserving the aspect ratio of the original image. Scales up the image if
`size` is bigger than the current size of the `image`. Defaults to False. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_image_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_image_with_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> align_corners)
		</h4>
		<div class="content">Resizes and pads an image to a target width and height. <p></p> Resizes an image to a target width and height by keeping
the aspect ratio the same without distortion. If the target
dimensions don't match the image dimensions, the image
is resized and then padded with zeroes to match requested
dimensions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>Method to use for resizing image. See `resize_images()` 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Resized and padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_image_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_image_with_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> target_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> align_corners)
		</h4>
		<div class="content">Resizes and pads an image to a target width and height. <p></p> Resizes an image to a target width and height by keeping
the aspect ratio the same without distortion. If the target
dimensions don't match the image dimensions, the image
is resized and then padded with zeroes to match requested
dimensions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>Method to use for resizing image. See `resize_images()` 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Resized and padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_image_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_image_with_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> target_height, <span title="System.int">int</span> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> align_corners)
		</h4>
		<div class="content">Resizes and pads an image to a target width and height. <p></p> Resizes an image to a target width and height by keeping
the aspect ratio the same without distortion. If the target
dimensions don't match the image dimensions, the image
is resized and then padded with zeroes to match requested
dimensions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>Method to use for resizing image. See `resize_images()` 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Resized and padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_image_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_image_with_pad</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> align_corners)
		</h4>
		<div class="content">Resizes and pads an image to a target width and height. <p></p> Resizes an image to a target width and height by keeping
the aspect ratio the same without distortion. If the target
dimensions don't match the image dimensions, the image
is resized and then padded with zeroes to match requested
dimensions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>Method to use for resizing image. See `resize_images()` 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Resized and padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_image_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_image_with_pad</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <span title="System.int">int</span> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> align_corners)
		</h4>
		<div class="content">Resizes and pads an image to a target width and height. <p></p> Resizes an image to a target width and height by keeping
the aspect ratio the same without distortion. If the target
dimensions don't match the image dimensions, the image
is resized and then padded with zeroes to match requested
dimensions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>Method to use for resizing image. See `resize_images()` 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Resized and padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_image_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_image_with_pad</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.int">int</span> target_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> align_corners)
		</h4>
		<div class="content">Resizes and pads an image to a target width and height. <p></p> Resizes an image to a target width and height by keeping
the aspect ratio the same without distortion. If the target
dimensions don't match the image dimensions, the image
is resized and then padded with zeroes to match requested
dimensions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>Method to use for resizing image. See `resize_images()` 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Resized and padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_image_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_image_with_pad</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.int">int</span> target_height, <span title="System.int">int</span> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> align_corners)
		</h4>
		<div class="content">Resizes and pads an image to a target width and height. <p></p> Resizes an image to a target width and height by keeping
the aspect ratio the same without distortion. If the target
dimensions don't match the image dimensions, the image
is resized and then padded with zeroes to match requested
dimensions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>Method to use for resizing image. See `resize_images()` 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Resized and padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_image_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_image_with_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <span title="System.int">int</span> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> align_corners)
		</h4>
		<div class="content">Resizes and pads an image to a target width and height. <p></p> Resizes an image to a target width and height by keeping
the aspect ratio the same without distortion. If the target
dimensions don't match the image dimensions, the image
is resized and then padded with zeroes to match requested
dimensions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>Method to use for resizing image. See `resize_images()` 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Resized and padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_image_with_pad_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_image_with_pad_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> align_corners)
		</h4>
		<div class="content">Resizes and pads an image to a target width and height. <p></p> Resizes an image to a target width and height by keeping
the aspect ratio the same without distortion. If the target
dimensions don't match the image dimensions, the image
is resized and then padded with zeroes to match requested
dimensions. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> method
						</dt>
						<dd>Method to use for resizing image. See `resize_images()` 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> align_corners
						</dt>
						<dd>bool.  If True, the centers of the 4 corner pixels of the
input and output tensors are aligned, preserving the values at the corner
pixels. Defaults to `False`. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Resized and padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.object">object</span> image, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> image, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> image, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> image, <a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> image, <span title="System.int">int</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> image, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> image, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.object">object</span> image, <a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.object">object</span> image, <span title="System.int">int</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.object">object</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.object">object</span> image, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> image, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> image, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> image, <span title="System.int">int</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> image, <a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> image, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> image, <a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> image, <span title="System.int">int</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> image, <a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> image, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_crop_or_pad_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_crop_or_pad_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width)
		</h4>
		<div class="content">Crops and/or pads an image to a target width and height. <p></p> Resizes an image to a target width and height by either centrally
cropping the image or padding it evenly with zeros. <p></p> If `width` or `height` is greater than the specified `target_width` or
`target_height` respectively, this op centrally crops along that dimension.
If `width` or `height` is smaller than the specified `target_width` or
`target_height` respectively, this op centrally pads with 0 along that
dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_height
						</dt>
						<dd>Target height. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> target_width
						</dt>
						<dd>Target width. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Cropped and/or padded image.
If `images` was 4-D, a 4-D float Tensor of shape
`[batch, new_height, new_width, channels]`.
If `images` was 3-D, a 3-D float Tensor of shape
`[new_height, new_width, channels]`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="resize_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_with_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> antialias)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="resize_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_with_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> target_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> antialias)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="resize_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_with_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> target_height, <span title="System.int">int</span> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> antialias)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="resize_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_with_pad</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> antialias)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="resize_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_with_pad</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <span title="System.int">int</span> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> antialias)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="resize_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_with_pad</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.int">int</span> target_height, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> antialias)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="resize_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_with_pad</strong>(<span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> image, <span title="System.int">int</span> target_height, <span title="System.int">int</span> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> antialias)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="resize_with_pad" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>resize_with_pad</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> target_height, <span title="System.int">int</span> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <span title="System.bool">bool</span> antialias)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="resize_with_pad_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>resize_with_pad_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> target_height, <span title="System.object">object</span> target_width, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> method, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> antialias)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="rgb_to_grayscale" class="method">
		<h4>
			<span title="System.object">object</span> <strong>rgb_to_grayscale</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Converts one or more images from RGB to Grayscale. <p></p> Outputs a tensor of the same `DType` and rank as `images`.  The size of the
last dimension of the output is 1, containing the Grayscale value of the
pixels. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>The RGB tensor to convert. Last dimension must have size 3 and
should contain RGB values. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The converted grayscale image(s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rgb_to_grayscale_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>rgb_to_grayscale_dyn</strong>(<span title="System.object">object</span> images, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Converts one or more images from RGB to Grayscale. <p></p> Outputs a tensor of the same `DType` and rank as `images`.  The size of the
last dimension of the output is 1, containing the Grayscale value of the
pixels. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>The RGB tensor to convert. Last dimension must have size 3 and
should contain RGB values. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The converted grayscale image(s). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rgb_to_hsv" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>rgb_to_hsv</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Converts one or more images from RGB to HSV. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the HSV
value of the pixels. The output is only well defined if the value in `images`
are in `[0,1]`. <p></p> `output[..., 0]` contains hue, `output[..., 1]` contains saturation, and
`output[..., 2]` contains value. All HSV values are in `[0,1]`. A hue of 0
corresponds to pure red, hue 1/3 is pure green, and 2/3 is pure blue. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
1-D or higher rank. RGB data to convert. Last dimension must be size 3. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `images`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rgb_to_hsv_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>rgb_to_hsv_dyn</strong>(<span title="System.object">object</span> images, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Converts one or more images from RGB to HSV. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the HSV
value of the pixels. The output is only well defined if the value in `images`
are in `[0,1]`. <p></p> `output[..., 0]` contains hue, `output[..., 1]` contains saturation, and
`output[..., 2]` contains value. All HSV values are in `[0,1]`. A hue of 0
corresponds to pure red, hue 1/3 is pure green, and 2/3 is pure blue. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
1-D or higher rank. RGB data to convert. Last dimension must be size 3. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `images`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rgb_to_yiq" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>rgb_to_yiq</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images)
		</h4>
		<div class="content">Converts one or more images from RGB to YIQ. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the YIQ
value of the pixels.
The output is only well defined if the value in images are in [0,1]. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>2-D or higher rank. Image data to convert. Last dimension must be
size 3. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rgb_to_yiq_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>rgb_to_yiq_dyn</strong>(<span title="System.object">object</span> images)
		</h4>
		<div class="content">Converts one or more images from RGB to YIQ. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the YIQ
value of the pixels.
The output is only well defined if the value in images are in [0,1]. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>2-D or higher rank. Image data to convert. Last dimension must be
size 3. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rgb_to_yuv" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>rgb_to_yuv</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images)
		</h4>
		<div class="content">Converts one or more images from RGB to YUV. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the YUV
value of the pixels.
The output is only well defined if the value in images are in [0,1]. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>2-D or higher rank. Image data to convert. Last dimension must be
size 3. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rgb_to_yuv_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>rgb_to_yuv_dyn</strong>(<span title="System.object">object</span> images)
		</h4>
		<div class="content">Converts one or more images from RGB to YUV. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the YUV
value of the pixels.
The output is only well defined if the value in images are in [0,1]. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>2-D or higher rank. Image data to convert. Last dimension must be
size 3. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="rot90" class="method">
		<h4>
			<span title="System.object">object</span> <strong>rot90</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> k, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Rotate image(s) counter-clockwise by 90 degrees. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> k
						</dt>
						<dd>A scalar integer. The number of times the image is rotated by 90 degrees. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A rotated tensor of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>a=tf.constant([[[1],[2]],[[3],[4]]])
            # rotating `a` counter clockwise by 90 degrees
            a_rot=tf.image.rot90(a,k=1) #rotated `a`
            print(a_rot) # [[[2],[4]],[[1],[3]]] </pre>
</div>
		</div>
	</div>
	<div id="rot90" class="method">
		<h4>
			<span title="System.object">object</span> <strong>rot90</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.int">int</span> k, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Rotate image(s) counter-clockwise by 90 degrees. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> k
						</dt>
						<dd>A scalar integer. The number of times the image is rotated by 90 degrees. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A rotated tensor of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>a=tf.constant([[[1],[2]],[[3],[4]]])
            # rotating `a` counter clockwise by 90 degrees
            a_rot=tf.image.rot90(a,k=1) #rotated `a`
            print(a_rot) # [[[2],[4]],[[1],[3]]] </pre>
</div>
		</div>
	</div>
	<div id="rot90_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>rot90_dyn</strong>(<span title="System.object">object</span> image, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> k, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Rotate image(s) counter-clockwise by 90 degrees. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> k
						</dt>
						<dd>A scalar integer. The number of times the image is rotated by 90 degrees. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A rotated tensor of the same type and shape as `image`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>a=tf.constant([[[1],[2]],[[3],[4]]])
            # rotating `a` counter clockwise by 90 degrees
            a_rot=tf.image.rot90(a,k=1) #rotated `a`
            print(a_rot) # [[[2],[4]],[[1],[3]]] </pre>
</div>
		</div>
	</div>
	<div id="sample_distorted_bounding_box" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sample_distorted_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> bounding_boxes, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed2, <span title="System.double">double</span> min_object_covered, <span title="System.Nullable<ValueTuple<double, object>>">Nullable&lt;ValueTuple&lt;double, object&gt;&gt;</span> aspect_ratio_range, <span title="System.Nullable<ValueTuple<double, object>>">Nullable&lt;ValueTuple&lt;double, object&gt;&gt;</span> area_range, <span title="System.object">object</span> max_attempts, <span title="System.object">object</span> use_image_if_no_bounding_boxes, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Generate a single randomly distorted bounding box for an image. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead. <p></p> Bounding box annotations are often supplied in addition to ground-truth labels
in image recognition or object localization tasks. A common technique for
training such a system is to randomly distort an image while preserving
its content, i.e. *data augmentation*. This Op outputs a randomly distorted
localization of an object, i.e. bounding box, given an `image_size`,
`bounding_boxes` and a series of constraints. <p></p> The output of this Op is a single bounding box that may be used to crop the
original image. The output is returned as 3 tensors: `begin`, `size` and
`bboxes`. The first 2 tensors can be fed directly into <a href="..\..\tf\slice.md"><code>tf.slice</code></a> to crop the
image. The latter may be supplied to <a href="..\..\tf\image\draw_bounding_boxes.md"><code>tf.image.draw_bounding_boxes</code></a> to
visualize what the bounding box looks like. <p></p> Bounding boxes are supplied and returned as `[y_min, x_min, y_max, x_max]`.
The
bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
height of the underlying image. <p></p> For example,
Note that if no bounding box information is available, setting
`use_image_if_no_bounding_boxes = True` will assume there is a single implicit
bounding box covering the whole image. If `use_image_if_no_bounding_boxes` is
false and no bounding boxes are supplied, an error is raised. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image_size
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `uint8`, `int8`,
`int16`, `int32`, `int64`. 1-D, containing `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> bounding_boxes
						</dt>
						<dd>A `Tensor` of type `float32`. 3-D with shape `[batch, N, 4]`
describing the N bounding boxes associated with the image. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>An optional `int`. Defaults to `0`. If either `seed` or `seed2` are
set to non-zero, the random number generator is seeded by the given
`seed`.  Otherwise, it is seeded by a random seed. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed2
						</dt>
						<dd>An optional `int`. Defaults to `0`. A second seed to avoid seed
collision. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> min_object_covered
						</dt>
						<dd>A Tensor of type `float32`. Defaults to `0.1`. The
cropped area of the image must contain at least this fraction of any
bounding box supplied. The value of this parameter should be non-negative.
In the case of 0, the cropped area does not need to overlap any of the
bounding boxes supplied. 
						</dd>
						<dt>
							<code><span title="System.Nullable<ValueTuple<double, object>>">Nullable&lt;ValueTuple&lt;double, object&gt;&gt;</span></code> aspect_ratio_range
						</dt>
						<dd>An optional list of `floats`. Defaults to `[0.75,
1.33]`. The cropped area of the image must have an aspect ratio = width /
height within this range. 
						</dd>
						<dt>
							<code><span title="System.Nullable<ValueTuple<double, object>>">Nullable&lt;ValueTuple&lt;double, object&gt;&gt;</span></code> area_range
						</dt>
						<dd>An optional list of `floats`. Defaults to `[0.05, 1]`. The
cropped area of the image must contain a fraction of the supplied image
within this range. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_attempts
						</dt>
						<dd>An optional `int`. Defaults to `100`. Number of attempts at
generating a cropped region of the image of the specified constraints.
After `max_attempts` failures, return the entire image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> use_image_if_no_bounding_boxes
						</dt>
						<dd>An optional `bool`. Defaults to `False`.
Controls behavior if no bounding boxes supplied. If true, assume an
implicit bounding box covering the whole input. If false, raise an error. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of `Tensor` objects (begin, size, bboxes). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Generate a single distorted bounding box.
            begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
                tf.shape(image),
                bounding_boxes=bounding_boxes,
                min_object_covered=0.1) <p></p> # Draw the bounding box in an image summary.
image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
                                              bbox_for_draw)
tf.compat.v1.summary.image('images_with_box', image_with_box) <p></p> # Employ the bounding box to distort the image.
distorted_image = tf.slice(image, begin, size) </pre>
</div>
		</div>
	</div>
	<div id="sample_distorted_bounding_box" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sample_distorted_bounding_box</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image_size, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> bounding_boxes, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> seed2, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> min_object_covered, <span title="System.Nullable<ValueTuple<double, object>>">Nullable&lt;ValueTuple&lt;double, object&gt;&gt;</span> aspect_ratio_range, <span title="System.Nullable<ValueTuple<double, object>>">Nullable&lt;ValueTuple&lt;double, object&gt;&gt;</span> area_range, <span title="System.object">object</span> max_attempts, <span title="System.object">object</span> use_image_if_no_bounding_boxes, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Generate a single randomly distorted bounding box for an image. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead. <p></p> Bounding box annotations are often supplied in addition to ground-truth labels
in image recognition or object localization tasks. A common technique for
training such a system is to randomly distort an image while preserving
its content, i.e. *data augmentation*. This Op outputs a randomly distorted
localization of an object, i.e. bounding box, given an `image_size`,
`bounding_boxes` and a series of constraints. <p></p> The output of this Op is a single bounding box that may be used to crop the
original image. The output is returned as 3 tensors: `begin`, `size` and
`bboxes`. The first 2 tensors can be fed directly into <a href="..\..\tf\slice.md"><code>tf.slice</code></a> to crop the
image. The latter may be supplied to <a href="..\..\tf\image\draw_bounding_boxes.md"><code>tf.image.draw_bounding_boxes</code></a> to
visualize what the bounding box looks like. <p></p> Bounding boxes are supplied and returned as `[y_min, x_min, y_max, x_max]`.
The
bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
height of the underlying image. <p></p> For example,
Note that if no bounding box information is available, setting
`use_image_if_no_bounding_boxes = True` will assume there is a single implicit
bounding box covering the whole image. If `use_image_if_no_bounding_boxes` is
false and no bounding boxes are supplied, an error is raised. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image_size
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `uint8`, `int8`,
`int16`, `int32`, `int64`. 1-D, containing `[height, width, channels]`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> bounding_boxes
						</dt>
						<dd>A `Tensor` of type `float32`. 3-D with shape `[batch, N, 4]`
describing the N bounding boxes associated with the image. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed
						</dt>
						<dd>An optional `int`. Defaults to `0`. If either `seed` or `seed2` are
set to non-zero, the random number generator is seeded by the given
`seed`.  Otherwise, it is seeded by a random seed. 
						</dd>
						<dt>
							<code><span title="System.Nullable<int>">Nullable&lt;int&gt;</span></code> seed2
						</dt>
						<dd>An optional `int`. Defaults to `0`. A second seed to avoid seed
collision. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> min_object_covered
						</dt>
						<dd>A Tensor of type `float32`. Defaults to `0.1`. The
cropped area of the image must contain at least this fraction of any
bounding box supplied. The value of this parameter should be non-negative.
In the case of 0, the cropped area does not need to overlap any of the
bounding boxes supplied. 
						</dd>
						<dt>
							<code><span title="System.Nullable<ValueTuple<double, object>>">Nullable&lt;ValueTuple&lt;double, object&gt;&gt;</span></code> aspect_ratio_range
						</dt>
						<dd>An optional list of `floats`. Defaults to `[0.75,
1.33]`. The cropped area of the image must have an aspect ratio = width /
height within this range. 
						</dd>
						<dt>
							<code><span title="System.Nullable<ValueTuple<double, object>>">Nullable&lt;ValueTuple&lt;double, object&gt;&gt;</span></code> area_range
						</dt>
						<dd>An optional list of `floats`. Defaults to `[0.05, 1]`. The
cropped area of the image must contain a fraction of the supplied image
within this range. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_attempts
						</dt>
						<dd>An optional `int`. Defaults to `100`. Number of attempts at
generating a cropped region of the image of the specified constraints.
After `max_attempts` failures, return the entire image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> use_image_if_no_bounding_boxes
						</dt>
						<dd>An optional `bool`. Defaults to `False`.
Controls behavior if no bounding boxes supplied. If true, assume an
implicit bounding box covering the whole input. If false, raise an error. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of `Tensor` objects (begin, size, bboxes). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Generate a single distorted bounding box.
            begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
                tf.shape(image),
                bounding_boxes=bounding_boxes,
                min_object_covered=0.1) <p></p> # Draw the bounding box in an image summary.
image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
                                              bbox_for_draw)
tf.compat.v1.summary.image('images_with_box', image_with_box) <p></p> # Employ the bounding box to distort the image.
distorted_image = tf.slice(image, begin, size) </pre>
</div>
		</div>
	</div>
	<div id="sample_distorted_bounding_box_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sample_distorted_bounding_box_dyn</strong>(<span title="System.object">object</span> image_size, <span title="System.object">object</span> bounding_boxes, <span title="System.object">object</span> seed, <span title="System.object">object</span> seed2, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> min_object_covered, <span title="System.object">object</span> aspect_ratio_range, <span title="System.object">object</span> area_range, <span title="System.object">object</span> max_attempts, <span title="System.object">object</span> use_image_if_no_bounding_boxes, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Generate a single randomly distorted bounding box for an image. (deprecated) <p></p> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead. <p></p> Bounding box annotations are often supplied in addition to ground-truth labels
in image recognition or object localization tasks. A common technique for
training such a system is to randomly distort an image while preserving
its content, i.e. *data augmentation*. This Op outputs a randomly distorted
localization of an object, i.e. bounding box, given an `image_size`,
`bounding_boxes` and a series of constraints. <p></p> The output of this Op is a single bounding box that may be used to crop the
original image. The output is returned as 3 tensors: `begin`, `size` and
`bboxes`. The first 2 tensors can be fed directly into <a href="..\..\tf\slice.md"><code>tf.slice</code></a> to crop the
image. The latter may be supplied to <a href="..\..\tf\image\draw_bounding_boxes.md"><code>tf.image.draw_bounding_boxes</code></a> to
visualize what the bounding box looks like. <p></p> Bounding boxes are supplied and returned as `[y_min, x_min, y_max, x_max]`.
The
bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
height of the underlying image. <p></p> For example,
Note that if no bounding box information is available, setting
`use_image_if_no_bounding_boxes = True` will assume there is a single implicit
bounding box covering the whole image. If `use_image_if_no_bounding_boxes` is
false and no bounding boxes are supplied, an error is raised. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image_size
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `uint8`, `int8`,
`int16`, `int32`, `int64`. 1-D, containing `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> bounding_boxes
						</dt>
						<dd>A `Tensor` of type `float32`. 3-D with shape `[batch, N, 4]`
describing the N bounding boxes associated with the image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed
						</dt>
						<dd>An optional `int`. Defaults to `0`. If either `seed` or `seed2` are
set to non-zero, the random number generator is seeded by the given
`seed`.  Otherwise, it is seeded by a random seed. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> seed2
						</dt>
						<dd>An optional `int`. Defaults to `0`. A second seed to avoid seed
collision. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> min_object_covered
						</dt>
						<dd>A Tensor of type `float32`. Defaults to `0.1`. The
cropped area of the image must contain at least this fraction of any
bounding box supplied. The value of this parameter should be non-negative.
In the case of 0, the cropped area does not need to overlap any of the
bounding boxes supplied. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> aspect_ratio_range
						</dt>
						<dd>An optional list of `floats`. Defaults to `[0.75,
1.33]`. The cropped area of the image must have an aspect ratio = width /
height within this range. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> area_range
						</dt>
						<dd>An optional list of `floats`. Defaults to `[0.05, 1]`. The
cropped area of the image must contain a fraction of the supplied image
within this range. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_attempts
						</dt>
						<dd>An optional `int`. Defaults to `100`. Number of attempts at
generating a cropped region of the image of the specified constraints.
After `max_attempts` failures, return the entire image. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> use_image_if_no_bounding_boxes
						</dt>
						<dd>An optional `bool`. Defaults to `False`.
Controls behavior if no bounding boxes supplied. If true, assume an
implicit bounding box covering the whole input. If false, raise an error. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tuple of `Tensor` objects (begin, size, bboxes). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Generate a single distorted bounding box.
            begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
                tf.shape(image),
                bounding_boxes=bounding_boxes,
                min_object_covered=0.1) <p></p> # Draw the bounding box in an image summary.
image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
                                              bbox_for_draw)
tf.compat.v1.summary.image('images_with_box', image_with_box) <p></p> # Employ the bounding box to distort the image.
distorted_image = tf.slice(image, begin, size) </pre>
</div>
		</div>
	</div>
	<div id="sobel_edges" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>sobel_edges</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image)
		</h4>
		<div class="content">Returns a tensor holding Sobel edge maps. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>Image tensor with shape [batch_size, h, w, d] and type float32 or
float64.  The image(s) must be 2x2 or larger. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>Tensor holding edge maps for each channel. Returns a tensor with shape
[batch_size, h, w, d, 2] where the last two dimensions hold [[dy[0], dx[0]],
[dy[1], dx[1]],..., [dy[d-1], dx[d-1]]] calculated using the Sobel filter. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="sobel_edges_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>sobel_edges_dyn</strong>(<span title="System.object">object</span> image)
		</h4>
		<div class="content">Returns a tensor holding Sobel edge maps. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>Image tensor with shape [batch_size, h, w, d] and type float32 or
float64.  The image(s) must be 2x2 or larger. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>Tensor holding edge maps for each channel. Returns a tensor with shape
[batch_size, h, w, d, 2] where the last two dimensions hold [[dy[0], dx[0]],
[dy[1], dx[1]],..., [dy[d-1], dx[d-1]]] calculated using the Sobel filter. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img1, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img2, <span title="System.int">int</span> max_val, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes SSIM index between img1 and img2. <p></p> This function is based on the standard SSIM implementation from:
Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image
quality assessment: from error visibility to structural similarity. IEEE
transactions on image processing. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Details:
- 11x11 Gaussian filter of width 1.5 is used.
- k1 = 0.01, k2 = 0.03 as in the original paper. <p></p> The image sizes must be at least 11x11 because of the filter size. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img2
						</dt>
						<dd>Second image batch. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an SSIM value for each image in batch.  Returned SSIM
values are in range (-1, 1], when pixel values are non-negative. Returns
a tensor with shape: broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute SSIM over tf.uint8 Tensors.
            ssim1 = tf.image.ssim(im1, im2, max_val=255, filter_size=11,
                                  filter_sigma=1.5, k1=0.01, k2=0.03) <p></p> # Compute SSIM over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
ssim2 = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11,
                      filter_sigma=1.5, k1=0.01, k2=0.03)
# ssim1 and ssim2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="ssim" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img1, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img2, <span title="System.double">double</span> max_val, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes SSIM index between img1 and img2. <p></p> This function is based on the standard SSIM implementation from:
Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image
quality assessment: from error visibility to structural similarity. IEEE
transactions on image processing. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Details:
- 11x11 Gaussian filter of width 1.5 is used.
- k1 = 0.01, k2 = 0.03 as in the original paper. <p></p> The image sizes must be at least 11x11 because of the filter size. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img2
						</dt>
						<dd>Second image batch. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an SSIM value for each image in batch.  Returned SSIM
values are in range (-1, 1], when pixel values are non-negative. Returns
a tensor with shape: broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute SSIM over tf.uint8 Tensors.
            ssim1 = tf.image.ssim(im1, im2, max_val=255, filter_size=11,
                                  filter_sigma=1.5, k1=0.01, k2=0.03) <p></p> # Compute SSIM over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
ssim2 = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11,
                      filter_sigma=1.5, k1=0.01, k2=0.03)
# ssim1 and ssim2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="ssim" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img1, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img2, <span title="System.double">double</span> max_val, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes SSIM index between img1 and img2. <p></p> This function is based on the standard SSIM implementation from:
Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image
quality assessment: from error visibility to structural similarity. IEEE
transactions on image processing. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Details:
- 11x11 Gaussian filter of width 1.5 is used.
- k1 = 0.01, k2 = 0.03 as in the original paper. <p></p> The image sizes must be at least 11x11 because of the filter size. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img2
						</dt>
						<dd>Second image batch. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an SSIM value for each image in batch.  Returned SSIM
values are in range (-1, 1], when pixel values are non-negative. Returns
a tensor with shape: broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute SSIM over tf.uint8 Tensors.
            ssim1 = tf.image.ssim(im1, im2, max_val=255, filter_size=11,
                                  filter_sigma=1.5, k1=0.01, k2=0.03) <p></p> # Compute SSIM over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
ssim2 = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11,
                      filter_sigma=1.5, k1=0.01, k2=0.03)
# ssim1 and ssim2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="ssim" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img1, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img2, <span title="System.int">int</span> max_val, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes SSIM index between img1 and img2. <p></p> This function is based on the standard SSIM implementation from:
Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image
quality assessment: from error visibility to structural similarity. IEEE
transactions on image processing. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Details:
- 11x11 Gaussian filter of width 1.5 is used.
- k1 = 0.01, k2 = 0.03 as in the original paper. <p></p> The image sizes must be at least 11x11 because of the filter size. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img2
						</dt>
						<dd>Second image batch. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an SSIM value for each image in batch.  Returned SSIM
values are in range (-1, 1], when pixel values are non-negative. Returns
a tensor with shape: broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute SSIM over tf.uint8 Tensors.
            ssim1 = tf.image.ssim(im1, im2, max_val=255, filter_size=11,
                                  filter_sigma=1.5, k1=0.01, k2=0.03) <p></p> # Compute SSIM over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
ssim2 = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11,
                      filter_sigma=1.5, k1=0.01, k2=0.03)
# ssim1 and ssim2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="ssim" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img1, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img2, <span title="System.double">double</span> max_val, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes SSIM index between img1 and img2. <p></p> This function is based on the standard SSIM implementation from:
Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image
quality assessment: from error visibility to structural similarity. IEEE
transactions on image processing. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Details:
- 11x11 Gaussian filter of width 1.5 is used.
- k1 = 0.01, k2 = 0.03 as in the original paper. <p></p> The image sizes must be at least 11x11 because of the filter size. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img2
						</dt>
						<dd>Second image batch. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an SSIM value for each image in batch.  Returned SSIM
values are in range (-1, 1], when pixel values are non-negative. Returns
a tensor with shape: broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute SSIM over tf.uint8 Tensors.
            ssim1 = tf.image.ssim(im1, im2, max_val=255, filter_size=11,
                                  filter_sigma=1.5, k1=0.01, k2=0.03) <p></p> # Compute SSIM over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
ssim2 = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11,
                      filter_sigma=1.5, k1=0.01, k2=0.03)
# ssim1 and ssim2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="ssim" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img1, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img2, <span title="System.int">int</span> max_val, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes SSIM index between img1 and img2. <p></p> This function is based on the standard SSIM implementation from:
Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image
quality assessment: from error visibility to structural similarity. IEEE
transactions on image processing. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Details:
- 11x11 Gaussian filter of width 1.5 is used.
- k1 = 0.01, k2 = 0.03 as in the original paper. <p></p> The image sizes must be at least 11x11 because of the filter size. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img2
						</dt>
						<dd>Second image batch. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an SSIM value for each image in batch.  Returned SSIM
values are in range (-1, 1], when pixel values are non-negative. Returns
a tensor with shape: broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute SSIM over tf.uint8 Tensors.
            ssim1 = tf.image.ssim(im1, im2, max_val=255, filter_size=11,
                                  filter_sigma=1.5, k1=0.01, k2=0.03) <p></p> # Compute SSIM over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
ssim2 = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11,
                      filter_sigma=1.5, k1=0.01, k2=0.03)
# ssim1 and ssim2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="ssim" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img1, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img2, <span title="System.double">double</span> max_val, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes SSIM index between img1 and img2. <p></p> This function is based on the standard SSIM implementation from:
Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image
quality assessment: from error visibility to structural similarity. IEEE
transactions on image processing. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Details:
- 11x11 Gaussian filter of width 1.5 is used.
- k1 = 0.01, k2 = 0.03 as in the original paper. <p></p> The image sizes must be at least 11x11 because of the filter size. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img2
						</dt>
						<dd>Second image batch. 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an SSIM value for each image in batch.  Returned SSIM
values are in range (-1, 1], when pixel values are non-negative. Returns
a tensor with shape: broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute SSIM over tf.uint8 Tensors.
            ssim1 = tf.image.ssim(im1, im2, max_val=255, filter_size=11,
                                  filter_sigma=1.5, k1=0.01, k2=0.03) <p></p> # Compute SSIM over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
ssim2 = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11,
                      filter_sigma=1.5, k1=0.01, k2=0.03)
# ssim1 and ssim2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="ssim" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img1, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img2, <span title="System.int">int</span> max_val, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes SSIM index between img1 and img2. <p></p> This function is based on the standard SSIM implementation from:
Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image
quality assessment: from error visibility to structural similarity. IEEE
transactions on image processing. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Details:
- 11x11 Gaussian filter of width 1.5 is used.
- k1 = 0.01, k2 = 0.03 as in the original paper. <p></p> The image sizes must be at least 11x11 because of the filter size. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img2
						</dt>
						<dd>Second image batch. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an SSIM value for each image in batch.  Returned SSIM
values are in range (-1, 1], when pixel values are non-negative. Returns
a tensor with shape: broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute SSIM over tf.uint8 Tensors.
            ssim1 = tf.image.ssim(im1, im2, max_val=255, filter_size=11,
                                  filter_sigma=1.5, k1=0.01, k2=0.03) <p></p> # Compute SSIM over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
ssim2 = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11,
                      filter_sigma=1.5, k1=0.01, k2=0.03)
# ssim1 and ssim2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="ssim_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ssim_dyn</strong>(<span title="System.object">object</span> img1, <span title="System.object">object</span> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> filter_size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> filter_sigma, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> k1, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> k2)
		</h4>
		<div class="content">Computes SSIM index between img1 and img2. <p></p> This function is based on the standard SSIM implementation from:
Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image
quality assessment: from error visibility to structural similarity. IEEE
transactions on image processing. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Details:
- 11x11 Gaussian filter of width 1.5 is used.
- k1 = 0.01, k2 = 0.03 as in the original paper. <p></p> The image sizes must be at least 11x11 because of the filter size. <p></p> Example: 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> img2
						</dt>
						<dd>Second image batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor containing an SSIM value for each image in batch.  Returned SSIM
values are in range (-1, 1], when pixel values are non-negative. Returns
a tensor with shape: broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre># Read images from file.
            im1 = tf.decode_png('path/to/im1.png')
            im2 = tf.decode_png('path/to/im2.png')
            # Compute SSIM over tf.uint8 Tensors.
            ssim1 = tf.image.ssim(im1, im2, max_val=255, filter_size=11,
                                  filter_sigma=1.5, k1=0.01, k2=0.03) <p></p> # Compute SSIM over tf.float32 Tensors.
im1 = tf.image.convert_image_dtype(im1, tf.float32)
im2 = tf.image.convert_image_dtype(im2, tf.float32)
ssim2 = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11,
                      filter_sigma=1.5, k1=0.01, k2=0.03)
# ssim1 and ssim2 both have type tf.float32 and are almost equal. </pre>
</div>
		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img1, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img1, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img1, <span title="System.object">object</span> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> img1, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> img1, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> img1, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> img1, <span title="System.object">object</span> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img1, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img1, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img1, <span title="System.object">object</span> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<span title="System.object">object</span> img1, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<span title="System.object">object</span> img1, <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<span title="System.object">object</span> img1, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<span title="System.object">object</span> img1, <span title="System.object">object</span> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img1, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>ssim_multiscale</strong>(<span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img1, <span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <span title="System.int">int</span> filter_size, <span title="System.double">double</span> filter_sigma, <span title="System.double">double</span> k1, <span title="System.double">double</span> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<PythonClassContainer, PythonClassContainer>">ValueTuple&lt;PythonClassContainer, PythonClassContainer&gt;</span></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><span title="System.double">double</span></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="ssim_multiscale_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>ssim_multiscale_dyn</strong>(<span title="System.object">object</span> img1, <span title="System.object">object</span> img2, <span title="System.object">object</span> max_val, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> power_factors, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> filter_size, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> filter_sigma, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> k1, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> k2)
		</h4>
		<div class="content">Computes the MS-SSIM between img1 and img2. <p></p> This function assumes that `img1` and `img2` are image batches, i.e. the last
three dimensions are [height, width, channels]. <p></p> Note: The true SSIM is only defined on grayscale.  This function does not
perform any colorspace transform.  (If input is already YUV, then it will
compute YUV SSIM average.) <p></p> Original paper: Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "Multiscale
structural similarity for image quality assessment." Signals, Systems and
Computers, 2004. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> img1
						</dt>
						<dd>First image batch. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> img2
						</dt>
						<dd>Second image batch. Must have the same rank as img1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> max_val
						</dt>
						<dd>The dynamic range of the images (i.e., the difference between the
maximum the and minimum allowed values). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> power_factors
						</dt>
						<dd>Iterable of weights for each of the scales. The number of
scales used is the length of the list. Index 0 is the unscaled
resolution's weight and each increasing scale corresponds to the image
being downsampled by 2.  Defaults to (0.0448, 0.2856, 0.3001, 0.2363,
0.1333), which are the values obtained in the original paper. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> filter_size
						</dt>
						<dd>Default value 11 (size of gaussian filter). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> filter_sigma
						</dt>
						<dd>Default value 1.5 (width of gaussian filter). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> k1
						</dt>
						<dd>Default value 0.01 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> k2
						</dt>
						<dd>Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so
it would be better if we taken the values in range of 0< K2 <0.4). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A tensor containing an MS-SSIM value for each image in batch.  The values
are in range [0, 1].  Returns a tensor with shape:
broadcast(img1.shape[:-3], img2.shape[:-3]). 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="total_variation" class="method">
		<h4>
			<span title="System.object">object</span> <strong>total_variation</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Calculate and return the total variation for one or more images. <p></p> The total variation is the sum of the absolute differences for neighboring
pixel-values in the input images. This measures how much noise is in the
images. <p></p> This can be used as a loss-function during optimization so as to suppress
noise in images. If you have a batch of images, then you should calculate
the scalar loss-value as the sum:
`loss = tf.reduce_sum(tf.image.total_variation(images))` <p></p> This implements the anisotropic 2-D version of the formula described here: <p></p> https://en.wikipedia.org/wiki/Total_variation_denoising 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The total variation of `images`. <p></p> If `images` was 4-D, return a 1-D float Tensor of shape `[batch]` with the
total variation for each image in the batch.
If `images` was 3-D, return a scalar float with the total variation for
that image. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="total_variation_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>total_variation_dyn</strong>(<span title="System.object">object</span> images, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Calculate and return the total variation for one or more images. <p></p> The total variation is the sum of the absolute differences for neighboring
pixel-values in the input images. This measures how much noise is in the
images. <p></p> This can be used as a loss-function during optimization so as to suppress
noise in images. If you have a batch of images, then you should calculate
the scalar loss-value as the sum:
`loss = tf.reduce_sum(tf.image.total_variation(images))` <p></p> This implements the anisotropic 2-D version of the formula described here: <p></p> https://en.wikipedia.org/wiki/Total_variation_denoising 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The total variation of `images`. <p></p> If `images` was 4-D, return a 1-D float Tensor of shape `[batch]` with the
total variation for each image in the batch.
If `images` was 3-D, return a scalar float with the total variation for
that image. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="transpose" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>transpose</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> image, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Transpose image(s) by swapping the height and width dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, width, height, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[width, height, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="transpose_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>transpose_dyn</strong>(<span title="System.object">object</span> image, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Transpose image(s) by swapping the height and width dimension. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> image
						</dt>
						<dd>4-D Tensor of shape `[batch, height, width, channels]` or 3-D Tensor
of shape `[height, width, channels]`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for this operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>If `image` was 4-D, a 4-D float Tensor of shape
`[batch, width, height, channels]`
If `image` was 3-D, a 3-D float Tensor of shape
`[width, height, channels]` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="yiq_to_rgb" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>yiq_to_rgb</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images)
		</h4>
		<div class="content">Converts one or more images from YIQ to RGB. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the RGB
value of the pixels.
The output is only well defined if the Y value in images are in [0,1],
I value are in [-0.5957,0.5957] and Q value are in [-0.5226,0.5226]. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>2-D or higher rank. Image data to convert. Last dimension must be
size 3. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="yiq_to_rgb_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>yiq_to_rgb_dyn</strong>(<span title="System.object">object</span> images)
		</h4>
		<div class="content">Converts one or more images from YIQ to RGB. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the RGB
value of the pixels.
The output is only well defined if the Y value in images are in [0,1],
I value are in [-0.5957,0.5957] and Q value are in [-0.5226,0.5226]. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>2-D or higher rank. Image data to convert. Last dimension must be
size 3. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="yuv_to_rgb" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>yuv_to_rgb</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> images)
		</h4>
		<div class="content">Converts one or more images from YUV to RGB. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the RGB
value of the pixels.
The output is only well defined if the Y value in images are in [0,1],
U and V value are in [-0.5,0.5]. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> images
						</dt>
						<dd>2-D or higher rank. Image data to convert. Last dimension must be
size 3. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="yuv_to_rgb_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>yuv_to_rgb_dyn</strong>(<span title="System.object">object</span> images)
		</h4>
		<div class="content">Converts one or more images from YUV to RGB. <p></p> Outputs a tensor of the same shape as the `images` tensor, containing the RGB
value of the pixels.
The output is only well defined if the Y value in images are in [0,1],
U and V value are in [-0.5,0.5]. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> images
						</dt>
						<dd>2-D or higher rank. Image data to convert. Last dimension must be
size 3. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd><p></p> 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	
	<h3 class="section">Public properties</h3>

	<div id="adjust_brightness_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>adjust_brightness_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="adjust_contrast_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>adjust_contrast_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="adjust_gamma_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>adjust_gamma_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="adjust_hue_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>adjust_hue_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="adjust_jpeg_quality_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>adjust_jpeg_quality_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="adjust_saturation_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>adjust_saturation_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="central_crop_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>central_crop_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="combined_non_max_suppression_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>combined_non_max_suppression_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="convert_image_dtype_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>convert_image_dtype_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="crop_and_resize_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>crop_and_resize_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="crop_to_bounding_box_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>crop_to_bounding_box_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="draw_bounding_boxes_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>draw_bounding_boxes_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="encode_png_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>encode_png_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="extract_glimpse_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>extract_glimpse_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="extract_patches_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>extract_patches_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="flip_left_right_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>flip_left_right_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="flip_up_down_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>flip_up_down_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="grayscale_to_rgb_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>grayscale_to_rgb_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="hsv_to_rgb_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>hsv_to_rgb_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="image_gradients_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>image_gradients_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="non_max_suppression_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>non_max_suppression_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="non_max_suppression_overlaps_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>non_max_suppression_overlaps_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="non_max_suppression_padded_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>non_max_suppression_padded_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="non_max_suppression_with_scores_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>non_max_suppression_with_scores_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="pad_to_bounding_box_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>pad_to_bounding_box_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="per_image_standardization_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>per_image_standardization_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="psnr_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>psnr_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_brightness_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_brightness_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_contrast_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_contrast_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_flip_left_right_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_flip_left_right_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_flip_up_down_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_flip_up_down_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_hue_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_hue_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_jpeg_quality_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_jpeg_quality_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="random_saturation_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>random_saturation_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="resize_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>resize_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="resize_image_with_pad_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>resize_image_with_pad_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="resize_with_crop_or_pad_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>resize_with_crop_or_pad_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="resize_with_pad_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>resize_with_pad_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="rgb_to_grayscale_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>rgb_to_grayscale_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="rgb_to_hsv_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>rgb_to_hsv_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="rgb_to_yiq_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>rgb_to_yiq_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="rgb_to_yuv_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>rgb_to_yuv_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="rot90_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>rot90_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sample_distorted_bounding_box_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sample_distorted_bounding_box_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sobel_edges_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>sobel_edges_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ssim_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ssim_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="ssim_multiscale_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>ssim_multiscale_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="total_variation_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>total_variation_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="transpose_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>transpose_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="yiq_to_rgb_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>yiq_to_rgb_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="yuv_to_rgb_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>yuv_to_rgb_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>