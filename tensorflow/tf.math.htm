<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>tf.math - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow/AggregationMethod.htm">AggregationMethod</a>
        </li>
				<li>
            <a href="../tensorflow/ConditionalAccumulator.htm">ConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/ConditionalAccumulatorBase.htm">ConditionalAccumulatorBase</a>
        </li>
				<li>
            <a href="../tensorflow/constant_initializer.htm">constant_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/CriticalSection.htm">CriticalSection</a>
        </li>
				<li>
            <a href="../tensorflow/DeviceSpec.htm">DeviceSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Dimension.htm">Dimension</a>
        </li>
				<li>
            <a href="../tensorflow/DType.htm">DType</a>
        </li>
				<li>
            <a href="../tensorflow/FIFOQueue.htm">FIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLenFeature.htm">FixedLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLengthRecordReader.htm">FixedLengthRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/FixedLenSequenceFeature.htm">FixedLenSequenceFeature</a>
        </li>
				<li>
            <a href="../tensorflow/glorot_normal_initializer.htm">glorot_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/glorot_uniform_initializer.htm">glorot_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/GradientTape.htm">GradientTape</a>
        </li>
				<li>
            <a href="../tensorflow/Graph.htm">Graph</a>
        </li>
				<li>
            <a href="../tensorflow/Graph._ControlDependenciesController.htm">Graph._ControlDependenciesController</a>
        </li>
				<li>
            <a href="../tensorflow/Graph.I_ControlDependenciesController.htm">Graph.I_ControlDependenciesController</a>
        </li>
				<li>
            <a href="../tensorflow/GraphKeys.htm">GraphKeys</a>
        </li>
				<li>
            <a href="../tensorflow/HeadingAxes.htm">HeadingAxes</a>
        </li>
				<li>
            <a href="../tensorflow/IAggregationMethod.htm">IAggregationMethod</a>
        </li>
				<li>
            <a href="../tensorflow/IConditionalAccumulator.htm">IConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/IConditionalAccumulatorBase.htm">IConditionalAccumulatorBase</a>
        </li>
				<li>
            <a href="../tensorflow/Iconstant_initializer.htm">Iconstant_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/ICriticalSection.htm">ICriticalSection</a>
        </li>
				<li>
            <a href="../tensorflow/IdentityReader.htm">IdentityReader</a>
        </li>
				<li>
            <a href="../tensorflow/IDeviceSpec.htm">IDeviceSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IDimension.htm">IDimension</a>
        </li>
				<li>
            <a href="../tensorflow/IDType.htm">IDType</a>
        </li>
				<li>
            <a href="../tensorflow/IFIFOQueue.htm">IFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLenFeature.htm">IFixedLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLengthRecordReader.htm">IFixedLengthRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/IFixedLenSequenceFeature.htm">IFixedLenSequenceFeature</a>
        </li>
				<li>
            <a href="../tensorflow/Iglorot_normal_initializer.htm">Iglorot_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Iglorot_uniform_initializer.htm">Iglorot_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IGradientTape.htm">IGradientTape</a>
        </li>
				<li>
            <a href="../tensorflow/IGraph.htm">IGraph</a>
        </li>
				<li>
            <a href="../tensorflow/IGraphKeys.htm">IGraphKeys</a>
        </li>
				<li>
            <a href="../tensorflow/IIdentityReader.htm">IIdentityReader</a>
        </li>
				<li>
            <a href="../tensorflow/IIndexedSlices.htm">IIndexedSlices</a>
        </li>
				<li>
            <a href="../tensorflow/IIndexedSlicesSpec.htm">IIndexedSlicesSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IInteractiveSession.htm">IInteractiveSession</a>
        </li>
				<li>
            <a href="../tensorflow/ILazyLoader.htm">ILazyLoader</a>
        </li>
				<li>
            <a href="../tensorflow/ILMDBReader.htm">ILMDBReader</a>
        </li>
				<li>
            <a href="../tensorflow/IModule.htm">IModule</a>
        </li>
				<li>
            <a href="../tensorflow/Iname_scope.htm">Iname_scope</a>
        </li>
				<li>
            <a href="../tensorflow/IndexedSlices.htm">IndexedSlices</a>
        </li>
				<li>
            <a href="../tensorflow/IndexedSlicesSpec.htm">IndexedSlicesSpec</a>
        </li>
				<li>
            <a href="../tensorflow/InteractiveSession.htm">InteractiveSession</a>
        </li>
				<li>
            <a href="../tensorflow/Iones_initializer.htm">Iones_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IOperation.htm">IOperation</a>
        </li>
				<li>
            <a href="../tensorflow/IOpError.htm">IOpError</a>
        </li>
				<li>
            <a href="../tensorflow/IOptionalSpec.htm">IOptionalSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Iorthogonal_initializer.htm">Iorthogonal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IPaddingFIFOQueue.htm">IPaddingFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IPriorityQueue.htm">IPriorityQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IQueueBase.htm">IQueueBase</a>
        </li>
				<li>
            <a href="../tensorflow/IRaggedTensor.htm">IRaggedTensor</a>
        </li>
				<li>
            <a href="../tensorflow/IRaggedTensorSpec.htm">IRaggedTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/Irandom_normal_initializer.htm">Irandom_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Irandom_uniform_initializer.htm">Irandom_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IRandomShuffleQueue.htm">IRandomShuffleQueue</a>
        </li>
				<li>
            <a href="../tensorflow/IReaderBase.htm">IReaderBase</a>
        </li>
				<li>
            <a href="../tensorflow/IRegisterGradient.htm">IRegisterGradient</a>
        </li>
				<li>
            <a href="../tensorflow/ISession.htm">ISession</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseConditionalAccumulator.htm">ISparseConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseFeature.htm">ISparseFeature</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensor.htm">ISparseTensor</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensorSpec.htm">ISparseTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/ISparseTensorValue.htm">ISparseTensorValue</a>
        </li>
				<li>
            <a href="../tensorflow/ITensor.htm">ITensor</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorArray.htm">ITensorArray</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorArraySpec.htm">ITensorArraySpec</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorShape.htm">ITensorShape</a>
        </li>
				<li>
            <a href="../tensorflow/ITensorSpec.htm">ITensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/ITextLineReader.htm">ITextLineReader</a>
        </li>
				<li>
            <a href="../tensorflow/ITFRecordReader.htm">ITFRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/Itruncated_normal_initializer.htm">Itruncated_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/ITypeSpec.htm">ITypeSpec</a>
        </li>
				<li>
            <a href="../tensorflow/IUnconnectedGradients.htm">IUnconnectedGradients</a>
        </li>
				<li>
            <a href="../tensorflow/Iuniform_unit_scaling_initializer.htm">Iuniform_unit_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IVariable.htm">IVariable</a>
        </li>
				<li>
            <a href="../tensorflow/Ivariable_scope.htm">Ivariable_scope</a>
        </li>
				<li>
            <a href="../tensorflow/IVariableScope.htm">IVariableScope</a>
        </li>
				<li>
            <a href="../tensorflow/Ivariance_scaling_initializer.htm">Ivariance_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/IVarLenFeature.htm">IVarLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/IWholeFileReader.htm">IWholeFileReader</a>
        </li>
				<li>
            <a href="../tensorflow/Izeros_initializer.htm">Izeros_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/LazyLoader.htm">LazyLoader</a>
        </li>
				<li>
            <a href="../tensorflow/LMDBReader.htm">LMDBReader</a>
        </li>
				<li>
            <a href="../tensorflow/Module.htm">Module</a>
        </li>
				<li>
            <a href="../tensorflow/name_scope.htm">name_scope</a>
        </li>
				<li>
            <a href="../tensorflow/ones_initializer.htm">ones_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Operation.htm">Operation</a>
        </li>
				<li>
            <a href="../tensorflow/Operation._InputList.htm">Operation._InputList</a>
        </li>
				<li>
            <a href="../tensorflow/Operation.I_InputList.htm">Operation.I_InputList</a>
        </li>
				<li>
            <a href="../tensorflow/OpError.htm">OpError</a>
        </li>
				<li>
            <a href="../tensorflow/OptionalSpec.htm">OptionalSpec</a>
        </li>
				<li>
            <a href="../tensorflow/orthogonal_initializer.htm">orthogonal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/PaddingFIFOQueue.htm">PaddingFIFOQueue</a>
        </li>
				<li>
            <a href="../tensorflow/PriorityQueue.htm">PriorityQueue</a>
        </li>
				<li>
            <a href="../tensorflow/QueueBase.htm">QueueBase</a>
        </li>
				<li>
            <a href="../tensorflow/RaggedTensor.htm">RaggedTensor</a>
        </li>
				<li>
            <a href="../tensorflow/RaggedTensorSpec.htm">RaggedTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/random_normal_initializer.htm">random_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/random_uniform_initializer.htm">random_uniform_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/RandomShuffleQueue.htm">RandomShuffleQueue</a>
        </li>
				<li>
            <a href="../tensorflow/ReaderBase.htm">ReaderBase</a>
        </li>
				<li>
            <a href="../tensorflow/RegisterGradient.htm">RegisterGradient</a>
        </li>
				<li>
            <a href="../tensorflow/Session.htm">Session</a>
        </li>
				<li>
            <a href="../tensorflow/SparseConditionalAccumulator.htm">SparseConditionalAccumulator</a>
        </li>
				<li>
            <a href="../tensorflow/SparseFeature.htm">SparseFeature</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensor.htm">SparseTensor</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensorSpec.htm">SparseTensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/SparseTensorValue.htm">SparseTensorValue</a>
        </li>
				<li>
            <a href="../tensorflow/Tensor.htm">Tensor</a>
        </li>
				<li>
            <a href="../tensorflow/Tensor`1.htm">Tensor&lt;T&gt;</a>
        </li>
				<li>
            <a href="../tensorflow/TensorArray.htm">TensorArray</a>
        </li>
				<li>
            <a href="../tensorflow/TensorArraySpec.htm">TensorArraySpec</a>
        </li>
				<li>
            <a href="../tensorflow/TensorDimension.htm">TensorDimension</a>
        </li>
				<li>
            <a href="../tensorflow/TensorDimensionSlice.htm">TensorDimensionSlice</a>
        </li>
				<li>
            <a href="../tensorflow/TensorShape.htm">TensorShape</a>
        </li>
				<li>
            <a href="../tensorflow/TensorSpec.htm">TensorSpec</a>
        </li>
				<li>
            <a href="../tensorflow/TextLineReader.htm">TextLineReader</a>
        </li>
				<li>
            <a href="../tensorflow/tf.htm">tf</a>
        </li>
				<li>
            <a href="../tensorflow/tf.audio.htm">tf.audio</a>
        </li>
				<li>
            <a href="../tensorflow/tf.autograph.htm">tf.autograph</a>
        </li>
				<li>
            <a href="../tensorflow/tf.autograph.experimental.htm">tf.autograph.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.bitwise.htm">tf.bitwise</a>
        </li>
				<li>
            <a href="../tensorflow/tf.compat.htm">tf.compat</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.htm">tf.config</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.experimental.htm">tf.config.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.optimizer.htm">tf.config.optimizer</a>
        </li>
				<li>
            <a href="../tensorflow/tf.config.threading.htm">tf.config.threading</a>
        </li>
				<li>
            <a href="../tensorflow/tf.data.htm">tf.data</a>
        </li>
				<li>
            <a href="../tensorflow/tf.data.experimental.htm">tf.data.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.debugging.htm">tf.debugging</a>
        </li>
				<li>
            <a href="../tensorflow/tf.distribute.htm">tf.distribute</a>
        </li>
				<li>
            <a href="../tensorflow/tf.distributions.htm">tf.distributions</a>
        </li>
				<li>
            <a href="../tensorflow/tf.errors.htm">tf.errors</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.htm">tf.estimator</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.experimental.htm">tf.estimator.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.export.htm">tf.estimator.export</a>
        </li>
				<li>
            <a href="../tensorflow/tf.estimator.inputs.htm">tf.estimator.inputs</a>
        </li>
				<li>
            <a href="../tensorflow/tf.experimental.htm">tf.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.feature_column.htm">tf.feature_column</a>
        </li>
				<li>
            <a href="../tensorflow/tf.gfile.htm">tf.gfile</a>
        </li>
				<li>
            <a href="../tensorflow/tf.graph_util.htm">tf.graph_util</a>
        </li>
				<li>
            <a href="../tensorflow/tf.image.htm">tf.image</a>
        </li>
				<li>
            <a href="../tensorflow/tf.initializers.htm">tf.initializers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.io.htm">tf.io</a>
        </li>
				<li>
            <a href="../tensorflow/tf.io.gfile.htm">tf.io.gfile</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.htm">tf.keras</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.activations.htm">tf.keras.activations</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.htm">tf.keras.applications</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.densenet.htm">tf.keras.applications.densenet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.imagenet_utils.htm">tf.keras.applications.imagenet_utils</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.inception_resnet_v2.htm">tf.keras.applications.inception_resnet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.inception_v3.htm">tf.keras.applications.inception_v3</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.mobilenet.htm">tf.keras.applications.mobilenet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.mobilenet_v2.htm">tf.keras.applications.mobilenet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.nasnet.htm">tf.keras.applications.nasnet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.resnet.htm">tf.keras.applications.resnet</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.resnet_v2.htm">tf.keras.applications.resnet_v2</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.vgg16.htm">tf.keras.applications.vgg16</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.vgg19.htm">tf.keras.applications.vgg19</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.applications.xception.htm">tf.keras.applications.xception</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.backend.htm">tf.keras.backend</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.constraints.htm">tf.keras.constraints</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.htm">tf.keras.datasets</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.boston_housing.htm">tf.keras.datasets.boston_housing</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.cifar10.htm">tf.keras.datasets.cifar10</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.cifar100.htm">tf.keras.datasets.cifar100</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.fashion_mnist.htm">tf.keras.datasets.fashion_mnist</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.imdb.htm">tf.keras.datasets.imdb</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.mnist.htm">tf.keras.datasets.mnist</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.datasets.reuters.htm">tf.keras.datasets.reuters</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.estimator.htm">tf.keras.estimator</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.experimental.htm">tf.keras.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.initializers.htm">tf.keras.initializers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.layers.htm">tf.keras.layers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.losses.htm">tf.keras.losses</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.metrics.htm">tf.keras.metrics</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.mixed_precision.htm">tf.keras.mixed_precision</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.mixed_precision.experimental.htm">tf.keras.mixed_precision.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.models.htm">tf.keras.models</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.optimizers.htm">tf.keras.optimizers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.optimizers.schedules.htm">tf.keras.optimizers.schedules</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.preprocessing.htm">tf.keras.preprocessing</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.preprocessing.image.htm">tf.keras.preprocessing.image</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.regularizers.htm">tf.keras.regularizers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.keras.utils.htm">tf.keras.utils</a>
        </li>
				<li>
            <a href="../tensorflow/tf.layers.htm">tf.layers</a>
        </li>
				<li>
            <a href="../tensorflow/tf.layers.experimental.htm">tf.layers.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.linalg.htm">tf.linalg</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.htm">tf.lite</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.htm">tf.lite.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.htm">tf.lite.experimental.microfrontend</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.python.htm">tf.lite.experimental.microfrontend.python</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.microfrontend.python.ops.htm">tf.lite.experimental.microfrontend.python.ops</a>
        </li>
				<li>
            <a href="../tensorflow/tf.lite.experimental.nn.htm">tf.lite.experimental.nn</a>
        </li>
				<li>
            <a href="../tensorflow/tf.logging.htm">tf.logging</a>
        </li>
				<li>
            <a href="../tensorflow/tf.losses.htm">tf.losses</a>
        </li>
				<li>
            <a href="../tensorflow/tf.math.htm" class="current">tf.math</a>
        </li>
				<li>
            <a href="../tensorflow/tf.metrics.htm">tf.metrics</a>
        </li>
				<li>
            <a href="../tensorflow/tf.nest.htm">tf.nest</a>
        </li>
				<li>
            <a href="../tensorflow/tf.nn.htm">tf.nn</a>
        </li>
				<li>
            <a href="../tensorflow/tf.profiler.htm">tf.profiler</a>
        </li>
				<li>
            <a href="../tensorflow/tf.quantization.htm">tf.quantization</a>
        </li>
				<li>
            <a href="../tensorflow/tf.ragged.htm">tf.ragged</a>
        </li>
				<li>
            <a href="../tensorflow/tf.random.htm">tf.random</a>
        </li>
				<li>
            <a href="../tensorflow/tf.random.experimental.htm">tf.random.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.resource_loader.htm">tf.resource_loader</a>
        </li>
				<li>
            <a href="../tensorflow/tf.saved_model.htm">tf.saved_model</a>
        </li>
				<li>
            <a href="../tensorflow/tf.saved_model.main_op.htm">tf.saved_model.main_op</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sets.htm">tf.sets</a>
        </li>
				<li>
            <a href="../tensorflow/tf.signal.htm">tf.signal</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sparse.htm">tf.sparse</a>
        </li>
				<li>
            <a href="../tensorflow/tf.strings.htm">tf.strings</a>
        </li>
				<li>
            <a href="../tensorflow/tf.summary.htm">tf.summary</a>
        </li>
				<li>
            <a href="../tensorflow/tf.summary.experimental.htm">tf.summary.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.sysconfig.htm">tf.sysconfig</a>
        </li>
				<li>
            <a href="../tensorflow/tf.test.htm">tf.test</a>
        </li>
				<li>
            <a href="../tensorflow/tf.tpu.htm">tf.tpu</a>
        </li>
				<li>
            <a href="../tensorflow/tf.tpu.experimental.htm">tf.tpu.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.train.htm">tf.train</a>
        </li>
				<li>
            <a href="../tensorflow/tf.train.experimental.htm">tf.train.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/tf.user_ops.htm">tf.user_ops</a>
        </li>
				<li>
            <a href="../tensorflow/tf.xla.htm">tf.xla</a>
        </li>
				<li>
            <a href="../tensorflow/tf.xla.experimental.htm">tf.xla.experimental</a>
        </li>
				<li>
            <a href="../tensorflow/TFRecordReader.htm">TFRecordReader</a>
        </li>
				<li>
            <a href="../tensorflow/truncated_normal_initializer.htm">truncated_normal_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/TypeSpec.htm">TypeSpec</a>
        </li>
				<li>
            <a href="../tensorflow/UnconnectedGradients.htm">UnconnectedGradients</a>
        </li>
				<li>
            <a href="../tensorflow/uniform_unit_scaling_initializer.htm">uniform_unit_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/Variable.htm">Variable</a>
        </li>
				<li>
            <a href="../tensorflow/variable_scope.htm">variable_scope</a>
        </li>
				<li>
            <a href="../tensorflow/VariableAggregation.htm">VariableAggregation</a>
        </li>
				<li>
            <a href="../tensorflow/VariableScope.htm">VariableScope</a>
        </li>
				<li>
            <a href="../tensorflow/VariableSynchronization.htm">VariableSynchronization</a>
        </li>
				<li>
            <a href="../tensorflow/variance_scaling_initializer.htm">variance_scaling_initializer</a>
        </li>
				<li>
            <a href="../tensorflow/VarLenFeature.htm">VarLenFeature</a>
        </li>
				<li>
            <a href="../tensorflow/WholeFileReader.htm">WholeFileReader</a>
        </li>
				<li>
            <a href="../tensorflow/zeros_initializer.htm">zeros_initializer</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> tf.math</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow</p>
		</header>
    <div class="sub-header">
		
		
			<h3 class="section">Methods</h3>
			<ul>
				<li><a href="../tensorflow/tf.math.htm#bessel_i0">bessel_i0</a></li>
				<li><a href="../tensorflow/tf.math.htm#bessel_i0_dyn">bessel_i0_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#bessel_i0e">bessel_i0e</a></li>
				<li><a href="../tensorflow/tf.math.htm#bessel_i0e_dyn">bessel_i0e_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#bessel_i1">bessel_i1</a></li>
				<li><a href="../tensorflow/tf.math.htm#bessel_i1_dyn">bessel_i1_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#bessel_i1e">bessel_i1e</a></li>
				<li><a href="../tensorflow/tf.math.htm#bessel_i1e_dyn">bessel_i1e_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#cumulative_logsumexp">cumulative_logsumexp</a></li>
				<li><a href="../tensorflow/tf.math.htm#cumulative_logsumexp_dyn">cumulative_logsumexp_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#multiply_no_nan">multiply_no_nan</a></li>
				<li><a href="../tensorflow/tf.math.htm#multiply_no_nan_dyn">multiply_no_nan_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#nextafter">nextafter</a></li>
				<li><a href="../tensorflow/tf.math.htm#nextafter_dyn">nextafter_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#polyval">polyval</a></li>
				<li><a href="../tensorflow/tf.math.htm#polyval_dyn">polyval_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#reciprocal_no_nan">reciprocal_no_nan</a></li>
				<li><a href="../tensorflow/tf.math.htm#reciprocal_no_nan_dyn">reciprocal_no_nan_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_euclidean_norm">reduce_euclidean_norm</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_euclidean_norm">reduce_euclidean_norm</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_euclidean_norm">reduce_euclidean_norm</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_euclidean_norm">reduce_euclidean_norm</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_euclidean_norm_dyn">reduce_euclidean_norm_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std">reduce_std</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std">reduce_std</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std">reduce_std</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std">reduce_std</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std">reduce_std</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std">reduce_std</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std">reduce_std</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std">reduce_std</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std">reduce_std</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std">reduce_std</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std_dyn">reduce_std_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance">reduce_variance</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance">reduce_variance</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance">reduce_variance</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance">reduce_variance</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance">reduce_variance</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance">reduce_variance</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance">reduce_variance</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance">reduce_variance</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance">reduce_variance</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance">reduce_variance</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance_dyn">reduce_variance_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#xdivy">xdivy</a></li>
				<li><a href="../tensorflow/tf.math.htm#xdivy_dyn">xdivy_dyn</a></li>
				<li><a href="../tensorflow/tf.math.htm#xlogy">xlogy</a></li>
				<li><a href="../tensorflow/tf.math.htm#xlogy_dyn">xlogy_dyn</a></li>
			</ul>
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow/tf.math.htm#bessel_i0_fn">bessel_i0_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#bessel_i0e_fn">bessel_i0e_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#bessel_i1_fn">bessel_i1_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#bessel_i1e_fn">bessel_i1e_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#cumulative_logsumexp_fn">cumulative_logsumexp_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#multiply_no_nan_fn">multiply_no_nan_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#nextafter_fn">nextafter_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#polyval_fn">polyval_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#reciprocal_no_nan_fn">reciprocal_no_nan_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_euclidean_norm_fn">reduce_euclidean_norm_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_std_fn">reduce_std_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#reduce_variance_fn">reduce_variance_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#xdivy_fn">xdivy_fn</a></li>
				<li><a href="../tensorflow/tf.math.htm#xlogy_fn">xlogy_fn</a></li>
			</ul>
		
	</div>
	
	
	<h3 class="section">Public static methods</h3>

	<div id="bessel_i0" class="method">
		<h4>
			<span title="System.object">object</span> <strong>bessel_i0</strong>(<span title="System.object">object</span> x, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the Bessel i0 function of `x` element-wise. <p></p> Modified Bessel function of order 0. <p></p> It is preferable to use the numerically stabler function `i0e(x)` instead. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor` or `SparseTensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` or `SparseTensor`, respectively. Has the same type as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bessel_i0_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>bessel_i0_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the Bessel i0 function of `x` element-wise. <p></p> Modified Bessel function of order 0. <p></p> It is preferable to use the numerically stabler function `i0e(x)` instead. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor` or `SparseTensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` or `SparseTensor`, respectively. Has the same type as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bessel_i0e" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bessel_i0e</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the Bessel i0e function of `x` element-wise. <p></p> Exponentially scaled modified Bessel function of order 0 defined as
`bessel_i0e(x) = exp(-abs(x)) bessel_i0(x)`. <p></p> This function is faster and numerically stabler than `bessel_i0(x)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `x`. <p></p> If `x` is a `SparseTensor`, returns
`SparseTensor(x.indices, tf.math.bessel_i0e(x.values,...), x.dense_shape)` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bessel_i0e_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>bessel_i0e_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the Bessel i0e function of `x` element-wise. <p></p> Exponentially scaled modified Bessel function of order 0 defined as
`bessel_i0e(x) = exp(-abs(x)) bessel_i0(x)`. <p></p> This function is faster and numerically stabler than `bessel_i0(x)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `x`. <p></p> If `x` is a `SparseTensor`, returns
`SparseTensor(x.indices, tf.math.bessel_i0e(x.values,...), x.dense_shape)` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bessel_i1" class="method">
		<h4>
			<span title="System.object">object</span> <strong>bessel_i1</strong>(<span title="System.object">object</span> x, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the Bessel i1 function of `x` element-wise. <p></p> Modified Bessel function of order 1. <p></p> It is preferable to use the numerically stabler function `i1e(x)` instead. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor` or `SparseTensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` or `SparseTensor`, respectively. Has the same type as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bessel_i1_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>bessel_i1_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the Bessel i1 function of `x` element-wise. <p></p> Modified Bessel function of order 1. <p></p> It is preferable to use the numerically stabler function `i1e(x)` instead. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor` or `SparseTensor`. Must be one of the following types: `half`,
`float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` or `SparseTensor`, respectively. Has the same type as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bessel_i1e" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>bessel_i1e</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the Bessel i1e function of `x` element-wise. <p></p> Exponentially scaled modified Bessel function of order 0 defined as
`bessel_i1e(x) = exp(-abs(x)) bessel_i1(x)`. <p></p> This function is faster and numerically stabler than `bessel_i1(x)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `x`. <p></p> If `x` is a `SparseTensor`, returns
`SparseTensor(x.indices, tf.math.bessel_i1e(x.values,...), x.dense_shape)` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="bessel_i1e_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>bessel_i1e_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the Bessel i1e function of `x` element-wise. <p></p> Exponentially scaled modified Bessel function of order 0 defined as
`bessel_i1e(x) = exp(-abs(x)) bessel_i1(x)`. <p></p> This function is faster and numerically stabler than `bessel_i1(x)`. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `x`. <p></p> If `x` is a `SparseTensor`, returns
`SparseTensor(x.indices, tf.math.bessel_i1e(x.values,...), x.dense_shape)` 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cumulative_logsumexp" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>cumulative_logsumexp</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> exclusive, <span title="System.bool">bool</span> reverse, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Compute the cumulative log-sum-exp of the tensor `x` along `axis`. <p></p> By default, this op performs an inclusive cumulative log-sum-exp, which means
that the first element of the input is identical to the first element of
the output. <p></p> This operation is significantly more numerically stable than the equivalent
tensorflow operation `tf.math.log(tf.math.cumsum(tf.math.exp(x)))`, although
computes the same result given infinite numerical precision. However, note
that in some cases, it may be less stable than <a href="..\..\tf\math\reduce_logsumexp.md"><code>tf.math.reduce_logsumexp</code></a>
for a given element, as it applies the "log-sum-exp trick" in a different
way. <p></p> More precisely, where <a href="..\..\tf\math\reduce_logsumexp.md"><code>tf.math.reduce_logsumexp</code></a> uses the following trick: <p></p> ```
log(sum(exp(x))) == log(sum(exp(x - max(x)))) + max(x)
``` <p></p> it cannot be directly used here as there is no fast way of applying it
to each prefix `x[:i]`. Instead, this function implements a prefix
scan using pairwise log-add-exp, which is a commutative and associative
(up to floating point precision) operator: <p></p> ```
log_add_exp(x, y) = log(exp(x) + exp(y))
= log(1 + exp(min(x, y) - max(x, y))) + max(x, y)
``` <p></p> However, reducing using the above operator leads to a different computation
tree (logs are taken repeatedly instead of only at the end), and the maximum
is only computed pairwise instead of over the entire prefix. In general, this
leads to a different and slightly less precise computation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float16`, `float32`,
`float64`. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>A `Tensor` of type `int32` or `int64` (default: 0). Must be in the
range `[-rank(x), rank(x))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> exclusive
						</dt>
						<dd>If `True`, perform exclusive cumulative log-sum-exp. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> reverse
						</dt>
						<dd>If `True`, performs the cumulative log-sum-exp in the reverse
direction. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same shape and type as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="cumulative_logsumexp_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>cumulative_logsumexp_dyn</strong>(<span title="System.object">object</span> x, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> exclusive, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> reverse, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Compute the cumulative log-sum-exp of the tensor `x` along `axis`. <p></p> By default, this op performs an inclusive cumulative log-sum-exp, which means
that the first element of the input is identical to the first element of
the output. <p></p> This operation is significantly more numerically stable than the equivalent
tensorflow operation `tf.math.log(tf.math.cumsum(tf.math.exp(x)))`, although
computes the same result given infinite numerical precision. However, note
that in some cases, it may be less stable than <a href="..\..\tf\math\reduce_logsumexp.md"><code>tf.math.reduce_logsumexp</code></a>
for a given element, as it applies the "log-sum-exp trick" in a different
way. <p></p> More precisely, where <a href="..\..\tf\math\reduce_logsumexp.md"><code>tf.math.reduce_logsumexp</code></a> uses the following trick: <p></p> ```
log(sum(exp(x))) == log(sum(exp(x - max(x)))) + max(x)
``` <p></p> it cannot be directly used here as there is no fast way of applying it
to each prefix `x[:i]`. Instead, this function implements a prefix
scan using pairwise log-add-exp, which is a commutative and associative
(up to floating point precision) operator: <p></p> ```
log_add_exp(x, y) = log(exp(x) + exp(y))
= log(1 + exp(min(x, y) - max(x, y))) + max(x, y)
``` <p></p> However, reducing using the above operator leads to a different computation
tree (logs are taken repeatedly instead of only at the end), and the maximum
is only computed pairwise instead of over the entire prefix. In general, this
leads to a different and slightly less precise computation. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float16`, `float32`,
`float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> axis
						</dt>
						<dd>A `Tensor` of type `int32` or `int64` (default: 0). Must be in the
range `[-rank(x), rank(x))`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> exclusive
						</dt>
						<dd>If `True`, perform exclusive cumulative log-sum-exp. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> reverse
						</dt>
						<dd>If `True`, performs the cumulative log-sum-exp in the reverse
direction. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same shape and type as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="multiply_no_nan" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>multiply_no_nan</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the product of x and y and returns 0 if the y is zero, even if x is NaN or infinite. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float32`, `float64`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>A `Tensor` whose dtype is compatible with `x`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The element-wise value of the x times y. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="multiply_no_nan_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>multiply_no_nan_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the product of x and y and returns 0 if the y is zero, even if x is NaN or infinite. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float32`, `float64`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>A `Tensor` whose dtype is compatible with `x`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The element-wise value of the x times y. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="nextafter" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>nextafter</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x1, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x2, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns the next representable value of `x1` in the direction of `x2`, element-wise. <p></p> This operation returns the same result as the C++ std::nextafter function. <p></p> It can also return a subnormal number. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x1
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float64`, `float32`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x2
						</dt>
						<dd>A `Tensor`. Must have the same type as `x1`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `x1`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="nextafter_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>nextafter_dyn</strong>(<span title="System.object">object</span> x1, <span title="System.object">object</span> x2, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Returns the next representable value of `x1` in the direction of `x2`, element-wise. <p></p> This operation returns the same result as the C++ std::nextafter function. <p></p> It can also return a subnormal number. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x1
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `float64`, `float32`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> x2
						</dt>
						<dd>A `Tensor`. Must have the same type as `x1`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `x1`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="polyval" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>polyval</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> coeffs, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the elementwise value of a polynomial. <p></p> If `x` is a tensor and `coeffs` is a list n + 1 tensors, this function returns
the value of the n-th order polynomial <p></p> p(x) = coeffs[n-1] + coeffs[n-2] * x +...  + coeffs[0] * x**(n-1) <p></p> evaluated using Horner's method, i.e. <p></p> p(x) = coeffs[n-1] + x * (coeffs[n-2] +... + x * (coeffs[1] +
x * coeffs[0])) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> coeffs
						</dt>
						<dd>A list of `Tensor` representing the coefficients of the polynomial. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor` representing the variable of the polynomial. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `tensor` of the shape as the expression p(x) with usual broadcasting rules
for element-wise addition and multiplication applied. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="polyval_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>polyval_dyn</strong>(<span title="System.object">object</span> coeffs, <span title="System.object">object</span> x, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the elementwise value of a polynomial. <p></p> If `x` is a tensor and `coeffs` is a list n + 1 tensors, this function returns
the value of the n-th order polynomial <p></p> p(x) = coeffs[n-1] + coeffs[n-2] * x +...  + coeffs[0] * x**(n-1) <p></p> evaluated using Horner's method, i.e. <p></p> p(x) = coeffs[n-1] + x * (coeffs[n-2] +... + x * (coeffs[1] +
x * coeffs[0])) 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> coeffs
						</dt>
						<dd>A list of `Tensor` representing the coefficients of the polynomial. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor` representing the variable of the polynomial. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `tensor` of the shape as the expression p(x) with usual broadcasting rules
for element-wise addition and multiplication applied. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="reciprocal_no_nan" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reciprocal_no_nan</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Performs a safe reciprocal operation, element wise. <p></p> If a particular element is zero, the reciprocal for that element is
also set to zero. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor` of type `float16`, `float32`, `float64` `complex64` or
`complex128`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor` of same shape and type as `x`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([2.0, 0.5, 0, 1], dtype=tf.float32)
            tf.math.reciprocal_no_nan(x)  # [ 0.5, 2, 0.0, 1.0 ] </pre>
</div>
		</div>
	</div>
	<div id="reciprocal_no_nan_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reciprocal_no_nan_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Performs a safe reciprocal operation, element wise. <p></p> If a particular element is zero, the reciprocal for that element is
also set to zero. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor` of type `float16`, `float32`, `float64` `complex64` or
`complex128`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor` of same shape and type as `x`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([2.0, 0.5, 0, 1], dtype=tf.float32)
            tf.math.reciprocal_no_nan(x)  # [ 0.5, 2, 0.0, 1.0 ] </pre>
</div>
		</div>
	</div>
	<div id="reduce_euclidean_norm" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_euclidean_norm</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the Euclidean norm of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1, 2, 3], [1, 1, 1]])
            tf.reduce_euclidean_norm(x)  # sqrt(17)
            tf.reduce_euclidean_norm(x, 0)  # [sqrt(2), sqrt(5), sqrt(10)]
            tf.reduce_euclidean_norm(x, 1)  # [sqrt(14), sqrt(3)]
            tf.reduce_euclidean_norm(x, 1, keepdims=True)  # [[sqrt(14)], [sqrt(3)]]
            tf.reduce_euclidean_norm(x, [0, 1])  # sqrt(17) </pre>
</div>
		</div>
	</div>
	<div id="reduce_euclidean_norm" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_euclidean_norm</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the Euclidean norm of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1, 2, 3], [1, 1, 1]])
            tf.reduce_euclidean_norm(x)  # sqrt(17)
            tf.reduce_euclidean_norm(x, 0)  # [sqrt(2), sqrt(5), sqrt(10)]
            tf.reduce_euclidean_norm(x, 1)  # [sqrt(14), sqrt(3)]
            tf.reduce_euclidean_norm(x, 1, keepdims=True)  # [[sqrt(14)], [sqrt(3)]]
            tf.reduce_euclidean_norm(x, [0, 1])  # sqrt(17) </pre>
</div>
		</div>
	</div>
	<div id="reduce_euclidean_norm" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_euclidean_norm</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the Euclidean norm of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1, 2, 3], [1, 1, 1]])
            tf.reduce_euclidean_norm(x)  # sqrt(17)
            tf.reduce_euclidean_norm(x, 0)  # [sqrt(2), sqrt(5), sqrt(10)]
            tf.reduce_euclidean_norm(x, 1)  # [sqrt(14), sqrt(3)]
            tf.reduce_euclidean_norm(x, 1, keepdims=True)  # [[sqrt(14)], [sqrt(3)]]
            tf.reduce_euclidean_norm(x, [0, 1])  # sqrt(17) </pre>
</div>
		</div>
	</div>
	<div id="reduce_euclidean_norm" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_euclidean_norm</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the Euclidean norm of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1, 2, 3], [1, 1, 1]])
            tf.reduce_euclidean_norm(x)  # sqrt(17)
            tf.reduce_euclidean_norm(x, 0)  # [sqrt(2), sqrt(5), sqrt(10)]
            tf.reduce_euclidean_norm(x, 1)  # [sqrt(14), sqrt(3)]
            tf.reduce_euclidean_norm(x, 1, keepdims=True)  # [[sqrt(14)], [sqrt(3)]]
            tf.reduce_euclidean_norm(x, [0, 1])  # sqrt(17) </pre>
</div>
		</div>
	</div>
	<div id="reduce_euclidean_norm_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_euclidean_norm_dyn</strong>(<span title="System.object">object</span> input_tensor, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the Euclidean norm of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1, 2, 3], [1, 1, 1]])
            tf.reduce_euclidean_norm(x)  # sqrt(17)
            tf.reduce_euclidean_norm(x, 0)  # [sqrt(2), sqrt(5), sqrt(10)]
            tf.reduce_euclidean_norm(x, 1)  # [sqrt(14), sqrt(3)]
            tf.reduce_euclidean_norm(x, 1, keepdims=True)  # [[sqrt(14)], [sqrt(3)]]
            tf.reduce_euclidean_norm(x, [0, 1])  # sqrt(17) </pre>
</div>
		</div>
	</div>
	<div id="reduce_std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_std" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_std_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_std_dyn</strong>(<span title="System.object">object</span> input_tensor, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the standard deviation of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_std(x)  # 1.1180339887498949
            tf.reduce_std(x, 0)  # [1., 1.]
            tf.reduce_std(x, 1)  # [0.5,  0.5] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_variance</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_variance</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_variance</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_variance</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_variance</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_variance</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_variance</strong>(<a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow.python.framework.composite_tensor/CompositeTensor.htm">CompositeTensor</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_variance</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> input_tensor, <span title="System.int">int</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_variance</strong>(<span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<PythonClassContainer>">IEnumerable&lt;PythonClassContainer&gt;</span></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>reduce_variance</strong>(<a href="../numpy/ndarray.htm">ndarray</a> input_tensor, <span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span> axis, <span title="System.bool">bool</span> keepdims, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../numpy/ndarray.htm">ndarray</a></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<int>">IEnumerable&lt;int&gt;</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="reduce_variance_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>reduce_variance_dyn</strong>(<span title="System.object">object</span> input_tensor, <span title="System.object">object</span> axis, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> keepdims, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Computes the variance of elements across dimensions of a tensor. <p></p> Reduces `input_tensor` along the dimensions given in `axis`.
Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
entry in `axis`. If `keepdims` is true, the reduced dimensions
are retained with length 1. <p></p> If `axis` is None, all dimensions are reduced, and a
tensor with a single element is returned. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> input_tensor
						</dt>
						<dd>The tensor to reduce. Should have numeric type. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> axis
						</dt>
						<dd>The dimensions to reduce. If `None` (the default), reduces all
dimensions. Must be in the range `[-rank(input_tensor),
rank(input_tensor))`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> keepdims
						</dt>
						<dd>If true, retains reduced dimensions with length 1. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name scope for the associated operations (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>The reduced tensor, of the same dtype as the input_tensor. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>x = tf.constant([[1., 2.], [3., 4.]])
            tf.reduce_variance(x)  # 1.25
            tf.reduce_variance(x, 0)  # [1., 1.]
            tf.reduce_variance(x, 1)  # [0.25,  0.25] </pre>
</div>
		</div>
	</div>
	<div id="xdivy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>xdivy</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns 0 if x == 0, and x / y otherwise, elementwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>A `Tensor`. Must have the same type as `x`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="xdivy_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>xdivy_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Returns 0 if x == 0, and x / y otherwise, elementwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>A `Tensor`. Must have the same type as `x`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="xlogy" class="method">
		<h4>
			<a href="../tensorflow/Tensor.htm">Tensor</a> <strong>xlogy</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> x, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> y, <span title="System.string">string</span> name)
		</h4>
		<div class="content">Returns 0 if x == 0, and x * log(y) otherwise, elementwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> y
						</dt>
						<dd>A `Tensor`. Must have the same type as `x`. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow/Tensor.htm">Tensor</a></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="xlogy_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>xlogy_dyn</strong>(<span title="System.object">object</span> x, <span title="System.object">object</span> y, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Returns 0 if x == 0, and x * log(y) otherwise, elementwise. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> x
						</dt>
						<dd>A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> y
						</dt>
						<dd>A `Tensor`. Must have the same type as `x`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>A name for the operation (optional). 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `Tensor`. Has the same type as `x`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	
	<h3 class="section">Public properties</h3>

	<div id="bessel_i0_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>bessel_i0_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="bessel_i0e_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>bessel_i0e_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="bessel_i1_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>bessel_i1_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="bessel_i1e_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>bessel_i1e_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="cumulative_logsumexp_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>cumulative_logsumexp_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="multiply_no_nan_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>multiply_no_nan_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="nextafter_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>nextafter_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="polyval_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>polyval_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="reciprocal_no_nan_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>reciprocal_no_nan_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="reduce_euclidean_norm_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>reduce_euclidean_norm_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="reduce_std_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>reduce_std_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="reduce_variance_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>reduce_variance_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="xdivy_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>xdivy_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="xlogy_fn" class="method">
		<h4>
			<a href="../LostTech.Gradient/PythonFunctionContainer.htm">PythonFunctionContainer</a> <strong>xlogy_fn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>