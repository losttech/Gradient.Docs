<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>DynamicLossScale - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow.train.experimental</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow.train.experimental/DynamicLossScale.htm" class="current">DynamicLossScale</a>
        </li>
				<li>
            <a href="../tensorflow.train.experimental/FixedLossScale.htm">FixedLossScale</a>
        </li>
				<li>
            <a href="../tensorflow.train.experimental/IDynamicLossScale.htm">IDynamicLossScale</a>
        </li>
				<li>
            <a href="../tensorflow.train.experimental/IFixedLossScale.htm">IFixedLossScale</a>
        </li>
				<li>
            <a href="../tensorflow.train.experimental/ILossScale.htm">ILossScale</a>
        </li>
				<li>
            <a href="../tensorflow.train.experimental/IMixedPrecisionLossScaleOptimizer.htm">IMixedPrecisionLossScaleOptimizer</a>
        </li>
				<li>
            <a href="../tensorflow.train.experimental/IPythonState.htm">IPythonState</a>
        </li>
				<li>
            <a href="../tensorflow.train.experimental/LossScale.htm">LossScale</a>
        </li>
				<li>
            <a href="../tensorflow.train.experimental/MixedPrecisionLossScaleOptimizer.htm">MixedPrecisionLossScaleOptimizer</a>
        </li>
				<li>
            <a href="../tensorflow.train.experimental/PythonState.htm">PythonState</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> DynamicLossScale</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow.train.experimental</p>
		<p><strong>Parent</strong> <a href="../tensorflow.train.experimental/LossScale.htm">LossScale</a></p>
		<p><strong>Interfaces</strong> <a href="../tensorflow.train.experimental/IDynamicLossScale.htm">IDynamicLossScale</a></p>
		</header>
    <div class="sub-header">
			<div id="summary">Loss scale that dynamically adjusts itself. <p></p> Dynamic loss scaling works by adjusting the loss scale as training progresses.
The goal is to keep the loss scale as high as possible without overflowing the
gradients. As long as the gradients do not overflow, raising the loss scale
never hurts. <p></p> The algorithm starts by setting the loss scale to an initial value. Every N
steps that the gradients are finite, the loss scale is increased by some
factor. However, if a NaN or Inf gradient is found, the gradients for that
step are not applied, and the loss scale is decreased by the factor. This
process tends to keep the loss scale as high as possible without gradients
overflowing. 
			</div>
		
		
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow.train.experimental/DynamicLossScale.htm#increment_period">increment_period</a></li>
				<li><a href="../tensorflow.train.experimental/DynamicLossScale.htm#increment_period_dyn">increment_period_dyn</a></li>
				<li><a href="../tensorflow.train.experimental/DynamicLossScale.htm#initial_loss_scale">initial_loss_scale</a></li>
				<li><a href="../tensorflow.train.experimental/DynamicLossScale.htm#initial_loss_scale_dyn">initial_loss_scale_dyn</a></li>
				<li><a href="../tensorflow.train.experimental/DynamicLossScale.htm#multiplier">multiplier</a></li>
				<li><a href="../tensorflow.train.experimental/DynamicLossScale.htm#multiplier_dyn">multiplier_dyn</a></li>
				<li><a href="../tensorflow.train.experimental/DynamicLossScale.htm#PythonObject">PythonObject</a></li>
			</ul>
		
	</div>
	
	
	
	<h3 class="section">Public properties</h3>

	<div id="increment_period" class="method">
		<h4>
			<span title="System.int">int</span> <strong>increment_period</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="increment_period_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>increment_period_dyn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="initial_loss_scale" class="method">
		<h4>
			<span title="System.double">double</span> <strong>initial_loss_scale</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="initial_loss_scale_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>initial_loss_scale_dyn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="multiplier" class="method">
		<h4>
			<span title="System.object">object</span> <strong>multiplier</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="multiplier_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>multiplier_dyn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="PythonObject" class="method">
		<h4>
			<span title="System.object">object</span> <strong>PythonObject</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>