<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>AdamParameters - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow.tpu.experimental</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow.tpu.experimental/AdagradParameters.htm">AdagradParameters</a>
        </li>
				<li>
            <a href="../tensorflow.tpu.experimental/AdamParameters.htm" class="current">AdamParameters</a>
        </li>
				<li>
            <a href="../tensorflow.tpu.experimental/DeviceAssignment.htm">DeviceAssignment</a>
        </li>
				<li>
            <a href="../tensorflow.tpu.experimental/IAdagradParameters.htm">IAdagradParameters</a>
        </li>
				<li>
            <a href="../tensorflow.tpu.experimental/IAdamParameters.htm">IAdamParameters</a>
        </li>
				<li>
            <a href="../tensorflow.tpu.experimental/IDeviceAssignment.htm">IDeviceAssignment</a>
        </li>
				<li>
            <a href="../tensorflow.tpu.experimental/IStochasticGradientDescentParameters.htm">IStochasticGradientDescentParameters</a>
        </li>
				<li>
            <a href="../tensorflow.tpu.experimental/StochasticGradientDescentParameters.htm">StochasticGradientDescentParameters</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> AdamParameters</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow.tpu.experimental</p>
		<p><strong>Parent</strong> <a href="../tensorflow.python.tpu.tpu_embedding/_OptimizationParameters.htm">_OptimizationParameters</a></p>
		<p><strong>Interfaces</strong> <a href="../tensorflow.tpu.experimental/IAdamParameters.htm">IAdamParameters</a></p>
		</header>
    <div class="sub-header">
			<div id="summary">Optimization parameters for Adam with TPU embeddings. <p></p> Pass this to <a href="..\..\..\tf\estimator\tpu\experimental\EmbeddingConfigSpec.md"><code>tf.estimator.tpu.experimental.EmbeddingConfigSpec</code></a> via the
`optimization_parameters` argument to set the optimizer and its parameters.
See the documentation for <a href="..\..\..\tf\estimator\tpu\experimental\EmbeddingConfigSpec.md"><code>tf.estimator.tpu.experimental.EmbeddingConfigSpec</code></a>
for more details. <p></p> ```
estimator = tf.estimator.tpu.TPUEstimator(
...
embedding_config_spec=tf.estimator.tpu.experimental.EmbeddingConfigSpec(
...
optimization_parameters=tf.tpu.experimental.AdamParameters(0.1),
...))
``` 
			</div>
		
		
			<h3 class="section">Methods</h3>
			<ul>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#NewDyn">NewDyn</a></li>
			</ul>
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#beta1">beta1</a></li>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#beta2">beta2</a></li>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#clip_weight_max">clip_weight_max</a></li>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#clip_weight_min">clip_weight_min</a></li>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#epsilon">epsilon</a></li>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#lazy_adam">lazy_adam</a></li>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#learning_rate">learning_rate</a></li>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#PythonObject">PythonObject</a></li>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#sum_inside_sqrt">sum_inside_sqrt</a></li>
				<li><a href="../tensorflow.tpu.experimental/AdamParameters.htm#use_gradient_accumulation">use_gradient_accumulation</a></li>
			</ul>
		
	</div>
	
	
	<h3 class="section">Public static methods</h3>

	<div id="NewDyn" class="method">
		<h4>
			<a href="../tensorflow.tpu.experimental/AdamParameters.htm">AdamParameters</a> <strong>NewDyn</strong>(<span title="System.object">object</span> learning_rate, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> beta1, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> beta2, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> epsilon, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> lazy_adam, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> sum_inside_sqrt, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> use_gradient_accumulation, <span title="System.object">object</span> clip_weight_min, <span title="System.object">object</span> clip_weight_max)
		</h4>
		<div class="content">Optimization parameters for Adam. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> learning_rate
						</dt>
						<dd>a floating point value. The learning rate. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> beta1
						</dt>
						<dd>A float value.
The exponential decay rate for the 1st moment estimates. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> beta2
						</dt>
						<dd>A float value.
The exponential decay rate for the 2nd moment estimates. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> epsilon
						</dt>
						<dd>A small constant for numerical stability. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> lazy_adam
						</dt>
						<dd>Use lazy Adam instead of Adam. Lazy Adam trains faster.
Please see `optimization_parameters.proto` for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> sum_inside_sqrt
						</dt>
						<dd>This improves training speed. Please see
`optimization_parameters.proto` for details. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> use_gradient_accumulation
						</dt>
						<dd>setting this to `False` makes embedding
gradients calculation less accurate but faster. Please see
`optimization_parameters.proto` for details.
for details. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> clip_weight_min
						</dt>
						<dd>the minimum value to clip by; None means -infinity. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> clip_weight_max
						</dt>
						<dd>the maximum value to clip by; None means +infinity. 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	
	<h3 class="section">Public properties</h3>

	<div id="beta1" class="method">
		<h4>
			<span title="System.double">double</span> <strong>beta1</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="beta2" class="method">
		<h4>
			<span title="System.double">double</span> <strong>beta2</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="clip_weight_max" class="method">
		<h4>
			<span title="System.object">object</span> <strong>clip_weight_max</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="clip_weight_min" class="method">
		<h4>
			<span title="System.object">object</span> <strong>clip_weight_min</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="epsilon" class="method">
		<h4>
			<span title="System.double">double</span> <strong>epsilon</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="lazy_adam" class="method">
		<h4>
			<span title="System.bool">bool</span> <strong>lazy_adam</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="learning_rate" class="method">
		<h4>
			<span title="System.double">double</span> <strong>learning_rate</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="PythonObject" class="method">
		<h4>
			<span title="System.object">object</span> <strong>PythonObject</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="sum_inside_sqrt" class="method">
		<h4>
			<span title="System.bool">bool</span> <strong>sum_inside_sqrt</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="use_gradient_accumulation" class="method">
		<h4>
			<span title="System.bool">bool</span> <strong>use_gradient_accumulation</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>