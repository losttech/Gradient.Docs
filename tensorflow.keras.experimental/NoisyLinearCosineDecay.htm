<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>NoisyLinearCosineDecay - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow.keras.experimental</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow.keras.experimental/CosineDecay.htm">CosineDecay</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/CosineDecayRestarts.htm">CosineDecayRestarts</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/ICosineDecay.htm">ICosineDecay</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/ICosineDecayRestarts.htm">ICosineDecayRestarts</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/ILinearCosineDecay.htm">ILinearCosineDecay</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/ILinearModel.htm">ILinearModel</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/INoisyLinearCosineDecay.htm">INoisyLinearCosineDecay</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/IPeepholeLSTMCell.htm">IPeepholeLSTMCell</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/ISequenceFeatures.htm">ISequenceFeatures</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/IWideDeepModel.htm">IWideDeepModel</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/LinearCosineDecay.htm">LinearCosineDecay</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/LinearModel.htm">LinearModel</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm" class="current">NoisyLinearCosineDecay</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/PeepholeLSTMCell.htm">PeepholeLSTMCell</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/SequenceFeatures.htm">SequenceFeatures</a>
        </li>
				<li>
            <a href="../tensorflow.keras.experimental/WideDeepModel.htm">WideDeepModel</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> NoisyLinearCosineDecay</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow.keras.experimental</p>
		<p><strong>Parent</strong> <a href="../tensorflow.keras.optimizers.schedules/LearningRateSchedule.htm">LearningRateSchedule</a></p>
		<p><strong>Interfaces</strong> <a href="../tensorflow.keras.experimental/INoisyLinearCosineDecay.htm">INoisyLinearCosineDecay</a></p>
		</header>
    <div class="sub-header">
			<div id="summary">A LearningRateSchedule that uses a noisy linear cosine decay schedule. 
			</div>
		
		
			<h3 class="section">Methods</h3>
			<ul>
				<li><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm#NewDyn">NewDyn</a></li>
			</ul>
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm#alpha">alpha</a></li>
				<li><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm#beta">beta</a></li>
				<li><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm#decay_steps">decay_steps</a></li>
				<li><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm#initial_learning_rate">initial_learning_rate</a></li>
				<li><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm#initial_variance">initial_variance</a></li>
				<li><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm#name">name</a></li>
				<li><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm#num_periods">num_periods</a></li>
				<li><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm#PythonObject">PythonObject</a></li>
				<li><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm#variance_decay">variance_decay</a></li>
			</ul>
		
	</div>
	
	
	<h3 class="section">Public static methods</h3>

	<div id="NewDyn" class="method">
		<h4>
			<a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm">NoisyLinearCosineDecay</a> <strong>NewDyn</strong>(<span title="System.object">object</span> initial_learning_rate, <span title="System.object">object</span> decay_steps, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> initial_variance, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> variance_decay, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> num_periods, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> alpha, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> beta, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Applies noisy linear cosine decay to the learning rate. <p></p> See [Bello et al., ICML2017] Neural Optimizer Search with RL.
https://arxiv.org/abs/1709.07417 <p></p> For the idea of warm starts here controlled by `num_periods`,
see [Loshchilov & Hutter, ICLR2016] SGDR: Stochastic Gradient Descent
with Warm Restarts. https://arxiv.org/abs/1608.03983 <p></p> Note that linear cosine decay is more aggressive than cosine decay and
larger initial learning rates can typically be used. <p></p> When training a model, it is often recommended to lower the learning rate as
the training progresses. This schedule applies a noisy linear cosine decay
function to an optimizer step, given a provided initial learning rate.
It requires a `step` value to compute the decayed learning rate. You can
just pass a TensorFlow variable that you increment at each training step. <p></p> The schedule a 1-arg callable that produces a decayed learning
rate when passed the current optimizer step. This can be useful for changing
the learning rate value across different invocations of optimizer functions.
It is computed as:
where eps_t is 0-centered gaussian noise with variance
initial_variance / (1 + global_step) ** variance_decay <p></p> Example usage:
You can pass this schedule directly into a <a href="..\..\..\tf\keras\optimizers\Optimizer.md"><code>tf.keras.optimizers.Optimizer</code></a>
as the learning rate. The learning rate schedule is also serializable and
deserializable using <a href="..\..\..\tf\keras\optimizers\schedules\serialize.md"><code>tf.keras.optimizers.schedules.serialize</code></a> and
<a href="..\..\..\tf\keras\optimizers\schedules\deserialize.md"><code>tf.keras.optimizers.schedules.deserialize</code></a>. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> initial_learning_rate
						</dt>
						<dd>A scalar `float32` or `float64` Tensor or a Python
number. The initial learning rate. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> decay_steps
						</dt>
						<dd>A scalar `int32` or `int64` `Tensor` or a Python number.
Number of steps to decay over. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> initial_variance
						</dt>
						<dd>initial variance for the noise. See computation above. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> variance_decay
						</dt>
						<dd>decay for the noise's variance. See computation above. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> num_periods
						</dt>
						<dd>Number of periods in the cosine part of the decay.
See computation above. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> alpha
						</dt>
						<dd>See computation above. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> beta
						</dt>
						<dd>See computation above. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>String.  Optional name of the operation.  Defaults to
'NoisyLinearCosineDecay'. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><a href="../tensorflow.keras.experimental/NoisyLinearCosineDecay.htm">NoisyLinearCosineDecay</a></code>
					</dt>
					<dd>A 1-arg callable learning rate schedule that takes the current optimizer
step and outputs the decayed learning rate, a scalar `Tensor` of the same
type as `initial_learning_rate`. 
					</dd>
				</dl>
			</div>
<div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>def decayed_learning_rate(step):
              step = min(step, decay_steps)
              linear_decay = (decay_steps - step) / decay_steps)
              cosine_decay = 0.5 * (
                  1 + cos(pi * 2 * num_periods * step / decay_steps))
              decayed = (alpha + linear_decay + eps_t) * cosine_decay + beta
              return initial_learning_rate * decayed </pre>
</div>
		</div>
	</div>
	
	<h3 class="section">Public properties</h3>

	<div id="alpha" class="method">
		<h4>
			<span title="System.double">double</span> <strong>alpha</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="beta" class="method">
		<h4>
			<span title="System.double">double</span> <strong>beta</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="decay_steps" class="method">
		<h4>
			<span title="System.int">int</span> <strong>decay_steps</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="initial_learning_rate" class="method">
		<h4>
			<span title="System.double">double</span> <strong>initial_learning_rate</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="initial_variance" class="method">
		<h4>
			<span title="System.double">double</span> <strong>initial_variance</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="name" class="method">
		<h4>
			<span title="System.object">object</span> <strong>name</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="num_periods" class="method">
		<h4>
			<span title="System.double">double</span> <strong>num_periods</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="PythonObject" class="method">
		<h4>
			<span title="System.object">object</span> <strong>PythonObject</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="variance_decay" class="method">
		<h4>
			<span title="System.double">double</span> <strong>variance_decay</strong> get; set;
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>