<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>BeamSearchDecoder - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow.contrib.seq2seq</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow.contrib.seq2seq/_BaseAttentionMechanism.htm">_BaseAttentionMechanism</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/_BaseAttentionMechanismV2.htm">_BaseAttentionMechanismV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/_BaseMonotonicAttentionMechanism.htm">_BaseMonotonicAttentionMechanism</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/_BaseMonotonicAttentionMechanismV2.htm">_BaseMonotonicAttentionMechanismV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/AttentionMechanism.htm">AttentionMechanism</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/AttentionWrapper.htm">AttentionWrapper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/AttentionWrapperState.htm">AttentionWrapperState</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BahdanauAttention.htm">BahdanauAttention</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BahdanauAttentionV2.htm">BahdanauAttentionV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BahdanauMonotonicAttention.htm">BahdanauMonotonicAttention</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BahdanauMonotonicAttentionV2.htm">BahdanauMonotonicAttentionV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BaseDecoder.htm">BaseDecoder</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BasicDecoder.htm">BasicDecoder</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BasicDecoderOutput.htm">BasicDecoderOutput</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BasicDecoderV2.htm">BasicDecoderV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm" class="current">BeamSearchDecoder</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BeamSearchDecoderMixin.htm">BeamSearchDecoderMixin</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BeamSearchDecoderOutput.htm">BeamSearchDecoderOutput</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BeamSearchDecoderState.htm">BeamSearchDecoderState</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/BeamSearchDecoderV2.htm">BeamSearchDecoderV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/CustomHelper.htm">CustomHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/Decoder.htm">Decoder</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/FinalBeamSearchDecoderOutput.htm">FinalBeamSearchDecoderOutput</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/GreedyEmbeddingHelper.htm">GreedyEmbeddingHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/Helper.htm">Helper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/I_BaseAttentionMechanism.htm">I_BaseAttentionMechanism</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/I_BaseAttentionMechanismV2.htm">I_BaseAttentionMechanismV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/I_BaseMonotonicAttentionMechanism.htm">I_BaseMonotonicAttentionMechanism</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/I_BaseMonotonicAttentionMechanismV2.htm">I_BaseMonotonicAttentionMechanismV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IAttentionMechanism.htm">IAttentionMechanism</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IAttentionWrapper.htm">IAttentionWrapper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IAttentionWrapperState.htm">IAttentionWrapperState</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBahdanauAttention.htm">IBahdanauAttention</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBahdanauAttentionV2.htm">IBahdanauAttentionV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBahdanauMonotonicAttention.htm">IBahdanauMonotonicAttention</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBahdanauMonotonicAttentionV2.htm">IBahdanauMonotonicAttentionV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBaseDecoder.htm">IBaseDecoder</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBasicDecoder.htm">IBasicDecoder</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBasicDecoderOutput.htm">IBasicDecoderOutput</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBasicDecoderV2.htm">IBasicDecoderV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBeamSearchDecoder.htm">IBeamSearchDecoder</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBeamSearchDecoderMixin.htm">IBeamSearchDecoderMixin</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBeamSearchDecoderOutput.htm">IBeamSearchDecoderOutput</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBeamSearchDecoderState.htm">IBeamSearchDecoderState</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IBeamSearchDecoderV2.htm">IBeamSearchDecoderV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/ICustomHelper.htm">ICustomHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IDecoder.htm">IDecoder</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IFinalBeamSearchDecoderOutput.htm">IFinalBeamSearchDecoderOutput</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IGreedyEmbeddingHelper.htm">IGreedyEmbeddingHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IHelper.htm">IHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IInferenceHelper.htm">IInferenceHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/ILuongAttention.htm">ILuongAttention</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/ILuongAttentionV2.htm">ILuongAttentionV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/ILuongMonotonicAttention.htm">ILuongMonotonicAttention</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/ILuongMonotonicAttentionV2.htm">ILuongMonotonicAttentionV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/InferenceHelper.htm">InferenceHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/ISampleEmbeddingHelper.htm">ISampleEmbeddingHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IScheduledEmbeddingTrainingHelper.htm">IScheduledEmbeddingTrainingHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/IScheduledOutputTrainingHelper.htm">IScheduledOutputTrainingHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/ISequenceLoss.htm">ISequenceLoss</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/ITrainingHelper.htm">ITrainingHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/LuongAttention.htm">LuongAttention</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/LuongAttentionV2.htm">LuongAttentionV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/LuongMonotonicAttention.htm">LuongMonotonicAttention</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/LuongMonotonicAttentionV2.htm">LuongMonotonicAttentionV2</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/SampleEmbeddingHelper.htm">SampleEmbeddingHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/ScheduledEmbeddingTrainingHelper.htm">ScheduledEmbeddingTrainingHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/ScheduledOutputTrainingHelper.htm">ScheduledOutputTrainingHelper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/seq2seq.htm">seq2seq</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/SequenceLoss.htm">SequenceLoss</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.seq2seq/TrainingHelper.htm">TrainingHelper</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> BeamSearchDecoder</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow.contrib.seq2seq</p>
		<p><strong>Parent</strong> <a href="../tensorflow.contrib.seq2seq/Decoder.htm">Decoder</a></p>
		<p><strong>Interfaces</strong> <a href="../tensorflow.contrib.seq2seq/IBeamSearchDecoder.htm">IBeamSearchDecoder</a></p>
		</header>
    <div class="sub-header">
			<div id="summary">BeamSearch sampling decoder. <p></p> **NOTE** If you are using the `BeamSearchDecoder` with a cell wrapped in
`AttentionWrapper`, then you must ensure that: <p></p> - The encoder output has been tiled to `beam_width` via
<a href="..\..\..\tf\contrib\seq2seq\tile_batch.md"><code>tf.contrib.seq2seq.tile_batch</code></a> (NOT <a href="..\..\..\tf\tile.md"><code>tf.tile</code></a>).
- The `batch_size` argument passed to the `zero_state` method of this
wrapper is equal to `true_batch_size * beam_width`.
- The initial state created with `zero_state` above contains a
`cell_state` value containing properly tiled final state from the
encoder. <p></p> An example: <p></p> ```
tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(
encoder_outputs, multiplier=beam_width)
tiled_encoder_final_state = tf.contrib.seq2seq.tile_batch(
encoder_final_state, multiplier=beam_width)
tiled_sequence_length = tf.contrib.seq2seq.tile_batch(
sequence_length, multiplier=beam_width)
attention_mechanism = MyFavoriteAttentionMechanism(
num_units=attention_depth,
memory=tiled_inputs,
memory_sequence_length=tiled_sequence_length)
attention_cell = AttentionWrapper(cell, attention_mechanism,...)
decoder_initial_state = attention_cell.zero_state(
dtype, batch_size=true_batch_size * beam_width)
decoder_initial_state = decoder_initial_state.clone(
cell_state=tiled_encoder_final_state)
``` <p></p> Meanwhile, with `AttentionWrapper`, coverage penalty is suggested to use
when computing scores (https://arxiv.org/pdf/1609.08144.pdf). It encourages
the decoder to cover all inputs. 
			</div>
		
		
			<h3 class="section">Methods</h3>
			<ul>
				<li><a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm#NewDyn">NewDyn</a></li>
			</ul>
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm#batch_size">batch_size</a></li>
				<li><a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm#batch_size_dyn">batch_size_dyn</a></li>
				<li><a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm#output_dtype">output_dtype</a></li>
				<li><a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm#output_dtype_dyn">output_dtype_dyn</a></li>
				<li><a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm#output_size">output_size</a></li>
				<li><a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm#output_size_dyn">output_size_dyn</a></li>
				<li><a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm#PythonObject">PythonObject</a></li>
				<li><a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm#tracks_own_finished">tracks_own_finished</a></li>
				<li><a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm#tracks_own_finished_dyn">tracks_own_finished_dyn</a></li>
			</ul>
		
	</div>
	
	
	<h3 class="section">Public static methods</h3>

	<div id="NewDyn" class="method">
		<h4>
			<a href="../tensorflow.contrib.seq2seq/BeamSearchDecoder.htm">BeamSearchDecoder</a> <strong>NewDyn</strong>(<span title="System.object">object</span> cell, <span title="System.object">object</span> embedding, <span title="System.object">object</span> start_tokens, <span title="System.object">object</span> end_token, <span title="System.object">object</span> initial_state, <span title="System.object">object</span> beam_width, <span title="System.object">object</span> output_layer, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> length_penalty_weight, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> coverage_penalty_weight, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> reorder_tensor_arrays)
		</h4>
		<div class="content">Initialize the BeamSearchDecoder. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> cell
						</dt>
						<dd>An `RNNCell` instance. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> embedding
						</dt>
						<dd>A callable that takes a vector tensor of `ids` (argmax ids),
or the `params` argument for `embedding_lookup`. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> start_tokens
						</dt>
						<dd>`int32` vector shaped `[batch_size]`, the start tokens. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> end_token
						</dt>
						<dd>`int32` scalar, the token that marks end of decoding. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_state
						</dt>
						<dd>A (possibly nested tuple of...) tensors and TensorArrays. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> beam_width
						</dt>
						<dd>Python integer, the number of beams. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> output_layer
						</dt>
						<dd>(Optional) An instance of <a href="..\..\..\tf\keras\layers\Layer.md"><code>tf.keras.layers.Layer</code></a>, i.e.,
<a href="..\..\..\tf\keras\layers\Dense.md"><code>tf.keras.layers.Dense</code></a>.  Optional layer to apply to the RNN output
prior to storing the result or sampling. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> length_penalty_weight
						</dt>
						<dd>Float weight to penalize length. Disabled with 0.0. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> coverage_penalty_weight
						</dt>
						<dd>Float weight to penalize the coverage of source
sentence. Disabled with 0.0. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> reorder_tensor_arrays
						</dt>
						<dd>If `True`, `TensorArray`s' elements within the cell
state will be reordered according to the beam search path. If the
`TensorArray` can be reordered, the stacked form will be returned.
Otherwise, the `TensorArray` will be returned as is. Set this flag to
`False` if the cell state contains `TensorArray`s that are not amenable
to reordering. 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	
	<h3 class="section">Public properties</h3>

	<div id="batch_size" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_size</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="batch_size_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_size_dyn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="output_dtype" class="method">
		<h4>
			<span title="System.object">object</span> <strong>output_dtype</strong> get; 
		</h4>
		<div class="content">A (possibly nested tuple of...) dtype[s]. 

		</div>
	</div>
	<div id="output_dtype_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>output_dtype_dyn</strong> get; 
		</h4>
		<div class="content">A (possibly nested tuple of...) dtype[s]. 

		</div>
	</div>
	<div id="output_size" class="method">
		<h4>
			<span title="System.object">object</span> <strong>output_size</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="output_size_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>output_size_dyn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="PythonObject" class="method">
		<h4>
			<span title="System.object">object</span> <strong>PythonObject</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="tracks_own_finished" class="method">
		<h4>
			<span title="System.bool">bool</span> <strong>tracks_own_finished</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="tracks_own_finished_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>tracks_own_finished_dyn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>