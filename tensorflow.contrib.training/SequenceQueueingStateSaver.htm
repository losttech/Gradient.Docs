<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>SequenceQueueingStateSaver - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow.contrib.training</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow.contrib.training/_SequenceInputWrapper.htm">_SequenceInputWrapper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/GreedyLoadBalancingStrategy.htm">GreedyLoadBalancingStrategy</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/HParams.htm">HParams</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/I_SequenceInputWrapper.htm">I_SequenceInputWrapper</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/IGreedyLoadBalancingStrategy.htm">IGreedyLoadBalancingStrategy</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/IHParams.htm">IHParams</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/INextQueuedSequenceBatch.htm">INextQueuedSequenceBatch</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/IRandomStrategy.htm">IRandomStrategy</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/ISequenceQueueingStateSaver.htm">ISequenceQueueingStateSaver</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/ISummaryAtEndHook.htm">ISummaryAtEndHook</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/ITuner.htm">ITuner</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/NextQueuedSequenceBatch.htm">NextQueuedSequenceBatch</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/RandomStrategy.htm">RandomStrategy</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm" class="current">SequenceQueueingStateSaver</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/SummaryAtEndHook.htm">SummaryAtEndHook</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/training.htm">training</a>
        </li>
				<li>
            <a href="../tensorflow.contrib.training/Tuner.htm">Tuner</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> SequenceQueueingStateSaver</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow.contrib.training</p>
		<p><strong>Parent</strong> <a href="../LostTech.Gradient/PythonObjectContainer.htm">PythonObjectContainer</a></p>
		<p><strong>Interfaces</strong> <a href="../tensorflow.contrib.training/ISequenceQueueingStateSaver.htm">ISequenceQueueingStateSaver</a></p>
		</header>
    <div class="sub-header">
			<div id="summary">SequenceQueueingStateSaver provides access to stateful values from input. <p></p> This class is meant to be used instead of, e.g., a `Queue`, for splitting
variable-length sequence inputs into segments of sequences with fixed length
and batching them into mini-batches.  It maintains contexts and state for a
sequence across the segments.  It can be used in conjunction with a
`QueueRunner` (see the example below). <p></p> The `SequenceQueueingStateSaver` (SQSS) accepts one example at a time via the
inputs `input_length`, `input_key`, `input_sequences` (a dict),
`input_context` (a dict), and `initial_states` (a dict).
The sequences, values in `input_sequences`, may have variable first dimension
(the `padded_length`), though this dimension must always be a multiple of
`num_unroll`.  All other dimensions must be fixed and accessible via
`get_shape` calls.  The length prior to padding can be recorded in
`input_length`.  The context values in `input_context` must all have fixed and
well defined dimensions.  The initial state values must all have fixed and
well defined dimensions. <p></p> The SQSS splits the sequences of an input example into segments of length
`num_unroll`.  Across examples minibatches of size `batch_size` are formed.
These minibatches contain a segment of the sequences, copy the context values,
and maintain state, length, and key information of the original input
examples.  In the first segment of an example the state is still the initial
state.  It can then be updated; and updated state values are accessible in
subsequent segments of the same example. After each segment
`batch.save_state()` must be called which is done by the state_saving_rnn.
Without this call, the dequeue op associated with the SQSS will not run.
Internally, SQSS has a queue for the input examples. Its `capacity` is
configurable.  If set smaller than `batch_size` then the dequeue op will block
indefinitely.  A small multiple of `batch_size` is a good rule of thumb to
prevent that queue from becoming a bottleneck and slowing down training.
If set too large (and note that it defaults to unbounded) memory consumption
goes up.  Moreover, when iterating over the same input examples multiple times
reusing the same `key` the `capacity` must be smaller than the number of
examples. <p></p> The prefetcher, which reads one unrolled, variable-length input sequence at
a time, is accessible via `prefetch_op`.  The underlying `Barrier` object
is accessible via `barrier`.  Processed minibatches, as well as
state read and write capabilities are accessible via `next_batch`.
Specifically, `next_batch` provides access to all of the minibatched
data, including the following, see `NextQueuedSequenceBatch` for details: <p></p> *  `total_length`, `length`, `insertion_index`, `key`, `next_key`,
*  `sequence` (the index each minibatch entry's time segment index),
*  `sequence_count` (the total time segment count for each minibatch entry),
*  `context` (a dict of the copied minibatched context values),
*  `sequences` (a dict of the split minibatched variable-length sequences),
*  `state` (to access the states of the current segments of these entries)
*  `save_state` (to save the states for the next segments of these entries) <p></p> Example usage:
**Note**: Usually the barrier is given to a QueueRunner as in the
examples above.  The QueueRunner will close the barrier if the prefetch_op
receives an OutOfRange Error from upstream input queues (i.e., reaches
the end of the input).  If the barrier is closed no further new examples
are added to the SQSS.  The underlying barrier might, however, still
contain further unroll-steps of examples that have not undergone all
iterations.  To gracefully finish all examples, the flag
`allow_small_batch` must be set to true, which causes the SQSS to issue
progressively smaller mini-batches with the remaining examples. <div class="example">
  <a href="javascript:void(0)">Show Example</a>
  <pre>batch_size = 32
            num_unroll = 20
            lstm_size = 8
            cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(num_units=lstm_size)
            initial_state_values = tf.zeros(cell.state_size, dtype=tf.float32) <p></p> raw_data = get_single_input_from_input_reader()
length, key, sequences, context = my_parser(raw_data)
assert "input" in sequences.keys()
assert "label" in context.keys()
initial_states = {"lstm_state": initial_state_value} <p></p> stateful_reader = tf.SequenceQueueingStateSaver(
    batch_size, num_unroll,
    length=length, input_key=key, input_sequences=sequences,
    input_context=context, initial_states=initial_states,
    capacity=batch_size*100) <p></p> batch = stateful_reader.next_batch
inputs = batch.sequences["input"]
context_label = batch.context["label"] <p></p> inputs_by_time = tf.split(value=inputs, num_or_size_splits=num_unroll, axis=1)
assert len(inputs_by_time) == num_unroll <p></p> lstm_output, _ = tf.contrib.rnn.static_state_saving_rnn(
  cell,
  inputs_by_time,
  state_saver=batch,
  state_name="lstm_state") <p></p> # Start a prefetcher in the background
sess = tf.compat.v1.Session()
num_threads = 3
queue_runner = tf.compat.v1.train.QueueRunner(
    stateful_reader, [stateful_reader.prefetch_op] * num_threads)
tf.compat.v1.train.add_queue_runner(queue_runner)
tf.compat.v1.train.start_queue_runners(sess=session) <p></p> while True:
  # Step through batches, perform training or inference...
  session.run([lstm_output]) </pre>
</div>
			</div>
		
		
			<h3 class="section">Methods</h3>
			<ul>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#NewDyn">NewDyn</a></li>
			</ul>
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#barrier">barrier</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#barrier_dyn">barrier_dyn</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#batch_size">batch_size</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#batch_size_dyn">batch_size_dyn</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#name">name</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#name_dyn">name_dyn</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#next_batch">next_batch</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#next_batch_dyn">next_batch_dyn</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#num_unroll">num_unroll</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#num_unroll_dyn">num_unroll_dyn</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#prefetch_op">prefetch_op</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#prefetch_op_dyn">prefetch_op_dyn</a></li>
				<li><a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm#PythonObject">PythonObject</a></li>
			</ul>
		
	</div>
	
	
	<h3 class="section">Public static methods</h3>

	<div id="NewDyn" class="method">
		<h4>
			<a href="../tensorflow.contrib.training/SequenceQueueingStateSaver.htm">SequenceQueueingStateSaver</a> <strong>NewDyn</strong>(<span title="System.object">object</span> batch_size, <span title="System.object">object</span> num_unroll, <span title="System.object">object</span> input_length, <span title="System.object">object</span> input_key, <span title="System.object">object</span> input_sequences, <span title="System.object">object</span> input_context, <span title="System.object">object</span> initial_states, <span title="System.object">object</span> capacity, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> allow_small_batch, <span title="System.object">object</span> name)
		</h4>
		<div class="content">Creates the SequenceQueueingStateSaver. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> batch_size
						</dt>
						<dd>int or int32 scalar `Tensor`, how large minibatches should
be when accessing the `state()` method and `context`, `sequences`, etc,
properties. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> num_unroll
						</dt>
						<dd>Python integer, how many time steps to unroll at a time.
The input sequences of length `k` are then split into `k / num_unroll`
many segments. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_length
						</dt>
						<dd>An int32 scalar `Tensor`, the length of the sequence prior
to padding.  This value may be at most `padded_length` for any given
input (see below for the definition of `padded_length`).
Batched and total lengths of the current iteration are made accessible
via the `length` and `total_length` properties.  The shape of
input_length (scalar) must be fully specified. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_key
						</dt>
						<dd>A string scalar `Tensor`, the **unique** key for the given
input.  This is used to keep track of the split minibatch elements
of this input.  Batched keys of the current iteration are made
accessible via the `key` property.  The shape of `input_key` (scalar)
must be fully specified. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_sequences
						</dt>
						<dd>A dict mapping string names to `Tensor` values.  The
values must all have matching first dimension, called `padded_length`.
The `SequenceQueueingStateSaver` will split these tensors along
this first dimension into minibatch elements of dimension
`num_unroll`. Batched and segmented sequences of the current iteration
are made accessible via the `sequences` property. <p></p> **Note**: `padded_length` may be dynamic, and may vary from input
to input, but must always be a multiple of `num_unroll`.  The remainder
of the shape (other than the first dimension) must be fully specified. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> input_context
						</dt>
						<dd>A dict mapping string names to `Tensor` values.  The values
are treated as "global" across all time splits of the given input,
and will be copied across for all minibatch elements accordingly.
Batched and copied context of the current iteration are made
accessible via the `context` property. <p></p> **Note**: All input_context values must have fully defined shapes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> initial_states
						</dt>
						<dd>A dict mapping string state names to multi-dimensional
values (e.g. constants or tensors).  This input defines the set of
states that will be kept track of during computing iterations, and
which can be accessed via the `state` and `save_state` methods. <p></p> **Note**: All initial_state values must have fully defined shapes. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> capacity
						</dt>
						<dd>The max capacity of the SQSS in number of examples. Needs to be
at least `batch_size`. Defaults to unbounded. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> allow_small_batch
						</dt>
						<dd>If true, the SQSS will return smaller batches when
there aren't enough input examples to fill a whole batch and the end of
the input has been reached (i.e., the underlying barrier has been
closed). 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>An op name string (optional). 
						</dd>
				</dl>
			</div>


		</div>
	</div>
	
	<h3 class="section">Public properties</h3>

	<div id="barrier" class="method">
		<h4>
			<span title="System.object">object</span> <strong>barrier</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="barrier_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>barrier_dyn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="batch_size" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_size</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="batch_size_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>batch_size_dyn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="name" class="method">
		<h4>
			<span title="System.object">object</span> <strong>name</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="name_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>name_dyn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="next_batch" class="method">
		<h4>
			<a href="../tensorflow.contrib.training/NextQueuedSequenceBatch.htm">NextQueuedSequenceBatch</a> <strong>next_batch</strong> get; 
		</h4>
		<div class="content">The `NextQueuedSequenceBatch` providing access to batched output data. <p></p> Also provides access to the `state` and `save_state` methods.
The first time this gets called, it additionally prepares barrier reads
and creates `NextQueuedSequenceBatch` / next_batch objects. Subsequent
calls simply return the previously created `next_batch`. <p></p> In order to access data in `next_batch` without blocking, the `prefetch_op`
must have been run at least `batch_size` times (ideally in a separate
thread, or launched via a `QueueRunner`). After processing a segment in
`next_batch()`, `batch.save_state()` must be called which is done by the
state_saving_rnn. Without this call, the dequeue op associated with the SQSS
will not run. 

		</div>
	</div>
	<div id="next_batch_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>next_batch_dyn</strong> get; 
		</h4>
		<div class="content">The `NextQueuedSequenceBatch` providing access to batched output data. <p></p> Also provides access to the `state` and `save_state` methods.
The first time this gets called, it additionally prepares barrier reads
and creates `NextQueuedSequenceBatch` / next_batch objects. Subsequent
calls simply return the previously created `next_batch`. <p></p> In order to access data in `next_batch` without blocking, the `prefetch_op`
must have been run at least `batch_size` times (ideally in a separate
thread, or launched via a `QueueRunner`). After processing a segment in
`next_batch()`, `batch.save_state()` must be called which is done by the
state_saving_rnn. Without this call, the dequeue op associated with the SQSS
will not run. 

		</div>
	</div>
	<div id="num_unroll" class="method">
		<h4>
			<span title="System.int">int</span> <strong>num_unroll</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="num_unroll_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>num_unroll_dyn</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	<div id="prefetch_op" class="method">
		<h4>
			<span title="System.object">object</span> <strong>prefetch_op</strong> get; 
		</h4>
		<div class="content">The op used to prefetch new data into the state saver. <p></p> Running it once enqueues one new input example into the state saver.
The first time this gets called, it additionally creates the prefetch_op.
Subsequent calls simply return the previously created `prefetch_op`. <p></p> It should be run in a separate thread via e.g. a `QueueRunner`. 

		</div>
	</div>
	<div id="prefetch_op_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>prefetch_op_dyn</strong> get; 
		</h4>
		<div class="content">The op used to prefetch new data into the state saver. <p></p> Running it once enqueues one new input example into the state saver.
The first time this gets called, it additionally creates the prefetch_op.
Subsequent calls simply return the previously created `prefetch_op`. <p></p> It should be run in a separate thread via e.g. a `QueueRunner`. 

		</div>
	</div>
	<div id="PythonObject" class="method">
		<h4>
			<span title="System.object">object</span> <strong>PythonObject</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>