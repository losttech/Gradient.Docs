<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
	<!--[if lt IE 9]>
	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
    <title>Benchmark - LostTech.TensorFlow Documentation</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"/>
    <link type="text/css" rel="stylesheet" href="../main.css"/>
    <script type="text/javascript" src="../js/jquery-1.3.2.min.js"></script>
    <script type="text/javascript" src="../js/jquery.scrollTo-min.js"></script>
    <script type="text/javascript" src="../js/navigation.js"></script>
    <script type="text/javascript" src="../js/example.js"></script>
  </head>
  <body>
  	<header><h1>LostTech.TensorFlow : API Documentation</h1>
	</header>

    <nav id="namespaces">
      <iframe src="../namespaces.htm"></iframe>
    </nav><nav id="types">
  <h2 class="fixed">Types in tensorflow.test</h2>
	<div class="scroll">
		<ul>
				<li>
            <a href="../tensorflow.test/Benchmark.htm" class="current">Benchmark</a>
        </li>
				<li>
            <a href="../tensorflow.test/IBenchmark.htm">IBenchmark</a>
        </li>
				<li>
            <a href="../tensorflow.test/IStubOutForTesting.htm">IStubOutForTesting</a>
        </li>
				<li>
            <a href="../tensorflow.test/ITestCase.htm">ITestCase</a>
        </li>
				<li>
            <a href="../tensorflow.test/StubOutForTesting.htm">StubOutForTesting</a>
        </li>
				<li>
            <a href="../tensorflow.test/TestCase.htm">TestCase</a>
        </li>
				<li>
            <a href="../tensorflow.test/TestCase._CheckedThread.htm">TestCase._CheckedThread</a>
        </li>
				<li>
            <a href="../tensorflow.test/TestCase.I_CheckedThread.htm">TestCase.I_CheckedThread</a>
        </li>
		</ul>
	</div>
</nav>
	<article>
    <header>
		<p class="class"><strong>Type</strong> Benchmark</p>
	</header>
	<section>
		<header>
		<p><strong>Namespace</strong> tensorflow.test</p>
		<p><strong>Parent</strong> <a href="../tensorflow.python.platform.benchmark/Benchmark.htm">Benchmark</a></p>
		<p><strong>Interfaces</strong> <a href="../tensorflow.test/IBenchmark.htm">IBenchmark</a></p>
		</header>
    <div class="sub-header">
			<div id="summary">Abstract class that provides helpers for TensorFlow benchmarks. 
			</div>
		
		
			<h3 class="section">Methods</h3>
			<ul>
				<li><a href="../tensorflow.test/Benchmark.htm#evaluate">evaluate</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#evaluate">evaluate</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#evaluate">evaluate</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#evaluate_dyn">evaluate_dyn</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#is_abstract_dyn``1">is_abstract_dyn&lt;TClass&gt;</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#is_abstract``1">is_abstract&lt;TClass&gt;</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#report_benchmark">report_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#report_benchmark">report_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#report_benchmark_dyn">report_benchmark_dyn</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark">run_op_benchmark</a></li>
				<li><a href="../tensorflow.test/Benchmark.htm#run_op_benchmark_dyn">run_op_benchmark_dyn</a></li>
			</ul>
		
			<h3 class="section">Properties</h3>
			<ul>
				<li><a href="../tensorflow.test/Benchmark.htm#PythonObject">PythonObject</a></li>
			</ul>
		
	</div>
	
	<h3 class="section">Public instance methods</h3>

	<div id="evaluate" class="method">
		<h4>
			<span title="System.object">object</span> <strong>evaluate</strong>(<a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a> tensors)
		</h4>
		<div class="content">Evaluates tensors and returns numpy values. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient/PythonClassContainer.htm">PythonClassContainer</a></code> tensors
						</dt>
						<dd>A Tensor or a nested list/tuple of Tensors. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>tensors numpy values. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="evaluate" class="method">
		<h4>
			<span title="System.object">object</span> <strong>evaluate</strong>(<a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> tensors)
		</h4>
		<div class="content">Evaluates tensors and returns numpy values. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> tensors
						</dt>
						<dd>A Tensor or a nested list/tuple of Tensors. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>tensors numpy values. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="evaluate" class="method">
		<h4>
			<span title="System.object">object</span> <strong>evaluate</strong>(<span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> tensors)
		</h4>
		<div class="content">Evaluates tensors and returns numpy values. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> tensors
						</dt>
						<dd>A Tensor or a nested list/tuple of Tensors. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>tensors numpy values. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="evaluate_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>evaluate_dyn</strong>(<span title="System.object">object</span> tensors)
		</h4>
		<div class="content">Evaluates tensors and returns numpy values. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> tensors
						</dt>
						<dd>A Tensor or a nested list/tuple of Tensors. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>tensors numpy values. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="report_benchmark" class="method">
		<h4>
			<span title="System.void">void</span> <strong>report_benchmark</strong>(<span title="System.Nullable<int>">Nullable&lt;int&gt;</span> iters, <span title="System.object">object</span> cpu_time, <span title="System.double">double</span> wall_time, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> throughput, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IEnumerable<IDictionary<string, object>>">IEnumerable&lt;IDictionary&lt;string, object&gt;&gt;</span> metrics)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="report_benchmark" class="method">
		<h4>
			<span title="System.void">void</span> <strong>report_benchmark</strong>(<span title="System.Nullable<int>">Nullable&lt;int&gt;</span> iters, <span title="System.object">object</span> cpu_time, <span title="System.Nullable<int>">Nullable&lt;int&gt;</span> wall_time, <span title="System.Nullable<double>">Nullable&lt;double&gt;</span> throughput, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IEnumerable<IDictionary<string, object>>">IEnumerable&lt;IDictionary&lt;string, object&gt;&gt;</span> metrics)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="report_benchmark_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>report_benchmark_dyn</strong>(<span title="System.object">object</span> iters, <span title="System.object">object</span> cpu_time, <span title="System.object">object</span> wall_time, <span title="System.object">object</span> throughput, <span title="System.object">object</span> extras, <span title="System.object">object</span> name, <span title="System.object">object</span> metrics)
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <span title="System.object">object</span> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <span title="System.object">object</span> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <span title="System.object">object</span> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.ValueTuple<int, int, object, object, object, int>">ValueTuple&lt;int, int, object, object, object, int&gt;</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object, object, int>">ValueTuple&lt;int, int, object, object, object, int&gt;</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.string">string</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.string">string</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object>">ValueTuple&lt;int, int, object&gt;</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.ValueTuple<int, int, object, object, object, int>">ValueTuple&lt;int, int, object, object, object, int&gt;</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IEnumerable<object>">IEnumerable&lt;object&gt;</span></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object, object, int>">ValueTuple&lt;int, int, object, object, object, int&gt;</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient.ManualWrappers/IGraphNodeBase.htm">IGraphNodeBase</a></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, object>">ValueTuple&lt;int, object&gt;</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark" class="method">
		<h4>
			<span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> <strong>run_op_benchmark</strong>(<a href="../tensorflow/Session.htm">Session</a> sess, <span title="System.object">object</span> op_or_tensor, <span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span> feed_dict, <span title="System.int">int</span> burn_iters, <span title="System.int">int</span> min_iters, <span title="System.bool">bool</span> store_trace, <span title="System.bool">bool</span> store_memory_usage, <span title="System.ValueTuple<int, int, object, object, object, int>">ValueTuple&lt;int, int, object, object, object, int&gt;</span> name, <span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span> extras, <span title="System.int">int</span> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><a href="../tensorflow/Session.htm">Session</a></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<object, object>">IDictionary&lt;object, object&gt;</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><span title="System.bool">bool</span></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.ValueTuple<int, int, object, object, object, int>">ValueTuple&lt;int, int, object, object, object, int&gt;</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><span title="System.int">int</span></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.Collections.Generic.IDictionary<string, object>">IDictionary&lt;string, object&gt;</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	<div id="run_op_benchmark_dyn" class="method">
		<h4>
			<span title="System.object">object</span> <strong>run_op_benchmark_dyn</strong>(<span title="System.object">object</span> sess, <span title="System.object">object</span> op_or_tensor, <span title="System.object">object</span> feed_dict, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> burn_iters, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> min_iters, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> store_trace, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> store_memory_usage, <span title="System.object">object</span> name, <span title="System.object">object</span> extras, <a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a> mbs)
		</h4>
		<div class="content">Run an op or tensor in the given session.  Report the results. 


			<div class="parameters">
				<h5>Parameters</h5>
				<dl>
						<dt>
							<code><span title="System.object">object</span></code> sess
						</dt>
						<dd>`Session` object to use for timing. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> op_or_tensor
						</dt>
						<dd>`Operation` or `Tensor` to benchmark. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> feed_dict
						</dt>
						<dd>A `dict` of values to feed for each op iteration (see the
`feed_dict` parameter of `Session.run`). 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> burn_iters
						</dt>
						<dd>Number of burn-in iterations to run. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> min_iters
						</dt>
						<dd>Minimum number of iterations to use for timing. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> store_trace
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration and
store the trace of iteration in returned extras.
The trace will be stored as a string in Google Chrome trace format
in the extras field "full_trace_chrome_format". Note that trace
will not be stored in test_log_pb2.TestResults proto. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> store_memory_usage
						</dt>
						<dd>Boolean, whether to run an extra untimed iteration,
calculate memory usage, and store that in extras fields. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> name
						</dt>
						<dd>(optional) Override the BenchmarkEntry name with `name`.
Otherwise it is inferred from the top-level method name. 
						</dd>
						<dt>
							<code><span title="System.object">object</span></code> extras
						</dt>
						<dd>(optional) Dict mapping string keys to additional benchmark info.
Values may be either floats or values that are convertible to strings. 
						</dd>
						<dt>
							<code><a href="../LostTech.Gradient/ImplicitContainer`1.htm">ImplicitContainer&lt;T&gt;</a></code> mbs
						</dt>
						<dd>(optional) The number of megabytes moved by this op, used to
calculate the ops throughput. 
						</dd>
				</dl>
			</div>

			<div class="return">

				<h5>Returns</h5>
				<dl>
					<dt>
						<code><span title="System.object">object</span></code>
					</dt>
					<dd>A `dict` containing the key-value pairs that were passed to
`report_benchmark`. If `store_trace` option is used, then
`full_chrome_trace_format` will be included in return dictionary even
though it is not passed to `report_benchmark` with `extras`. 
					</dd>
				</dl>
			</div>

		</div>
	</div>
	
	<h3 class="section">Public static methods</h3>

	<div id="is_abstract_dyn``1" class="method">
		<h4>
			<span title="System.object">object</span> <strong>is_abstract_dyn&lt;TClass&gt;</strong>()
		</h4>
		<div class="content">




		</div>
	</div>
	<div id="is_abstract``1" class="method">
		<h4>
			<span title="tensorflow.test.TClass">TClass</span> <strong>is_abstract&lt;TClass&gt;</strong>()
		</h4>
		<div class="content">




		</div>
	</div>
	
	<h3 class="section">Public properties</h3>

	<div id="PythonObject" class="method">
		<h4>
			<span title="System.object">object</span> <strong>PythonObject</strong> get; 
		</h4>
		<div class="content">

		</div>
	</div>
	</section>
	</article><footer>
	<span id="version">Built from v1.15.0.0 of LostTech.TensorFlow</span>
	<span id="docu-link">
		Generated by <a href="http://docu.jagregory.com">docu</a>
	</span>
</footer>
  </body>
</html>